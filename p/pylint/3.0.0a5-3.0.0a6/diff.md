# Comparing `tmp/pylint-3.0.0a5.tar.gz` & `tmp/pylint-3.0.0a6.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "pylint-3.0.0a5.tar", last modified: Thu Jun  2 07:33:24 2022, max compression
+gzip compressed data, was "pylint-3.0.0a6.tar", last modified: Sat Apr  1 16:06:02 2023, max compression
```

## Comparing `pylint-3.0.0a5.tar` & `pylint-3.0.0a6.tar`

### file list

```diff
@@ -1,202 +1,209 @@
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.858708 pylint-3.0.0a5/
--rw-r--r--   0 runner    (1001) docker     (121)    26633 2022-06-02 07:33:08.000000 pylint-3.0.0a5/CONTRIBUTORS.txt
--rw-r--r--   0 runner    (1001) docker     (121)    17984 2022-06-02 07:33:08.000000 pylint-3.0.0a5/LICENSE
--rw-r--r--   0 runner    (1001) docker     (121)      216 2022-06-02 07:33:08.000000 pylint-3.0.0a5/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (121)     9098 2022-06-02 07:33:24.862707 pylint-3.0.0a5/PKG-INFO
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.842707 pylint-3.0.0a5/pylint/
--rw-r--r--   0 runner    (1001) docker     (121)     3237 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      305 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/__main__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1342 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/__pkginfo__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.846707 pylint-3.0.0a5/pylint/checkers/
--rw-r--r--   0 runner    (1001) docker     (121)     4341 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3906 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/async.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.846707 pylint-3.0.0a5/pylint/checkers/base/
--rw-r--r--   0 runner    (1001) docker     (121)     1483 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    35406 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base/basic_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)    22033 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base/basic_error_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)    13407 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base/comparison_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)     7890 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base/docstring_checker.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.846707 pylint-3.0.0a5/pylint/checkers/base/name_checker/
--rw-r--r--   0 runner    (1001) docker     (121)      689 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base/name_checker/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    25158 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base/name_checker/checker.py
--rw-r--r--   0 runner    (1001) docker     (121)     5825 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base/name_checker/naming_style.py
--rw-r--r--   0 runner    (1001) docker     (121)      992 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base/pass_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)    10279 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/base_checker.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.850707 pylint-3.0.0a5/pylint/checkers/classes/
--rw-r--r--   0 runner    (1001) docker     (121)      644 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/classes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    83568 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/classes/class_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)    13843 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/classes/special_methods_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)     9258 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/deprecated.py
--rw-r--r--   0 runner    (1001) docker     (121)    22211 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/design_analysis.py
--rw-r--r--   0 runner    (1001) docker     (121)     7267 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/dunder_methods.py
--rw-r--r--   0 runner    (1001) docker     (121)     2014 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/ellipsis_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)    22530 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/exceptions.py
--rw-r--r--   0 runner    (1001) docker     (121)    27165 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/format.py
--rw-r--r--   0 runner    (1001) docker     (121)    37435 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/imports.py
--rw-r--r--   0 runner    (1001) docker     (121)     3462 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/lambda_expressions.py
--rw-r--r--   0 runner    (1001) docker     (121)    14730 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/logging.py
--rw-r--r--   0 runner    (1001) docker     (121)     1085 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/mapreduce_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)     6278 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/misc.py
--rw-r--r--   0 runner    (1001) docker     (121)     5771 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/modified_iterating_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)     4356 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/newstyle.py
--rw-r--r--   0 runner    (1001) docker     (121)     7581 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/non_ascii_names.py
--rw-r--r--   0 runner    (1001) docker     (121)     3900 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/raw_metrics.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.850707 pylint-3.0.0a5/pylint/checkers/refactoring/
--rw-r--r--   0 runner    (1001) docker     (121)     1114 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/refactoring/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     8828 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/refactoring/implicit_booleaness_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)     2818 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/refactoring/not_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)    17243 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/refactoring/recommendation_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)    84934 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/refactoring/refactoring_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)    33698 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/similar.py
--rw-r--r--   0 runner    (1001) docker     (121)    15709 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/spelling.py
--rw-r--r--   0 runner    (1001) docker     (121)    28040 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/stdlib.py
--rw-r--r--   0 runner    (1001) docker     (121)    40284 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/strings.py
--rw-r--r--   0 runner    (1001) docker     (121)     1942 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/threading_checker.py
--rw-r--r--   0 runner    (1001) docker     (121)    83549 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/typecheck.py
--rw-r--r--   0 runner    (1001) docker     (121)    18500 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/unicode.py
--rw-r--r--   0 runner    (1001) docker     (121)     2999 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/unsupported_version.py
--rw-r--r--   0 runner    (1001) docker     (121)    60654 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/utils.py
--rw-r--r--   0 runner    (1001) docker     (121)   112428 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/checkers/variables.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.850707 pylint-3.0.0a5/pylint/config/
--rw-r--r--   0 runner    (1001) docker     (121)     2380 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.850707 pylint-3.0.0a5/pylint/config/_pylint_config/
--rw-r--r--   0 runner    (1001) docker     (121)      494 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/_pylint_config/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1763 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/_pylint_config/generate_command.py
--rw-r--r--   0 runner    (1001) docker     (121)     1997 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/_pylint_config/help_message.py
--rw-r--r--   0 runner    (1001) docker     (121)      845 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/_pylint_config/main.py
--rw-r--r--   0 runner    (1001) docker     (121)     1603 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/_pylint_config/setup.py
--rw-r--r--   0 runner    (1001) docker     (121)     3445 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/_pylint_config/utils.py
--rw-r--r--   0 runner    (1001) docker     (121)    14171 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/argument.py
--rw-r--r--   0 runner    (1001) docker     (121)    30969 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/arguments_manager.py
--rw-r--r--   0 runner    (1001) docker     (121)     7954 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/arguments_provider.py
--rw-r--r--   0 runner    (1001) docker     (121)    13369 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/callback_actions.py
--rw-r--r--   0 runner    (1001) docker     (121)     4376 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/config_file_parser.py
--rw-r--r--   0 runner    (1001) docker     (121)     4230 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/config_initialization.py
--rw-r--r--   0 runner    (1001) docker     (121)     1399 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/configuration_mixin.py
--rw-r--r--   0 runner    (1001) docker     (121)     2931 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/deprecation_actions.py
--rw-r--r--   0 runner    (1001) docker     (121)      405 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/environment_variable.py
--rw-r--r--   0 runner    (1001) docker     (121)      816 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/exceptions.py
--rw-r--r--   0 runner    (1001) docker     (121)     3135 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/find_default_config_files.py
--rw-r--r--   0 runner    (1001) docker     (121)     2688 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/help_formatter.py
--rw-r--r--   0 runner    (1001) docker     (121)     7430 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/option.py
--rw-r--r--   0 runner    (1001) docker     (121)    13629 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/option_manager_mixin.py
--rw-r--r--   0 runner    (1001) docker     (121)     1992 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/option_parser.py
--rw-r--r--   0 runner    (1001) docker     (121)     4556 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/options_provider_mixin.py
--rw-r--r--   0 runner    (1001) docker     (121)     8364 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/config/utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     9796 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/constants.py
--rwxr-xr-x   0 runner    (1001) docker     (121)     6971 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/epylint.py
--rw-r--r--   0 runner    (1001) docker     (121)     1000 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/exceptions.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.854708 pylint-3.0.0a5/pylint/extensions/
--rw-r--r--   0 runner    (1001) docker     (121)      575 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    25097 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/_check_docs_utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     2262 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/bad_builtin.py
--rw-r--r--   0 runner    (1001) docker     (121)     2267 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/broad_try_clause.py
--rw-r--r--   0 runner    (1001) docker     (121)     2071 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/check_elif.py
--rw-r--r--   0 runner    (1001) docker     (121)    12066 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/code_style.py
--rw-r--r--   0 runner    (1001) docker     (121)     2478 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/comparetozero.py
--rw-r--r--   0 runner    (1001) docker     (121)     2344 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/comparison_placement.py
--rw-r--r--   0 runner    (1001) docker     (121)     2000 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/confusing_elif.py
--rw-r--r--   0 runner    (1001) docker     (121)     1701 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/consider_ternary_expression.py
--rw-r--r--   0 runner    (1001) docker     (121)    24647 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/docparams.py
--rw-r--r--   0 runner    (1001) docker     (121)     2868 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/docstyle.py
--rw-r--r--   0 runner    (1001) docker     (121)     1921 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/empty_comment.py
--rw-r--r--   0 runner    (1001) docker     (121)     2438 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/emptystring.py
--rw-r--r--   0 runner    (1001) docker     (121)     1456 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/eq_without_hash.py
--rw-r--r--   0 runner    (1001) docker     (121)     2893 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/for_any_all.py
--rw-r--r--   0 runner    (1001) docker     (121)     5977 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/mccabe.py
--rw-r--r--   0 runner    (1001) docker     (121)     3712 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/no_self_use.py
--rw-r--r--   0 runner    (1001) docker     (121)     3323 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/overlapping_exceptions.py
--rw-r--r--   0 runner    (1001) docker     (121)    11035 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/private_import.py
--rw-r--r--   0 runner    (1001) docker     (121)     3221 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/redefined_loop_name.py
--rw-r--r--   0 runner    (1001) docker     (121)     4000 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/redefined_variable_type.py
--rw-r--r--   0 runner    (1001) docker     (121)     1797 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/set_membership.py
--rw-r--r--   0 runner    (1001) docker     (121)    17453 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/typing.py
--rw-r--r--   0 runner    (1001) docker     (121)     1009 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/extensions/while_used.py
--rw-r--r--   0 runner    (1001) docker     (121)     7183 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/graph.py
--rw-r--r--   0 runner    (1001) docker     (121)     4028 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/interfaces.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.854708 pylint-3.0.0a5/pylint/lint/
--rw-r--r--   0 runner    (1001) docker     (121)     1298 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    20346 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/base_options.py
--rw-r--r--   0 runner    (1001) docker     (121)     2335 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/caching.py
--rw-r--r--   0 runner    (1001) docker     (121)     5982 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/expand_modules.py
--rw-r--r--   0 runner    (1001) docker     (121)    16993 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/message_state_handler.py
--rw-r--r--   0 runner    (1001) docker     (121)     6462 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/parallel.py
--rw-r--r--   0 runner    (1001) docker     (121)    47118 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/pylinter.py
--rw-r--r--   0 runner    (1001) docker     (121)     2945 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/report_functions.py
--rw-r--r--   0 runner    (1001) docker     (121)     8258 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/run.py
--rw-r--r--   0 runner    (1001) docker     (121)     3126 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/lint/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.854708 pylint-3.0.0a5/pylint/message/
--rw-r--r--   0 runner    (1001) docker     (121)      622 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/message/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2419 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/message/message.py
--rw-r--r--   0 runner    (1001) docker     (121)     4791 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/message/message_definition.py
--rw-r--r--   0 runner    (1001) docker     (121)     4936 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/message/message_definition_store.py
--rw-r--r--   0 runner    (1001) docker     (121)     5563 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/message/message_id_store.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.858708 pylint-3.0.0a5/pylint/pyreverse/
--rw-r--r--   0 runner    (1001) docker     (121)      274 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     8645 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/diadefslib.py
--rw-r--r--   0 runner    (1001) docker     (121)    10397 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/diagrams.py
--rw-r--r--   0 runner    (1001) docker     (121)     5562 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/dot_printer.py
--rw-r--r--   0 runner    (1001) docker     (121)    12384 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/inspector.py
--rw-r--r--   0 runner    (1001) docker     (121)     7321 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/main.py
--rw-r--r--   0 runner    (1001) docker     (121)     3457 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/mermaidjs_printer.py
--rw-r--r--   0 runner    (1001) docker     (121)     3516 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/plantuml_printer.py
--rw-r--r--   0 runner    (1001) docker     (121)     3702 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/printer.py
--rw-r--r--   0 runner    (1001) docker     (121)      900 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/printer_factory.py
--rw-r--r--   0 runner    (1001) docker     (121)     8145 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     8559 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/vcg_printer.py
--rw-r--r--   0 runner    (1001) docker     (121)     6336 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/pyreverse/writer.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.858708 pylint-3.0.0a5/pylint/reporters/
--rw-r--r--   0 runner    (1001) docker     (121)     1026 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3453 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/base_reporter.py
--rw-r--r--   0 runner    (1001) docker     (121)      725 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/collecting_reporter.py
--rw-r--r--   0 runner    (1001) docker     (121)     1588 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/json_reporter.py
--rw-r--r--   0 runner    (1001) docker     (121)     3655 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/multi_reporter.py
--rw-r--r--   0 runner    (1001) docker     (121)     3067 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/reports_handler_mix_in.py
--rw-r--r--   0 runner    (1001) docker     (121)    10598 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/text.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.858708 pylint-3.0.0a5/pylint/reporters/ureports/
--rw-r--r--   0 runner    (1001) docker     (121)      310 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/ureports/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3430 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/ureports/base_writer.py
--rw-r--r--   0 runner    (1001) docker     (121)     5245 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/ureports/nodes.py
--rw-r--r--   0 runner    (1001) docker     (121)     3606 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/reporters/ureports/text_writer.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.858708 pylint-3.0.0a5/pylint/testutils/
--rw-r--r--   0 runner    (1001) docker     (121)     1309 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1549 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/_run.py
--rw-r--r--   0 runner    (1001) docker     (121)     4301 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/checker_test_case.py
--rw-r--r--   0 runner    (1001) docker     (121)     6036 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/configuration_test.py
--rw-r--r--   0 runner    (1001) docker     (121)     1145 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/constants.py
--rw-r--r--   0 runner    (1001) docker     (121)     1252 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/decorator.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.858708 pylint-3.0.0a5/pylint/testutils/functional/
--rw-r--r--   0 runner    (1001) docker     (121)      790 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/functional/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2945 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/functional/find_functional_tests.py
--rw-r--r--   0 runner    (1001) docker     (121)     2143 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/functional/lint_module_output_update.py
--rw-r--r--   0 runner    (1001) docker     (121)     3711 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/functional/test_file.py
--rw-r--r--   0 runner    (1001) docker     (121)      617 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/functional_test_file.py
--rw-r--r--   0 runner    (1001) docker     (121)     2127 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/get_test_info.py
--rw-r--r--   0 runner    (1001) docker     (121)      685 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/global_test_linter.py
--rw-r--r--   0 runner    (1001) docker     (121)    12409 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/lint_module_test.py
--rw-r--r--   0 runner    (1001) docker     (121)     6512 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/output_line.py
--rw-r--r--   0 runner    (1001) docker     (121)     3953 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/primer.py
--rw-r--r--   0 runner    (1001) docker     (121)     3738 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/pyreverse.py
--rw-r--r--   0 runner    (1001) docker     (121)     2414 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/reporter_for_tests.py
--rw-r--r--   0 runner    (1001) docker     (121)      198 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/testing_pylintrc
--rw-r--r--   0 runner    (1001) docker     (121)      447 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/tokenize_str.py
--rw-r--r--   0 runner    (1001) docker     (121)     2834 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/unittest_linter.py
--rw-r--r--   0 runner    (1001) docker     (121)     1753 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/testutils/utils.py
--rw-r--r--   0 runner    (1001) docker     (121)     2858 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/typing.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.858708 pylint-3.0.0a5/pylint/utils/
--rw-r--r--   0 runner    (1001) docker     (121)     1382 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4213 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/utils/ast_walker.py
--rw-r--r--   0 runner    (1001) docker     (121)     3648 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/utils/docs.py
--rw-r--r--   0 runner    (1001) docker     (121)    10791 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/utils/file_state.py
--rw-r--r--   0 runner    (1001) docker     (121)    12337 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/utils/linterstats.py
--rw-r--r--   0 runner    (1001) docker     (121)     5053 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/utils/pragma_parser.py
--rw-r--r--   0 runner    (1001) docker     (121)    13109 2022-06-02 07:33:08.000000 pylint-3.0.0a5/pylint/utils/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-06-02 07:33:24.842707 pylint-3.0.0a5/pylint.egg-info/
--rw-r--r--   0 runner    (1001) docker     (121)     9098 2022-06-02 07:33:24.000000 pylint-3.0.0a5/pylint.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (121)     5960 2022-06-02 07:33:24.000000 pylint-3.0.0a5/pylint.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (121)        1 2022-06-02 07:33:24.000000 pylint-3.0.0a5/pylint.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (121)      178 2022-06-02 07:33:24.000000 pylint-3.0.0a5/pylint.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (121)      293 2022-06-02 07:33:24.000000 pylint-3.0.0a5/pylint.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (121)        7 2022-06-02 07:33:24.000000 pylint-3.0.0a5/pylint.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (121)     4029 2022-06-02 07:33:24.862707 pylint-3.0.0a5/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (121)       38 2022-06-02 07:33:08.000000 pylint-3.0.0a5/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.185055 pylint-3.0.0a6/
+-rw-r--r--   0 runner    (1001) docker     (123)    28931 2023-04-01 16:05:41.000000 pylint-3.0.0a6/CONTRIBUTORS.txt
+-rw-r--r--   0 runner    (1001) docker     (123)    17984 2023-04-01 16:05:41.000000 pylint-3.0.0a6/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (123)       19 2023-04-01 16:05:41.000000 pylint-3.0.0a6/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (123)    11562 2023-04-01 16:06:02.185055 pylint-3.0.0a6/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     9640 2023-04-01 16:05:41.000000 pylint-3.0.0a6/README.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.153054 pylint-3.0.0a6/pylint/
+-rw-r--r--   0 runner    (1001) docker     (123)     3100 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      315 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/__main__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1361 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/__pkginfo__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.161054 pylint-3.0.0a6/pylint/checkers/
+-rw-r--r--   0 runner    (1001) docker     (123)     4294 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3933 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/async.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2238 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/bad_chained_comparison.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.161054 pylint-3.0.0a6/pylint/checkers/base/
+-rw-r--r--   0 runner    (1001) docker     (123)     1578 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    40674 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base/basic_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22524 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base/basic_error_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13874 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base/comparison_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7925 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base/docstring_checker.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.161054 pylint-3.0.0a6/pylint/checkers/base/name_checker/
+-rw-r--r--   0 runner    (1001) docker     (123)      699 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base/name_checker/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27077 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base/name_checker/checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5891 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base/name_checker/naming_style.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1002 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base/pass_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9060 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/base_checker.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.165054 pylint-3.0.0a6/pylint/checkers/classes/
+-rw-r--r--   0 runner    (1001) docker     (123)      654 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/classes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    90151 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/classes/class_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15125 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/classes/special_methods_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9671 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/deprecated.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22149 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/design_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3528 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/dunder_methods.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2024 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/ellipsis_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26464 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27583 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/format.py
+-rw-r--r--   0 runner    (1001) docker     (123)    42188 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/imports.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3472 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/lambda_expressions.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15605 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/logging.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4744 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/method_args.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4997 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/misc.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7869 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/modified_iterating_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3730 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/nested_min_max.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4577 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/newstyle.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7156 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/non_ascii_names.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3910 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/raw_metrics.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.165054 pylint-3.0.0a6/pylint/checkers/refactoring/
+-rw-r--r--   0 runner    (1001) docker     (123)     1124 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/refactoring/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9409 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/refactoring/implicit_booleaness_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2828 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/refactoring/not_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18133 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/refactoring/recommendation_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)    97505 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/refactoring/refactoring_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)    34146 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/similar.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16566 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/spelling.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32038 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/stdlib.py
+-rw-r--r--   0 runner    (1001) docker     (123)    41257 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/strings.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1951 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/threading_checker.py
+-rw-r--r--   0 runner    (1001) docker     (123)    88571 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/typecheck.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18490 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/unicode.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3009 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/unsupported_version.py
+-rw-r--r--   0 runner    (1001) docker     (123)    74955 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)   128458 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/checkers/variables.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.165054 pylint-3.0.0a6/pylint/config/
+-rw-r--r--   0 runner    (1001) docker     (123)      387 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.169055 pylint-3.0.0a6/pylint/config/_pylint_config/
+-rw-r--r--   0 runner    (1001) docker     (123)      571 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/_pylint_config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1718 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/_pylint_config/generate_command.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2007 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/_pylint_config/help_message.py
+-rw-r--r--   0 runner    (1001) docker     (123)      855 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/_pylint_config/main.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1613 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/_pylint_config/setup.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3764 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/_pylint_config/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14913 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/argument.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14982 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/arguments_manager.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2392 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/arguments_provider.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14033 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/callback_actions.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4125 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/config_file_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5089 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/config_initialization.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2983 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/deprecation_actions.py
+-rw-r--r--   0 runner    (1001) docker     (123)      826 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3550 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/find_default_config_files.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2583 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/help_formatter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8774 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/config/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8123 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1726 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/exceptions.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.173055 pylint-3.0.0a6/pylint/extensions/
+-rw-r--r--   0 runner    (1001) docker     (123)      585 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26370 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/_check_docs_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2279 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/bad_builtin.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2312 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/broad_try_clause.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2149 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/check_elif.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12817 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/code_style.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3178 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/comparetozero.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2362 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/comparison_placement.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2048 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/confusing_elif.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3322 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/consider_refactoring_into_while_condition.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1708 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/consider_ternary_expression.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2121 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/dict_init_mutate.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25915 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/docparams.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2953 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/docstyle.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2396 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/dunder.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1965 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/empty_comment.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2982 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/emptystring.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1470 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/eq_without_hash.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5835 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/for_any_all.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4248 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/magic_value.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7066 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/mccabe.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3721 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/no_self_use.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3350 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/overlapping_exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11245 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/private_import.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3230 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/redefined_loop_name.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4105 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/redefined_variable_type.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1806 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/set_membership.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20400 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/typing.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1103 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/extensions/while_used.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7122 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/graph.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1135 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/interfaces.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.173055 pylint-3.0.0a6/pylint/lint/
+-rw-r--r--   0 runner    (1001) docker     (123)     1408 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21460 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/base_options.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2424 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/caching.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6627 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/expand_modules.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17411 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/message_state_handler.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6156 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/parallel.py
+-rw-r--r--   0 runner    (1001) docker     (123)    49415 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/pylinter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2955 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/report_functions.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8746 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/run.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3695 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/lint/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.177055 pylint-3.0.0a6/pylint/message/
+-rw-r--r--   0 runner    (1001) docker     (123)      632 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/message/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7654 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/message/_deleted_message_ids.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2165 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/message/message.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5019 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/message/message_definition.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5115 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/message/message_definition_store.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6457 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/message/message_id_store.py
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/py.typed
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.177055 pylint-3.0.0a6/pylint/pyreverse/
+-rw-r--r--   0 runner    (1001) docker     (123)      284 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8897 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/diadefslib.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10463 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/diagrams.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5956 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/dot_printer.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13362 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/inspector.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9203 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/main.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3400 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/mermaidjs_printer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3500 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/plantuml_printer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3686 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/printer.py
+-rw-r--r--   0 runner    (1001) docker     (123)      835 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/printer_factory.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8194 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5911 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/pyreverse/writer.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.177055 pylint-3.0.0a6/pylint/reporters/
+-rw-r--r--   0 runner    (1001) docker     (123)     1036 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2788 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/base_reporter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      735 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/collecting_reporter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3779 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/json_reporter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3771 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/multi_reporter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3077 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/reports_handler_mix_in.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8814 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/text.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.181055 pylint-3.0.0a6/pylint/reporters/ureports/
+-rw-r--r--   0 runner    (1001) docker     (123)      320 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/ureports/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3440 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/ureports/base_writer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5255 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/ureports/nodes.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3616 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/reporters/ureports/text_writer.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.181055 pylint-3.0.0a6/pylint/testutils/
+-rw-r--r--   0 runner    (1001) docker     (123)     1319 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.185055 pylint-3.0.0a6/pylint/testutils/_primer/
+-rw-r--r--   0 runner    (1001) docker     (123)      389 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/_primer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4758 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/_primer/package_to_lint.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4073 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/_primer/primer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1120 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/_primer/primer_command.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6432 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/_primer/primer_compare_command.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1957 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/_primer/primer_prepare_command.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4185 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/_primer/primer_run_command.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1431 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/_run.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3459 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/checker_test_case.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6046 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/configuration_test.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1155 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1262 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/decorator.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.185055 pylint-3.0.0a6/pylint/testutils/functional/
+-rw-r--r--   0 runner    (1001) docker     (123)      800 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/functional/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5196 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/functional/find_functional_tests.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2153 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/functional/lint_module_output_update.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3816 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/functional/test_file.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2137 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/get_test_info.py
+-rw-r--r--   0 runner    (1001) docker     (123)      695 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/global_test_linter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12847 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/lint_module_test.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4265 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/output_line.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4278 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/pyreverse.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2321 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/reporter_for_tests.py
+-rw-r--r--   0 runner    (1001) docker     (123)      198 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/testing_pylintrc
+-rw-r--r--   0 runner    (1001) docker     (123)      457 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/tokenize_str.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2805 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/unittest_linter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3143 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/testutils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3260 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/typing.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.185055 pylint-3.0.0a6/pylint/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)     1290 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4245 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/utils/ast_walker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3406 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/utils/docs.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9745 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/utils/file_state.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12564 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/utils/linterstats.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5064 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/utils/pragma_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11481 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pylint/utils/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-01 16:06:02.153054 pylint-3.0.0a6/pylint.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)    11562 2023-04-01 16:06:01.000000 pylint-3.0.0a6/pylint.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     6246 2023-04-01 16:06:02.000000 pylint-3.0.0a6/pylint.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-01 16:06:01.000000 pylint-3.0.0a6/pylint.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      149 2023-04-01 16:06:01.000000 pylint-3.0.0a6/pylint.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      341 2023-04-01 16:06:01.000000 pylint-3.0.0a6/pylint.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        7 2023-04-01 16:06:01.000000 pylint-3.0.0a6/pylint.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     5036 2023-04-01 16:05:42.000000 pylint-3.0.0a6/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (123)       94 2023-04-01 16:06:02.185055 pylint-3.0.0a6/setup.cfg
```

### Comparing `pylint-3.0.0a5/CONTRIBUTORS.txt` & `pylint-3.0.0a6/CONTRIBUTORS.txt`

 * *Files 4% similar despite different names*

```diff
@@ -9,26 +9,28 @@
 - Claudiu Popa <pcmanticore@gmail.com>
 - Sylvain Thnault <thenault@gmail.com> : main author / maintainer
 - Torsten Marek <shlomme@gmail.com>
 
 
 Maintainers
 -----------
-
 - Pierre Sassoulas <pierre.sassoulas@gmail.com>
 - Danil van Noord <13665637+DanielNoord@users.noreply.github.com>
 - Marc Mueller <30130371+cdce8p@users.noreply.github.com>
-- Hippo91 <guillaume.peillex@gmail.com>
 - Jacob Walls <jacobtylerwalls@gmail.com>
-- Matus Valo <matusvalo@users.noreply.github.com>
+- Hippo91 <guillaume.peillex@gmail.com>
+- Mark Byrne <31762852+mbyrnepr2@users.noreply.github.com>
 - Andreas Finkler <3929834+DudeNr33@users.noreply.github.com>
+- Matus Valo <matusvalo@users.noreply.github.com>
+- Dani Alcala <112832187+clavedeluna@users.noreply.github.com>
 - ukasz Rogalski <rogalski.91@gmail.com>
 - Ashley Whetter <ashley@awhetter.co.uk>
 - Bryce Guinta <bryce.paul.guinta@gmail.com>
 - Yu Shao, Pang <36848472+yushao2@users.noreply.github.com>
+- Nick Drozd <nicholasdrozd@gmail.com>: performance improvements to astroid
 - Dimitri Prybysh <dmand@yandex.ru>
   * multiple-imports, not-iterable, not-a-mapping, various patches.
 - Roy Williams <roy.williams.iii@gmail.com> (Lyft)
   * added check for implementing __eq__ without implementing __hash__,
   * Added Python 3 check for accessing Exception.message.
   * Added Python 3 check for calling encode/decode with invalid codecs.
   * Added Python 3 check for accessing sys.maxint.
@@ -47,15 +49,15 @@
 contributors:
 
 - Emile Anclin <emile.anclin@logilab.fr> (Logilab): python 3 support
 - Michal Nowikowski <godfryd@gmail.com>:
   * wrong-spelling-in-comment
   * wrong-spelling-in-docstring
   * parallel execution on multiple CPUs
-- Mark Byrne <31762852+mbyrnepr2@users.noreply.github.com>
+- Julthep Nandakwang <julthep@nandakwang.com>
 - Bruno Daniel <bruno.daniel@blue-yonder.com>: check_docs extension.
 - Sushobhit <31987769+sushobhit27@users.noreply.github.com> (sushobhit27)
   * Added new check 'comparison-with-itself'.
   * Added new check 'useless-import-alias'.
   * Added support of annotations in missing-type-doc and missing-return-type-doc.
   * Added new check 'comparison-with-callable'.
   * Removed six package dependency.
@@ -71,174 +73,197 @@
   * too-many-nested-blocks,
   * too-many-boolean-expressions
   * unneeded-not
   * wrong-import-order
   * ungrouped-imports,
   * wrong-import-position
   * redefined-variable-type
+- Harutaka Kawamura <hkawamura0130@gmail.com>
 - Alexandre Fayolle <alexandre.fayolle@logilab.fr> (Logilab): TkInter gui, documentation, debian support
-- Nick Drozd <nicholasdrozd@gmail.com>: performance improvements to astroid
+- Ville Skytt <ville.skytta@iki.fi>
 - Julien Cristau <julien.cristau@logilab.fr> (Logilab): python 3 support
 - Adrien Di Mascio <Adrien.DiMascio@logilab.fr>
-- Frank Harrison <frank@doublethefish.com> (doublethefish)
 - Moiss Lpez <moylop260@vauxoo.com> (Vauxoo):
   * Support for deprecated-modules in modules not installed,
   * Refactor wrong-import-order to integrate it with `isort` library
   * Add check too-complex with mccabe for cyclomatic complexity
   * Refactor wrong-import-position to skip try-import and nested cases
   * Add consider-merging-isinstance, superfluous-else-return
   * Fix consider-using-ternary for 'True and True and True or True' case
   * Add bad-docstring-quotes and docstring-first-line-empty
-- Ville Skytt <ville.skytta@iki.fi>
+  * Add missing-timeout
+- Frank Harrison <frank@doublethefish.com> (doublethefish)
 - Pierre-Yves David <pierre-yves.david@logilab.fr>
 - David Shea <dshea@redhat.com>: invalid sequence and slice index
 - Gunung P. Wibisono <55311527+gunungpw@users.noreply.github.com>
 - Derek Gustafson <degustaf@gmail.com>
 - Cezar Elnazli <cezar.elnazli2@gmail.com>: deprecated-method
 - Joseph Young <80432516+jpy-git@users.noreply.github.com> (jpy-git)
-- Nicolas Chauvat <nicolas.chauvat@logilab.fr>
 - Tim Martin <tim@asymptotic.co.uk>
+- Ollie <46904826+ollie-iterators@users.noreply.github.com>
+- Tushar Sadhwani <tushar.sadhwani000@gmail.com> (tusharsadhwani)
+- Nicolas Chauvat <nicolas.chauvat@logilab.fr>
+- orSolocate <38433858+orSolocate@users.noreply.github.com>
 - Radu Ciorba <radu@devrandom.ro>: not-context-manager and confusing-with-statement warnings.
 - Holger Peters <email@holger-peters.de>
 - Cosmin Poiean <cmin@ropython.org>: unichr-builtin and improvements to bad-open-mode.
 - Steven Myint <hg@stevenmyint.com>: duplicate-except.
 - Peter Kolbus <peter.kolbus@gmail.com> (Garmin)
 - Luigi Bertaco Cristofolini <lucristofolini@gmail.com> (luigibertaco)
 - Glenn Matthews <glenn@e-dad.net>:
   * autogenerated documentation for optional extensions,
   * bug fixes and enhancements for docparams (ne check_docs) extension
 - Vlad Temian <vladtemian@gmail.com>: redundant-unittest-assert and the JSON reporter.
-- Tushar Sadhwani <tushar.sadhwani000@gmail.com> (tusharsadhwani)
 - Julien Jehannet <julien.jehannet@logilab.fr>
 - Boris Feld <lothiraldan@gmail.com>
 - Anthony Sottile <asottile@umich.edu>
+- Zen Lee <53538590+zenlyj@users.noreply.github.com>
 - Pedro Algarvio <pedro@algarvio.me> (s0undt3ch)
 - Julien Palard <julien@palard.fr>
 - David Liu <david@cs.toronto.edu> (david-yz-liu)
 - Dan Goldsmith <djgoldsmith@googlemail.com>: support for msg-template in HTML reporter.
+- Buck Evan <buck.2019@gmail.com>
+- Robert Hofer <hofrob@protonmail.com>
 - Mariatta Wijaya <Mariatta@users.noreply.github.com>
   * Added new check `logging-fstring-interpolation`
   * Documentation typo fixes
 - Jakub Wilk <jwilk@jwilk.net>
 - Eli Fine <ejfine@gmail.com> (eli88fine): Fixed false positive duplicate code warning for lines with symbols only
 - Andrew Haigh <nelfin@gmail.com> (nelfin)
 - mile Crater <emile@crater.logilab.fr>
-- orSolocate <38433858+orSolocate@users.noreply.github.com>
 - Pavel Roskin <proski@gnu.org>
 - David Gilman <davidgilman1@gmail.com>
 -  <hira9603859504@gmail.com>
+- Yilei "Dolee" Yang <yileiyang@google.com>
 - Thomas Hisch <t.hisch@gmail.com>
 - Marianna Polatoglou <mpolatoglou@bloomberg.net>: minor contribution for wildcard import check
 - Manuel Vzquez Acosta <mva.led@gmail.com>
 - Luis Escobar <lescobar@vauxoo.com> (Vauxoo): Add bad-docstring-quotes and docstring-first-line-empty
+- Konstantina Saketou <56515303+ksaketou@users.noreply.github.com>
+- Konstantin <Github@pheanex.de>
 - Jim Robertson <jrobertson98atx@gmail.com>
+- Hugo van Kemenade <hugovk@users.noreply.github.com>
 - Ethan Leba <ethanleba5@gmail.com>
 - Enji Cooper <yaneurabeya@gmail.com>
+- Drum Ogilvie <me@daogilvie.com>
 - David Lindquist <dlindquist@google.com>: logging-format-interpolation warning.
-- Buck (Yelp) <buck@yelp.com>
+- Daniel Harding <dharding@gmail.com>
 - Anthony Truchet <anthony.truchet@logilab.fr>
 - Alexander Todorov <atodorov@otb.bg>:
   * added new error conditions to 'bad-super-call',
   * Added new check for incorrect len(SEQUENCE) usage,
   * Added new extension for comparison against empty string constants,
   * Added new extension which detects comparing integers to zero,
   * Added new useless-return checker,
   * Added new try-except-raise checker
 - To Bouvard <teobouvard@gmail.com>
 - Mihai Balint <balint.mihai@gmail.com>
 - Mark Bell <mark00bell@googlemail.com>
-- Konstantina Saketou <56515303+ksaketou@users.noreply.github.com>
-- Hugo van Kemenade <hugovk@users.noreply.github.com>
+- Levi Gruspe <mail.levig@gmail.com>
+- Jakub Kuczys <me@jacken.men>
 - Hornwitser <github@hornwitser.no>: fix import graph
 - Fureigh <rhys.fureigh@gsa.gov>
 - David Douard <david.douard@sdfa3.org>
 - Daniel Balparda <balparda@google.com> (Google): GPyLint maintainer (Google's pylint variant)
 - Bastien Vallet <bastien.vallet@gmail.com> (Djailla)
 - Aru Sahni <arusahni@gmail.com>: Git ignoring, regex-based ignores
 - Andreas Freimuth <andreas.freimuth@united-bits.de>: fix indentation checking with tabs
 - Alexandru Coman <fcoman@bitdefender.com>
 - jpkotta <jpkotta@gmail.com>
 - Takahide Nojima <nozzy123nozzy@gmail.com>
 - Taewon D. Kim <kimt33@mcmaster.ca>
+- Stavros Ntentos <133706+stdedos@users.noreply.github.com>
 - Sneaky Pete <sneakypete81@gmail.com>
 - Sergey B Kirpichev <skirpichev@gmail.com>
+- Sandro Tosi <sandro.tosi@gmail.com>: Debian packaging
 - Rene Zhang <rz99@cornell.edu>
+- Paul Lichtenberger <paul.lichtenberger.rgbg@gmail.com>
 - Or Bahari <or.ba402@gmail.com>
 - Mr. Senko <atodorov@mrsenko.com>
+- Mike Frysinger <vapier@gmail.com>
 - Martin von Gagern <gagern@google.com> (Google): Added 'raising-format-tuple' warning.
 - Martin Vielsmaier <martin@vielsmaier.net>
 - Martin Pool <mbp@google.com> (Google):
   * warnings for anomalous backslashes
   * symbolic names for messages (like 'unused')
   * etc.
 - Martin Bati <MartinBasti@users.noreply.github.com>
   * Added new check for shallow copy of os.environ
   * Added new check for useless `with threading.Lock():` statement
 - Marcus Nslund <naslundx@gmail.com> (naslundx)
+- Marco Pernigotti <7657251+mpernigo@users.noreply.github.com>
 - Marco Forte <fortemarco.irl@gmail.com>
+- James Addison <55152140+jayaddison@users.noreply.github.com>
 - Ionel Maries Cristian <contact@ionelmc.ro>
 - Gergely Kalmr <gergely.kalmar@logikal.jp>
-- Daniel Harding <dharding@gmail.com>
 - Damien Baty <damien.baty@polyconseil.fr>
 - Benjamin Drung <benjamin.drung@profitbricks.com>: contributing Debian Developer
 - Anubhav <35621759+anubh-v@users.noreply.github.com>
-- Antonio Quarta <sgheppy88@gmail.com> (sgheppy)
-- Andrew J. Simmons <anjsimmo@gmail.com> (anjsimmo)
+- Antonio Quarta <sgheppy88@gmail.com>
+- Andrew J. Simmons <anjsimmo@gmail.com>
+- Alexey Pelykh <alexey.pelykh@gmail.com>
 - wtracy <afishionado@gmail.com>
+- jessebrennan <jesse@jesse.computer>
 - chohner <mail@chohner.com>
 - Tiago Honorato <61059243+tiagohonorato@users.noreply.github.com>
 - Steven M. Vascellaro <svascellaro@gmail.com>
+- Robin Tweedie <70587124+robin-wayve@users.noreply.github.com>
 - Roberto Leinardi <leinardi@gmail.com>: PyCharm plugin maintainer
 - Ricardo Gemignani <ricardo.gemignani@gmail.com>
 - Pieter Engelbrecht <pengelbrecht@rems2.com>
 - Philipp Albrecht <flying-sheep@web.de> (pylbrecht)
 - Nicolas Dickreuter <dickreuter@gmail.com>
 - Nick Bastin <nick.bastin@gmail.com>
 - Nathaniel Manista <nathaniel@google.com>: suspicious lambda checking
-- Mike Frysinger <vapier@gmail.com>
 - Maksym Humetskyi <Humetsky@gmail.com> (mhumetskyi)
   * Fixed ignored empty functions by similarities checker with "ignore-signatures" option enabled
   * Ignore function decorators signatures as well by similarities checker with "ignore-signatures" option enabled
   * Ignore class methods and nested functions signatures as well by similarities checker with "ignore-signatures" option enabled
 - Lucas Cimon <lucas.cimon@gmail.com>
 - Kylian <development@goudcode.nl>
 - Konstantin Manna <Konstantin@Manna.uno>
-- Kai Mueller <15907922+kasium@users.noreply.github.com> (kasium)
+- Kai Mueller <15907922+kasium@users.noreply.github.com>
 - Joshua Cannon <joshdcannon@gmail.com>
 - John Leach <jfleach@jfleach.com>
 - James Morgensen <james.morgensen@gmail.com>: ignored-modules option applies to import errors.
 - Jaehoon Hwang <jaehoonhwang@users.noreply.github.com> (jaehoonhwang)
+- Huw Jones <huw@huwcbjones.co.uk>
+- Gideon <87426140+GideonBear@users.noreply.github.com>
 - Ganden Schaffner <gschaffner@pm.me>
-- Frost Ming <frostming@tencent.com> (frostming)
+- Frost Ming <frostming@tencent.com>
 - Federico Bond <federicobond@gmail.com>
 - Erik Wright <erik.wright@shopify.com>
 - Erik Eriksson <molobrakos@users.noreply.github.com>: Added overlapping-except error check.
 - Dan Hemberger <846186+hemberger@users.noreply.github.com>
 - Chris Rebert <code@rebertia.com>: unidiomatic-typecheck.
 - Aurelien Campeas <aurelien.campeas@logilab.fr>
 - Alexander Pervakov <frost.nzcr4@jagmort.com>
 - Alain Leufroy <alain.leufroy@logilab.fr>
+- Adam Williamson <awilliam@redhat.com>
 - xmo-odoo <xmo-odoo@users.noreply.github.com>
-- root@clnstor.am.local <root@clnstor.am.local>
+- tbennett0 <tbennett0@users.noreply.github.com>
 - omarandlorraine <64254276+omarandlorraine@users.noreply.github.com>
-- grizzly.nyo@gmail.com <grizzly.nyo@gmail.com>
 - craig-sh <craig-sh@users.noreply.github.com>
 - bernie gray <bfgray3@users.noreply.github.com>
-- Yilei "Dolee" Yang <yileiyang@google.com>
 - Wes Turner <westurner@google.com> (Google): added new check 'inconsistent-quotes'
 - Tyler Thieding <tyler@thieding.com>
 - Tobias Hernstig <30827238+thernstig@users.noreply.github.com>
 - Thomas Grainger <tagrain@gmail.com>
+- Smixi <sismixx@hotmail.fr>
 - Simu Toni <simutoni@gmail.com>
-- Sergei Lebedev <185856+superbobry@users.noreply.github.com> (superbobry)
+- Sergei Lebedev <185856+superbobry@users.noreply.github.com>
 - Scott Worley <scottworley@scottworley.com>
+- Saugat Pachhai <suagatchhetri@outlook.com>
+- Samuel FORESTIER <HorlogeSkynet@users.noreply.github.com>
 - Rmi Cardona <remi.cardona@polyconseil.fr>
+- Rogdham <contact@rogdham.net>
 - Raphael Gaschignard <raphael@makeleaps.com>
 - Ram Rachum <ram@rachum.com> (cool-RR)
 - Radostin Stoyanov <rst0git@users.noreply.github.com>
+- Peter Bittner <django@bittner.it>
 - Paul Renvois <PaulRenvoise@users.noreply.github.com>
 - PHeanEX <github@pheanex.de>
 - Omega Weapon <OmegaPhil+hg@gmail.com>
 - Nikolai Kristiansen <nikolaik@gmail.com>
 - Nick Pesce <nickpesce22@gmail.com>
 - Nathan Marrow <nmarrow@google.com>
 - Mikhail Fesenko <m.fesenko@corp.vk.com>
@@ -246,139 +271,152 @@
 - Matthew Beckers <17108752+mattlbeck@users.noreply.github.com> (mattlbeck)
 - Mark Roman Miller <mtmiller@users.noreply.github.com>: fix inline defs in too-many-statements
 - MalanB <malan.kmu@gmail.com>
 - Mads Kiilerich <mads@kiilerich.com>
 - Maarten ter Huurne <maarten@treewalker.org>
 - Lefteris Karapetsas <lefteris@refu.co>
 - LCD 47 <lcd047@gmail.com>
-- Justin Li <justinnhli@gmail.com> (justinnhli)
+- Justin Li <justinnhli@gmail.com>
 - John Kirkham <jakirkham@gmail.com>
 - Jens H. Nielsen <Jens.Nielsen@microsoft.com>
 - Ioana Tagirta <ioana.tagirta@gmail.com>: fix bad thread instantiation check
 - Ikraduya Edian <ikraduya@gmail.com>: Added new checks 'consider-using-generator' and 'use-a-generator'.
 - Hugues Bruant <hugues.bruant@affirm.com>
 - Harut <yes@harutune.name>
 - Grygorii Iermolenko <gyermolenko@gmail.com>
+- Grizzly Nyo <grizzly.nyo@gmail.com>
 - Gabriel R. Sezefredo <g@briel.dev>: Fixed "exception-escape" false positive with generators
 - Filipe Brandenburger <filbranden@google.com>
 - Fantix King <fantix@uchicago.edu> (UChicago)
+- Eric McDonald <221418+emcd@users.noreply.github.com>
 - Elias Dorneles <eliasdorneles@gmail.com>: minor adjust to config defaults and docs
 - Derek Harland <derek.harland@finq.co.nz>
 - David Pursehouse <david.pursehouse@gmail.com>
+- Dave Bunten <dave.bunten@cuanschutz.edu>
+- Daniel Mouritzen <dmrtzn@gmail.com>
 - Daniel Miller <millerdev@gmail.com>
+- Christoph Blessing <33834216+cblessing24@users.noreply.github.com>
 - Chris Murray <chris@chrismurray.scot>
 - Chris Lamb <chris@chris-lamb.co.uk>
 - Charles Hebert <charles.hebert@logilab.fr>
 - Carli Freudenberg <carli.freudenberg@energymeteo.de> (CarliJoy)
   * Fixed issue 5281, added Unicode checker
   * Improve non-ascii-name checker
-- Buck Golemon <workitharder@gmail.com>
+- Bruce Dawson <randomascii@users.noreply.github.com>
 - Brian Shaginaw <brian.shaginaw@warbyparker.com>: prevent error on exception check for functions
 - Benny Mueller <benny.mueller91@gmail.com>
 - Ben James <benjames1999@hotmail.co.uk>
 - Ben Green <benhgreen@icloud.com>
 - Batuhan Taskaya <batuhanosmantaskaya@gmail.com>
+- Alvaro Frias <alvarofriasgaray@gmail.com>
 - Alexander Kapshuna <kapsh@kap.sh>
 - Adam Parkin <pzelnip@users.noreply.github.com>
 -  <109224573@qq.com>
 - ukasz Sznuk <ls@rdprojekt.pl>
 - y2kbugger <y2kbugger@users.noreply.github.com>
 - vinnyrose <vinnyrose@users.noreply.github.com>
 - ttenhoeve-aa <ttenhoeve@appannie.com>
 - thinwybk <florian.k@mailbox.org>
 - syutbai <syutbai@gmail.com>
+- sur.la.route <17788706+christopherpickering@users.noreply.github.com>
 - sdet_liang <liangway@users.noreply.github.com>
-- pyves@crater.logilab.fr <pyves@crater.logilab.fr>
 - paschich <millen@gridium.com>
 - oittaa <8972248+oittaa@users.noreply.github.com>
 - nyabkun <75878387+nyabkun@users.noreply.github.com>
 - moxian <aleftmail@inbox.ru>
 - mar-chi-pan <mar.polatoglou@gmail.com>
-- ludal@logilab.fr <ludal@logilab.fr>
 - lrjball <50599110+lrjball@users.noreply.github.com>
 - laike9m <laike9m@users.noreply.github.com>
+- kriek <sylvain.ackermann@gmail.com>
 - jaydesl <35102795+jaydesl@users.noreply.github.com>
 - jab <jab@users.noreply.github.com>
 - glmdgrielson <32415403+glmdgrielson@users.noreply.github.com>
 - glegoux <gilles.legoux@gmail.com>
 - gaurikholkar <f2013002@goa.bits-pilani.ac.in>
 - flyingbot91 <flyingbot91@gmx.com>
+- fly <fly@users.noreply.github.com>
 - fahhem <fahhem>
 - fadedDexofan <fadedDexofan@gmail.com>
+- epenet <6771947+epenet@users.noreply.github.com>
 - danields <danields761@gmail.com>
 - cosven <cosven@users.noreply.github.com>
 - cordis-dev <darius@adroiti.com>
+- cherryblossom <31467609+cherryblossom000@users.noreply.github.com>
 - bluesheeptoken <louis.fruleux1@gmail.com>
 - anatoly techtonik <techtonik@gmail.com>
-- amdev@AMDEV-WS01.cisco.com <amdev@AMDEV-WS01.cisco.com>
 - agutole <toldo_carp@hotmail.com>
 - Zeckie <49095968+Zeckie@users.noreply.github.com>
 - Zeb Nicholls <zebedee.nicholls@climate-energy-college.org>
   * Made W9011 compatible with 'of' syntax in return types
 - Yuval Langer <yuvallanger@mail.tau.ac.il>
 - Yury Gribov <tetra2005@gmail.com>
 - Yuri Bochkarev <baltazar.bz@gmail.com>: Added epytext support to docparams extension.
 - Youngsoo Sung <ysung@bepro11.com>
-- Yory <39745367+yory8@users.noreply.github.com> (yory8)
+- Yory <39745367+yory8@users.noreply.github.com>
 - Yoichi Nakayama <yoichi.nakayama@gmail.com>
 - Yeting Li <liyt@ios.ac.cn> (yetingli)
 - Yannack <yannack@users.noreply.github.com>
 - Yann Dirson <ydirson@free.fr>
 - Yang Yang <y4n9squared@gmail.com>
 - Xi Shen <davidshen84@gmail.com>
 - Will Shanks <wsha@posteo.net>
 - Viorel tirbu <viorels@gmail.com>: intern-builtin warning.
+- VictorT <victor.taix@gmail.com>
 - Victor Jiajunsu <16359131+jiajunsu@users.noreply.github.com>
 - Trevor Bekolay <tbekolay@gmail.com>
   * Added --list-msgs-enabled command
 - Tomer Chachamu <tomer.chachamu@gmail.com>: simplifiable-if-expression
 - Tomasz Magulski <tomasz@magullab.io>
+- Tom <tsarantis@proton.me>
 - Tim Hatch <tim@timhatch.com>
 - Tim Gates <tim.gates@iress.com>
+- Thomas Benhamou <thomas@lightricks.com>
 - Tanvi Moharir <74228962+tanvimoharir@users.noreply.github.com>: Fix for invalid toml config
 - T.Rzepka <Tobias.Rzepka@gmail.com>
 - Svetoslav Neykov <svet@hyperscience.com>
 - Stphane Wirtel <stephane@wirtel.be>: nonlocal-without-binding
 - Stephen Longofono <8992396+SLongofono@users.noreply.github.com>
+- Stephane Odul <1504511+sodul@users.noreply.github.com>
 - Stanislav Levin <slev@altlinux.org>
 - Sorin Sbarnea <ssbarnea@redhat.com>
 - Slavfox <slavfoxman@gmail.com>
 - Skip Montanaro <skip@pobox.com>
+- Sigurd Spieckermann <2206639+sisp@users.noreply.github.com>
 - Shiv Venkatasubrahmanyam <shvenkat@users.noreply.github.com>
 - Sebastian Mller <mueller.seb@posteo.de>
-- Saugat Pachhai <suagatchhetri@outlook.com>
 - Sasha Bagan <pnlbagan@gmail.com>
 - Sardorbek Imomaliev <sardorbek.imomaliev@gmail.com>
 - Santiago Castro <bryant@montevideo.com.uy>
-- Sandro Tosi <sandro.tosi@gmail.com>: Debian packaging
 - Samuel Freilich <sfreilich@google.com> (sfreilich)
-- Samuel FORESTIER <HorlogeSkynet@users.noreply.github.com>
-- Sam Vermeiren <88253337+PaaEl@users.noreply.github.com> (PaaEl)
+- Sam Vermeiren <88253337+PaaEl@users.noreply.github.com>
 - Ryan McGuire <ryan@enigmacurry.com>
 - Ry4an Brase <ry4an-hg@ry4an.org>
 - Ruro <ruro.ruro@ya.ru>
 - Roman Ivanov <me@roivanov.com>
-- Robin Tweedie <70587124+robin-wayve@users.noreply.github.com>
 - Robert Schweizer <robert_schweizer@gmx.de>
 - Reverb Chu <reverbc@users.noreply.github.com>
 - Renat Galimov <renat2017@gmail.com>
 - Rebecca Turner <rbt@sent.as> (9999years)
 - Randall Leeds <randall@bleeds.info>
+- Ramon Saraiva <ramonsaraiva@gmail.com>
 - Ramiro Leal-Cavazos <ramiroleal050@gmail.com> (ramiro050): Fixed bug preventing pylint from working with Emacs tramp
+- R. N. West <98110034+rnwst@users.noreply.github.com>
 - Qwiddle13 <32040075+Qwiddle13@users.noreply.github.com>
 - Quentin Young <qlyoung@users.noreply.github.com>
+- Prajwal Borkar <sunnyborkar7777@gmail.com>
 - Petr Pulc <petrpulc@gmail.com>: require whitespace around annotations
 - Peter Dawyndt <Peter.Dawyndt@UGent.be>
-- Peter Bittner <django@bittner.it>
+- Peter Dave Hello <hsu@peterdavehello.org>
 - Peter Aronoff <peter@aronoff.org>
 - Paul Cochrane <paul@liekut.de>
 - Patrik <patrik.mrx@gmail.com>
 - Pascal Corpet <pcorpet@users.noreply.github.com>
 - Pablo Galindo Salgado <Pablogsal@gmail.com>
   * Fix false positive 'Non-iterable value' with async comprehensions.
+- Osher De Paz <odepaz@redhat.com>
 - Oisn Moran <OisinMoran@users.noreply.github.com>
 - Obscuron <Abscuron@gmail.com>
 - Noam Yorav-Raphael <noamraph@gmail.com>
 - Nir Soffer <nirsof@gmail.com>
 - Niko Wenselowski <niko@nerdno.de>
 - Nikita Sobolev <mail@sobolevn.me>
 - Nick Smith <clickthisnick@users.noreply.github.com>
@@ -391,140 +429,156 @@
 - Mike Bryant <leachim@leachim.info>
 - Michka Popoff <michkapopoff@gmail.com>
 - Michal Vasilek <michal@vasilek.cz>
 - Michael Scott Cuthbert <cuthbert@mit.edu>
 - Michael Kefeder <oss@multiwave.ch>
 - Michael Hudson-Doyle <michael.hudson@canonical.com>
 - Michael Giuffrida <mgiuffrida@users.noreply.github.com>
-- Melvin Hazeleger <31448155+melvio@users.noreply.github.com> (melvio)
+- Melvin Hazeleger <31448155+melvio@users.noreply.github.com>
 - Matj Grabovsk <mgrabovs@redhat.com>
 - Matthijs Blom <19817960+MatthijsBlom@users.noreply.github.com>
 - Matej Maruk <marusak.matej@gmail.com>
 - Markus Siebenhaar <41283549+siehar@users.noreply.github.com>
 - Marco Edward Gorelli <marcogorelli@protonmail.com>: Documented Jupyter integration
 - Marcin Kurczewski <rr-@sakuya.pl> (rr-)
 - Maik Rder <maikroeder@gmail.com>
+- Lumr 'Frenzy' Balhar <frenzy.madness@gmail.com>
+- Ludovic Aubry <ludal@logilab.fr>
 - Louis Sautier <sautier.louis@gmail.com>
-- Lorena Buciu <46202743+lorena-b@users.noreply.github.com> (lorena-b)
-- Logan Miller <14319179+komodo472@users.noreply.github.com> (komodo472)
+- Lorena Buciu <46202743+lorena-b@users.noreply.github.com>
+- Logan Miller <14319179+komodo472@users.noreply.github.com>
 - Kri Tristan Helgason <kthelgason@gmail.com>
 - Kurian Benoy <70306694+kurianbenoy-aot@users.noreply.github.com>
 - Krzysztof Czapla <k.czapla68@gmail.com>
 - Kraig Brockschmidt <kraigbr@msn.com>
 - Kound <norman.freudenberg@posteo.de>
 - KotlinIsland <65446343+KotlinIsland@users.noreply.github.com>
 - Kosarchuk Sergey <sergeykosarchuk@gmail.com>
 - Konrad Weihmann <46938494+priv-kweihmann@users.noreply.github.com>
 - Kian Meng, Ang <kianmeng.ang@gmail.com>
 - Kevin Phillips <thefriendlycoder@gmail.com>
 - Kevin Jing Qiu <kevin.jing.qiu@gmail.com>
 - Kayran Schmidt <59456929+yumasheta@users.noreply.github.com>
+- Karthik Nadig <kanadig@microsoft.com>
 - Jrgen Hermann <jh@web.de>
-- Jrome Perrin <perrinjerome@gmail.com> (perrinjerome)
+- Jrome Perrin <perrinjerome@gmail.com>
 - Josselin Feist <josselin@trailofbits.com>
 - Jonathan Kotta <KottaJonathan@JohnDeere.com>
 - John Paraskevopoulos <io.paraskev@gmail.com>: add 'differing-param-doc' and 'differing-type-doc'
 - John McGehee <jmcgehee@altera.com>
 - John Gabriele <jgabriele@fastmail.fm>
 - John Belmonte <john@neggie.net>
 - Joffrey Mander <joffrey.mander+pro@gmail.com>
-- Jochen Preusche <iilei@users.noreply.github.com> (iilei)
-- Jeroen Seegers <jeroenseegers@users.noreply.github.com> (jeroenseegers)
+- Jochen Preusche <iilei@users.noreply.github.com>
+- Jeroen Seegers <jeroenseegers@users.noreply.github.com>:
   * Fixed `toml` dependency issue
-- Jeremy Fleischman <jeremyfleischman@gmail.com> (jfly)
+- Jeremy Fleischman <jeremyfleischman@gmail.com>
 - Jason Owen <jason.a.owen@gmail.com>
 - Jared Garst <cultofjared@gmail.com>
 - Jared Deckard <jared.deckard@gmail.com>
 - Janne Rnkk <jannero@users.noreply.github.com>
-- James Sinclair <james@nurfherder.com> (irgeek)
+- James Sinclair <james@nurfherder.com>
 - James M. Allen <james.m.allen@gmail.com>
 - James Lingard <jchl@aristanetworks.com>
 - James Broadhead <jamesbroadhead@gmail.com>
+- Jakub Kulk <Kulikjak@gmail.com>
 - Jakob Normark <jakobnormark@gmail.com>
-- Jake Lishman <jake@binhbar.com> (jakelishman)
+- Jake Lishman <jake@binhbar.com>
 - Jacques Kvam <jwkvam@gmail.com>
 - Jace Browning <jacebrowning@gmail.com>: updated default report format with clickable paths
 - JT Olds <jtolds@xnet5.com>
-- Huw Jones <huw@huwcbjones.co.uk> (huwcbjones)
-- Hayden Richards <62866982+SupImDos@users.noreply.github.com> (SupImDos)
+- Hayden Richards <62866982+SupImDos@users.noreply.github.com>
   * Fixed "no-self-use" for async methods
   * Fixed "docparams" extension for async functions and methods
-- Harshil <37377066+harshil21@users.noreply.github.com> (harshil21)
+- Harshil <37377066+harshil21@users.noreply.github.com>
 - Harry <harrymcwinters@gmail.com>
+- Grgoire <96051754+gregoire-mullvad@users.noreply.github.com>
 - Grant Welch <gwelch925+github@gmail.com>
 - Giuseppe Valente <gvalente@arista.com>
 - Gary Tyler McLeod <mail@garytyler.com>
-- Felix von Drigalski <FvDrigalski@gmail.com> (felixvd)
+- Felix von Drigalski <FvDrigalski@gmail.com>
 - Fabrice Douchant <Fabrice.Douchant@logilab.fr>
 - Fabio Natali <me@fabionatali.com>
 - Fabian Damken <fdamken+github@frisp.org>
 - Eric Froemling <ericfroemling@gmail.com>
 - Emmanuel Chaudron <manu.chaud@hotmail.fr>
 - Elizabeth Bott <52465744+elizabethbott@users.noreply.github.com>
-- Eisuke Kawashima <e-kwsm@users.noreply.github.com> (e-kwsm)
+- Eisuke Kawashima <e-kwsm@users.noreply.github.com>
 - Edward K. Ream <edreamleo@gmail.com>
 - Edgemaster <grand.edgemaster@gmail.com>
+- Eddie Darling <eddie.darling@genapsys.com>
 - Drew Risinger <drewrisinger@users.noreply.github.com>
 - Dr. Nick <das-intensity@users.noreply.github.com>
 - Don Jayamanne <don.jayamanne@yahoo.com>
 - Dmytro Kyrychuk <dmytro.kyrychuck@gmail.com>
+- DetachHead <57028336+DetachHead@users.noreply.github.com>
 - Denis Laxalde <denis.laxalde@logilab.fr>
+- David Lawson <dmrlawson@gmail.com>
 - David Cain <davidjosephcain@gmail.com>
 - Danny Hermes <daniel.j.hermes@gmail.com>
 - Daniele Procida <daniele@vurt.org>
 - Daniela Plascencia <daplascen@gmail.com>
+- Daniel Werner <daniel.werner@scalableminds.com>
 - Daniel R. Neal <dan.r.neal@gmail.com> (danrneal)
 - Daniel Draper <Germandrummer92@users.noreply.github.com>
 - Daniel Dorani <ddandd@gmail.com> (doranid)
 - Daniel Brookman <53625739+dbrookman@users.noreply.github.com>
 - Dan Garrette <dhgarrette@gmail.com>
 - Damien Nozay <damien.nozay@gmail.com>
+- Cubicpath <Cubicpath@protonmail.com>
 - Craig Citro <craigcitro@gmail.com>
+- Cosmo <cosmo@cosmo.red>
 - Clment Pit-Claudel <cpitclaudel@users.noreply.github.com>
 - Christopher Zurcher <zurcher@users.noreply.github.com>
+- Christian Clauss <cclauss@me.com>
 - Carl Crowder <bitbucket@carlcrowder.com>: don't evaluate the value of arguments for 'dangerous-default-value'
 - Carey Metcalfe <carey@cmetcalfe.ca>: demoted `try-except-raise` from error to warning
 - Cameron Olechowski <camsterole@users.noreply.github.com>
 - Calin Don <calin.don@gmail.com>
 - Caio Carrara <ccarrara@redhat.com>
 - C.A.M. Gerlach <WIDEnetServices@gmail.com>
 - Bruno P. Kinoshita <kinow@users.noreply.github.com>
+- Brice Chardin <brice.chardin@gmail.com>
 - Brian C. Lane <bcl@redhat.com>
 - Brandon W Maister <quodlibetor@gmail.com>
 - BioGeek <jeroen.vangoey@gmail.com>
 - Benjamin Graham <benwilliamgraham@gmail.com>
 - Benedikt Morbach <benedikt.morbach@googlemail.com>
+- Ben Greiner <code@bnavigator.de>
 - Banjamin Freeman <befreeman@users.noreply.github.com>
+- Avram Lubkin <avylove@rockhopper.net>
 - Athos Ribeiro <athoscr@fedoraproject.org>: Fixed dict-keys-not-iterating false positive for inverse containment checks
 - Arun Persaud <arun@nubati.net>
 - Arthur Lutz <arthur.lutz@logilab.fr>
 - Antonio Ossa <aaossa@uc.cl>
 - Anthony VEREZ <anthony.verez.external@cassidian.com>
 - Anthony Tan <tanant@users.noreply.github.com>
 - Anthony Foglia <afoglia@users.noreply.github.com> (Google): Added simple string slots check.
 - Anentropic <ego@anentropic.com>
 - Andy Young <a7young@ucsd.edu>
 - Andy Palmer <25123779+ninezerozeronine@users.noreply.github.com>
 - Andrzej Klajnert <github@aklajnert.pl>
 - Andrew Howe <howeaj@users.noreply.github.com>
 - Andres Perez Hortal <andresperezcba@gmail.com>
+- Andre Hora <andrehora@users.noreply.github.com>
 - Alok Singh <8325708+alok@users.noreply.github.com>
 - Allan Chandler <95424144+allanc65@users.noreply.github.com> (allanc65)
   * Fixed issue 5452, false positive missing-param-doc for multi-line Google-style params
 - Alex Jurkiewicz <alex@jurkiewi.cz>
 - Alex Hearn <alex.d.hearn@gmail.com>
 - Alan Evangelista <alanoe@linux.vnet.ibm.com>
 - Alan Chan <achan961117@gmail.com>
 - Aivar Annamaa <aivarannamaa@users.noreply.github.com>
 - Aidan Haase <44787650+haasea@users.noreply.github.com>
 - Ahirnish Pareek <ahirnish@gmail.com>: 'keyword-arg-before-var-arg' check
 - Adrian Chirieac <chirieacam@gmail.com>
 - Aditya Gupta <adityagupta1089@users.noreply.github.com> (adityagupta1089)
   * Added ignore_signatures to duplicate checker
 - Adam Dangoor <adamdangoor@gmail.com>
+- 243f6a88 85a308d3 <33170174+243f6a8885a308d313198a2e037@users.noreply.github.com>
 
 
 Co-Author
 ---------
 The following persons were credited manually but did not commit themselves
 under this name, or we did not manage to find their commits in the history.
```

### Comparing `pylint-3.0.0a5/LICENSE` & `pylint-3.0.0a6/LICENSE`

 * *Files identical despite different names*

### Comparing `pylint-3.0.0a5/PKG-INFO` & `pylint-3.0.0a6/PKG-INFO`

 * *Files 18% similar despite different names*

```diff
@@ -1,202 +1,258 @@
 Metadata-Version: 2.1
 Name: pylint
-Version: 3.0.0a5
+Version: 3.0.0a6
 Summary: python code static checker
-Author: Python Code Quality Authority
-Author-email: code-quality@python.org
+Author-email: Python Code Quality Authority <code-quality@python.org>
 License: GPL-2.0-or-later
-Project-URL: Homepage, https://www.pylint.org/
-Project-URL: Source Code, https://github.com/PyCQA/pylint
-Project-URL: What's New, https://pylint.pycqa.org/en/latest/whatsnew/
-Project-URL: Bug Tracker, https://github.com/PyCQA/pylint/issues
+Project-URL: Docs: User Guide, https://pylint.readthedocs.io/en/latest/
+Project-URL: Source Code, https://github.com/pylint-dev/pylint
+Project-URL: homepage, https://github.com/pylint-dev/pylint
+Project-URL: What's New, https://pylint.readthedocs.io/en/latest/whatsnew/2/
+Project-URL: Bug Tracker, https://github.com/pylint-dev/pylint/issues
 Project-URL: Discord Server, https://discord.com/invite/Egy6P8AMB5
-Project-URL: Docs: User Guide, https://pylint.pycqa.org/en/latest/
-Project-URL: Docs: Contributing, https://pylint.pycqa.org/en/latest/development_guide/contribute.html
-Project-URL: Docs: Technical Reference, https://pylint.pycqa.org/en/latest/technical_reference/index.html
-Keywords: static code analysis linter python lint
+Project-URL: Docs: Contributor Guide, https://pylint.readthedocs.io/en/latest/development_guide/contributor_guide/index.html
+Keywords: static code analysis,linter,python,lint
 Classifier: Development Status :: 6 - Mature
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: GNU General Public License v2 (GPLv2)
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3 :: Only
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Programming Language :: Python :: Implementation :: PyPy
 Classifier: Topic :: Software Development :: Debuggers
 Classifier: Topic :: Software Development :: Quality Assurance
 Classifier: Topic :: Software Development :: Testing
+Classifier: Typing :: Typed
 Requires-Python: >=3.7.2
 Description-Content-Type: text/x-rst
 Provides-Extra: testutils
 Provides-Extra: spelling
 License-File: LICENSE
 License-File: CONTRIBUTORS.txt
 
 `Pylint`_
 =========
 
-.. _`Pylint`: https://pylint.pycqa.org/
+.. _`Pylint`: https://pylint.readthedocs.io/
 
 .. This is used inside the doc to recover the start of the introduction
 
-.. image:: https://github.com/PyCQA/pylint/actions/workflows/tests.yaml/badge.svg?branch=main
-    :target: https://github.com/PyCQA/pylint/actions
+.. image:: https://github.com/pylint-dev/pylint/actions/workflows/tests.yaml/badge.svg?branch=main
+    :target: https://github.com/pylint-dev/pylint/actions
 
-.. image:: https://coveralls.io/repos/github/PyCQA/pylint/badge.svg?branch=main
-    :target: https://coveralls.io/github/PyCQA/pylint?branch=main
+.. image:: https://codecov.io/gh/pylint-dev/pylint/branch/main/graph/badge.svg?token=ZETEzayrfk
+    :target: https://codecov.io/gh/pylint-dev/pylint
 
 .. image:: https://img.shields.io/pypi/v/pylint.svg
     :alt: Pypi Package version
     :target: https://pypi.python.org/pypi/pylint
 
 .. image:: https://readthedocs.org/projects/pylint/badge/?version=latest
     :target: https://pylint.readthedocs.io/en/latest/?badge=latest
     :alt: Documentation Status
 
 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg
     :target: https://github.com/ambv/black
 
 .. image:: https://img.shields.io/badge/linting-pylint-yellowgreen
-    :target: https://github.com/PyCQA/pylint
+    :target: https://github.com/pylint-dev/pylint
 
-.. image:: https://results.pre-commit.ci/badge/github/PyCQA/pylint/main.svg
-   :target: https://results.pre-commit.ci/latest/github/PyCQA/pylint/main
+.. image:: https://results.pre-commit.ci/badge/github/pylint-dev/pylint/main.svg
+   :target: https://results.pre-commit.ci/latest/github/pylint-dev/pylint/main
    :alt: pre-commit.ci status
 
+.. image:: https://bestpractices.coreinfrastructure.org/projects/6328/badge
+   :target: https://bestpractices.coreinfrastructure.org/projects/6328
+   :alt: CII Best Practices
+
+.. image:: https://img.shields.io/ossf-scorecard/github.com/PyCQA/pylint?label=openssf%20scorecard&style=flat
+   :target: https://api.securityscorecards.dev/projects/github.com/PyCQA/pylint
+   :alt: OpenSSF Scorecard
+
+.. image:: https://img.shields.io/discord/825463413634891776.svg
+   :target: https://discord.gg/qYxpadCgkx
+   :alt: Discord
+
 What is Pylint?
-================
+---------------
 
 Pylint is a `static code analyser`_ for Python 2 or 3. The latest version supports Python
 3.7.2 and above.
 
 .. _`static code analyser`: https://en.wikipedia.org/wiki/Static_code_analysis
 
 Pylint analyses your code without actually running it. It checks for errors, enforces a
 coding standard, looks for `code smells`_, and can make suggestions about how the code
-could be refactored. Pylint can infer actual values from your code using its internal
-code representation (astroid). If your code is ``import logging as argparse``, Pylint
-will know that ``argparse.error(...)`` is in fact a logging call and not an argparse call.
+could be refactored.
 
 .. _`code smells`: https://martinfowler.com/bliki/CodeSmell.html
 
-Pylint is highly configurable and permits to write plugins in order to add your
-own checks (for example, for internal libraries or an internal rule). Pylint has an
-ecosystem of existing plugins for popular frameworks such as `pylint-django`_ or
-`pylint-i18n`_.
+Install
+-------
 
-.. _`pylint-django`: https://github.com/PyCQA/pylint-django
-.. _`pylint-i18n`: https://github.com/amandasaurus/python-pylint-i18n
+.. This is used inside the doc to recover the start of the short text for installation
+
+For command line use, pylint is installed with::
+
+    pip install pylint
+
+Or if you want to also check spelling with ``enchant`` (you might need to
+`install the enchant C library <https://pyenchant.github.io/pyenchant/install.html#installing-the-enchant-c-library>`_):
+
+.. code-block:: sh
+
+   pip install pylint[spelling]
+
+It can also be integrated in most editors or IDEs. More information can be found
+`in the documentation`_.
+
+.. _in the documentation: https://pylint.readthedocs.io/en/latest/user_guide/installation/index.html
+
+.. This is used inside the doc to recover the end of the short text for installation
+
+What differentiates Pylint?
+---------------------------
+
+Pylint is not trusting your typing and is inferring the actual value of nodes (for a
+start because there was no typing when pylint started off) using its internal code
+representation (astroid). If your code is ``import logging as argparse``, Pylint
+can check and know that ``argparse.error(...)`` is in fact a logging call and not an
+argparse call. This makes pylint slower, but it also lets pylint find more issues if
+your code is not fully typed.
+
+    [inference] is the killer feature that keeps us using [pylint] in our project despite how painfully slow it is.
+    - `Realist pylint user`_, 2022
+
+.. _`Realist pylint user`: https://github.com/charliermarsh/ruff/issues/970#issuecomment-1381067064
+
+pylint, not afraid of being a little slower than it already is, is also a lot more thorough than other linters.
+There are more checks, including some opinionated ones that are deactivated by default
+but can be enabled using configuration.
+
+How to use pylint
+-----------------
 
 Pylint isn't smarter than you: it may warn you about things that you have
 conscientiously done or check for some things that you don't care about.
 During adoption, especially in a legacy project where pylint was never enforced,
 it's best to start with the ``--errors-only`` flag, then disable
-convention and refactor message with ``--disable=C,R`` and progressively
+convention and refactor messages with ``--disable=C,R`` and progressively
 re-evaluate and re-enable messages as your priorities evolve.
 
-Pylint ships with three additional tools:
+Pylint is highly configurable and permits to write plugins in order to add your
+own checks (for example, for internal libraries or an internal rule). Pylint also has an
+ecosystem of existing plugins for popular frameworks and third-party libraries.
 
-- pyreverse_ (standalone tool that generates package and class diagrams.)
-- symilar_  (duplicate code finder that is also integrated in pylint)
-- epylint_ (Emacs and Flymake compatible Pylint)
+.. note::
+
+    Pylint supports the Python standard library out of the box. Third-party
+    libraries are not always supported, so a plugin might be needed. A good place
+    to start is ``PyPI`` which often returns a plugin by searching for
+    ``pylint <library>``. `pylint-pydantic`_, `pylint-django`_ and
+    `pylint-sonarjson`_ are examples of such plugins. More information about plugins
+    and how to load them can be found at `plugins`_.
 
-.. _pyreverse: https://pylint.pycqa.org/en/latest/pyreverse.html
-.. _symilar: https://pylint.pycqa.org/en/latest/symilar.html
-.. _epylint: https://pylint.pycqa.org/en/latest/user_guide/ide_integration/flymake-emacs.html
-
-Projects that you might want to use alongside pylint include flake8_ (faster and simpler checks
-with very few false positives), mypy_, pyright_ or pyre_ (typing checks), bandit_ (security
-oriented checks), black_ and isort_ (auto-formatting), autoflake_ (automated removal of
-unused imports or variables), pyupgrade_ (automated upgrade to newer python syntax) and
-pydocstringformatter_ (automated pep257).
+.. _`plugins`: https://pylint.readthedocs.io/en/latest/development_guide/how_tos/plugins.html#plugins
+.. _`pylint-pydantic`: https://pypi.org/project/pylint-pydantic
+.. _`pylint-django`: https://github.com/PyCQA/pylint-django
+.. _`pylint-sonarjson`: https://github.com/omegacen/pylint-sonarjson
 
-.. _flake8: https://gitlab.com/pycqa/flake8/
+Advised linters alongside pylint
+--------------------------------
+
+Projects that you might want to use alongside pylint include ruff_ (**really** fast,
+with builtin auto-fix and a growing number of checks taken from popular
+linters but implemented in ``rust``) or flake8_ (faster and simpler checks with very few false positives),
+mypy_, pyright_ or pyre_ (typing checks), bandit_ (security oriented checks), black_ and
+isort_ (auto-formatting), autoflake_ (automated removal of unused imports or variables),
+pyupgrade_ (automated upgrade to newer python syntax) and pydocstringformatter_ (automated pep257).
+
+.. _ruff: https://github.com/charliermarsh/ruff
+.. _flake8: https://github.com/PyCQA/flake8
 .. _bandit: https://github.com/PyCQA/bandit
 .. _mypy: https://github.com/python/mypy
 .. _pyright: https://github.com/microsoft/pyright
 .. _pyre: https://github.com/facebook/pyre-check
 .. _black: https://github.com/psf/black
 .. _autoflake: https://github.com/myint/autoflake
 .. _pyupgrade: https://github.com/asottile/pyupgrade
 .. _pydocstringformatter: https://github.com/DanielNoord/pydocstringformatter
 .. _isort: https://pycqa.github.io/isort/
 
-.. This is used inside the doc to recover the end of the introduction
-
-Install
--------
-
-.. This is used inside the doc to recover the start of the short text for installation
+Additional tools included in pylint
+-----------------------------------
 
-For command line use, pylint is installed with::
+Pylint ships with two additional tools:
 
-    pip install pylint
+- pyreverse_ (standalone tool that generates package and class diagrams.)
+- symilar_  (duplicate code finder that is also integrated in pylint)
 
-It can also be integrated in most editors or IDEs. More information can be found
-`in the documentation`_.
+.. _pyreverse: https://pylint.readthedocs.io/en/latest/pyreverse.html
+.. _symilar: https://pylint.readthedocs.io/en/latest/symilar.html
 
-.. _in the documentation: https://pylint.pycqa.org/en/latest/user_guide/installation/index.html
 
-.. This is used inside the doc to recover the end of the short text for installation
+.. This is used inside the doc to recover the end of the introduction
 
 Contributing
 ------------
 
 .. This is used inside the doc to recover the start of the short text for contribution
 
 We welcome all forms of contributions such as updates for documentation, new code, checking issues for duplicates or telling us
 that we can close them, confirming that issues still exist, `creating issues because
 you found a bug or want a feature`_, etc. Everything is much appreciated!
 
 Please follow the `code of conduct`_ and check `the Contributor Guides`_ if you want to
 make a code contribution.
 
-.. _creating issues because you found a bug or want a feature: https://pylint.pycqa.org/en/latest/contact.html#bug-reports-feedback
-.. _code of conduct: https://github.com/PyCQA/pylint/blob/main/CODE_OF_CONDUCT.md
-.. _the Contributor Guides: https://pylint.pycqa.org/en/latest/development_guide/contribute.html
+.. _creating issues because you found a bug or want a feature: https://pylint.readthedocs.io/en/latest/contact.html#bug-reports-feedback
+.. _code of conduct: https://github.com/pylint-dev/pylint/blob/main/CODE_OF_CONDUCT.md
+.. _the Contributor Guides: https://pylint.readthedocs.io/en/latest/development_guide/contribute.html
 
 .. This is used inside the doc to recover the end of the short text for contribution
 
 Show your usage
 -----------------
 
 You can place this badge in your README to let others know your project uses pylint.
 
     .. image:: https://img.shields.io/badge/linting-pylint-yellowgreen
-        :target: https://github.com/PyCQA/pylint
+        :target: https://github.com/pylint-dev/pylint
 
 Learn how to add a badge to your documentation in the `the badge documentation`_.
 
-.. _the badge documentation: https://pylint.pycqa.org/en/latest/user_guide/installation/badge.html
+.. _the badge documentation: https://pylint.readthedocs.io/en/latest/user_guide/installation/badge.html
 
 License
 -------
 
-pylint is, with a few exceptions listed below, `GPLv2 <https://github.com/PyCQA/pylint/blob/main/LICENSE>`_.
+pylint is, with a few exceptions listed below, `GPLv2 <https://github.com/pylint-dev/pylint/blob/main/LICENSE>`_.
 
 The icon files are licensed under the `CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0/>`_ license:
 
-- `doc/logo.png <https://raw.githubusercontent.com/PyCQA/pylint/main/doc/logo.png>`_
-- `doc/logo.svg <https://raw.githubusercontent.com/PyCQA/pylint/main/doc/logo.svg>`_
+- `doc/logo.png <https://raw.githubusercontent.com/pylint-dev/pylint/main/doc/logo.png>`_
+- `doc/logo.svg <https://raw.githubusercontent.com/pylint-dev/pylint/main/doc/logo.svg>`_
 
 Support
 -------
 
 Please check `the contact information`_.
 
-.. _`the contact information`: https://pylint.pycqa.org/en/latest/contact.html
+.. _`the contact information`: https://pylint.readthedocs.io/en/latest/contact.html
 
-.. |tideliftlogo| image:: https://raw.githubusercontent.com/PyCQA/pylint/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png
+.. |tideliftlogo| image:: https://raw.githubusercontent.com/pylint-dev/pylint/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png
    :width: 200
    :alt: Tidelift
 
 .. list-table::
    :widths: 10 100
 
    * - |tideliftlogo|
```

### Comparing `pylint-3.0.0a5/pylint/__init__.py` & `pylint-3.0.0a6/pylint/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,13 +1,22 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
+__all__ = [
+    "__version__",
+    "version",
+    "modify_sys_path",
+    "run_pylint",
+    "run_symilar",
+    "run_pyreverse",
+]
+
 import os
 import sys
 from collections.abc import Sequence
 from typing import NoReturn
 
 from pylint.__pkginfo__ import __version__
 
@@ -33,25 +42,15 @@
     argv can be a sequence of strings normally supplied as arguments on the command line
     """
     from pylint.lint.run import _PylintConfigRun
 
     _PylintConfigRun(argv or sys.argv[1:])
 
 
-def run_epylint(argv: Sequence[str] | None = None) -> NoReturn:
-    """Run epylint.
-
-    argv can be a list of strings normally supplied as arguments on the command line
-    """
-    from pylint.epylint import Run as EpylintRun
-
-    EpylintRun(argv)
-
-
-def run_pyreverse(argv: Sequence[str] | None = None) -> NoReturn:  # type: ignore[misc]
+def run_pyreverse(argv: Sequence[str] | None = None) -> NoReturn:
     """Run pyreverse.
 
     argv can be a sequence of strings normally supplied as arguments on the command line
     """
     from pylint.pyreverse.main import Run as PyreverseRun
 
     PyreverseRun(argv or sys.argv[1:])
@@ -75,25 +74,25 @@
     inadvertently import user code from modules having the same name as
     stdlib or pylint's own modules.
     CPython issue: https://bugs.python.org/issue33053
 
     - Remove the first entry. This will always be either "" or the working directory
     - Remove the working directory from the second and third entries
       if PYTHONPATH includes a ":" at the beginning or the end.
-      https://github.com/PyCQA/pylint/issues/3636
+      https://github.com/pylint-dev/pylint/issues/3636
       Don't remove it if PYTHONPATH contains the cwd or '.' as the entry will
       only be added once.
     - Don't remove the working directory from the rest. It will be included
       if pylint is installed in an editable configuration (as the last item).
-      https://github.com/PyCQA/pylint/issues/4161
+      https://github.com/pylint-dev/pylint/issues/4161
     """
-    sys.path.pop(0)
-    env_pythonpath = os.environ.get("PYTHONPATH", "")
     cwd = os.getcwd()
+    if sys.path[0] in ("", ".", cwd):
+        sys.path.pop(0)
+    env_pythonpath = os.environ.get("PYTHONPATH", "")
     if env_pythonpath.startswith(":") and env_pythonpath not in (f":{cwd}", ":."):
         sys.path.pop(0)
     elif env_pythonpath.endswith(":") and env_pythonpath not in (f"{cwd}:", ".:"):
         sys.path.pop(1)
 
 
 version = __version__
-__all__ = ["__version__", "version", "modify_sys_path"]
```

### Comparing `pylint-3.0.0a5/pylint/__pkginfo__.py` & `pylint-3.0.0a6/pylint/__pkginfo__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """This module exists for compatibility reasons.
 
 It's updated via tbump, do not modify.
 """
 
 from __future__ import annotations
 
-__version__ = "3.0.0-a5"
+__version__ = "3.0.0a6"
 
 
 def get_numversion_from_version(v: str) -> tuple[int, int, int]:
     """Kept for compatibility reason.
 
-    See https://github.com/PyCQA/pylint/issues/4399
-    https://github.com/PyCQA/pylint/issues/4420,
+    See https://github.com/pylint-dev/pylint/issues/4399
+    https://github.com/pylint-dev/pylint/issues/4420,
     """
     version = v.replace("pylint-", "")
     result_version = []
     for number in version.split(".")[0:3]:
         try:
             result_version.append(int(number))
         except ValueError:
```

### Comparing `pylint-3.0.0a5/pylint/checkers/__init__.py` & `pylint-3.0.0a6/pylint/checkers/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Utilities methods and classes for checkers.
 
 Base id of standard checkers (used in msg and report ids):
 01: base
 02: classes
 03: format
@@ -47,15 +47,14 @@
 
 from pylint.checkers.base_checker import (
     BaseChecker,
     BaseRawFileChecker,
     BaseTokenChecker,
 )
 from pylint.checkers.deprecated import DeprecatedMixin
-from pylint.checkers.mapreduce_checker import MapReduceMixin
 from pylint.utils import LinterStats, diff_string, register_plugins
 
 if sys.version_info >= (3, 8):
     from typing import Literal
 else:
     from typing_extensions import Literal
 
@@ -123,25 +122,24 @@
         diff_str = (
             diff_string(old_value, new_value)
             if isinstance(old_value, float)
             else old_value
         )
         new_str = f"{new_value:.3f}" if isinstance(new_value, float) else str(new_value)
         old_str = f"{old_value:.3f}" if isinstance(old_value, float) else str(old_value)
-        lines.extend((value[0].replace("_", " "), new_str, old_str, diff_str))
+        lines.extend((value[0].replace("_", " "), new_str, old_str, diff_str))  # type: ignore[arg-type]
     return lines
 
 
 def initialize(linter: PyLinter) -> None:
     """Initialize linter with checkers in this package."""
     register_plugins(linter, __path__[0])
 
 
 __all__ = [
     "BaseChecker",
     "BaseTokenChecker",
     "BaseRawFileChecker",
     "initialize",
-    "MapReduceMixin",
     "DeprecatedMixin",
     "register_plugins",
 ]
```

### Comparing `pylint-3.0.0a5/pylint/checkers/async.py` & `pylint-3.0.0a6/pylint/checkers/async.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checker for anything related to the async protocol (PEP 492)."""
 
 from __future__ import annotations
 
 import sys
 from typing import TYPE_CHECKING
 
 import astroid
-from astroid import nodes
+from astroid import nodes, util
 
 from pylint import checkers
 from pylint.checkers import utils as checker_utils
 from pylint.checkers.utils import decorated_with
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
@@ -51,15 +51,15 @@
             ):
                 self.add_message("yield-inside-async-function", node=child)
 
     @checker_utils.only_required_for_messages("not-async-context-manager")
     def visit_asyncwith(self, node: nodes.AsyncWith) -> None:
         for ctx_mgr, _ in node.items:
             inferred = checker_utils.safe_infer(ctx_mgr)
-            if inferred is None or inferred is astroid.Uninferable:
+            if inferred is None or isinstance(inferred, util.UninferableBase):
                 continue
 
             if isinstance(inferred, nodes.AsyncFunctionDef):
                 # Check if we are dealing with a function decorated
                 # with contextlib.asynccontextmanager.
                 if decorated_with(inferred, self._async_generators):
                     continue
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base/__init__.py` & `pylint-3.0.0a6/pylint/checkers/base/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,10 +1,12 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
+
+# pylint: disable=duplicate-code # This is similar to the __init__ of .name_checker
 
 from __future__ import annotations
 
 __all__ = [
     "NameChecker",
     "NamingStyle",
     "KNOWN_NAME_TYPES_WITH_STYLE",
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base/basic_checker.py` & `pylint-3.0.0a6/pylint/checkers/base/basic_checker.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Basic checker for Python code."""
 
 from __future__ import annotations
 
 import collections
 import itertools
 import sys
 from collections.abc import Iterator
 from typing import TYPE_CHECKING, cast
 
 import astroid
-from astroid import nodes
+from astroid import nodes, objects, util
 
 from pylint import utils as lint_utils
 from pylint.checkers import BaseChecker, utils
-from pylint.interfaces import HIGH
+from pylint.interfaces import HIGH, INFERENCE, Confidence
 from pylint.reporters.ureports import nodes as reporter_nodes
 from pylint.utils import LinterStats
 
 if TYPE_CHECKING:
     from pylint.lint.pylinter import PyLinter
 
 if sys.version_info >= (3, 8):
@@ -100,14 +100,15 @@
             diff_str if diff_str else "NC",
             nice_stats[node_type].get("percent_documented", "0"),
             nice_stats[node_type].get("percent_badname", "0"),
         ]
     sect.append(reporter_nodes.Table(children=lines, cols=6, rheaders=1))
 
 
+# pylint: disable-next = too-many-public-methods
 class BasicChecker(_BasicChecker):
     """Basic checker.
 
     Checks for :
     * doc strings
     * number of arguments, local variables, branches, returns and statements in
     functions, methods
@@ -162,17 +163,18 @@
             "Duplicate key %r in dictionary",
             "duplicate-key",
             "Used when a dictionary expression binds the same key multiple times.",
         ),
         "W0122": (
             "Use of exec",
             "exec-used",
-            'Used when you use the "exec" statement (function for Python '
-            "3), to discourage its usage. That doesn't "
-            "mean you cannot use it !",
+            "Raised when the 'exec' statement is used. It's dangerous to use this "
+            "function for a user input, and it's also slower than actual code in "
+            "general. This doesn't mean you should never use it, but you should "
+            "consider alternatives first and restrict the functions available.",
         ),
         "W0123": (
             "Use of eval",
             "eval-used",
             'Used when you use the "eval" function, to discourage its '
             "usage. Consider using `ast.literal_eval` for safely evaluating "
             "strings containing Python expressions "
@@ -183,15 +185,15 @@
             "lost-exception",
             "Used when a break or a return statement is found inside the "
             "finally clause of a try...finally block: the exceptions raised "
             "in the try clause will be silently swallowed instead of being "
             "re-raised.",
         ),
         "W0199": (
-            "Assert called on a 2-item-tuple. Did you mean 'assert x,y'?",
+            "Assert called on a populated tuple. Did you mean 'assert x,y'?",
             "assert-on-tuple",
             "A call of assert on a tuple will always evaluate to true if "
             "the tuple is not empty, and will always evaluate to false if "
             "it is.",
         ),
         "W0124": (
             'Following "as" with another context manager looks like a tuple.',
@@ -206,15 +208,16 @@
             "Using a conditional statement with a constant value",
             "using-constant-test",
             "Emitted when a conditional statement (If or ternary if) "
             "uses a constant value for its test. This might not be what "
             "the user intended to do.",
         ),
         "W0126": (
-            "Using a conditional statement with potentially wrong function or method call due to missing parentheses",
+            "Using a conditional statement with potentially wrong function or method call due to "
+            "missing parentheses",
             "missing-parentheses-for-call-in-test",
             "Emitted when a conditional statement (If or ternary if) "
             "seems to wrongly call a function due to missing parentheses",
         ),
         "W0127": (
             "Assigning the same variable %r to itself",
             "self-assigning-variable",
@@ -247,14 +250,26 @@
             "cause the assert to always pass.",
         ),
         "W0130": (
             "Duplicate value %r in set",
             "duplicate-value",
             "This message is emitted when a set contains the same value two or more times.",
         ),
+        "W0131": (
+            "Named expression used without context",
+            "named-expr-without-context",
+            "Emitted if named expression is used to do a regular assignment "
+            "outside a context like if, for, while, or a comprehension.",
+        ),
+        "W0133": (
+            "Exception statement has no effect",
+            "pointless-exception-statement",
+            "Used when an exception is created without being assigned, raised or returned "
+            "for subsequent use elsewhere.",
+        ),
     }
 
     reports = (("RP0101", "Statistics by type", report_by_type_stats),)
 
     def __init__(self, linter: PyLinter) -> None:
         super().__init__(linter)
         self._tryfinallys: list[nodes.TryFinally] | None = None
@@ -310,55 +325,113 @@
             nodes.Call,
             nodes.BinOp,
             nodes.BoolOp,
             nodes.UnaryOp,
             nodes.Subscript,
         )
         inferred = None
-        emit = isinstance(test, (nodes.Const,) + structs + const_nodes)
+        emit = isinstance(test, (nodes.Const, *structs, *const_nodes))
+        maybe_generator_call = None
         if not isinstance(test, except_nodes):
             inferred = utils.safe_infer(test)
+            if isinstance(inferred, util.UninferableBase) and isinstance(
+                test, nodes.Name
+            ):
+                emit, maybe_generator_call = BasicChecker._name_holds_generator(test)
+
+        # Emit if calling a function that only returns GeneratorExp (always tests True)
+        elif isinstance(test, nodes.Call):
+            maybe_generator_call = test
+        if maybe_generator_call:
+            inferred_call = utils.safe_infer(maybe_generator_call.func)
+            if isinstance(inferred_call, nodes.FunctionDef):
+                # Can't use all(x) or not any(not x) for this condition, because it
+                # will return True for empty generators, which is not what we want.
+                all_returns_were_generator = None
+                for return_node in inferred_call._get_return_nodes_skip_functions():
+                    if not isinstance(return_node.value, nodes.GeneratorExp):
+                        all_returns_were_generator = False
+                        break
+                    all_returns_were_generator = True
+                if all_returns_were_generator:
+                    self.add_message(
+                        "using-constant-test", node=node, confidence=INFERENCE
+                    )
+                    return
 
         if emit:
-            self.add_message("using-constant-test", node=test)
+            self.add_message("using-constant-test", node=test, confidence=INFERENCE)
         elif isinstance(inferred, const_nodes):
             # If the constant node is a FunctionDef or Lambda then
             # it may be an illicit function call due to missing parentheses
             call_inferred = None
             try:
+                # Just forcing the generator to infer all elements.
+                # astroid.exceptions.InferenceError are false positives
+                # see https://github.com/pylint-dev/pylint/pull/8185
                 if isinstance(inferred, nodes.FunctionDef):
-                    call_inferred = inferred.infer_call_result()
+                    call_inferred = list(inferred.infer_call_result())
                 elif isinstance(inferred, nodes.Lambda):
-                    call_inferred = inferred.infer_call_result(node)
+                    call_inferred = list(inferred.infer_call_result(node))
             except astroid.InferenceError:
                 call_inferred = None
             if call_inferred:
-                try:
-                    for inf_call in call_inferred:
-                        if inf_call != astroid.Uninferable:
-                            self.add_message(
-                                "missing-parentheses-for-call-in-test", node=test
-                            )
-                            break
-                except astroid.InferenceError:
-                    pass
-            self.add_message("using-constant-test", node=test)
+                self.add_message(
+                    "missing-parentheses-for-call-in-test",
+                    node=test,
+                    confidence=INFERENCE,
+                )
+            self.add_message("using-constant-test", node=test, confidence=INFERENCE)
+
+    @staticmethod
+    def _name_holds_generator(test: nodes.Name) -> tuple[bool, nodes.Call | None]:
+        """Return whether `test` tests a name certain to hold a generator, or optionally
+        a call that should be then tested to see if *it* returns only generators.
+        """
+        assert isinstance(test, nodes.Name)
+        emit = False
+        maybe_generator_call = None
+        lookup_result = test.frame(future=True).lookup(test.name)
+        if not lookup_result:
+            return emit, maybe_generator_call
+        maybe_generator_assigned = (
+            isinstance(assign_name.parent.value, nodes.GeneratorExp)
+            for assign_name in lookup_result[1]
+            if isinstance(assign_name.parent, nodes.Assign)
+        )
+        first_item = next(maybe_generator_assigned, None)
+        if first_item is not None:
+            # Emit if this variable is certain to hold a generator
+            if all(itertools.chain((first_item,), maybe_generator_assigned)):
+                emit = True
+            # If this variable holds the result of a call, save it for next test
+            elif (
+                len(lookup_result[1]) == 1
+                and isinstance(lookup_result[1][0].parent, nodes.Assign)
+                and isinstance(lookup_result[1][0].parent.value, nodes.Call)
+            ):
+                maybe_generator_call = lookup_result[1][0].parent.value
+        return emit, maybe_generator_call
 
     def visit_module(self, _: nodes.Module) -> None:
         """Check module name, docstring and required arguments."""
         self.linter.stats.node_count["module"] += 1
 
     def visit_classdef(self, _: nodes.ClassDef) -> None:
         """Check module name, docstring and redefinition
         increment branch counter.
         """
         self.linter.stats.node_count["klass"] += 1
 
     @utils.only_required_for_messages(
-        "pointless-statement", "pointless-string-statement", "expression-not-assigned"
+        "pointless-statement",
+        "pointless-exception-statement",
+        "pointless-string-statement",
+        "expression-not-assigned",
+        "named-expr-without-context",
     )
     def visit_expr(self, node: nodes.Expr) -> None:
         """Check for various kind of statements without effect."""
         expr = node.value
         if isinstance(expr, nodes.Const) and isinstance(expr.value, str):
             # treat string statement in a separated message
             # Handle PEP-257 attribute docstrings.
@@ -375,28 +448,47 @@
                         and sibling.scope() is scope
                         and isinstance(sibling, (nodes.Assign, nodes.AnnAssign))
                     ):
                         return
             self.add_message("pointless-string-statement", node=node)
             return
 
+        # Warn W0133 for exceptions that are used as statements
+        if isinstance(expr, nodes.Call):
+            name = ""
+            if isinstance(expr.func, nodes.Name):
+                name = expr.func.name
+            elif isinstance(expr.func, nodes.Attribute):
+                name = expr.func.attrname
+
+            # Heuristic: only run inference for names that begin with an uppercase char
+            # This reduces W0133's coverage, but retains acceptable runtime performance
+            # For more details, see: https://github.com/pylint-dev/pylint/issues/8073
+            inferred = utils.safe_infer(expr) if name[:1].isupper() else None
+            if isinstance(inferred, objects.ExceptionInstance):
+                self.add_message(
+                    "pointless-exception-statement", node=node, confidence=INFERENCE
+                )
+            return
+
         # Ignore if this is :
-        # * a direct function call
         # * the unique child of a try/except body
         # * a yield statement
         # * an ellipsis (which can be used on Python 3 instead of pass)
         # warn W0106 if we have any underlying function call (we can't predict
         # side effects), else pointless-statement
         if (
-            isinstance(expr, (nodes.Yield, nodes.Await, nodes.Call))
+            isinstance(expr, (nodes.Yield, nodes.Await))
             or (isinstance(node.parent, nodes.TryExcept) and node.parent.body == [node])
             or (isinstance(expr, nodes.Const) and expr.value is Ellipsis)
         ):
             return
-        if any(expr.nodes_of_class(nodes.Call)):
+        if isinstance(expr, nodes.NamedExpr):
+            self.add_message("named-expr-without-context", node=node, confidence=HIGH)
+        elif any(expr.nodes_of_class(nodes.Call)):
             self.add_message(
                 "expression-not-assigned", node=node, args=expr.as_string()
             )
         else:
             self.add_message("pointless-statement", node=node)
 
     @staticmethod
@@ -423,14 +515,15 @@
             isinstance(a.value, nodes.Name)
             and a.value.name != variadic_name
             or not isinstance(a.value, nodes.Name)
             for a in args
         )
 
     @utils.only_required_for_messages("unnecessary-lambda")
+    # pylint: disable-next=too-many-return-statements
     def visit_lambda(self, node: nodes.Lambda) -> None:
         """Check whether the lambda is suspicious."""
         # if the body of the lambda is a call expression with the same
         # argument list as the lambda itself, then the lambda is
         # possibly unnecessary and at least suspicious.
         if node.args.defaults:
             # If the arguments of the lambda include defaults, then a
@@ -480,14 +573,21 @@
             return
         for arg, passed_arg in zip(ordinary_args, new_call_args):
             if not isinstance(passed_arg, nodes.Name):
                 return
             if arg.name != passed_arg.name:
                 return
 
+        # The lambda is necessary if it uses its parameter in the function it is
+        # calling in the lambda's body
+        # e.g. lambda foo: (func1 if foo else func2)(foo)
+        for name in call.func.nodes_of_class(nodes.Name):
+            if name.lookup(name.name)[0] is node:
+                return
+
         self.add_message("unnecessary-lambda", line=node.fromlineno, node=node)
 
     @utils.only_required_for_messages("dangerous-default-value")
     def visit_functiondef(self, node: nodes.FunctionDef) -> None:
         """Check function name, docstring, arguments, redefinition,
         variable names, max locals.
         """
@@ -501,15 +601,15 @@
 
     def _check_dangerous_default(self, node: nodes.FunctionDef) -> None:
         """Check for dangerous default values as arguments."""
 
         def is_iterable(internal_node: nodes.NodeNG) -> bool:
             return isinstance(internal_node, (nodes.List, nodes.Set, nodes.Dict))
 
-        defaults = node.args.defaults or [] + node.args.kw_defaults or []
+        defaults = (node.args.defaults or []) + (node.args.kw_defaults or [])
         for default in defaults:
             if not default:
                 continue
             try:
                 value = next(default.infer())
             except astroid.InferenceError:
                 continue
@@ -583,35 +683,39 @@
     def _check_misplaced_format_function(self, call_node: nodes.Call) -> None:
         if not isinstance(call_node.func, nodes.Attribute):
             return
         if call_node.func.attrname != "format":
             return
 
         expr = utils.safe_infer(call_node.func.expr)
-        if expr is astroid.Uninferable:
+        if isinstance(expr, util.UninferableBase):
             return
         if not expr:
             # we are doubtful on inferred type of node, so here just check if format
             # was called on print()
             call_expr = call_node.func.expr
             if not isinstance(call_expr, nodes.Call):
                 return
             if (
                 isinstance(call_expr.func, nodes.Name)
                 and call_expr.func.name == "print"
             ):
                 self.add_message("misplaced-format-function", node=call_node)
 
     @utils.only_required_for_messages(
-        "eval-used", "exec-used", "bad-reversed-sequence", "misplaced-format-function"
+        "eval-used",
+        "exec-used",
+        "bad-reversed-sequence",
+        "misplaced-format-function",
+        "unreachable",
     )
     def visit_call(self, node: nodes.Call) -> None:
-        """Visit a Call node -> check if this is not a disallowed builtin
-        call and check for * or ** use.
-        """
+        """Visit a Call node."""
+        if utils.is_terminating_func(node):
+            self._check_unreachable(node, confidence=INFERENCE)
         self._check_misplaced_format_function(node)
         if isinstance(node.func, nodes.Name):
             name = node.func.name
             # ignore the name if it's not a builtin (i.e. not defined in the
             # locals nor globals scope)
             if not (name in node.frame(future=True) or name in node.root()):
                 if name == "exec":
@@ -620,20 +724,16 @@
                     self._check_reversed(node)
                 elif name == "eval":
                     self.add_message("eval-used", node=node)
 
     @utils.only_required_for_messages("assert-on-tuple", "assert-on-string-literal")
     def visit_assert(self, node: nodes.Assert) -> None:
         """Check whether assert is used on a tuple or string literal."""
-        if (
-            node.fail is None
-            and isinstance(node.test, nodes.Tuple)
-            and len(node.test.elts) == 2
-        ):
-            self.add_message("assert-on-tuple", node=node)
+        if isinstance(node.test, nodes.Tuple) and len(node.test.elts) > 0:
+            self.add_message("assert-on-tuple", node=node, confidence=HIGH)
 
         if isinstance(node.test, nodes.Const) and isinstance(node.test.value, str):
             if node.test.value:
                 when = "never"
             else:
                 when = "always"
             self.add_message("assert-on-string-literal", node=node, args=(when,))
@@ -675,30 +775,34 @@
 
     def leave_tryfinally(self, _: nodes.TryFinally) -> None:
         """Update try...finally flag."""
         assert self._tryfinallys is not None
         self._tryfinallys.pop()
 
     def _check_unreachable(
-        self, node: nodes.Return | nodes.Continue | nodes.Break | nodes.Raise
+        self,
+        node: nodes.Return | nodes.Continue | nodes.Break | nodes.Raise | nodes.Call,
+        confidence: Confidence = HIGH,
     ) -> None:
         """Check unreachable code."""
-        unreach_stmt = node.next_sibling()
-        if unreach_stmt is not None:
+        unreachable_statement = node.next_sibling()
+        if unreachable_statement is not None:
             if (
                 isinstance(node, nodes.Return)
-                and isinstance(unreach_stmt, nodes.Expr)
-                and isinstance(unreach_stmt.value, nodes.Yield)
+                and isinstance(unreachable_statement, nodes.Expr)
+                and isinstance(unreachable_statement.value, nodes.Yield)
             ):
                 # Don't add 'unreachable' for empty generators.
                 # Only add warning if 'yield' is followed by another node.
-                unreach_stmt = unreach_stmt.next_sibling()
-                if unreach_stmt is None:
+                unreachable_statement = unreachable_statement.next_sibling()
+                if unreachable_statement is None:
                     return
-            self.add_message("unreachable", node=unreach_stmt)
+            self.add_message(
+                "unreachable", node=unreachable_statement, confidence=confidence
+            )
 
     def _check_not_in_finally(
         self,
         node: nodes.Break | nodes.Return,
         node_name: str,
         breaker_classes: tuple[nodes.NodeNG, ...] = (),
     ) -> None:
@@ -724,15 +828,15 @@
     def _check_reversed(self, node: nodes.Call) -> None:
         """Check that the argument to `reversed` is a sequence."""
         try:
             argument = utils.safe_infer(utils.get_argument_from_call(node, position=0))
         except utils.NoSuchArgumentError:
             pass
         else:
-            if argument is astroid.Uninferable:
+            if isinstance(argument, util.UninferableBase):
                 return
             if argument is None:
                 # Nothing was inferred.
                 # Try to see if we have iter().
                 if isinstance(node.args[0], nodes.Call):
                     try:
                         func = next(node.args[0].func.infer())
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base/basic_error_checker.py` & `pylint-3.0.0a6/pylint/checkers/base/basic_error_checker.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,21 +1,22 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Basic Error checker from the basic checker."""
 
 from __future__ import annotations
 
 import itertools
 from collections.abc import Iterator
 from typing import Any
 
 import astroid
 from astroid import nodes
+from astroid.typing import InferenceResult
 
 from pylint.checkers import utils
 from pylint.checkers.base.basic_checker import _BasicChecker
 from pylint.checkers.utils import infer_all
 from pylint.interfaces import HIGH
 
 ABC_METACLASSES = {"_py_abc.ABCMeta", "abc.ABCMeta"}  # Python 3.7+,
@@ -64,15 +65,15 @@
     return any(
         _node
         for _node in loop.nodes_of_class(nodes.Break, skip_klass=definition_nodes)
         if _get_break_loop_node(_node) not in inner_loop_nodes
     )
 
 
-def _has_abstract_methods(node):
+def _has_abstract_methods(node: nodes.ClassDef) -> bool:
     """Determine if the given `node` has abstract methods.
 
     The methods should be made abstract by decorating them
     with `abc` decorators.
     """
     return len(utils.unimplemented_abstract_methods(node)) > 0
 
@@ -185,15 +186,14 @@
             "Emitted when a name is both nonlocal and global.",
         ),
         "E0116": (
             "'continue' not supported inside 'finally' clause",
             "continue-in-finally",
             "Emitted when the `continue` keyword is found "
             "inside a finally clause, which is a SyntaxError.",
-            {"maxversion": (3, 8)},
         ),
         "E0117": (
             "nonlocal name %s found without binding",
             "nonlocal-without-binding",
             "Emitted when a nonlocal variable does not have an attached "
             "name somewhere in the parent scopes",
         ),
@@ -202,14 +202,18 @@
             "used-prior-global-declaration",
             "Emitted when a name is used prior a global declaration, "
             "which results in an error since Python 3.6.",
             {"minversion": (3, 6)},
         ),
     }
 
+    def open(self) -> None:
+        py_version = self.linter.config.py_version
+        self._py38_plus = py_version >= (3, 8)
+
     @utils.only_required_for_messages("function-redefined")
     def visit_classdef(self, node: nodes.ClassDef) -> None:
         self._check_redefinition("class", node)
 
     def _too_many_starred_for_tuple(self, assign_tuple: nodes.Tuple) -> bool:
         starred_count = 0
         for elem in assign_tuple.itered():
@@ -293,15 +297,14 @@
                 )
             else:
                 arg_clusters[arg.name] = arg
 
     visit_asyncfunctiondef = visit_functiondef
 
     def _check_name_used_prior_global(self, node: nodes.FunctionDef) -> None:
-
         scope_globals = {
             name: child
             for child in node.nodes_of_class(nodes.Global)
             for name in child.names
             if child.scope() is node
         }
 
@@ -389,46 +392,50 @@
             and (node.operand.op == node.op)
             and (node.col_offset + 1 == node.operand.col_offset)
         ):
             self.add_message("nonexistent-operator", node=node, args=node.op * 2)
 
     def _check_nonlocal_without_binding(self, node: nodes.Nonlocal, name: str) -> None:
         current_scope = node.scope()
-        while True:
-            if current_scope.parent is None:
-                break
-
+        while current_scope.parent is not None:
             if not isinstance(current_scope, (nodes.ClassDef, nodes.FunctionDef)):
                 self.add_message("nonlocal-without-binding", args=(name,), node=node)
                 return
 
-            if name not in current_scope.locals:
+            # Search for `name` in the parent scope if:
+            #  `current_scope` is the same scope in which the `nonlocal` name is declared
+            #  or `name` is not in `current_scope.locals`.
+            if current_scope is node.scope() or name not in current_scope.locals:
                 current_scope = current_scope.parent.scope()
                 continue
 
             # Okay, found it.
             return
 
         if not isinstance(current_scope, nodes.FunctionDef):
-            self.add_message("nonlocal-without-binding", args=(name,), node=node)
+            self.add_message(
+                "nonlocal-without-binding", args=(name,), node=node, confidence=HIGH
+            )
 
     @utils.only_required_for_messages("nonlocal-without-binding")
     def visit_nonlocal(self, node: nodes.Nonlocal) -> None:
         for name in node.names:
             self._check_nonlocal_without_binding(node, name)
 
     @utils.only_required_for_messages("abstract-class-instantiated")
     def visit_call(self, node: nodes.Call) -> None:
         """Check instantiating abstract class with
         abc.ABCMeta as metaclass.
         """
         for inferred in infer_all(node.func):
             self._check_inferred_class_is_abstract(inferred, node)
 
-    def _check_inferred_class_is_abstract(self, inferred, node: nodes.Call):
+    def _check_inferred_class_is_abstract(
+        self, inferred: InferenceResult, node: nodes.Call
+    ) -> None:
         if not isinstance(inferred, nodes.ClassDef):
             return
 
         klass = utils.node_frame_class(node)
         if klass is inferred:
             # Don't emit the warning if the class is instantiated
             # in its own body or if the call is not an instance
@@ -488,14 +495,15 @@
 
             if isinstance(parent, (nodes.ClassDef, nodes.FunctionDef)):
                 break
             if (
                 isinstance(parent, nodes.TryFinally)
                 and node in parent.finalbody
                 and isinstance(node, nodes.Continue)
+                and not self._py38_plus
             ):
                 self.add_message("continue-in-finally", node=node)
 
         self.add_message("not-in-loop", node=node, args=node_name)
 
     def _check_redefinition(
         self, redeftype: str, node: nodes.Call | nodes.FunctionDef
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base/comparison_checker.py` & `pylint-3.0.0a6/pylint/checkers/base/comparison_checker.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Comparison checker from the basic checker."""
 
 import astroid
 from astroid import nodes
 
 from pylint.checkers import utils
@@ -44,15 +44,15 @@
             "The idiomatic way to perform an explicit typecheck in "
             "Python is to use isinstance(x, Y) rather than "
             "type(x) == Y, type(x) is Y. Though there are unusual "
             "situations where these give different results.",
             {"old_names": [("W0154", "old-unidiomatic-typecheck")]},
         ),
         "R0123": (
-            "Comparison to literal",
+            "In '%s', use '%s' when comparing constant literals not '%s' ('%s')",
             "literal-comparison",
             "Used when comparing an object to a literal, which is usually "
             "what you do not want to do, since you can compare to a different "
             "literal than what was expected altogether.",
         ),
         "R0124": (
             "Redundant comparison - %s",
@@ -72,37 +72,31 @@
             "This message is emitted when pylint detects that a comparison with a "
             "callable was made, which might suggest that some parenthesis were omitted, "
             "resulting in potential unwanted behaviour.",
         ),
         "W0177": (
             "Comparison %s should be %s",
             "nan-comparison",
-            "Used when an expression is compared to NaN"
-            "values like numpy.NaN and float('nan')",
+            "Used when an expression is compared to NaN "
+            "values like numpy.NaN and float('nan').",
         ),
     }
 
     def _check_singleton_comparison(
         self,
         left_value: nodes.NodeNG,
         right_value: nodes.NodeNG,
         root_node: nodes.Compare,
         checking_for_absence: bool = False,
     ) -> None:
         """Check if == or != is being used to compare a singleton value."""
-        singleton_values = (True, False, None)
 
-        def _is_singleton_const(node: nodes.NodeNG) -> bool:
-            return isinstance(node, nodes.Const) and any(
-                node.value is value for value in singleton_values
-            )
-
-        if _is_singleton_const(left_value):
+        if utils.is_singleton_const(left_value):
             singleton, other_value = left_value.value, right_value
-        elif _is_singleton_const(right_value):
+        elif utils.is_singleton_const(right_value):
             singleton, other_value = right_value.value, left_value
         else:
             return
 
         singleton_comparison_example = {False: "'{} is {}'", True: "'{} is not {}'"}
 
         # True/False singletons have a special-cased message in case the user is
@@ -197,15 +191,35 @@
         if isinstance(literal, nodes.Const):
             if isinstance(literal.value, bool) or literal.value is None:
                 # Not interested in these values.
                 return
             is_const = isinstance(literal.value, (bytes, str, int, float))
 
         if is_const or is_other_literal:
-            self.add_message("literal-comparison", node=node)
+            incorrect_node_str = node.as_string()
+            if "is not" in incorrect_node_str:
+                equal_or_not_equal = "!="
+                is_or_is_not = "is not"
+            else:
+                equal_or_not_equal = "=="
+                is_or_is_not = "is"
+            fixed_node_str = incorrect_node_str.replace(
+                is_or_is_not, equal_or_not_equal
+            )
+            self.add_message(
+                "literal-comparison",
+                args=(
+                    incorrect_node_str,
+                    equal_or_not_equal,
+                    is_or_is_not,
+                    fixed_node_str,
+                ),
+                node=node,
+                confidence=HIGH,
+            )
 
     def _check_logical_tautology(self, node: nodes.Compare) -> None:
         """Check if identifier is compared against itself.
 
         :param node: Compare node
         :Example:
         val = 786
@@ -226,16 +240,16 @@
             left_operand = left_operand.name
             right_operand = right_operand.name
 
         if left_operand == right_operand:
             suggestion = f"{left_operand} {operator} {right_operand}"
             self.add_message("comparison-with-itself", node=node, args=(suggestion,))
 
-    def _check_two_literals_being_compared(self, node: nodes.Compare) -> None:
-        """Check if two literals are being compared; this is always a logical tautology."""
+    def _check_constants_comparison(self, node: nodes.Compare) -> None:
+        """When two constants are being compared it is always a logical tautology."""
         left_operand = node.left
         if not isinstance(left_operand, nodes.Const):
             return
 
         right_operand = node.ops[0][1]
         if not isinstance(right_operand, nodes.Const):
             return
@@ -280,15 +294,15 @@
         "comparison-with-callable",
         "nan-comparison",
     )
     def visit_compare(self, node: nodes.Compare) -> None:
         self._check_callable_comparison(node)
         self._check_logical_tautology(node)
         self._check_unidiomatic_typecheck(node)
-        self._check_two_literals_being_compared(node)
+        self._check_constants_comparison(node)
         # NOTE: this checker only works with binary comparisons like 'x == 42'
         # but not 'x == y == 42'
         if len(node.ops) != 1:
             return
 
         left = node.left
         operator, right = node.ops[0]
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base/docstring_checker.py` & `pylint-3.0.0a6/pylint/checkers/base/docstring_checker.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Docstring checker from the basic checker."""
 
 from __future__ import annotations
 
 import re
 import sys
@@ -55,29 +55,29 @@
             "Used when a module, function, class or method has an empty "
             "docstring (it would be too easy ;).",
             {"old_names": [("W0132", "old-empty-docstring")]},
         ),
         "C0114": (
             "Missing module docstring",
             "missing-module-docstring",
-            "Used when a module has no docstring."
+            "Used when a module has no docstring. "
             "Empty modules do not require a docstring.",
             {"old_names": [("C0111", "missing-docstring")]},
         ),
         "C0115": (
             "Missing class docstring",
             "missing-class-docstring",
-            "Used when a class has no docstring."
+            "Used when a class has no docstring. "
             "Even an empty class must have a docstring.",
             {"old_names": [("C0111", "missing-docstring")]},
         ),
         "C0116": (
             "Missing function or method docstring",
             "missing-function-docstring",
-            "Used when a function or method has no docstring."
+            "Used when a function or method has no docstring. "
             "Some special methods like __init__ do not require a "
             "docstring.",
             {"old_names": [("C0111", "missing-docstring")]},
         ),
     }
     options = (
         (
@@ -104,24 +104,24 @@
             },
         ),
     )
 
     def open(self) -> None:
         self.linter.stats.reset_undocumented()
 
-    @utils.only_required_for_messages("missing-docstring", "empty-docstring")
+    @utils.only_required_for_messages("missing-module-docstring", "empty-docstring")
     def visit_module(self, node: nodes.Module) -> None:
         self._check_docstring("module", node)
 
-    @utils.only_required_for_messages("missing-docstring", "empty-docstring")
+    @utils.only_required_for_messages("missing-class-docstring", "empty-docstring")
     def visit_classdef(self, node: nodes.ClassDef) -> None:
         if self.linter.config.no_docstring_rgx.match(node.name) is None:
             self._check_docstring("class", node)
 
-    @utils.only_required_for_messages("missing-docstring", "empty-docstring")
+    @utils.only_required_for_messages("missing-function-docstring", "empty-docstring")
     def visit_functiondef(self, node: nodes.FunctionDef) -> None:
         if self.linter.config.no_docstring_rgx.match(node.name) is None:
             ftype = "method" if node.is_method() else "function"
             if (
                 is_property_setter(node)
                 or is_property_deleter(node)
                 or is_overload_stub(node)
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base/name_checker/__init__.py` & `pylint-3.0.0a6/pylint/checkers/base/name_checker/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 __all__ = [
     "NameChecker",
     "NamingStyle",
     "KNOWN_NAME_TYPES_WITH_STYLE",
     "SnakeCaseStyle",
     "CamelCaseStyle",
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base/name_checker/checker.py` & `pylint-3.0.0a6/pylint/checkers/base/name_checker/checker.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Basic checker for Python code."""
 
 from __future__ import annotations
 
 import argparse
 import collections
@@ -35,20 +35,28 @@
     from pylint.lint.pylinter import PyLinter
 
 _BadNamesTuple = Tuple[nodes.NodeNG, str, str, interfaces.Confidence]
 
 # Default patterns for name types that do not have styles
 DEFAULT_PATTERNS = {
     "typevar": re.compile(
-        r"^_{0,2}(?:[^\W\da-z_]+|(?:[^\W\da-z_]+[^\WA-Z_]+)+T?(?<!Type))(?:_co(?:ntra)?)?$"
-    )
+        r"^_{0,2}(?!T[A-Z])(?:[A-Z]+|(?:[A-Z]+[a-z]+)+T?(?<!Type))(?:_co(?:ntra)?)?$"
+    ),
+    "typealias": re.compile(
+        r"^_{0,2}(?!T[A-Z]|Type)[A-Z]+[a-z0-9]+(?:[A-Z][a-z0-9]+)*$"
+    ),
 }
 
 BUILTIN_PROPERTY = "builtins.property"
-TYPING_TYPE_VAR_QNAME = "typing.TypeVar"
+TYPE_VAR_QNAME = frozenset(
+    (
+        "typing.TypeVar",
+        "typing_extensions.TypeVar",
+    )
+)
 
 
 class TypeVarVariance(Enum):
     invariant = auto()
     covariant = auto()
     contravariant = auto()
     double_variant = auto()
@@ -333,15 +341,15 @@
             prevalent_group, _ = max(all_groups.items(), key=lambda item: len(item[1]))
             for group in all_groups.values():
                 groups[len(group)].append(group)
                 min_warnings = min(len(group), min_warnings)
             if len(groups[min_warnings]) > 1:
                 by_line = sorted(
                     groups[min_warnings],
-                    key=lambda group: min(
+                    key=lambda group: min(  # type: ignore[no-any-return]
                         warning[0].lineno
                         for warning in group
                         if warning[0].lineno is not None
                     ),
                 )
                 warnings: Iterable[_BadNamesTuple] = itertools.chain(*by_line[1:])
             else:
@@ -379,91 +387,107 @@
         # Check argument names
         args = node.args.args
         if args is not None:
             self._recursive_check_names(args)
 
     visit_asyncfunctiondef = visit_functiondef
 
-    @utils.only_required_for_messages("disallowed-name", "invalid-name")
-    def visit_global(self, node: nodes.Global) -> None:
-        for name in node.names:
-            self._check_name("const", name, node)
-
     @utils.only_required_for_messages(
         "disallowed-name",
         "invalid-name",
         "typevar-name-incorrect-variance",
         "typevar-double-variance",
         "typevar-name-mismatch",
     )
-    def visit_assignname(self, node: nodes.AssignName) -> None:
+    def visit_assignname(  # pylint: disable=too-many-branches
+        self, node: nodes.AssignName
+    ) -> None:
         """Check module level assigned names."""
         frame = node.frame(future=True)
         assign_type = node.assign_type()
 
         # Check names defined in comprehensions
         if isinstance(assign_type, nodes.Comprehension):
             self._check_name("inlinevar", node.name, node)
 
         # Check names defined in module scope
         elif isinstance(frame, nodes.Module):
             # Check names defined in Assign nodes
             if isinstance(assign_type, nodes.Assign):
                 inferred_assign_type = utils.safe_infer(assign_type.value)
 
-                # Check TypeVar's assigned alone or in tuple assignment
-                if isinstance(node.parent, nodes.Assign) and self._assigns_typevar(
-                    assign_type.value
-                ):
-                    self._check_name("typevar", assign_type.targets[0].name, node)
-                elif (
+                # Check TypeVar's and TypeAliases assigned alone or in tuple assignment
+                if isinstance(node.parent, nodes.Assign):
+                    if self._assigns_typevar(assign_type.value):
+                        self._check_name("typevar", assign_type.targets[0].name, node)
+                        return
+                    if self._assigns_typealias(assign_type.value):
+                        self._check_name("typealias", assign_type.targets[0].name, node)
+                        return
+
+                if (
                     isinstance(node.parent, nodes.Tuple)
                     and isinstance(assign_type.value, nodes.Tuple)
                     # protect against unbalanced tuple unpacking
                     and node.parent.elts.index(node) < len(assign_type.value.elts)
-                    and self._assigns_typevar(
-                        assign_type.value.elts[node.parent.elts.index(node)]
-                    )
                 ):
-                    self._check_name(
-                        "typevar",
-                        assign_type.targets[0].elts[node.parent.elts.index(node)].name,
-                        node,
-                    )
+                    assigner = assign_type.value.elts[node.parent.elts.index(node)]
+                    if self._assigns_typevar(assigner):
+                        self._check_name(
+                            "typevar",
+                            assign_type.targets[0]
+                            .elts[node.parent.elts.index(node)]
+                            .name,
+                            node,
+                        )
+                        return
+                    if self._assigns_typealias(assigner):
+                        self._check_name(
+                            "typealias",
+                            assign_type.targets[0]
+                            .elts[node.parent.elts.index(node)]
+                            .name,
+                            node,
+                        )
+                        return
 
                 # Check classes (TypeVar's are classes so they need to be excluded first)
                 elif isinstance(inferred_assign_type, nodes.ClassDef):
                     self._check_name("class", node.name, node)
 
                 # Don't emit if the name redefines an import in an ImportError except handler.
                 elif not _redefines_import(node) and isinstance(
                     inferred_assign_type, nodes.Const
                 ):
                     self._check_name("const", node.name, node)
+                else:
+                    self._check_name(
+                        "variable", node.name, node, disallowed_check_only=True
+                    )
+
             # Check names defined in AnnAssign nodes
-            elif isinstance(
-                assign_type, nodes.AnnAssign
-            ) and utils.is_assign_name_annotated_with(node, "Final"):
-                self._check_name("const", node.name, node)
+            elif isinstance(assign_type, nodes.AnnAssign):
+                if utils.is_assign_name_annotated_with(node, "Final"):
+                    self._check_name("const", node.name, node)
+                elif self._assigns_typealias(assign_type.annotation):
+                    self._check_name("typealias", node.name, node)
 
         # Check names defined in function scopes
         elif isinstance(frame, nodes.FunctionDef):
             # global introduced variable aren't in the function locals
             if node.name in frame and node.name not in frame.argnames():
                 if not _redefines_import(node):
                     self._check_name("variable", node.name, node)
 
         # Check names defined in class scopes
         elif isinstance(frame, nodes.ClassDef):
             if not list(frame.local_attr_ancestors(node.name)):
                 for ancestor in frame.ancestors():
-                    if (
-                        ancestor.name == "Enum"
-                        and ancestor.root().name == "enum"
-                        or utils.is_assign_name_annotated_with(node, "Final")
+                    if utils.is_enum(ancestor) or utils.is_assign_name_annotated_with(
+                        node, "Final"
                     ):
                         self._check_name("class_const", node.name, node)
                         break
                 else:
                     self._check_name("class_attribute", node.name, node)
 
     def _recursive_check_names(self, args: list[nodes.AssignName]) -> None:
@@ -513,59 +537,84 @@
 
     def _check_name(
         self,
         node_type: str,
         name: str,
         node: nodes.NodeNG,
         confidence: interfaces.Confidence = interfaces.HIGH,
+        disallowed_check_only: bool = False,
     ) -> None:
         """Check for a name using the type's regexp."""
 
         def _should_exempt_from_invalid_name(node: nodes.NodeNG) -> bool:
             if node_type == "variable":
                 inferred = utils.safe_infer(node)
                 if isinstance(inferred, nodes.ClassDef):
                     return True
             return False
 
         if self._name_allowed_by_regex(name=name):
             return
         if self._name_disallowed_by_regex(name=name):
             self.linter.stats.increase_bad_name(node_type, 1)
-            self.add_message("disallowed-name", node=node, args=name)
+            self.add_message(
+                "disallowed-name", node=node, args=name, confidence=interfaces.HIGH
+            )
             return
         regexp = self._name_regexps[node_type]
         match = regexp.match(name)
 
         if _is_multi_naming_match(match, node_type, confidence):
             name_group = self._find_name_group(node_type)
             bad_name_group = self._bad_names.setdefault(name_group, {})
             # Ignored because this is checked by the if statement
             warnings = bad_name_group.setdefault(match.lastgroup, [])  # type: ignore[union-attr, arg-type]
             warnings.append((node, node_type, name, confidence))
 
-        if match is None and not _should_exempt_from_invalid_name(node):
+        if (
+            match is None
+            and not disallowed_check_only
+            and not _should_exempt_from_invalid_name(node)
+        ):
             self._raise_name_warning(None, node, node_type, name, confidence)
 
         # Check TypeVar names for variance suffixes
         if node_type == "typevar":
             self._check_typevar(name, node)
 
     @staticmethod
     def _assigns_typevar(node: nodes.NodeNG | None) -> bool:
         """Check if a node is assigning a TypeVar."""
         if isinstance(node, astroid.Call):
             inferred = utils.safe_infer(node.func)
             if (
                 isinstance(inferred, astroid.ClassDef)
-                and inferred.qname() == TYPING_TYPE_VAR_QNAME
+                and inferred.qname() in TYPE_VAR_QNAME
             ):
                 return True
         return False
 
+    @staticmethod
+    def _assigns_typealias(node: nodes.NodeNG | None) -> bool:
+        """Check if a node is assigning a TypeAlias."""
+        inferred = utils.safe_infer(node)
+        if isinstance(inferred, nodes.ClassDef):
+            if inferred.qname() == ".Union":
+                # Union is a special case because it can be used as a type alias
+                # or as a type annotation. We only want to check the former.
+                assert node is not None
+                return not (
+                    isinstance(node.parent, nodes.AnnAssign)
+                    and node.parent.value is not None
+                )
+        elif isinstance(inferred, nodes.FunctionDef):
+            if inferred.qname() == "typing.TypeAlias":
+                return True
+        return False
+
     def _check_typevar(self, name: str, node: nodes.AssignName) -> None:
         """Check for TypeVar lint violations."""
         if isinstance(node.parent, nodes.Assign):
             keywords = node.assign_type().value.keywords
             args = node.assign_type().value.args
         elif isinstance(node.parent, nodes.Tuple):
             keywords = (
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base/name_checker/naming_style.py` & `pylint-3.0.0a6/pylint/checkers/base/name_checker/naming_style.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import re
 from re import Pattern
 
 from pylint import constants
@@ -133,27 +133,31 @@
 }
 
 
 # Name types that have a 'rgx' option
 KNOWN_NAME_TYPES = {
     *KNOWN_NAME_TYPES_WITH_STYLE,
     "typevar",
+    "typealias",
 }
 
 
 def _create_naming_options() -> Options:
     name_options: list[tuple[str, OptionDict]] = []
     for name_type in sorted(KNOWN_NAME_TYPES):
         human_readable_name = constants.HUMAN_READABLE_TYPES[name_type]
         name_type_hyphened = name_type.replace("_", "-")
 
         help_msg = f"Regular expression matching correct {human_readable_name} names. "
         if name_type in KNOWN_NAME_TYPES_WITH_STYLE:
             help_msg += f"Overrides {name_type_hyphened}-naming-style. "
-        help_msg += f"If left empty, {human_readable_name} names will be checked with the set naming style."
+        help_msg += (
+            f"If left empty, {human_readable_name} names will be checked "
+            "with the set naming style."
+        )
 
         # Add style option for names that support it
         if name_type in KNOWN_NAME_TYPES_WITH_STYLE:
             default_style = DEFAULT_NAMING_STYLES[name_type]
             name_options.append(
                 (
                     f"{name_type_hyphened}-naming-style",
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base/pass_checker.py` & `pylint-3.0.0a6/pylint/checkers/base/pass_checker.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from astroid import nodes
 
 from pylint.checkers import utils
 from pylint.checkers.base.basic_checker import _BasicChecker
```

### Comparing `pylint-3.0.0a5/pylint/checkers/base_checker.py` & `pylint-3.0.0a6/pylint/checkers/base_checker.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,27 +1,26 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import abc
 import functools
-import warnings
-from collections.abc import Iterator
+from collections.abc import Iterable, Sequence
 from inspect import cleandoc
 from tokenize import TokenInfo
 from typing import TYPE_CHECKING, Any
 
 from astroid import nodes
 
 from pylint.config.arguments_provider import _ArgumentsProvider
 from pylint.constants import _MSG_ORDER, MAIN_CHECKER_NAME, WarningScope
 from pylint.exceptions import InvalidMessageError
-from pylint.interfaces import Confidence, IRawChecker, ITokenChecker, implements
+from pylint.interfaces import Confidence
 from pylint.message.message_definition import MessageDefinition
 from pylint.typing import (
     ExtraMessageOptions,
     MessageDefinitionTuple,
     OptionDict,
     Options,
     ReportsCallable,
@@ -30,39 +29,30 @@
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
 @functools.total_ordering
 class BaseChecker(_ArgumentsProvider):
-
     # checker name (you may reuse an existing one)
     name: str = ""
     # ordered list of options to control the checker behaviour
     options: Options = ()
     # messages issued by this checker
     msgs: dict[str, MessageDefinitionTuple] = {}
     # reports issued by this checker
     reports: tuple[tuple[str, str, ReportsCallable], ...] = ()
     # mark this checker as enabled or not.
     enabled: bool = True
 
     def __init__(self, linter: PyLinter) -> None:
         """Checker instances should have the linter as argument."""
-        if getattr(self, "__implements__", None):
-            warnings.warn(
-                "Using the __implements__ inheritance pattern for BaseChecker is no "
-                "longer supported. Child classes should only inherit BaseChecker or any "
-                "of the other checker types from pylint.checkers.",
-                DeprecationWarning,
-            )
         if self.name is not None:
             self.name = self.name.lower()
         self.linter = linter
-
         _ArgumentsProvider.__init__(self, linter)
 
     def __gt__(self, other: Any) -> bool:
         """Sorting of checkers."""
         if not isinstance(other, BaseChecker):
             return False
         if self.name == MAIN_CHECKER_NAME:
@@ -92,27 +82,26 @@
 
     def __str__(self) -> str:
         """This might be incomplete because multiple classes inheriting BaseChecker
         can have the same name.
 
         See: MessageHandlerMixIn.get_full_documentation()
         """
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", category=DeprecationWarning)
-            return self.get_full_documentation(
-                msgs=self.msgs, options=self.options_and_values(), reports=self.reports
-            )
+        return self.get_full_documentation(
+            msgs=self.msgs, options=self._options_and_values(), reports=self.reports
+        )
 
     def get_full_documentation(
         self,
         msgs: dict[str, MessageDefinitionTuple],
-        options: Iterator[tuple[str, OptionDict, Any]],
-        reports: tuple[tuple[str, str, ReportsCallable], ...],
+        options: Iterable[tuple[str, OptionDict, Any]],
+        reports: Sequence[tuple[str, str, ReportsCallable]],
         doc: str | None = None,
         module: str | None = None,
+        show_options: bool = True,
     ) -> str:
         result = ""
         checker_title = f"{self.name.replace('_', ' ').title()} checker"
         if module:
             # Provide anchor to link against
             result += f".. _{module}:\n\n"
         result += f"{get_rst_title(checker_title, '~')}\n"
@@ -122,16 +111,19 @@
         if doc:
             # Provide anchor to link against
             result += get_rst_title(f"{checker_title} Documentation", "^")
             result += f"{cleandoc(doc)}\n\n"
         # options might be an empty generator and not be False when cast to boolean
         options_list = list(options)
         if options_list:
-            result += get_rst_title(f"{checker_title} Options", "^")
-            result += f"{get_rst_section(None, options_list)}\n"
+            if show_options:
+                result += get_rst_title(f"{checker_title} Options", "^")
+                result += f"{get_rst_section(None, options_list)}\n"
+            else:
+                result += f"See also :ref:`{self.name} checker's options' documentation <{self.name}-options>`\n\n"
         if msgs:
             result += get_rst_title(f"{checker_title} Messages", "^")
             for msgid, msg in sorted(
                 msgs.items(), key=lambda kv: (_MSG_ORDER.index(kv[0][0]), kv[1])
             ):
                 msg_def = self.create_message_definition_from_tuple(msgid, msg)
                 result += f"{msg_def.format_help(checkerref=False)}\n"
@@ -170,40 +162,33 @@
 
         :raises InvalidMessageError: If the checker id in the messages are not
         always the same.
         """
         checker_id = None
         existing_ids = []
         for message in self.messages:
+            # Id's for shared messages such as the 'deprecated-*' messages
+            # can be inconsistent with their checker id.
+            if message.shared:
+                continue
             if checker_id is not None and checker_id != message.msgid[1:3]:
                 error_msg = "Inconsistent checker part in message id "
                 error_msg += f"'{message.msgid}' (expected 'x{checker_id}xx' "
                 error_msg += f"because we already had {existing_ids})."
                 raise InvalidMessageError(error_msg)
             checker_id = message.msgid[1:3]
             existing_ids.append(message.msgid)
 
     def create_message_definition_from_tuple(
         self, msgid: str, msg_tuple: MessageDefinitionTuple
     ) -> MessageDefinition:
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", category=DeprecationWarning)
-            if isinstance(self, (BaseTokenChecker, BaseRawFileChecker)):
-                default_scope = WarningScope.LINE
-            # TODO: 3.0: Remove deprecated if-statement
-            elif implements(self, (IRawChecker, ITokenChecker)):
-                warnings.warn(  # pragma: no cover
-                    "Checkers should subclass BaseTokenChecker or BaseRawFileChecker"
-                    "instead of using the __implements__ mechanism. Use of __implements__"
-                    "will no longer be supported in pylint 3.0",
-                    DeprecationWarning,
-                )
-                default_scope = WarningScope.LINE  # pragma: no cover
-            else:
-                default_scope = WarningScope.NODE
+        if isinstance(self, (BaseTokenChecker, BaseRawFileChecker)):
+            default_scope = WarningScope.LINE
+        else:
+            default_scope = WarningScope.NODE
         options: ExtraMessageOptions = {}
         if len(msg_tuple) == 4:
             (msg, symbol, descr, options) = msg_tuple  # type: ignore[misc]
         elif len(msg_tuple) == 3:
             (msg, symbol, descr) = msg_tuple  # type: ignore[misc]
         else:
             error_msg = """Messages should have a msgid, a symbol and a description. Something like this :
@@ -222,22 +207,14 @@
     @property
     def messages(self) -> list[MessageDefinition]:
         return [
             self.create_message_definition_from_tuple(msgid, msg_tuple)
             for msgid, msg_tuple in sorted(self.msgs.items())
         ]
 
-    def get_message_definition(self, msgid: str) -> MessageDefinition:
-        for message_definition in self.messages:
-            if message_definition.msgid == msgid:
-                return message_definition
-        error_msg = f"MessageDefinition for '{msgid}' does not exists. "
-        error_msg += f"Choose from {[m.msgid for m in self.messages]}."
-        raise InvalidMessageError(error_msg)
-
     def open(self) -> None:
         """Called before visiting project (i.e. set of modules)."""
 
     def close(self) -> None:
         """Called after visiting project (i.e set of modules)."""
 
     def get_map_data(self) -> Any:
```

### Comparing `pylint-3.0.0a5/pylint/checkers/classes/__init__.py` & `pylint-3.0.0a6/pylint/checkers/classes/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from pylint.checkers.classes.class_checker import ClassChecker
 from pylint.checkers.classes.special_methods_checker import SpecialMethodsChecker
```

### Comparing `pylint-3.0.0a5/pylint/checkers/classes/class_checker.py` & `pylint-3.0.0a6/pylint/checkers/classes/class_checker.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,27 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Classes checker for Python code."""
 
 from __future__ import annotations
 
 import collections
 import sys
+from collections import defaultdict
+from collections.abc import Callable, Sequence
 from itertools import chain, zip_longest
 from re import Pattern
+from typing import TYPE_CHECKING, Any, Union
 
 import astroid
-from astroid import bases, nodes
+from astroid import bases, nodes, util
+from astroid.nodes import LocalsDictNodeNG
+from astroid.typing import SuccessfulInferenceResult
 
 from pylint.checkers import BaseChecker, utils
 from pylint.checkers.utils import (
     PYMETHODS,
     class_is_abstract,
     decorated_with,
     decorated_with_property,
@@ -34,19 +39,25 @@
     safe_infer,
     unimplemented_abstract_methods,
     uninferable_final_decorators,
 )
 from pylint.interfaces import HIGH, INFERENCE
 from pylint.typing import MessageDefinitionTuple
 
+if TYPE_CHECKING:
+    from pylint.lint.pylinter import PyLinter
+
+
 if sys.version_info >= (3, 8):
     from functools import cached_property
 else:
     from astroid.decorators import cachedproperty as cached_property
 
+_AccessNodes = Union[nodes.Attribute, nodes.AssignAttr]
+
 INVALID_BASE_CLASSES = {"bool", "range", "slice", "memoryview"}
 BUILTIN_DECORATORS = {"builtins.property", "builtins.classmethod"}
 ASTROID_TYPE_COMPARATORS = {
     nodes.Const: lambda a, b: a.value == b.value,
     nodes.ClassDef: lambda a, b: a.qname == b.qname,
     nodes.Tuple: lambda a, b: a.elts == b.elts,
     nodes.List: lambda a, b: a.elts == b.elts,
@@ -61,23 +72,23 @@
     "_CallSignature", "args kws starred_args starred_kws"
 )
 _ParameterSignature = collections.namedtuple(
     "_ParameterSignature", "args kwonlyargs varargs kwargs"
 )
 
 
-def _signature_from_call(call):
+def _signature_from_call(call: nodes.Call) -> _CallSignature:
     kws = {}
     args = []
     starred_kws = []
     starred_args = []
     for keyword in call.keywords or []:
         arg, value = keyword.arg, keyword.value
         if arg is None and isinstance(value, nodes.Name):
-            # Starred node and we are interested only in names,
+            # Starred node, and we are interested only in names,
             # otherwise some transformation might occur for the parameter.
             starred_kws.append(value.name)
         elif isinstance(value, nodes.Name):
             kws[arg] = value.name
         else:
             kws[arg] = None
 
@@ -90,27 +101,29 @@
             args.append(arg.name)
         else:
             args.append(None)
 
     return _CallSignature(args, kws, starred_args, starred_kws)
 
 
-def _signature_from_arguments(arguments):
+def _signature_from_arguments(arguments: nodes.Arguments) -> _ParameterSignature:
     kwarg = arguments.kwarg
     vararg = arguments.vararg
     args = [
         arg.name
         for arg in chain(arguments.posonlyargs, arguments.args)
         if arg.name != "self"
     ]
     kwonlyargs = [arg.name for arg in arguments.kwonlyargs]
     return _ParameterSignature(args, kwonlyargs, vararg, kwarg)
 
 
-def _definition_equivalent_to_call(definition, call):
+def _definition_equivalent_to_call(
+    definition: _ParameterSignature, call: _CallSignature
+) -> bool:
     """Check if a definition signature is equivalent to a call."""
     if definition.kwargs:
         if definition.kwargs not in call.starred_kws:
             return False
     elif call.starred_kws:
         return False
     if definition.varargs:
@@ -179,29 +192,31 @@
 
     return True
 
 
 # Deal with parameters overriding in two methods.
 
 
-def _positional_parameters(method):
+def _positional_parameters(method: nodes.FunctionDef) -> list[nodes.AssignName]:
     positional = method.args.args
     if method.is_bound() and method.type in {"classmethod", "method"}:
         positional = positional[1:]
-    return positional
+    return positional  # type: ignore[no-any-return]
 
 
 class _DefaultMissing:
     """Sentinel value for missing arg default, use _DEFAULT_MISSING."""
 
 
 _DEFAULT_MISSING = _DefaultMissing()
 
 
-def _has_different_parameters_default_value(original, overridden):
+def _has_different_parameters_default_value(
+    original: nodes.Arguments, overridden: nodes.Arguments
+) -> bool:
     """Check if original and overridden methods arguments have different default values.
 
     Return True if one of the overridden arguments has a default
     value different from the default value of the original argument
     If one of the method doesn't have argument (.args is None)
     return False
     """
@@ -225,28 +240,30 @@
             # Only the override has a default.
             return True
 
         original_type = type(original_default)
         if not isinstance(overridden_default, original_type):
             # Two args with same name but different types
             return True
-        is_same_fn = ASTROID_TYPE_COMPARATORS.get(original_type)
+        is_same_fn: Callable[[Any, Any], bool] | None = ASTROID_TYPE_COMPARATORS.get(
+            original_type
+        )
         if is_same_fn is None:
             # If the default value comparison is unhandled, assume the value is different
             return True
         if not is_same_fn(original_default, overridden_default):
             # Two args with same type but different values
             return True
     return False
 
 
 def _has_different_parameters(
     original: list[nodes.AssignName],
     overridden: list[nodes.AssignName],
-    dummy_parameter_regex: Pattern,
+    dummy_parameter_regex: Pattern[str],
 ) -> list[str]:
     result: list[str] = []
     zipped = zip_longest(original, overridden)
     for original_param, overridden_param in zipped:
         if not overridden_param:
             return ["Number of parameters "]
 
@@ -292,15 +309,15 @@
 
     return []
 
 
 def _different_parameters(
     original: nodes.FunctionDef,
     overridden: nodes.FunctionDef,
-    dummy_parameter_regex: Pattern,
+    dummy_parameter_regex: Pattern[str],
 ) -> list[str]:
     """Determine if the two methods have different parameters.
 
     They are considered to have different parameters if:
 
        * they have different positional parameters, including different names
 
@@ -366,19 +383,19 @@
 
     if kwarg_lost or vararg_lost:
         output_messages += ["Variadics removed in"]
 
     return output_messages
 
 
-def _is_invalid_base_class(cls):
+def _is_invalid_base_class(cls: nodes.ClassDef) -> bool:
     return cls.name in INVALID_BASE_CLASSES and is_builtin_object(cls)
 
 
-def _has_data_descriptor(cls, attr):
+def _has_data_descriptor(cls: nodes.ClassDef, attr: str) -> bool:
     attributes = cls.getattr(attr)
     for attribute in attributes:
         try:
             for inferred in attribute.infer():
                 if isinstance(inferred, astroid.Instance):
                     try:
                         inferred.getattr("__get__")
@@ -389,15 +406,19 @@
                         return True
         except astroid.InferenceError:
             # Can't infer, avoid emitting a false positive in this case.
             return True
     return False
 
 
-def _called_in_methods(func, klass, methods):
+def _called_in_methods(
+    func: LocalsDictNodeNG,
+    klass: nodes.ClassDef,
+    methods: Sequence[str],
+) -> bool:
     """Check if the func was called in any of the given methods,
     belonging to the *klass*.
 
     Returns True if so, False otherwise.
     """
     if not isinstance(func, nodes.FunctionDef):
         return False
@@ -418,15 +439,15 @@
                 if isinstance(func_obj, astroid.UnboundMethod):
                     func_obj = func_obj._proxied
                 if func_obj.name == func.name:
                     return True
     return False
 
 
-def _is_attribute_property(name, klass):
+def _is_attribute_property(name: str, klass: nodes.ClassDef) -> bool:
     """Check if the given attribute *name* is a property in the given *klass*.
 
     It will look for `property` calls or for functions
     with the given name, decorated by `property` or `property`
     subclasses.
     Returns ``True`` if the name is a property in the given klass,
     ``False`` otherwise.
@@ -434,15 +455,15 @@
 
     try:
         attributes = klass.getattr(name)
     except astroid.NotFoundError:
         return False
     property_name = "builtins.property"
     for attr in attributes:
-        if attr is astroid.Uninferable:
+        if isinstance(attr, util.UninferableBase):
             continue
         try:
             inferred = next(attr.infer())
         except astroid.InferenceError:
             continue
         if isinstance(inferred, nodes.FunctionDef) and decorated_with_property(
             inferred
@@ -454,29 +475,29 @@
         cls = node_frame_class(inferred)
         if cls == klass.declared_metaclass():
             continue
         return True
     return False
 
 
-def _has_same_layout_slots(slots, assigned_value):
+def _has_same_layout_slots(
+    slots: list[nodes.Const | None], assigned_value: nodes.Name
+) -> bool:
     inferred = next(assigned_value.infer())
     if isinstance(inferred, nodes.ClassDef):
         other_slots = inferred.slots()
         if all(
             first_slot and second_slot and first_slot.value == second_slot.value
             for (first_slot, second_slot) in zip_longest(slots, other_slots)
         ):
             return True
     return False
 
 
-MSGS: dict[
-    str, MessageDefinitionTuple
-] = {  # pylint: disable=consider-using-namedtuple-or-dataclass
+MSGS: dict[str, MessageDefinitionTuple] = {
     "F0202": (
         "Unable to check methods signature (%s / %s)",
         "method-check-failed",
         "Used when Pylint has been unable to check methods signature "
         "compatibility for an unexpected reason. Please report this kind "
         "if you don't make sense of it.",
     ),
@@ -500,22 +521,28 @@
     "W0212": (
         "Access to a protected member %s of a client class",  # E0214
         "protected-access",
         "Used when a protected member (i.e. class member with a name "
         "beginning with an underscore) is access outside the class or a "
         "descendant of the class where it's defined.",
     ),
+    "W0213": (
+        "Flag member %(overlap)s shares bit positions with %(sources)s",
+        "implicit-flag-alias",
+        "Used when multiple integer values declared within an enum.IntFlag "
+        "class share a common bit position.",
+    ),
     "E0211": (
-        "Method has no argument",
+        "Method %r has no argument",
         "no-method-argument",
         "Used when a method which should have the bound instance as "
         "first argument has no argument defined.",
     ),
     "E0213": (
-        'Method should have "self" as first argument',
+        'Method %r should have "self" as first argument',
         "no-self-argument",
         'Used when a method has an attribute different the "self" as '
         "first argument. This is considered as an error since this is "
         "a so common convention that you shouldn't break it!",
     ),
     "C0202": (
         "Class method %s should have %s as first argument",
@@ -558,15 +585,15 @@
     "W0222": (
         "Signature differs from %s %r method",
         "signature-differs",
         "Used when a method signature is different than in the "
         "implemented interface or in an overridden method.",
     ),
     "W0223": (
-        "Method %r is abstract in class %r but is not overridden",
+        "Method %r is abstract in class %r but is not overridden in child class %r",
         "abstract-method",
         "Used when an abstract method (i.e. raise NotImplementedError) is "
         "not overridden in concrete class.",
     ),
     "W0231": (
         "__init__ method from base class %r is not called",
         "super-init-not-called",
@@ -575,20 +602,21 @@
     ),
     "W0233": (
         "__init__ method from a non direct base class %r is called",
         "non-parent-init-called",
         "Used when an __init__ method is called on a class which is not "
         "in the direct ancestors for the analysed class.",
     ),
-    "W0235": (
-        "Useless super delegation in method %r",
-        "useless-super-delegation",
+    "W0246": (
+        "Useless parent or super() delegation in method %r",
+        "useless-parent-delegation",
         "Used whenever we can detect that an overridden method is useless, "
-        "relying on super() delegation to do the same thing as another method "
+        "relying on parent or super() delegation to do the same thing as another method "
         "from the MRO.",
+        {"old_names": [("W0235", "useless-super-delegation")]},
     ),
     "W0236": (
         "Method %r was expected to be %r, found it instead as %r",
         "invalid-overridden-method",
         "Used when we detect that a method was overridden in a way "
         "that does not match its base class "
         "which could result in potential bugs at runtime.",
@@ -658,15 +686,15 @@
     ),
     "E0242": (
         "Value %r in slots conflicts with class variable",
         "class-variable-slots-conflict",
         "Used when a value in __slots__ conflicts with a class variable, property or method.",
     ),
     "E0243": (
-        "Invalid __class__ object",
+        "Invalid assignment to '__class__'. Should be a class definition but got a '%s'",
         "invalid-class-object",
         "Used when an invalid object is assigned to a __class__ property. "
         "Only a class is permitted.",
     ),
     "E0244": (
         'Extending inherited Enum class "%s"',
         "invalid-enum-extension",
@@ -699,34 +727,37 @@
         "property-with-parameters",
         "Used when we detect that a property also has parameters, which are useless, "
         "given that properties cannot be called with additional arguments.",
     ),
 }
 
 
-def _scope_default():
-    return collections.defaultdict(list)
+def _scope_default() -> defaultdict[str, list[_AccessNodes]]:
+    # It's impossible to nest defaultdicts so we must use a function
+    return defaultdict(list)
 
 
 class ScopeAccessMap:
     """Store the accessed variables per scope."""
 
-    def __init__(self):
-        self._scopes = collections.defaultdict(_scope_default)
+    def __init__(self) -> None:
+        self._scopes: defaultdict[
+            nodes.ClassDef, defaultdict[str, list[_AccessNodes]]
+        ] = defaultdict(_scope_default)
 
-    def set_accessed(self, node):
+    def set_accessed(self, node: _AccessNodes) -> None:
         """Set the given node as accessed."""
 
         frame = node_frame_class(node)
         if frame is None:
             # The node does not live in a class.
             return
         self._scopes[frame][node.attrname].append(node)
 
-    def accessed(self, scope):
+    def accessed(self, scope: nodes.ClassDef) -> dict[str, list[_AccessNodes]]:
         """Get the accessed variables for the given scope."""
         return self._scopes.get(scope, {})
 
 
 class ClassChecker(BaseChecker):
     """Checker for class nodes.
 
@@ -743,15 +774,21 @@
     # messages
     msgs = MSGS
     # configuration options
     options = (
         (
             "defining-attr-methods",
             {
-                "default": ("__init__", "__new__", "setUp", "__post_init__"),
+                "default": (
+                    "__init__",
+                    "__new__",
+                    "setUp",
+                    "asyncSetUp",
+                    "__post_init__",
+                ),
                 "type": "csv",
                 "metavar": "<method names>",
                 "help": "List of method names used to declare (i.e. assign) \
 instance attributes.",
             },
         ),
         (
@@ -763,15 +800,15 @@
                 "help": "List of valid names for the first argument in \
 a class method.",
             },
         ),
         (
             "valid-metaclass-classmethod-first-arg",
             {
-                "default": ("cls",),
+                "default": ("mcs",),
                 "type": "csv",
                 "metavar": "<argument names>",
                 "help": "List of valid names for the first argument in \
 a metaclass class method.",
             },
         ),
         (
@@ -780,14 +817,15 @@
                 "default": (
                     # namedtuple public API.
                     "_asdict",
                     "_fields",
                     "_replace",
                     "_source",
                     "_make",
+                    "os._exit",
                 ),
                 "type": "csv",
                 "metavar": "<protected access exclusions>",
                 "help": (
                     "List of member names, which should be excluded "
                     "from the protected access warning."
                 ),
@@ -800,63 +838,111 @@
                 "type": "yn",
                 "metavar": "<y or n>",
                 "help": "Warn about protected attribute access inside special methods",
             },
         ),
     )
 
-    def __init__(self, linter=None):
+    def __init__(self, linter: PyLinter) -> None:
         super().__init__(linter)
         self._accessed = ScopeAccessMap()
-        self._first_attrs = []
+        self._first_attrs: list[str | None] = []
 
     def open(self) -> None:
         self._mixin_class_rgx = self.linter.config.mixin_class_rgx
         py_version = self.linter.config.py_version
         self._py38_plus = py_version >= (3, 8)
 
     @cached_property
-    def _dummy_rgx(self):
-        return self.linter.config.dummy_variables_rgx
+    def _dummy_rgx(self) -> Pattern[str]:
+        return self.linter.config.dummy_variables_rgx  # type: ignore[no-any-return]
 
     @only_required_for_messages(
         "abstract-method",
         "invalid-slots",
         "single-string-used-for-slots",
         "invalid-slots-object",
         "class-variable-slots-conflict",
         "inherit-non-class",
         "useless-object-inheritance",
         "inconsistent-mro",
         "duplicate-bases",
         "redefined-slots-in-subclass",
         "invalid-enum-extension",
         "subclassed-final-class",
+        "implicit-flag-alias",
     )
     def visit_classdef(self, node: nodes.ClassDef) -> None:
         """Init visit variable _accessed."""
         self._check_bases_classes(node)
         self._check_slots(node)
         self._check_proper_bases(node)
         self._check_typing_final(node)
         self._check_consistent_mro(node)
 
-    def _check_consistent_mro(self, node):
+    def _check_consistent_mro(self, node: nodes.ClassDef) -> None:
         """Detect that a class has a consistent mro or duplicate bases."""
         try:
             node.mro()
         except astroid.InconsistentMroError:
             self.add_message("inconsistent-mro", args=node.name, node=node)
         except astroid.DuplicateBasesError:
             self.add_message("duplicate-bases", args=node.name, node=node)
-        except NotImplementedError:
-            # Old style class, there's no mro so don't do anything.
-            pass
 
-    def _check_proper_bases(self, node):
+    def _check_enum_base(self, node: nodes.ClassDef, ancestor: nodes.ClassDef) -> None:
+        members = ancestor.getattr("__members__")
+        if members and isinstance(members[0], nodes.Dict) and members[0].items:
+            self.add_message(
+                "invalid-enum-extension",
+                args=ancestor.name,
+                node=node,
+                confidence=INFERENCE,
+            )
+
+        if ancestor.is_subtype_of("enum.IntFlag"):
+            # Collect integer flag assignments present on the class
+            assignments = defaultdict(list)
+            for assign_name in node.nodes_of_class(nodes.AssignName):
+                if isinstance(assign_name.parent, nodes.Assign):
+                    value = getattr(assign_name.parent.value, "value", None)
+                    if isinstance(value, int):
+                        assignments[value].append(assign_name)
+
+            # For each bit position, collect all the flags that set the bit
+            bit_flags = defaultdict(set)
+            for flag in assignments:
+                flag_bits = (i for i, c in enumerate(reversed(bin(flag))) if c == "1")
+                for bit in flag_bits:
+                    bit_flags[bit].add(flag)
+
+            # Collect the minimum, unique values that each flag overlaps with
+            overlaps = defaultdict(list)
+            for flags in bit_flags.values():
+                source, *conflicts = sorted(flags)
+                for conflict in conflicts:
+                    overlaps[conflict].append(source)
+
+            # Report the overlapping values
+            for overlap in overlaps:
+                for assignment_node in assignments[overlap]:
+                    self.add_message(
+                        "implicit-flag-alias",
+                        node=assignment_node,
+                        args={
+                            "overlap": f"<{node.name}.{assignment_node.name}: {overlap}>",
+                            "sources": ", ".join(
+                                f"<{node.name}.{assignments[source][0].name}: {source}> "
+                                f"({overlap} & {source} = {overlap & source})"
+                                for source in overlaps[overlap]
+                            ),
+                        },
+                        confidence=INFERENCE,
+                    )
+
+    def _check_proper_bases(self, node: nodes.ClassDef) -> None:
         """Detect that a class inherits something which is not
         a class or a type.
         """
         for base in node.bases:
             ancestor = safe_infer(base)
             if not ancestor:
                 continue
@@ -869,22 +955,15 @@
                 ancestor
             ):
                 self.add_message("inherit-non-class", args=base.as_string(), node=node)
 
             if isinstance(ancestor, nodes.ClassDef) and ancestor.is_subtype_of(
                 "enum.Enum"
             ):
-                members = ancestor.getattr("__members__")
-                if members and isinstance(members[0], nodes.Dict) and members[0].items:
-                    self.add_message(
-                        "invalid-enum-extension",
-                        args=ancestor.name,
-                        node=node,
-                        confidence=INFERENCE,
-                    )
+                self._check_enum_base(node, ancestor)
 
             if ancestor.name == object.__name__:
                 self.add_message(
                     "useless-object-inheritance", args=node.name, node=node
                 )
 
     def _check_typing_final(self, node: nodes.ClassDef) -> None:
@@ -932,15 +1011,16 @@
             if isinstance(parent_scope, nodes.FunctionDef):
                 # Handle nested functions
                 if function_def.name in (
                     n.name for n in parent_scope.nodes_of_class(nodes.Name)
                 ):
                     continue
             for child in node.nodes_of_class((nodes.Name, nodes.Attribute)):
-                # Check for cases where the functions are used as a variable instead of as a method call
+                # Check for cases where the functions are used as a variable instead of as a
+                # method call
                 if isinstance(child, nodes.Name) and child.name == function_def.name:
                     break
                 if isinstance(child, nodes.Attribute):
                     # Ignore recursive calls
                     if (
                         child.attrname != function_def.name
                         or child.scope() == function_def
@@ -949,15 +1029,14 @@
 
                     # Check self.__attrname, cls.__attrname, node_name.__attrname
                     if isinstance(child.expr, nodes.Name) and child.expr.name in {
                         "self",
                         "cls",
                         node.name,
                     }:
-
                         break
 
                     # Check type(self).__attrname
                     if isinstance(child.expr, nodes.Call):
                         inferred = safe_infer(child.expr)
                         if (
                             isinstance(inferred, nodes.ClassDef)
@@ -1125,25 +1204,26 @@
                                 node.frame(future=True), cnode, defining_methods
                             ):
                                 continue
                             self.add_message(
                                 "attribute-defined-outside-init", args=attr, node=node
                             )
 
+    # pylint: disable = too-many-branches
     def visit_functiondef(self, node: nodes.FunctionDef) -> None:
         """Check method arguments, overriding."""
         # ignore actual functions
         if not node.is_method():
             return
 
         self._check_useless_super_delegation(node)
         self._check_property_with_parameters(node)
 
         # 'is_method()' is called and makes sure that this is a 'nodes.ClassDef'
-        klass = node.parent.frame(future=True)  # type: nodes.ClassDef
+        klass: nodes.ClassDef = node.parent.frame(future=True)
         # check first argument is self if this is actually a method
         self._check_first_arg_for_type(node, klass.type == "metaclass")
         if node.name == "__init__":
             self._check_init(node, klass)
             return
         # check signature if the method overloads inherited method
         for overridden in klass.local_attr_ancestors(node.name):
@@ -1153,15 +1233,15 @@
             except KeyError:
                 # we have found the method but it's not in the local
                 # dictionary.
                 # This may happen with astroid build from living objects
                 continue
             if not isinstance(parent_function, nodes.FunctionDef):
                 continue
-            self._check_signature(node, parent_function, "overridden", klass)
+            self._check_signature(node, parent_function, klass)
             self._check_invalid_overridden_method(node, parent_function)
             break
 
         if node.decorators:
             for decorator in node.decorators.nodes:
                 if isinstance(decorator, nodes.Attribute) and decorator.attrname in {
                     "getter",
@@ -1193,14 +1273,15 @@
                         and inferred.getattr("__set__")
                     ):
                         return
                 except astroid.AttributeInferenceError:
                     pass
 
         # check if the method is hidden by an attribute
+        # pylint: disable = too-many-try-statements
         try:
             overridden = klass.instance_attr(node.name)[0]
             overridden_frame = overridden.frame(future=True)
             if (
                 isinstance(overridden_frame, nodes.FunctionDef)
                 and overridden_frame.type == "method"
             ):
@@ -1235,15 +1316,15 @@
         passed to super() are the same as the parameters that were passed to
         this method, then the method could be removed altogether, by letting
         other implementation to take precedence.
         """
         if not _is_trivial_super_delegation(function):
             return
 
-        call = function.body[0].value
+        call: nodes.Call = function.body[0].value
 
         # Classes that override __eq__ should also override
         # __hash__, even a trivial override is meaningful
         if function.name == "__hash__":
             for other_method in function.parent.mymethods():
                 if other_method.name == "__eq__":
                     return
@@ -1263,25 +1344,33 @@
             if (
                 not isinstance(meth_node, nodes.FunctionDef)
                 # If the method have an ancestor which is not a
                 # function then it is legitimate to redefine it
                 or _has_different_parameters_default_value(
                     meth_node.args, function.args
                 )
+                # arguments to builtins such as Exception.__init__() cannot be inspected
+                or (meth_node.args.args is None and function.argnames() != ["self"])
             ):
                 return
             break
 
         # Detect if the parameters are the same as the call's arguments.
         params = _signature_from_arguments(function.args)
         args = _signature_from_call(call)
 
         if meth_node is not None:
+            # Detect if the super method uses varargs and the function doesn't or makes some of those explicit
+            if meth_node.args.vararg and (
+                not function.args.vararg
+                or len(function.args.args) > len(meth_node.args.args)
+            ):
+                return
 
-            def form_annotations(arguments):
+            def form_annotations(arguments: nodes.Arguments) -> list[str]:
                 annotations = chain(
                     (arguments.posonlyargs_annotations or []), arguments.annotations
                 )
                 return [ann.as_string() for ann in annotations if ann is not None]
 
             called_annotations = form_annotations(function.args)
             overridden_annotations = form_annotations(meth_node.args)
@@ -1295,27 +1384,34 @@
                 and meth_node.returns.as_string() != function.returns.as_string()
             ):
                 # Override adds typing information to the return type
                 return
 
         if _definition_equivalent_to_call(params, args):
             self.add_message(
-                "useless-super-delegation", node=function, args=(function.name,)
+                "useless-parent-delegation",
+                node=function,
+                args=(function.name,),
+                confidence=INFERENCE,
             )
 
-    def _check_property_with_parameters(self, node):
+    def _check_property_with_parameters(self, node: nodes.FunctionDef) -> None:
         if (
             node.args.args
             and len(node.args.args) > 1
             and decorated_with_property(node)
             and not is_property_setter(node)
         ):
             self.add_message("property-with-parameters", node=node)
 
-    def _check_invalid_overridden_method(self, function_node, parent_function_node):
+    def _check_invalid_overridden_method(
+        self,
+        function_node: nodes.FunctionDef,
+        parent_function_node: nodes.FunctionDef,
+    ) -> None:
         parent_is_property = decorated_with_property(
             parent_function_node
         ) or is_property_setter_or_deleter(parent_function_node)
         current_is_property = decorated_with_property(
             function_node
         ) or is_property_setter_or_deleter(function_node)
         if parent_is_property and not current_is_property:
@@ -1356,17 +1452,18 @@
                 args=(function_node.name, parent_function_node.parent.frame().name),
                 node=function_node,
             )
 
     def _check_slots(self, node: nodes.ClassDef) -> None:
         if "__slots__" not in node.locals:
             return
-        for slots in node.igetattr("__slots__"):
+
+        for slots in node.ilookup("__slots__"):
             # check if __slots__ is a valid type
-            if slots is astroid.Uninferable:
+            if isinstance(slots, util.UninferableBase):
                 continue
             if not is_iterable(slots) and not is_comprehension(slots):
                 self.add_message("invalid-slots", node=node)
                 continue
 
             if isinstance(slots, nodes.Const):
                 # a string, ignore the following checks
@@ -1376,16 +1473,16 @@
                 # we can't obtain the values, maybe a .deque?
                 continue
 
             if isinstance(slots, nodes.Dict):
                 values = [item[0] for item in slots.items]
             else:
                 values = slots.itered()
-            if values is astroid.Uninferable:
-                return
+            if isinstance(values, util.UninferableBase):
+                continue
             for elt in values:
                 try:
                     self._check_slots_elt(elt, node)
                 except astroid.InferenceError:
                     continue
             self._check_redefined_slots(node, slots, values)
 
@@ -1419,17 +1516,19 @@
         if redefined_slots:
             self.add_message(
                 "redefined-slots-in-subclass",
                 args=([name for name in slots_names if name in redefined_slots],),
                 node=slots_node,
             )
 
-    def _check_slots_elt(self, elt, node):
+    def _check_slots_elt(
+        self, elt: SuccessfulInferenceResult, node: nodes.ClassDef
+    ) -> None:
         for inferred in elt.infer():
-            if inferred is astroid.Uninferable:
+            if isinstance(inferred, util.UninferableBase):
                 continue
             if not isinstance(inferred, nodes.Const) or not isinstance(
                 inferred.value, str
             ):
                 self.add_message(
                     "invalid-slots-object",
                     args=elt.as_string(),
@@ -1513,25 +1612,40 @@
             self._accessed.set_accessed(node)
         self._check_in_slots(node)
         self._check_invalid_class_object(node)
 
     def _check_invalid_class_object(self, node: nodes.AssignAttr) -> None:
         if not node.attrname == "__class__":
             return
-        inferred = safe_infer(node.parent.value)
+        if isinstance(node.parent, nodes.Tuple):
+            class_index = -1
+            for i, elt in enumerate(node.parent.elts):
+                if hasattr(elt, "attrname") and elt.attrname == "__class__":
+                    class_index = i
+            if class_index == -1:
+                # This should not happen because we checked that the node name
+                # is '__class__' earlier, but let's not be too confident here
+                return  # pragma: no cover
+            inferred = safe_infer(node.parent.parent.value.elts[class_index])
+        else:
+            inferred = safe_infer(node.parent.value)
         if (
-            isinstance(inferred, nodes.ClassDef)
-            or inferred is astroid.Uninferable
+            isinstance(inferred, (nodes.ClassDef, util.UninferableBase))
             or inferred is None
         ):
             # If is uninferable, we allow it to prevent false positives
             return
-        self.add_message("invalid-class-object", node=node)
+        self.add_message(
+            "invalid-class-object",
+            node=node,
+            args=inferred.__class__.__name__,
+            confidence=INFERENCE,
+        )
 
-    def _check_in_slots(self, node):
+    def _check_in_slots(self, node: nodes.AssignAttr) -> None:
         """Check that the given AssignAttr node
         is defined in the class slots.
         """
         inferred = safe_infer(node.expr)
         if not isinstance(inferred, astroid.Instance):
             return
 
@@ -1571,14 +1685,18 @@
             # If we have a '__dict__' in slots, then
             # assigning any name is valid.
             if not any(slot.value == "__dict__" for slot in slots):
                 if _is_attribute_property(node.attrname, klass):
                     # Properties circumvent the slots mechanism,
                     # so we should not emit a warning for them.
                     return
+                if node.attrname != "__class__" and utils.is_class_attr(
+                    node.attrname, klass
+                ):
+                    return
                 if node.attrname in klass.locals:
                     for local_name in klass.locals.get(node.attrname):
                         statement = local_name.statement(future=True)
                         if (
                             isinstance(statement, nodes.AnnAssign)
                             and not statement.value
                         ):
@@ -1586,30 +1704,35 @@
                     if _has_data_descriptor(klass, node.attrname):
                         # Descriptors circumvent the slots mechanism as well.
                         return
                 if node.attrname == "__class__" and _has_same_layout_slots(
                     slots, node.parent.value
                 ):
                     return
-                self.add_message("assigning-non-slot", args=(node.attrname,), node=node)
+                self.add_message(
+                    "assigning-non-slot",
+                    args=(node.attrname,),
+                    node=node,
+                    confidence=INFERENCE,
+                )
 
     @only_required_for_messages(
         "protected-access", "no-classmethod-decorator", "no-staticmethod-decorator"
     )
     def visit_assign(self, assign_node: nodes.Assign) -> None:
         self._check_classmethod_declaration(assign_node)
         node = assign_node.targets[0]
         if not isinstance(node, nodes.AssignAttr):
             return
 
         if self._uses_mandatory_method_param(node):
             return
         self._check_protected_attribute_access(node)
 
-    def _check_classmethod_declaration(self, node):
+    def _check_classmethod_declaration(self, node: nodes.Assign) -> None:
         """Checks for uses of classmethod() or staticmethod().
 
         When a @classmethod or @staticmethod decorator should be used instead.
         A message will be emitted only if the assignment is at a class scope
         and only if the classmethod's argument belongs to the class where it
         is defined.
         `node` is an assign node.
@@ -1640,108 +1763,120 @@
         if not isinstance(classmeth_arg, nodes.Name):
             return
 
         method_name = classmeth_arg.name
         if any(method_name == member.name for member in parent_class.mymethods()):
             self.add_message(msg, node=node.targets[0])
 
-    def _check_protected_attribute_access(self, node: nodes.Attribute):
+    def _check_protected_attribute_access(
+        self, node: nodes.Attribute | nodes.AssignAttr
+    ) -> None:
         """Given an attribute access node (set or get), check if attribute
         access is legitimate.
 
         Call _check_first_attr with node before calling
         this method. Valid cases are:
         * self._attr in a method or cls._attr in a classmethod. Checked by
         _check_first_attr.
         * Klass._attr inside "Klass" class.
         * Klass2._attr inside "Klass" class when Klass2 is a base class of
             Klass.
         """
         attrname = node.attrname
 
         if (
-            is_attr_protected(attrname)
-            and attrname not in self.linter.config.exclude_protected
+            not is_attr_protected(attrname)
+            or attrname in self.linter.config.exclude_protected
         ):
+            return
 
-            klass = node_frame_class(node)
-
-            # In classes, check we are not getting a parent method
-            # through the class object or through super
-            callee = node.expr.as_string()
+        # Typing annotations in function definitions can include protected members
+        if utils.is_node_in_type_annotation_context(node):
+            return
 
-            # Typing annotations in function definitions can include protected members
-            if utils.is_node_in_type_annotation_context(node):
-                return
+        # Return if `attrname` is defined at the module-level or as a class attribute
+        # and is listed in `exclude-protected`.
+        inferred = safe_infer(node.expr)
+        if (
+            inferred
+            and isinstance(inferred, (nodes.ClassDef, nodes.Module))
+            and f"{inferred.name}.{attrname}" in self.linter.config.exclude_protected
+        ):
+            return
 
+        klass = node_frame_class(node)
+        if klass is None:
             # We are not in a class, no remaining valid case
-            if klass is None:
-                self.add_message("protected-access", node=node, args=attrname)
-                return
-
-            # If the expression begins with a call to super, that's ok.
-            if (
-                isinstance(node.expr, nodes.Call)
-                and isinstance(node.expr.func, nodes.Name)
-                and node.expr.func.name == "super"
-            ):
-                return
-
-            # If the expression begins with a call to type(self), that's ok.
-            if self._is_type_self_call(node.expr):
-                return
+            self.add_message("protected-access", node=node, args=attrname)
+            return
 
-            # Check if we are inside the scope of a class or nested inner class
-            inside_klass = True
-            outer_klass = klass
-            parents_callee = callee.split(".")
-            parents_callee.reverse()
-            for callee in parents_callee:
-                if not outer_klass or callee != outer_klass.name:
-                    inside_klass = False
-                    break
+        # In classes, check we are not getting a parent method
+        # through the class object or through super
 
-                # Move up one level within the nested classes
-                outer_klass = get_outer_class(outer_klass)
+        # If the expression begins with a call to super, that's ok.
+        if (
+            isinstance(node.expr, nodes.Call)
+            and isinstance(node.expr.func, nodes.Name)
+            and node.expr.func.name == "super"
+        ):
+            return
 
-            # We are in a class, one remaining valid cases, Klass._attr inside
-            # Klass
-            if not (inside_klass or callee in klass.basenames):
-                # Detect property assignments in the body of the class.
-                # This is acceptable:
-                #
-                # class A:
-                #     b = property(lambda: self._b)
+        # If the expression begins with a call to type(self), that's ok.
+        if self._is_type_self_call(node.expr):
+            return
 
-                stmt = node.parent.statement(future=True)
-                if (
-                    isinstance(stmt, nodes.Assign)
-                    and len(stmt.targets) == 1
-                    and isinstance(stmt.targets[0], nodes.AssignName)
-                ):
-                    name = stmt.targets[0].name
-                    if _is_attribute_property(name, klass):
-                        return
+        # Check if we are inside the scope of a class or nested inner class
+        inside_klass = True
+        outer_klass = klass
+        callee = node.expr.as_string()
+        parents_callee = callee.split(".")
+        parents_callee.reverse()
+        for callee in parents_callee:
+            if not outer_klass or callee != outer_klass.name:
+                inside_klass = False
+                break
+
+            # Move up one level within the nested classes
+            outer_klass = get_outer_class(outer_klass)
+
+        # We are in a class, one remaining valid cases, Klass._attr inside
+        # Klass
+        if not (inside_klass or callee in klass.basenames):
+            # Detect property assignments in the body of the class.
+            # This is acceptable:
+            #
+            # class A:
+            #     b = property(lambda: self._b)
 
-                if (
-                    self._is_classmethod(node.frame(future=True))
-                    and self._is_inferred_instance(node.expr, klass)
-                    and self._is_class_attribute(attrname, klass)
-                ):
+            stmt = node.parent.statement(future=True)
+            if (
+                isinstance(stmt, nodes.Assign)
+                and len(stmt.targets) == 1
+                and isinstance(stmt.targets[0], nodes.AssignName)
+            ):
+                name = stmt.targets[0].name
+                if _is_attribute_property(name, klass):
                     return
 
-                licit_protected_member = not attrname.startswith("__")
-                if (
-                    not self.linter.config.check_protected_access_in_special_methods
-                    and licit_protected_member
-                    and self._is_called_inside_special_method(node)
-                ):
-                    return
+            if (
+                self._is_classmethod(node.frame(future=True))
+                and self._is_inferred_instance(node.expr, klass)
+                and self._is_class_or_instance_attribute(attrname, klass)
+            ):
+                return
 
-                self.add_message("protected-access", node=node, args=attrname)
+            licit_protected_member = not attrname.startswith("__")
+            if (
+                not self.linter.config.check_protected_access_in_special_methods
+                and licit_protected_member
+                and self._is_called_inside_special_method(node)
+            ):
+                return
+
+            self.add_message("protected-access", node=node, args=attrname)
 
     @staticmethod
     def _is_called_inside_special_method(node: nodes.NodeNG) -> bool:
         """Returns true if the node is located inside a special (aka dunder) method."""
         frame_name = node.frame(future=True).name
         return frame_name and frame_name in PYMETHODS
 
@@ -1751,55 +1886,51 @@
             and isinstance(expr.func, nodes.Name)
             and expr.func.name == "type"
             and len(expr.args) == 1
             and self._is_mandatory_method_param(expr.args[0])
         )
 
     @staticmethod
-    def _is_classmethod(func):
+    def _is_classmethod(func: LocalsDictNodeNG) -> bool:
         """Check if the given *func* node is a class method."""
-
         return isinstance(func, nodes.FunctionDef) and (
             func.type == "classmethod" or func.name == "__class_getitem__"
         )
 
     @staticmethod
-    def _is_inferred_instance(expr, klass):
+    def _is_inferred_instance(expr: nodes.NodeNG, klass: nodes.ClassDef) -> bool:
         """Check if the inferred value of the given *expr* is an instance of
         *klass*.
         """
-
         inferred = safe_infer(expr)
         if not isinstance(inferred, astroid.Instance):
             return False
-
         return inferred._proxied is klass
 
     @staticmethod
-    def _is_class_attribute(name, klass):
+    def _is_class_or_instance_attribute(name: str, klass: nodes.ClassDef) -> bool:
         """Check if the given attribute *name* is a class or instance member of the
         given *klass*.
 
         Returns ``True`` if the name is a property in the given klass,
         ``False`` otherwise.
         """
 
-        try:
-            klass.getattr(name)
+        if utils.is_class_attr(name, klass):
             return True
-        except astroid.NotFoundError:
-            pass
 
         try:
             klass.instance_attr(name)
             return True
         except astroid.NotFoundError:
             return False
 
-    def _check_accessed_members(self, node, accessed):
+    def _check_accessed_members(
+        self, node: nodes.ClassDef, accessed: dict[str, list[_AccessNodes]]
+    ) -> None:
         """Check that accessed members are defined."""
         excs = ("AttributeError", "Exception", "BaseException")
         for attr, nodes_lst in accessed.items():
             try:
                 # is it a class attribute ?
                 node.local_attr(attr)
                 # yes, stop here
@@ -1851,15 +1982,17 @@
                         ):
                             self.add_message(
                                 "access-member-before-definition",
                                 node=_node,
                                 args=(attr, lno),
                             )
 
-    def _check_first_arg_for_type(self, node, metaclass=0):
+    def _check_first_arg_for_type(
+        self, node: nodes.FunctionDef, metaclass: bool
+    ) -> None:
         """Check the name of first argument, expect:.
 
         * 'self' for a regular method
         * 'cls' for a class method or a metaclass regular method (actually
           valid-classmethod-first-arg value)
         * 'mcs' for a metaclass class method (actually
           valid-metaclass-classmethod-first-arg)
@@ -1882,17 +2015,26 @@
                 first_arg == "self"
                 or first_arg in self.linter.config.valid_classmethod_first_arg
                 or first_arg in self.linter.config.valid_metaclass_classmethod_first_arg
             ):
                 self.add_message("bad-staticmethod-argument", args=first, node=node)
                 return
             self._first_attrs[-1] = None
+        elif "builtins.staticmethod" in node.decoratornames():
+            # Check if there is a decorator which is not named `staticmethod`
+            # but is assigned to one.
+            return
         # class / regular method with no args
-        elif not node.args.args and not node.args.posonlyargs:
-            self.add_message("no-method-argument", node=node)
+        elif not (
+            node.args.args
+            or node.args.posonlyargs
+            or node.args.vararg
+            or node.args.kwarg
+        ):
+            self.add_message("no-method-argument", node=node, args=node.name)
         # metaclass
         elif metaclass:
             # metaclass __new__ or classmethod
             if node.type == "classmethod":
                 self._check_first_arg_config(
                     first,
                     self.linter.config.valid_metaclass_classmethod_first_arg,
@@ -1916,32 +2058,39 @@
                 self.linter.config.valid_classmethod_first_arg,
                 node,
                 "bad-classmethod-argument",
                 node.name,
             )
         # regular class with regular method without self as argument
         elif first != "self":
-            self.add_message("no-self-argument", node=node)
+            self.add_message("no-self-argument", node=node, args=node.name)
 
-    def _check_first_arg_config(self, first, config, node, message, method_name):
+    def _check_first_arg_config(
+        self,
+        first: str | None,
+        config: Sequence[str],
+        node: nodes.FunctionDef,
+        message: str,
+        method_name: str,
+    ) -> None:
         if first not in config:
             if len(config) == 1:
                 valid = repr(config[0])
             else:
                 valid = ", ".join(repr(v) for v in config[:-1])
                 valid = f"{valid} or {config[-1]!r}"
             self.add_message(message, args=(method_name, valid), node=node)
 
-    def _check_bases_classes(self, node):
+    def _check_bases_classes(self, node: nodes.ClassDef) -> None:
         """Check that the given class node implements abstract methods from
         base classes.
         """
 
-        def is_abstract(method):
-            return method.is_abstract(pass_is_abstract=False)
+        def is_abstract(method: nodes.FunctionDef) -> bool:
+            return method.is_abstract(pass_is_abstract=False)  # type: ignore[no-any-return]
 
         # check if this class abstract
         if class_is_abstract(node):
             return
 
         methods = sorted(
             unimplemented_abstract_methods(node, is_abstract).items(),
@@ -1952,15 +2101,21 @@
             if owner is node:
                 continue
             # owner is not this class, it must be a parent class
             # check that the ancestor's method is not abstract
             if name in node.locals:
                 # it is redefined as an attribute or with a descriptor
                 continue
-            self.add_message("abstract-method", node=node, args=(name, owner.name))
+
+            self.add_message(
+                "abstract-method",
+                node=node,
+                args=(name, owner.name, node.name),
+                confidence=INFERENCE,
+            )
 
     def _check_init(self, node: nodes.FunctionDef, klass_node: nodes.ClassDef) -> None:
         """Check that the __init__ method call super or ancestors'__init__
         method (unless it is used for type hinting with `typing.overload`).
         """
         if not self.linter.is_message_enabled(
             "super-init-not-called"
@@ -1976,17 +2131,18 @@
             # skip the test if using super
             if (
                 isinstance(expr.expr, nodes.Call)
                 and isinstance(expr.expr.func, nodes.Name)
                 and expr.expr.func.name == "super"
             ):
                 return
+            # pylint: disable = too-many-try-statements
             try:
                 for klass in expr.expr.infer():
-                    if klass is astroid.Uninferable:
+                    if isinstance(klass, util.UninferableBase):
                         continue
                     # The inferred klass can be super(), which was
                     # assigned to a variable and the `__init__`
                     # was called later.
                     #
                     # base = super()
                     # base.__init__(...)
@@ -2001,52 +2157,44 @@
                     if isinstance(klass, astroid.objects.Super):
                         return
                     try:
                         method = not_called_yet.pop(klass)
                         # Record that the class' init has been called
                         parents_with_called_inits.add(node_frame_class(method))
                     except KeyError:
-                        if klass not in to_call:
+                        if klass not in klass_node.ancestors(recurs=False):
                             self.add_message(
                                 "non-parent-init-called", node=expr, args=klass.name
                             )
             except astroid.InferenceError:
                 continue
         for klass, method in not_called_yet.items():
             # Check if the init of the class that defines this init has already
             # been called.
             if node_frame_class(method) in parents_with_called_inits:
                 return
 
-            # Return if klass is protocol
-            if klass.qname() in utils.TYPING_PROTOCOLS:
+            if utils.is_protocol_class(klass):
                 return
 
-            # Return if any of the klass' first-order bases is protocol
-            for base in klass.bases:
-                try:
-                    for inf_base in base.infer():
-                        if inf_base.qname() in utils.TYPING_PROTOCOLS:
-                            return
-                except astroid.InferenceError:
-                    continue
-
             if decorated_with(node, ["typing.overload"]):
                 continue
-            cls = node_frame_class(method)
-            if klass.name == "object" or (cls and cls.name == "object"):
-                continue
             self.add_message(
                 "super-init-not-called",
                 args=klass.name,
                 node=node,
                 confidence=INFERENCE,
             )
 
-    def _check_signature(self, method1, refmethod, class_type, cls):
+    def _check_signature(
+        self,
+        method1: nodes.FunctionDef,
+        refmethod: nodes.FunctionDef,
+        cls: nodes.ClassDef,
+    ) -> None:
         """Check that the signature of the two given methods match."""
         if not (
             isinstance(method1, nodes.FunctionDef)
             and isinstance(refmethod, nodes.FunctionDef)
         ):
             self.add_message(
                 "method-check-failed", args=(method1, refmethod), node=method1
@@ -2068,14 +2216,17 @@
         # which shouldn't be taken in consideration.
         if is_property_setter(method1):
             return
 
         arg_differ_output = _different_parameters(
             refmethod, method1, dummy_parameter_regex=self._dummy_rgx
         )
+
+        class_type = "overriding"
+
         if len(arg_differ_output) > 0:
             for msg in arg_differ_output:
                 if "Number" in msg:
                     total_args_method1 = len(method1.args.args)
                     if method1.args.vararg:
                         total_args_method1 += 1
                     if method1.args.kwarg:
@@ -2112,19 +2263,22 @@
                         f"{method1.parent.frame().name}.{method1.name}",
                     )
                 self.add_message(error_type, args=msg_args, node=method1)
         elif (
             len(method1.args.defaults) < len(refmethod.args.defaults)
             and not method1.args.vararg
         ):
+            class_type = "overridden"
             self.add_message(
                 "signature-differs", args=(class_type, method1.name), node=method1
             )
 
-    def _uses_mandatory_method_param(self, node):
+    def _uses_mandatory_method_param(
+        self, node: nodes.Attribute | nodes.Assign | nodes.AssignAttr
+    ) -> bool:
         """Check that attribute lookup name use first attribute variable name.
 
         Name is `self` for method, `cls` for classmethod and `mcs` for metaclass.
         """
         return self._is_mandatory_method_param(node.expr)
 
     def _is_mandatory_method_param(self, node: nodes.NodeNG) -> bool:
@@ -2147,19 +2301,24 @@
             if not closest_func.args.args:
                 return False
             first_attr = closest_func.args.args[0].name
         return isinstance(node, nodes.Name) and node.name == first_attr
 
 
 def _ancestors_to_call(
-    klass_node: nodes.ClassDef, method="__init__"
+    klass_node: nodes.ClassDef, method_name: str = "__init__"
 ) -> dict[nodes.ClassDef, bases.UnboundMethod]:
     """Return a dictionary where keys are the list of base classes providing
     the queried method, and so that should/may be called from the method node.
     """
     to_call: dict[nodes.ClassDef, bases.UnboundMethod] = {}
     for base_node in klass_node.ancestors(recurs=False):
         try:
-            to_call[base_node] = next(base_node.igetattr(method))
+            init_node = next(base_node.igetattr(method_name))
+            if not isinstance(init_node, astroid.UnboundMethod):
+                continue
+            if init_node.is_abstract():
+                continue
+            to_call[base_node] = init_node
         except astroid.InferenceError:
             continue
     return to_call
```

### Comparing `pylint-3.0.0a5/pylint/checkers/classes/special_methods_checker.py` & `pylint-3.0.0a6/pylint/checkers/classes/special_methods_checker.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,30 +1,41 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Special methods checker and helper function's module."""
 
+from __future__ import annotations
+
+from collections.abc import Callable
+
 import astroid
-from astroid import nodes
+from astroid import bases, nodes, util
+from astroid.context import InferenceContext
+from astroid.typing import InferenceResult
 
 from pylint.checkers import BaseChecker
 from pylint.checkers.utils import (
     PYMETHODS,
     SPECIAL_METHODS_PARAMS,
     decorated_with,
     is_function_body_ellipsis,
     only_required_for_messages,
     safe_infer,
 )
+from pylint.lint.pylinter import PyLinter
 
 NEXT_METHOD = "__next__"
 
 
-def _safe_infer_call_result(node, caller, context=None):
+def _safe_infer_call_result(
+    node: nodes.FunctionDef,
+    caller: nodes.FunctionDef,
+    context: InferenceContext | None = None,
+) -> InferenceResult | None:
     """Safely infer the return value of a function.
 
     Returns None if inference failed or if there is some ambiguity (more than
     one node has been inferred). Otherwise, returns inferred value.
     """
     try:
         inferit = node.infer_call_result(caller, context=context)
@@ -127,17 +138,19 @@
             "__getnewargs_ex__ does not return a tuple containing (tuple, dict)",
             "invalid-getnewargs-ex-returned",
             "Used when a __getnewargs_ex__ method returns something which is not "
             "of the form tuple(tuple, dict)",
         ),
     }
 
-    def __init__(self, linter=None):
+    def __init__(self, linter: PyLinter) -> None:
         super().__init__(linter)
-        self._protocol_map = {
+        self._protocol_map: dict[
+            str, Callable[[nodes.FunctionDef, InferenceResult], None]
+        ] = {
             "__iter__": self._check_iter,
             "__len__": self._check_len,
             "__bool__": self._check_bool,
             "__index__": self._check_index,
             "__repr__": self._check_repr,
             "__str__": self._check_str,
             "__bytes__": self._check_bytes,
@@ -177,15 +190,15 @@
             self._protocol_map[node.name](node, inferred)
 
         if node.name in PYMETHODS:
             self._check_unexpected_method_signature(node)
 
     visit_asyncfunctiondef = visit_functiondef
 
-    def _check_unexpected_method_signature(self, node):
+    def _check_unexpected_method_signature(self, node: nodes.FunctionDef) -> None:
         expected_params = SPECIAL_METHODS_PARAMS[node.name]
 
         if expected_params is None:
             # This can support a variable number of parameters.
             return
         if not node.args.args and not node.args.vararg:
             # Method has no parameter, will be caught
@@ -203,16 +216,17 @@
 
         emit = False  # If we don't know we choose a false negative
         if isinstance(expected_params, tuple):
             # The expected number of parameters can be any value from this
             # tuple, although the user should implement the method
             # to take all of them in consideration.
             emit = mandatory not in expected_params
-            # pylint: disable-next=consider-using-f-string
-            expected_params = "between %d or %d" % expected_params
+            # mypy thinks that expected_params has type tuple[int, int] | int | None
+            # But at this point it must be 'tuple[int, int]' because of the type check
+            expected_params = f"between {expected_params[0]} or {expected_params[1]}"  # type: ignore[assignment]
         else:
             # If the number of mandatory parameters doesn't
             # suffice, the expected parameters for this
             # function will be deduced from the optional
             # parameters.
             rest = expected_params - mandatory
             if rest == 0:
@@ -227,76 +241,73 @@
             self.add_message(
                 "unexpected-special-method-signature",
                 args=(node.name, expected_params, current_params, verb),
                 node=node,
             )
 
     @staticmethod
-    def _is_wrapped_type(node, type_):
+    def _is_wrapped_type(node: InferenceResult, type_: str) -> bool:
         return (
-            isinstance(node, astroid.Instance)
+            isinstance(node, bases.Instance)
             and node.name == type_
             and not isinstance(node, nodes.Const)
         )
 
     @staticmethod
-    def _is_int(node):
+    def _is_int(node: InferenceResult) -> bool:
         if SpecialMethodsChecker._is_wrapped_type(node, "int"):
             return True
 
         return isinstance(node, nodes.Const) and isinstance(node.value, int)
 
     @staticmethod
-    def _is_str(node):
+    def _is_str(node: InferenceResult) -> bool:
         if SpecialMethodsChecker._is_wrapped_type(node, "str"):
             return True
 
         return isinstance(node, nodes.Const) and isinstance(node.value, str)
 
     @staticmethod
-    def _is_bool(node):
+    def _is_bool(node: InferenceResult) -> bool:
         if SpecialMethodsChecker._is_wrapped_type(node, "bool"):
             return True
 
         return isinstance(node, nodes.Const) and isinstance(node.value, bool)
 
     @staticmethod
-    def _is_bytes(node):
+    def _is_bytes(node: InferenceResult) -> bool:
         if SpecialMethodsChecker._is_wrapped_type(node, "bytes"):
             return True
 
         return isinstance(node, nodes.Const) and isinstance(node.value, bytes)
 
     @staticmethod
-    def _is_tuple(node):
+    def _is_tuple(node: InferenceResult) -> bool:
         if SpecialMethodsChecker._is_wrapped_type(node, "tuple"):
             return True
 
         return isinstance(node, nodes.Const) and isinstance(node.value, tuple)
 
     @staticmethod
-    def _is_dict(node):
+    def _is_dict(node: InferenceResult) -> bool:
         if SpecialMethodsChecker._is_wrapped_type(node, "dict"):
             return True
 
         return isinstance(node, nodes.Const) and isinstance(node.value, dict)
 
     @staticmethod
-    def _is_iterator(node):
-        if node is astroid.Uninferable:
-            # Just ignore Uninferable objects.
-            return True
-        if isinstance(node, astroid.bases.Generator):
+    def _is_iterator(node: InferenceResult) -> bool:
+        if isinstance(node, bases.Generator):
             # Generators can be iterated.
             return True
         if isinstance(node, nodes.ComprehensionScope):
             # Comprehensions can be iterated.
             return True
 
-        if isinstance(node, astroid.Instance):
+        if isinstance(node, bases.Instance):
             try:
                 node.local_attr(NEXT_METHOD)
                 return True
             except astroid.NotFoundError:
                 pass
         elif isinstance(node, nodes.ClassDef):
             metaclass = node.metaclass()
@@ -304,63 +315,69 @@
                 try:
                     metaclass.local_attr(NEXT_METHOD)
                     return True
                 except astroid.NotFoundError:
                     pass
         return False
 
-    def _check_iter(self, node, inferred):
+    def _check_iter(self, node: nodes.FunctionDef, inferred: InferenceResult) -> None:
         if not self._is_iterator(inferred):
             self.add_message("non-iterator-returned", node=node)
 
-    def _check_len(self, node, inferred):
+    def _check_len(self, node: nodes.FunctionDef, inferred: InferenceResult) -> None:
         if not self._is_int(inferred):
             self.add_message("invalid-length-returned", node=node)
         elif isinstance(inferred, nodes.Const) and inferred.value < 0:
             self.add_message("invalid-length-returned", node=node)
 
-    def _check_bool(self, node, inferred):
+    def _check_bool(self, node: nodes.FunctionDef, inferred: InferenceResult) -> None:
         if not self._is_bool(inferred):
             self.add_message("invalid-bool-returned", node=node)
 
-    def _check_index(self, node, inferred):
+    def _check_index(self, node: nodes.FunctionDef, inferred: InferenceResult) -> None:
         if not self._is_int(inferred):
             self.add_message("invalid-index-returned", node=node)
 
-    def _check_repr(self, node, inferred):
+    def _check_repr(self, node: nodes.FunctionDef, inferred: InferenceResult) -> None:
         if not self._is_str(inferred):
             self.add_message("invalid-repr-returned", node=node)
 
-    def _check_str(self, node, inferred):
+    def _check_str(self, node: nodes.FunctionDef, inferred: InferenceResult) -> None:
         if not self._is_str(inferred):
             self.add_message("invalid-str-returned", node=node)
 
-    def _check_bytes(self, node, inferred):
+    def _check_bytes(self, node: nodes.FunctionDef, inferred: InferenceResult) -> None:
         if not self._is_bytes(inferred):
             self.add_message("invalid-bytes-returned", node=node)
 
-    def _check_hash(self, node, inferred):
+    def _check_hash(self, node: nodes.FunctionDef, inferred: InferenceResult) -> None:
         if not self._is_int(inferred):
             self.add_message("invalid-hash-returned", node=node)
 
-    def _check_length_hint(self, node, inferred):
+    def _check_length_hint(
+        self, node: nodes.FunctionDef, inferred: InferenceResult
+    ) -> None:
         if not self._is_int(inferred):
             self.add_message("invalid-length-hint-returned", node=node)
         elif isinstance(inferred, nodes.Const) and inferred.value < 0:
             self.add_message("invalid-length-hint-returned", node=node)
 
-    def _check_format(self, node, inferred):
+    def _check_format(self, node: nodes.FunctionDef, inferred: InferenceResult) -> None:
         if not self._is_str(inferred):
             self.add_message("invalid-format-returned", node=node)
 
-    def _check_getnewargs(self, node, inferred):
+    def _check_getnewargs(
+        self, node: nodes.FunctionDef, inferred: InferenceResult
+    ) -> None:
         if not self._is_tuple(inferred):
             self.add_message("invalid-getnewargs-returned", node=node)
 
-    def _check_getnewargs_ex(self, node, inferred):
+    def _check_getnewargs_ex(
+        self, node: nodes.FunctionDef, inferred: InferenceResult
+    ) -> None:
         if not self._is_tuple(inferred):
             self.add_message("invalid-getnewargs-ex-returned", node=node)
             return
 
         if not isinstance(inferred, nodes.Tuple):
             # If it's not an astroid.Tuple we can't analyze it further
             return
@@ -370,18 +387,17 @@
         if len(inferred.elts) != 2:
             found_error = True
         else:
             for arg, check in (
                 (inferred.elts[0], self._is_tuple),
                 (inferred.elts[1], self._is_dict),
             ):
-
                 if isinstance(arg, nodes.Call):
                     arg = safe_infer(arg)
 
-                if arg and arg is not astroid.Uninferable:
+                if arg and not isinstance(arg, util.UninferableBase):
                     if not check(arg):
                         found_error = True
                         break
 
         if found_error:
             self.add_message("invalid-getnewargs-ex-returned", node=node)
```

### Comparing `pylint-3.0.0a5/pylint/checkers/deprecated.py` & `pylint-3.0.0a6/pylint/checkers/deprecated.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checker mixin for deprecated functionality."""
 
 from __future__ import annotations
 
 from collections.abc import Container, Iterable
 from itertools import chain
@@ -27,39 +27,56 @@
 
 class DeprecatedMixin(BaseChecker):
     """A mixin implementing logic for checking deprecated symbols.
 
     A class implementing mixin must define "deprecated-method" Message.
     """
 
-    msgs: dict[str, MessageDefinitionTuple] = {
-        "W1505": (
+    DEPRECATED_MODULE_MESSAGE: dict[str, MessageDefinitionTuple] = {
+        "W4901": (
+            "Deprecated module %r",
+            "deprecated-module",
+            "A module marked as deprecated is imported.",
+            {"old_names": [("W0402", "old-deprecated-module")], "shared": True},
+        ),
+    }
+
+    DEPRECATED_METHOD_MESSAGE: dict[str, MessageDefinitionTuple] = {
+        "W4902": (
             "Using deprecated method %s()",
             "deprecated-method",
             "The method is marked as deprecated and will be removed in the future.",
+            {"old_names": [("W1505", "old-deprecated-method")], "shared": True},
         ),
-        "W1511": (
+    }
+
+    DEPRECATED_ARGUMENT_MESSAGE: dict[str, MessageDefinitionTuple] = {
+        "W4903": (
             "Using deprecated argument %s of method %s()",
             "deprecated-argument",
             "The argument is marked as deprecated and will be removed in the future.",
+            {"old_names": [("W1511", "old-deprecated-argument")], "shared": True},
         ),
-        "W0402": (
-            "Deprecated module %r",
-            "deprecated-module",
-            "A module marked as deprecated is imported.",
-        ),
-        "W1512": (
+    }
+
+    DEPRECATED_CLASS_MESSAGE: dict[str, MessageDefinitionTuple] = {
+        "W4904": (
             "Using deprecated class %s of module %s",
             "deprecated-class",
             "The class is marked as deprecated and will be removed in the future.",
+            {"old_names": [("W1512", "old-deprecated-class")], "shared": True},
         ),
-        "W1513": (
+    }
+
+    DEPRECATED_DECORATOR_MESSAGE: dict[str, MessageDefinitionTuple] = {
+        "W4905": (
             "Using deprecated decorator %s()",
             "deprecated-decorator",
             "The decorator is marked as deprecated and will be removed in the future.",
+            {"old_names": [("W1513", "old-deprecated-decorator")], "shared": True},
         ),
     }
 
     @utils.only_required_for_messages(
         "deprecated-method",
         "deprecated-argument",
         "deprecated-class",
@@ -168,18 +185,18 @@
 
         Returns:
             collections.abc.Container of deprecated class names.
         """
         # pylint: disable=unused-argument
         return ()
 
-    def check_deprecated_module(self, node: nodes.Import, mod_path: str) -> None:
+    def check_deprecated_module(self, node: nodes.Import, mod_path: str | None) -> None:
         """Checks if the module is deprecated."""
         for mod_name in self.deprecated_modules():
-            if mod_path == mod_name or mod_path.startswith(mod_name + "."):
+            if mod_path == mod_name or mod_path and mod_path.startswith(mod_name + "."):
                 self.add_message("deprecated-module", node=node, args=mod_path)
 
     def check_deprecated_method(self, node: nodes.Call, inferred: nodes.NodeNG) -> None:
         """Executes the checker for the given node.
 
         This method should be called from the checker implementing this mixin.
         """
@@ -192,24 +209,15 @@
             func_name = node.func.attrname
         elif isinstance(node.func, nodes.Name):
             func_name = node.func.name
         else:
             # Not interested in other nodes.
             return
 
-        if hasattr(inferred.parent, "qname") and inferred.parent.qname():
-            # Handling the situation when deprecated function is
-            # alias to existing function.
-            qnames = {
-                inferred.qname(),
-                f"{inferred.parent.qname()}.{func_name}",
-                func_name,
-            }
-        else:
-            qnames = {inferred.qname(), func_name}
+        qnames = {inferred.qname(), func_name}
         if any(name in self.deprecated_methods() for name in qnames):
             self.add_message("deprecated-method", node=node, args=(func_name,))
             return
         num_of_args = len(node.args)
         kwargs = {kw.arg for kw in node.keywords} if node.keywords else {}
         deprecated_arguments = (self.deprecated_arguments(qn) for qn in qnames)
         for position, arg_name in chain(*deprecated_arguments):
```

### Comparing `pylint-3.0.0a5/pylint/checkers/design_analysis.py` & `pylint-3.0.0a6/pylint/checkers/design_analysis.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Check for signs of poor design."""
 
 from __future__ import annotations
 
 import re
 from collections import defaultdict
 from collections.abc import Iterator
-from typing import TYPE_CHECKING, List, cast
+from typing import TYPE_CHECKING
 
 import astroid
 from astroid import nodes
 
 from pylint.checkers import BaseChecker
-from pylint.checkers.utils import only_required_for_messages
+from pylint.checkers.utils import is_enum, only_required_for_messages
 from pylint.typing import MessageDefinitionTuple
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 MSGS: dict[
     str, MessageDefinitionTuple
@@ -171,15 +171,15 @@
 
 
 def _is_exempt_from_public_methods(node: astroid.ClassDef) -> bool:
     """Check if a class is exempt from too-few-public-methods."""
 
     # If it's a typing.Namedtuple, typing.TypedDict or an Enum
     for ancestor in node.ancestors():
-        if ancestor.name == "Enum" and ancestor.root().name == "enum":
+        if is_enum(ancestor):
             return True
         if ancestor.qname() in (TYPING_NAMEDTUPLE, TYPING_TYPEDDICT):
             return True
 
     # Or if it's a dataclass
     if not node.decorators:
         return False
@@ -241,15 +241,15 @@
            \/
             A      # class A(B, C): ...
 
     And ``ignored_parents`` is ``{"E"}``, then this function will return
     ``{A, B, C, D}`` -- both ``E`` and its ancestors are excluded.
     """
     parents: set[nodes.ClassDef] = set()
-    to_explore = cast(List[nodes.ClassDef], list(node.ancestors(recurs=False)))
+    to_explore = list(node.ancestors(recurs=False))
     while to_explore:
         parent = to_explore.pop()
         if parent.qname() in ignored_parents:
             continue
         if parent not in parents:
             # This guard might appear to be performing the same function as
             # adding the resolved parents to a set to eliminate duplicates
```

### Comparing `pylint-3.0.0a5/pylint/checkers/dunder_methods.py` & `pylint-3.0.0a6/pylint/constants.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,186 +1,249 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING
-
-from astroid import Instance, Uninferable, nodes
-
-from pylint.checkers import BaseChecker
-from pylint.checkers.utils import safe_infer
-from pylint.interfaces import HIGH
-
-if TYPE_CHECKING:
-    from pylint.lint import PyLinter
-
-
-DUNDER_METHODS: dict[str, str] = {
-    "__init__": "Instantiate class directly",
-    "__del__": "Use del keyword",
-    "__repr__": "Use repr built-in function",
-    "__str__": "Use str built-in function",
-    "__bytes__": "Use bytes built-in function",
-    "__format__": "Use format built-in function, format string method, or f-string",
-    "__lt__": "Use < operator",
-    "__le__": "Use <= operator",
-    "__eq__": "Use == operator",
-    "__ne__": "Use != operator",
-    "__gt__": "Use > operator",
-    "__ge__": "Use >= operator",
-    "__hash__": "Use hash built-in function",
-    "__bool__": "Use bool built-in function",
-    "__getattr__": "Access attribute directly or use getattr built-in function",
-    "__getattribute__": "Access attribute directly or use getattr built-in function",
-    "__setattr__": "Set attribute directly or use setattr built-in function",
-    "__delattr__": "Use del keyword",
-    "__dir__": "Use dir built-in function",
-    "__get__": "Use get method",
-    "__set__": "Use set method",
-    "__delete__": "Use del keyword",
-    "__instancecheck__": "Use isinstance built-in function",
-    "__subclasscheck__": "Use issubclass built-in function",
-    "__call__": "Invoke instance directly",
-    "__len__": "Use len built-in function",
-    "__length_hint__": "Use length_hint method",
-    "__getitem__": "Access item via subscript",
-    "__setitem__": "Set item via subscript",
-    "__delitem__": "Use del keyword",
-    "__iter__": "Use iter built-in function",
-    "__next__": "Use next built-in function",
-    "__reversed__": "Use reversed built-in funciton",
-    "__contains__": "Use in keyword",
-    "__add__": "Use + operator",
-    "__sub__": "Use - operator",
-    "__mul__": "Use * operator",
-    "__matmul__": "Use @ operator",
-    "__truediv__": "Use / operator",
-    "__floordiv__": "Use // operator",
-    "__mod__": "Use % operator",
-    "__divmod__": "Use divmod built-in function",
-    "__pow__": "Use ** operator or pow built-in function",
-    "__lshift__": "Use << operator",
-    "__rshift__": "Use >> operator",
-    "__and__": "Use & operator",
-    "__xor__": "Use ^ operator",
-    "__or__": "Use | operator",
-    "__radd__": "Use + operator",
-    "__rsub__": "Use - operator",
-    "__rmul__": "Use * operator",
-    "__rmatmul__": "Use @ operator",
-    "__rtruediv__": "Use / operator",
-    "__rfloordiv__": "Use // operator",
-    "__rmod__": "Use % operator",
-    "__rdivmod__": "Use divmod built-in function",
-    "__rpow__": "Use ** operator or pow built-in function",
-    "__rlshift__": "Use << operator",
-    "__rrshift__": "Use >> operator",
-    "__rand__": "Use & operator",
-    "__rxor__": "Use ^ operator",
-    "__ror__": "Use | operator",
-    "__iadd__": "Use += operator",
-    "__isub__": "Use -= operator",
-    "__imul__": "Use *= operator",
-    "__imatmul__": "Use @= operator",
-    "__itruediv__": "Use /= operator",
-    "__ifloordiv__": "Use //= operator",
-    "__imod__": "Use %= operator",
-    "__ipow__": "Use **= operator",
-    "__ilshift__": "Use <<= operator",
-    "__irshift__": "Use >>= operator",
-    "__iand__": "Use &= operator",
-    "__ixor__": "Use ^= operator",
-    "__ior__": "Use |= operator",
-    "__neg__": "Multiply by -1 instead",
-    "__pos__": "Multiply by +1 instead",
-    "__abs__": "Use abs built-in function",
-    "__invert__": "Use ~ operator",
-    "__complex__": "Use complex built-in function",
-    "__int__": "Use int built-in function",
-    "__float__": "Use float built-in function",
-    "__index__": "Use index method",
-    "__round__": "Use round built-in function",
-    "__trunc__": "Use math.trunc function",
-    "__floor__": "Use math.floor function",
-    "__ceil__": "Use math.ceil function",
-    "__enter__": "Invoke context manager directly",
-    "__aiter__": "Use iter built-in function",
-    "__anext__": "Use next built-in function",
-    "__aenter__": "Invoke context manager directly",
-    "__copy__": "Use copy.copy function",
-    "__deepcopy__": "Use copy.deepcopy function",
-    "__fspath__": "Use os.fspath function instead",
+import os
+import platform
+import sys
+
+import astroid
+import platformdirs
+
+from pylint.__pkginfo__ import __version__
+from pylint.typing import MessageTypesFullName
+
+PY38_PLUS = sys.version_info[:2] >= (3, 8)
+PY39_PLUS = sys.version_info[:2] >= (3, 9)
+PY310_PLUS = sys.version_info[:2] >= (3, 10)
+
+IS_PYPY = platform.python_implementation() == "PyPy"
+
+PY_EXTS = (".py", ".pyc", ".pyo", ".pyw", ".so", ".dll")
+
+MSG_STATE_CONFIDENCE = 2
+_MSG_ORDER = "EWRCIF"
+MSG_STATE_SCOPE_CONFIG = 0
+MSG_STATE_SCOPE_MODULE = 1
+
+# The line/node distinction does not apply to fatal errors and reports.
+_SCOPE_EXEMPT = "FR"
+
+MSG_TYPES: dict[str, MessageTypesFullName] = {
+    "I": "info",
+    "C": "convention",
+    "R": "refactor",
+    "W": "warning",
+    "E": "error",
+    "F": "fatal",
 }
+MSG_TYPES_LONG: dict[str, str] = {v: k for k, v in MSG_TYPES.items()}
 
+MSG_TYPES_STATUS = {"I": 0, "C": 16, "R": 8, "W": 4, "E": 2, "F": 1}
 
-class DunderCallChecker(BaseChecker):
-    """Check for unnecessary dunder method calls.
-
-    Docs: https://docs.python.org/3/reference/datamodel.html#basic-customization
-    We exclude __new__, __subclasses__, __init_subclass__, __set_name__,
-    __class_getitem__, __missing__, __exit__, __await__,
-    __aexit__, __getnewargs_ex__, __getnewargs__, __getstate__,
-    __setstate__, __reduce__, __reduce_ex__
-    since these either have no alternative method of being called or
-    have a genuine use case for being called manually.
-
-    Additionally, we exclude classes that are not instantiated since these
-    might be used to access the dunder methods of a base class of an instance.
-    We also exclude dunder method calls on super() since
-    these can't be written in an alternative manner.
-    """
-
-    name = "unnecessary-dunder-call"
-    priority = -1
-    msgs = {
-        "C2801": (
-            "Unnecessarily calls dunder method %s. %s.",
-            "unnecessary-dunder-call",
-            "Used when a dunder method is manually called instead "
-            "of using the corresponding function/method/operator.",
-        ),
-    }
-    options = ()
-
-    @staticmethod
-    def within_dunder_def(node: nodes.NodeNG) -> bool:
-        """Check if dunder method call is within a dunder method definition."""
-        parent = node.parent
-        while parent is not None:
-            if (
-                isinstance(parent, nodes.FunctionDef)
-                and parent.name.startswith("__")
-                and parent.name.endswith("__")
-            ):
-                return True
-            parent = parent.parent
-        return False
-
-    def visit_call(self, node: nodes.Call) -> None:
-        """Check if method being called is an unnecessary dunder method."""
-        if (
-            isinstance(node.func, nodes.Attribute)
-            and node.func.attrname in DUNDER_METHODS
-            and not self.within_dunder_def(node)
-            and not (
-                isinstance(node.func.expr, nodes.Call)
-                and isinstance(node.func.expr.func, nodes.Name)
-                and node.func.expr.func.name == "super"
-            )
-        ):
-            inf_expr = safe_infer(node.func.expr)
-            if not (inf_expr in {None, Uninferable} or isinstance(inf_expr, Instance)):
-                # Skip dunder calls to non instantiated classes.
-                return
-
-            self.add_message(
-                "unnecessary-dunder-call",
-                node=node,
-                args=(node.func.attrname, DUNDER_METHODS[node.func.attrname]),
-                confidence=HIGH,
-            )
+# You probably don't want to change the MAIN_CHECKER_NAME
+# This would affect rcfile generation and retro-compatibility
+# on all project using [MAIN] in their rcfile.
+MAIN_CHECKER_NAME = "main"
+
+DEFAULT_PYLINT_HOME = platformdirs.user_cache_dir("pylint")
+
+DEFAULT_IGNORE_LIST = ("CVS",)
+
+
+class WarningScope:
+    LINE = "line-based-msg"
+    NODE = "node-based-msg"
+
+
+full_version = f"""pylint {__version__}
+astroid {astroid.__version__}
+Python {sys.version}"""
+
+HUMAN_READABLE_TYPES = {
+    "file": "file",
+    "module": "module",
+    "const": "constant",
+    "class": "class",
+    "function": "function",
+    "method": "method",
+    "attr": "attribute",
+    "argument": "argument",
+    "variable": "variable",
+    "class_attribute": "class attribute",
+    "class_const": "class constant",
+    "inlinevar": "inline iteration",
+    "typevar": "type variable",
+    "typealias": "type alias",
+}
 
+# ignore some messages when emitting useless-suppression:
+# - cyclic-import: can show false positives due to incomplete context
+# - deprecated-{module, argument, class, method, decorator}:
+#   can cause false positives for multi-interpreter projects
+#   when linting with an interpreter on a lower python version
+INCOMPATIBLE_WITH_USELESS_SUPPRESSION = frozenset(
+    [
+        "R0401",  # cyclic-import
+        "W0402",  # deprecated-module
+        "W1505",  # deprecated-method
+        "W1511",  # deprecated-argument
+        "W1512",  # deprecated-class
+        "W1513",  # deprecated-decorator
+        "R0801",  # duplicate-code
+    ]
+)
+
+
+def _get_pylint_home() -> str:
+    """Return the pylint home."""
+    if "PYLINTHOME" in os.environ:
+        return os.environ["PYLINTHOME"]
+    return DEFAULT_PYLINT_HOME
+
+
+PYLINT_HOME = _get_pylint_home()
+
+TYPING_NORETURN = frozenset(
+    (
+        "typing.NoReturn",
+        "typing_extensions.NoReturn",
+    )
+)
+TYPING_NEVER = frozenset(
+    (
+        "typing.Never",
+        "typing_extensions.Never",
+    )
+)
+
+DUNDER_METHODS: dict[tuple[int, int], dict[str, str]] = {
+    (0, 0): {
+        "__init__": "Instantiate class directly",
+        "__del__": "Use del keyword",
+        "__repr__": "Use repr built-in function",
+        "__str__": "Use str built-in function",
+        "__bytes__": "Use bytes built-in function",
+        "__format__": "Use format built-in function, format string method, or f-string",
+        "__lt__": "Use < operator",
+        "__le__": "Use <= operator",
+        "__eq__": "Use == operator",
+        "__ne__": "Use != operator",
+        "__gt__": "Use > operator",
+        "__ge__": "Use >= operator",
+        "__hash__": "Use hash built-in function",
+        "__bool__": "Use bool built-in function",
+        "__getattr__": "Access attribute directly or use getattr built-in function",
+        "__getattribute__": "Access attribute directly or use getattr built-in function",
+        "__setattr__": "Set attribute directly or use setattr built-in function",
+        "__delattr__": "Use del keyword",
+        "__dir__": "Use dir built-in function",
+        "__get__": "Use get method",
+        "__set__": "Use set method",
+        "__delete__": "Use del keyword",
+        "__instancecheck__": "Use isinstance built-in function",
+        "__subclasscheck__": "Use issubclass built-in function",
+        "__call__": "Invoke instance directly",
+        "__len__": "Use len built-in function",
+        "__length_hint__": "Use length_hint method",
+        "__getitem__": "Access item via subscript",
+        "__setitem__": "Set item via subscript",
+        "__delitem__": "Use del keyword",
+        "__iter__": "Use iter built-in function",
+        "__next__": "Use next built-in function",
+        "__reversed__": "Use reversed built-in function",
+        "__contains__": "Use in keyword",
+        "__add__": "Use + operator",
+        "__sub__": "Use - operator",
+        "__mul__": "Use * operator",
+        "__matmul__": "Use @ operator",
+        "__truediv__": "Use / operator",
+        "__floordiv__": "Use // operator",
+        "__mod__": "Use % operator",
+        "__divmod__": "Use divmod built-in function",
+        "__pow__": "Use ** operator or pow built-in function",
+        "__lshift__": "Use << operator",
+        "__rshift__": "Use >> operator",
+        "__and__": "Use & operator",
+        "__xor__": "Use ^ operator",
+        "__or__": "Use | operator",
+        "__radd__": "Use + operator",
+        "__rsub__": "Use - operator",
+        "__rmul__": "Use * operator",
+        "__rmatmul__": "Use @ operator",
+        "__rtruediv__": "Use / operator",
+        "__rfloordiv__": "Use // operator",
+        "__rmod__": "Use % operator",
+        "__rdivmod__": "Use divmod built-in function",
+        "__rpow__": "Use ** operator or pow built-in function",
+        "__rlshift__": "Use << operator",
+        "__rrshift__": "Use >> operator",
+        "__rand__": "Use & operator",
+        "__rxor__": "Use ^ operator",
+        "__ror__": "Use | operator",
+        "__iadd__": "Use += operator",
+        "__isub__": "Use -= operator",
+        "__imul__": "Use *= operator",
+        "__imatmul__": "Use @= operator",
+        "__itruediv__": "Use /= operator",
+        "__ifloordiv__": "Use //= operator",
+        "__imod__": "Use %= operator",
+        "__ipow__": "Use **= operator",
+        "__ilshift__": "Use <<= operator",
+        "__irshift__": "Use >>= operator",
+        "__iand__": "Use &= operator",
+        "__ixor__": "Use ^= operator",
+        "__ior__": "Use |= operator",
+        "__neg__": "Multiply by -1 instead",
+        "__pos__": "Multiply by +1 instead",
+        "__abs__": "Use abs built-in function",
+        "__invert__": "Use ~ operator",
+        "__complex__": "Use complex built-in function",
+        "__int__": "Use int built-in function",
+        "__float__": "Use float built-in function",
+        "__round__": "Use round built-in function",
+        "__trunc__": "Use math.trunc function",
+        "__floor__": "Use math.floor function",
+        "__ceil__": "Use math.ceil function",
+        "__enter__": "Invoke context manager directly",
+        "__aenter__": "Invoke context manager directly",
+        "__copy__": "Use copy.copy function",
+        "__deepcopy__": "Use copy.deepcopy function",
+        "__fspath__": "Use os.fspath function instead",
+    },
+    (3, 10): {
+        "__aiter__": "Use aiter built-in function",
+        "__anext__": "Use anext built-in function",
+    },
+}
 
-def register(linter: PyLinter) -> None:
-    linter.register_checker(DunderCallChecker(linter))
+EXTRA_DUNDER_METHODS = [
+    "__new__",
+    "__subclasses__",
+    "__init_subclass__",
+    "__set_name__",
+    "__class_getitem__",
+    "__missing__",
+    "__exit__",
+    "__await__",
+    "__aexit__",
+    "__getnewargs_ex__",
+    "__getnewargs__",
+    "__getstate__",
+    "__setstate__",
+    "__reduce__",
+    "__reduce_ex__",
+    "__post_init__",  # part of `dataclasses` module
+]
+
+DUNDER_PROPERTIES = [
+    "__class__",
+    "__dict__",
+    "__doc__",
+    "__format__",
+    "__module__",
+    "__sizeof__",
+    "__subclasshook__",
+    "__weakref__",
+]
```

### Comparing `pylint-3.0.0a5/pylint/checkers/ellipsis_checker.py` & `pylint-3.0.0a6/pylint/checkers/ellipsis_checker.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Ellipsis checker for Python code."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
```

### Comparing `pylint-3.0.0a5/pylint/checkers/exceptions.py` & `pylint-3.0.0a6/pylint/checkers/exceptions.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,98 +1,101 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checks for various exception related errors."""
 
 from __future__ import annotations
 
 import builtins
 import inspect
+import warnings
+from collections.abc import Generator
 from typing import TYPE_CHECKING, Any
 
 import astroid
-from astroid import nodes, objects
+from astroid import nodes, objects, util
+from astroid.context import InferenceContext
+from astroid.typing import InferenceResult, SuccessfulInferenceResult
 
 from pylint import checkers
 from pylint.checkers import utils
-from pylint.interfaces import HIGH
+from pylint.interfaces import HIGH, INFERENCE
 from pylint.typing import MessageDefinitionTuple
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
-def _builtin_exceptions():
-    def predicate(obj):
+def _builtin_exceptions() -> set[str]:
+    def predicate(obj: Any) -> bool:
         return isinstance(obj, type) and issubclass(obj, BaseException)
 
     members = inspect.getmembers(builtins, predicate)
     return {exc.__name__ for (_, exc) in members}
 
 
-def _annotated_unpack_infer(stmt, context=None):
+def _annotated_unpack_infer(
+    stmt: nodes.NodeNG, context: InferenceContext | None = None
+) -> Generator[tuple[nodes.NodeNG, SuccessfulInferenceResult], None, None]:
     """Recursively generate nodes inferred by the given statement.
 
     If the inferred value is a list or a tuple, recurse on the elements.
     Returns an iterator which yields tuples in the format
     ('original node', 'inferred node').
     """
     if isinstance(stmt, (nodes.List, nodes.Tuple)):
         for elt in stmt.elts:
             inferred = utils.safe_infer(elt)
-            if inferred and inferred is not astroid.Uninferable:
+            if inferred and not isinstance(inferred, util.UninferableBase):
                 yield elt, inferred
         return
     for inferred in stmt.infer(context):
-        if inferred is astroid.Uninferable:
+        if isinstance(inferred, util.UninferableBase):
             continue
         yield stmt, inferred
 
 
-def _is_raising(body: list) -> bool:
+def _is_raising(body: list[nodes.NodeNG]) -> bool:
     """Return whether the given statement node raises an exception."""
     return any(isinstance(node, nodes.Raise) for node in body)
 
 
-OVERGENERAL_EXCEPTIONS = ("BaseException", "Exception")
-
-MSGS: dict[
-    str, MessageDefinitionTuple
-] = {  # pylint: disable=consider-using-namedtuple-or-dataclass
+MSGS: dict[str, MessageDefinitionTuple] = {
     "E0701": (
         "Bad except clauses order (%s)",
         "bad-except-order",
         "Used when except clauses are not in the correct order (from the "
         "more specific to the more generic). If you don't fix the order, "
         "some exceptions may not be caught by the most specific handler.",
     ),
     "E0702": (
         "Raising %s while only classes or instances are allowed",
         "raising-bad-type",
         "Used when something which is neither a class nor an instance "
         "is raised (i.e. a `TypeError` will be raised).",
     ),
-    "E0703": (
-        "Exception context set to something which is not an exception, nor None",
-        "bad-exception-context",
-        'Used when using the syntax "raise ... from ...", '
-        "where the exception context is not an exception, "
-        "nor None.",
-    ),
     "E0704": (
         "The raise statement is not inside an except clause",
         "misplaced-bare-raise",
         "Used when a bare raise is not used inside an except clause. "
         "This generates an error, since there are no active exceptions "
         "to be reraised. An exception to this rule is represented by "
         "a bare raise inside a finally clause, which might work, as long "
         "as an exception is raised inside the try block, but it is "
         "nevertheless a code smell that must not be relied upon.",
     ),
+    "E0705": (
+        "Exception cause set to something which is not an exception, nor None",
+        "bad-exception-cause",
+        'Used when using the syntax "raise ... from ...", '
+        "where the exception cause is not an exception, "
+        "nor None.",
+        {"old_names": [("E0703", "bad-exception-context")]},
+    ),
     "E0710": (
         "Raising a new style class which doesn't inherit from BaseException",
         "raising-non-exception",
         "Used when a new style class which doesn't inherit from "
         "BaseException is raised.",
     ),
     "E0711": (
@@ -105,21 +108,27 @@
         "catching-non-exception",
         "Used when a class which doesn't inherit from "
         "Exception is used as an exception in an except clause.",
     ),
     "W0702": (
         "No exception type(s) specified",
         "bare-except",
-        "Used when an except clause doesn't specify exceptions type to catch.",
+        "A bare ``except:`` clause will catch ``SystemExit`` and "
+        "``KeyboardInterrupt`` exceptions, making it harder to interrupt a program "
+        "with ``Control-C``, and can disguise other problems. If you want to catch "
+        "all exceptions that signal program errors, use ``except Exception:`` (bare "
+        "except is equivalent to ``except BaseException:``).",
     ),
-    "W0703": (
+    "W0718": (
         "Catching too general exception %s",
-        "broad-except",
-        "Used when an except catches a too general exception, "
-        "possibly burying unrelated errors.",
+        "broad-exception-caught",
+        "If you use a naked ``except Exception:`` clause, you might end up catching "
+        "exceptions other than the ones you expect to catch. This can hide bugs or "
+        "make it harder to debug programs when unrelated errors are hidden.",
+        {"old_names": [("W0703", "broad-except")]},
     ),
     "W0705": (
         "Catching previously caught exception type %s",
         "duplicate-except",
         "Used when an except catches a type that was already caught by "
         "a previous handler.",
     ),
@@ -157,25 +166,34 @@
     "W0716": (
         "Invalid exception operation. %s",
         "wrong-exception-operation",
         "Used when an operation is done against an exception, but the operation "
         "is not valid for the exception in question. Usually emitted when having "
         "binary operations between exceptions in except handlers.",
     ),
+    "W0719": (
+        "Raising too general exception: %s",
+        "broad-exception-raised",
+        "Raising exceptions that are too generic force you to catch exceptions "
+        "generically too. It will force you to use a naked ``except Exception:`` "
+        "clause. You might then end up catching exceptions other than the ones "
+        "you expect to catch. This can hide bugs or make it harder to debug programs "
+        "when unrelated errors are hidden.",
+    ),
 }
 
 
 class BaseVisitor:
     """Base class for visitors defined in this module."""
 
-    def __init__(self, checker, node):
+    def __init__(self, checker: ExceptionsChecker, node: nodes.Raise) -> None:
         self._checker = checker
         self._node = node
 
-    def visit(self, node):
+    def visit(self, node: SuccessfulInferenceResult) -> None:
         name = node.__class__.__name__.lower()
         dispatch_meth = getattr(self, "visit_" + name, None)
         if dispatch_meth:
             dispatch_meth(node)
         else:
             self.visit_default(node)
 
@@ -184,106 +202,158 @@
 
 
 class ExceptionRaiseRefVisitor(BaseVisitor):
     """Visit references (anything that is not an AST leaf)."""
 
     def visit_name(self, node: nodes.Name) -> None:
         if node.name == "NotImplemented":
-            self._checker.add_message("notimplemented-raised", node=self._node)
+            self._checker.add_message(
+                "notimplemented-raised", node=self._node, confidence=HIGH
+            )
+            return
+        try:
+            exceptions = [
+                c
+                for _, c in _annotated_unpack_infer(node)
+                if isinstance(c, nodes.ClassDef)
+            ]
+        except astroid.InferenceError:
+            return
+
+        for exception in exceptions:
+            if self._checker._is_overgeneral_exception(exception):
+                self._checker.add_message(
+                    "broad-exception-raised",
+                    args=exception.name,
+                    node=self._node,
+                    confidence=INFERENCE,
+                )
 
     def visit_call(self, node: nodes.Call) -> None:
         if isinstance(node.func, nodes.Name):
             self.visit_name(node.func)
         if (
             len(node.args) > 1
             and isinstance(node.args[0], nodes.Const)
             and isinstance(node.args[0].value, str)
         ):
             msg = node.args[0].value
             if "%" in msg or ("{" in msg and "}" in msg):
-                self._checker.add_message("raising-format-tuple", node=self._node)
+                self._checker.add_message(
+                    "raising-format-tuple", node=self._node, confidence=HIGH
+                )
 
 
 class ExceptionRaiseLeafVisitor(BaseVisitor):
     """Visitor for handling leaf kinds of a raise value."""
 
     def visit_const(self, node: nodes.Const) -> None:
         self._checker.add_message(
-            "raising-bad-type", node=self._node, args=node.value.__class__.__name__
+            "raising-bad-type",
+            node=self._node,
+            args=node.value.__class__.__name__,
+            confidence=INFERENCE,
         )
 
     def visit_instance(self, instance: objects.ExceptionInstance) -> None:
         cls = instance._proxied
         self.visit_classdef(cls)
 
     # Exception instances have a particular class type
     visit_exceptioninstance = visit_instance
 
     def visit_classdef(self, node: nodes.ClassDef) -> None:
         if not utils.inherit_from_std_ex(node) and utils.has_known_bases(node):
             if node.newstyle:
-                self._checker.add_message("raising-non-exception", node=self._node)
+                self._checker.add_message(
+                    "raising-non-exception",
+                    node=self._node,
+                    confidence=INFERENCE,
+                )
 
     def visit_tuple(self, _: nodes.Tuple) -> None:
-        self._checker.add_message("raising-bad-type", node=self._node, args="tuple")
+        self._checker.add_message(
+            "raising-bad-type",
+            node=self._node,
+            args="tuple",
+            confidence=INFERENCE,
+        )
 
     def visit_default(self, node: nodes.NodeNG) -> None:
         name = getattr(node, "name", node.__class__.__name__)
-        self._checker.add_message("raising-bad-type", node=self._node, args=name)
+        self._checker.add_message(
+            "raising-bad-type",
+            node=self._node,
+            args=name,
+            confidence=INFERENCE,
+        )
 
 
 class ExceptionsChecker(checkers.BaseChecker):
     """Exception related checks."""
 
     name = "exceptions"
     msgs = MSGS
     options = (
         (
             "overgeneral-exceptions",
             {
-                "default": OVERGENERAL_EXCEPTIONS,
+                "default": ("builtins.BaseException", "builtins.Exception"),
                 "type": "csv",
                 "metavar": "<comma-separated class names>",
                 "help": "Exceptions that will emit a warning when caught.",
             },
         ),
     )
 
-    def open(self):
+    def open(self) -> None:
         self._builtin_exceptions = _builtin_exceptions()
+        # TODO 3.1: Remove this check and put it elsewhere
+        for exc_name in self.linter.config.overgeneral_exceptions:
+            if "." not in exc_name:
+                warnings.warn_explicit(
+                    f"'{exc_name}' is not a proper value for the 'overgeneral-exceptions' option. "
+                    f"Use fully qualified name (maybe 'builtins.{exc_name}' ?) instead. "
+                    "This will cease to be checked at runtime in 3.1.0.",
+                    category=UserWarning,
+                    filename="pylint: Command line or configuration file",
+                    lineno=1,
+                    module="pylint",
+                )
         super().open()
 
     @utils.only_required_for_messages(
         "misplaced-bare-raise",
         "raising-bad-type",
         "raising-non-exception",
         "notimplemented-raised",
-        "bad-exception-context",
+        "bad-exception-cause",
         "raising-format-tuple",
         "raise-missing-from",
+        "broad-exception-raised",
     )
     def visit_raise(self, node: nodes.Raise) -> None:
         if node.exc is None:
             self._check_misplaced_bare_raise(node)
             return
 
         if node.cause is None:
             self._check_raise_missing_from(node)
         else:
-            self._check_bad_exception_context(node)
+            self._check_bad_exception_cause(node)
 
         expr = node.exc
         ExceptionRaiseRefVisitor(self, node).visit(expr)
 
         inferred = utils.safe_infer(expr)
-        if inferred is None or inferred is astroid.Uninferable:
+        if inferred is None or isinstance(inferred, util.UninferableBase):
             return
         ExceptionRaiseLeafVisitor(self, node).visit(inferred)
 
-    def _check_misplaced_bare_raise(self, node):
+    def _check_misplaced_bare_raise(self, node: nodes.Raise) -> None:
         # Filter out if it's present in __exit__.
         scope = node.scope()
         if (
             isinstance(scope, nodes.FunctionDef)
             and scope.is_method()
             and scope.name == "__exit__"
         ):
@@ -294,32 +364,32 @@
         # statement is found inside a TryFinally.
         ignores = (nodes.ExceptHandler, nodes.FunctionDef)
         while current and not isinstance(current.parent, ignores):
             current = current.parent
 
         expected = (nodes.ExceptHandler,)
         if not current or not isinstance(current.parent, expected):
-            self.add_message("misplaced-bare-raise", node=node)
+            self.add_message("misplaced-bare-raise", node=node, confidence=HIGH)
 
-    def _check_bad_exception_context(self, node: nodes.Raise) -> None:
-        """Verify that the exception context is properly set.
+    def _check_bad_exception_cause(self, node: nodes.Raise) -> None:
+        """Verify that the exception cause is properly set.
 
-        An exception context can be only `None` or an exception.
+        An exception cause can be only `None` or an exception.
         """
         cause = utils.safe_infer(node.cause)
-        if cause in (astroid.Uninferable, None):
+        if cause is None or isinstance(cause, util.UninferableBase):
             return
 
         if isinstance(cause, nodes.Const):
             if cause.value is not None:
-                self.add_message("bad-exception-context", node=node)
+                self.add_message("bad-exception-cause", node=node, confidence=INFERENCE)
         elif not isinstance(cause, nodes.ClassDef) and not utils.inherit_from_std_ex(
             cause
         ):
-            self.add_message("bad-exception-context", node=node)
+            self.add_message("bad-exception-cause", node=node, confidence=INFERENCE)
 
     def _check_raise_missing_from(self, node: nodes.Raise) -> None:
         if node.exc is None:
             # This is a plain `raise`, raising the previously-caught exception. No need for a
             # cause.
             return
         # We'd like to check whether we're inside an `except` clause:
@@ -359,19 +429,24 @@
             self.add_message(
                 "raise-missing-from",
                 node=node,
                 args=("", node.as_string(), containing_except_node.name.name),
                 confidence=HIGH,
             )
 
-    def _check_catching_non_exception(self, handler, exc, part):
+    def _check_catching_non_exception(
+        self,
+        handler: nodes.ExceptHandler,
+        exc: SuccessfulInferenceResult,
+        part: nodes.NodeNG,
+    ) -> None:
         if isinstance(exc, nodes.Tuple):
             # Check if it is a tuple of exceptions.
             inferred = [utils.safe_infer(elt) for elt in exc.elts]
-            if any(node is astroid.Uninferable for node in inferred):
+            if any(isinstance(node, util.UninferableBase) for node in inferred):
                 # Don't emit if we don't know every component.
                 return
             if all(
                 node
                 and (utils.inherit_from_std_ex(node) or not utils.has_known_bases(node))
                 for node in inferred
             ):
@@ -407,39 +482,39 @@
             and exc.name not in self._builtin_exceptions
         ):
             if utils.has_known_bases(exc):
                 self.add_message(
                     "catching-non-exception", node=handler.type, args=(exc.name,)
                 )
 
-    def _check_try_except_raise(self, node):
+    def _check_try_except_raise(self, node: nodes.TryExcept) -> None:
         def gather_exceptions_from_handler(
-            handler,
-        ) -> list[nodes.NodeNG] | None:
-            exceptions: list[nodes.NodeNG] = []
+            handler: nodes.ExceptHandler,
+        ) -> list[InferenceResult] | None:
+            exceptions: list[InferenceResult] = []
             if handler.type:
                 exceptions_in_handler = utils.safe_infer(handler.type)
                 if isinstance(exceptions_in_handler, nodes.Tuple):
                     exceptions = list(
                         {
                             exception
                             for exception in exceptions_in_handler.elts
-                            if isinstance(exception, nodes.Name)
+                            if isinstance(exception, (nodes.Name, nodes.Attribute))
                         }
                     )
                 elif exceptions_in_handler:
                     exceptions = [exceptions_in_handler]
                 else:
                     # Break when we cannot infer anything reliably.
                     return None
             return exceptions
 
         bare_raise = False
         handler_having_bare_raise = None
-        exceptions_in_bare_handler = []
+        exceptions_in_bare_handler: list[InferenceResult] | None = []
         for handler in node.handlers:
             if bare_raise:
                 # check that subsequent handler is not parent of handler which had bare raise.
                 # since utils.safe_infer can fail for bare except, check it before.
                 # also break early if bare except is followed by bare except.
 
                 excs_in_current_handler = gather_exceptions_from_handler(handler)
@@ -475,55 +550,61 @@
             suggestion = f"Did you mean '({node.left.as_string()}, {node.right.as_string()})' instead?"
             self.add_message("wrong-exception-operation", node=node, args=(suggestion,))
 
     @utils.only_required_for_messages("wrong-exception-operation")
     def visit_compare(self, node: nodes.Compare) -> None:
         if isinstance(node.parent, nodes.ExceptHandler):
             # except (V < A)
-            suggestion = f"Did you mean '({node.left.as_string()}, {', '.join(operand.as_string() for _, operand in node.ops)})' instead?"
+            suggestion = (
+                f"Did you mean '({node.left.as_string()}, "
+                f"{', '.join(o.as_string() for _, o in node.ops)})' instead?"
+            )
             self.add_message("wrong-exception-operation", node=node, args=(suggestion,))
 
     @utils.only_required_for_messages(
         "bare-except",
-        "broad-except",
+        "broad-exception-caught",
         "try-except-raise",
         "binary-op-exception",
         "bad-except-order",
         "catching-non-exception",
         "duplicate-except",
     )
     def visit_tryexcept(self, node: nodes.TryExcept) -> None:
         """Check for empty except."""
         self._check_try_except_raise(node)
         exceptions_classes: list[Any] = []
         nb_handlers = len(node.handlers)
         for index, handler in enumerate(node.handlers):
             if handler.type is None:
                 if not _is_raising(handler.body):
-                    self.add_message("bare-except", node=handler)
+                    self.add_message("bare-except", node=handler, confidence=HIGH)
 
                 # check if an "except:" is followed by some other
                 # except
                 if index < (nb_handlers - 1):
                     msg = "empty except clause should always appear last"
-                    self.add_message("bad-except-order", node=node, args=msg)
+                    self.add_message(
+                        "bad-except-order", node=node, args=msg, confidence=HIGH
+                    )
 
             elif isinstance(handler.type, nodes.BoolOp):
                 self.add_message(
-                    "binary-op-exception", node=handler, args=handler.type.op
+                    "binary-op-exception",
+                    node=handler,
+                    args=handler.type.op,
+                    confidence=HIGH,
                 )
             else:
                 try:
                     exceptions = list(_annotated_unpack_infer(handler.type))
                 except astroid.InferenceError:
                     continue
 
                 for part, exception in exceptions:
-                    if exception is astroid.Uninferable:
-                        continue
                     if isinstance(
                         exception, astroid.Instance
                     ) and utils.inherit_from_std_ex(exception):
                         exception = exception._proxied
 
                     self._check_catching_non_exception(handler, exception, part)
 
@@ -536,28 +617,38 @@
                         if isinstance(anc, nodes.ClassDef)
                     ]
 
                     for previous_exc in exceptions_classes:
                         if previous_exc in exc_ancestors:
                             msg = f"{previous_exc.name} is an ancestor class of {exception.name}"
                             self.add_message(
-                                "bad-except-order", node=handler.type, args=msg
+                                "bad-except-order",
+                                node=handler.type,
+                                args=msg,
+                                confidence=INFERENCE,
                             )
-                    if (
-                        exception.name in self.linter.config.overgeneral_exceptions
-                        and exception.root().name == utils.EXCEPTIONS_MODULE
-                        and not _is_raising(handler.body)
+                    if self._is_overgeneral_exception(exception) and not _is_raising(
+                        handler.body
                     ):
                         self.add_message(
-                            "broad-except", args=exception.name, node=handler.type
+                            "broad-exception-caught",
+                            args=exception.name,
+                            node=handler.type,
+                            confidence=INFERENCE,
                         )
 
                     if exception in exceptions_classes:
                         self.add_message(
-                            "duplicate-except", args=exception.name, node=handler.type
+                            "duplicate-except",
+                            args=exception.name,
+                            node=handler.type,
+                            confidence=INFERENCE,
                         )
 
                 exceptions_classes += [exc for _, exc in exceptions]
 
+    def _is_overgeneral_exception(self, exception: nodes.ClassDef) -> bool:
+        return exception.qname() in self.linter.config.overgeneral_exceptions
+
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(ExceptionsChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/checkers/format.py` & `pylint-3.0.0a6/pylint/checkers/format.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,56 +1,61 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Python code format's checker.
 
 By default, try to follow Guido's style guide :
 
 https://www.python.org/doc/essays/styleguide/
 
 Some parts of the process_token method is based from The Tab Nanny std module.
 """
 
 from __future__ import annotations
 
+import sys
 import tokenize
 from functools import reduce
+from re import Match
 from typing import TYPE_CHECKING
 
 from astroid import nodes
 
 from pylint.checkers import BaseRawFileChecker, BaseTokenChecker
-from pylint.checkers.utils import (
-    is_overload_stub,
-    is_protocol_class,
-    node_frame_class,
-    only_required_for_messages,
-)
+from pylint.checkers.utils import only_required_for_messages
 from pylint.constants import WarningScope
+from pylint.interfaces import HIGH
 from pylint.typing import MessageDefinitionTuple
 from pylint.utils.pragma_parser import OPTION_PO, PragmaParserError, parse_pragma
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
+if sys.version_info >= (3, 8):
+    from typing import Literal
+else:
+    from typing_extensions import Literal
+
 _KEYWORD_TOKENS = {
     "assert",
     "del",
     "elif",
     "except",
     "for",
     "if",
     "in",
     "not",
     "raise",
     "return",
     "while",
     "yield",
     "with",
+    "=",
+    ":=",
 }
 _JUNK_TOKENS = {tokenize.COMMENT, tokenize.NL}
 
 
 MSGS: dict[str, MessageDefinitionTuple] = {
     "C0301": (
         "Line too long (%s/%s)",
@@ -110,43 +115,43 @@
         "Unexpected line ending format. There is '%s' while it should be '%s'.",
         "unexpected-line-ending-format",
         "Used when there is different newline than expected.",
     ),
 }
 
 
-def _last_token_on_line_is(tokens, line_end, token):
+def _last_token_on_line_is(tokens: TokenWrapper, line_end: int, token: str) -> bool:
     return (
         line_end > 0
         and tokens.token(line_end - 1) == token
         or line_end > 1
         and tokens.token(line_end - 2) == token
         and tokens.type(line_end - 1) == tokenize.COMMENT
     )
 
 
 class TokenWrapper:
     """A wrapper for readable access to token information."""
 
-    def __init__(self, tokens):
+    def __init__(self, tokens: list[tokenize.TokenInfo]) -> None:
         self._tokens = tokens
 
-    def token(self, idx):
+    def token(self, idx: int) -> str:
         return self._tokens[idx][1]
 
-    def type(self, idx):
+    def type(self, idx: int) -> int:
         return self._tokens[idx][0]
 
-    def start_line(self, idx):
+    def start_line(self, idx: int) -> int:
         return self._tokens[idx][2][0]
 
-    def start_col(self, idx):
+    def start_col(self, idx: int) -> int:
         return self._tokens[idx][2][1]
 
-    def line(self, idx):
+    def line(self, idx: int) -> str:
         return self._tokens[idx][4]
 
 
 class FormatChecker(BaseTokenChecker, BaseRawFileChecker):
     """Formatting checker.
 
     Checks for :
@@ -247,51 +252,47 @@
                     "Expected format of line ending, "
                     "e.g. empty (any line ending), LF or CRLF."
                 ),
             },
         ),
     )
 
-    def __init__(self, linter=None):
+    def __init__(self, linter: PyLinter) -> None:
         super().__init__(linter)
-        self._lines = None
-        self._visited_lines = None
-        self._bracket_stack = [None]
+        self._lines: dict[int, str] = {}
+        self._visited_lines: dict[int, Literal[1, 2]] = {}
 
-    def new_line(self, tokens, line_end, line_start):
+    def new_line(self, tokens: TokenWrapper, line_end: int, line_start: int) -> None:
         """A new line has been encountered, process it if necessary."""
         if _last_token_on_line_is(tokens, line_end, ";"):
             self.add_message("unnecessary-semicolon", line=tokens.start_line(line_end))
 
         line_num = tokens.start_line(line_start)
         line = tokens.line(line_start)
         if tokens.type(line_start) not in _JUNK_TOKENS:
             self._lines[line_num] = line.split("\n")[0]
-        self.check_lines(line, line_num)
+        self.check_lines(tokens, line_start, line, line_num)
 
     def process_module(self, node: nodes.Module) -> None:
         pass
 
-    # pylint: disable-next=too-many-return-statements
+    # pylint: disable-next = too-many-return-statements, too-many-branches
     def _check_keyword_parentheses(
         self, tokens: list[tokenize.TokenInfo], start: int
     ) -> None:
         """Check that there are not unnecessary parentheses after a keyword.
 
         Parens are unnecessary if there is exactly one balanced outer pair on a
-        line, and it is followed by a colon, and contains no commas (i.e. is not a
-        tuple).
+        line and contains no commas (i.e. is not a tuple).
 
         Args:
-        tokens: list of Tokens; the entire list of Tokens.
-        start: int; the position of the keyword in the token list.
+        tokens: The entire list of Tokens.
+        start: The position of the keyword in the token list.
         """
         # If the next token is not a paren, we're fine.
-        if self._bracket_stack[-1] == ":" and tokens[start].string == "for":
-            self._bracket_stack.pop()
         if tokens[start + 1].string != "(":
             return
         if (
             tokens[start].string == "not"
             and start > 0
             and tokens[start - 1].string == "is"
         ):
@@ -341,15 +342,15 @@
                         return
                     # The empty tuple () is always accepted.
                     if i == start + 2:
                         return
                     if found_and_or:
                         return
                     if keyword_token == "in":
-                        # This special case was added in https://github.com/PyCQA/pylint/pull/4948
+                        # This special case was added in https://github.com/pylint-dev/pylint/pull/4948
                         # but it could be removed in the future. Avoid churn for now.
                         return
                     self.add_message(
                         "superfluous-parens", line=line_num, args=keyword_token
                     )
                 return
             elif depth == 1:
@@ -375,29 +376,28 @@
                 # the 'else'.
                 elif token[1] == "else":
                     if "(" in (i.string for i in tokens[i:]):
                         self._check_keyword_parentheses(tokens[i:], 0)
                     return
 
     def process_tokens(self, tokens: list[tokenize.TokenInfo]) -> None:
-        """Process tokens and search for :
+        """Process tokens and search for:
 
-        _ too long lines (i.e. longer than <max_chars>)
-        _ optionally bad construct (if given, bad_construct must be a compiled
+        - too long lines (i.e. longer than <max_chars>)
+        - optionally bad construct (if given, bad_construct must be a compiled
           regular expression).
         """
-        self._bracket_stack = [None]
         indents = [0]
         check_equal = False
         line_num = 0
         self._lines = {}
         self._visited_lines = {}
-        self._last_line_ending = None
+        self._last_line_ending: str | None = None
         last_blank_line_num = 0
-        for idx, (tok_type, token, start, _, line) in enumerate(tokens):
+        for idx, (tok_type, string, start, _, line) in enumerate(tokens):
             if start[0] != line_num:
                 line_num = start[0]
                 # A tokenizer oddity: if an indented line contains a multi-line
                 # docstring, the line member of the INDENT token does not contain
                 # the full line; therefore we check the next token on the line.
                 if tok_type == tokenize.INDENT:
                     self.new_line(TokenWrapper(tokens), idx - 1, idx + 1)
@@ -407,18 +407,18 @@
             if tok_type == tokenize.NEWLINE:
                 # a program statement, or ENDMARKER, will eventually follow,
                 # after some (possibly empty) run of tokens of the form
                 #     (NL | COMMENT)* (INDENT | DEDENT+)?
                 # If an INDENT appears, setting check_equal is wrong, and will
                 # be undone when we see the INDENT.
                 check_equal = True
-                self._check_line_ending(token, line_num)
+                self._check_line_ending(string, line_num)
             elif tok_type == tokenize.INDENT:
                 check_equal = False
-                self.check_indent_level(token, indents[-1] + 1, line_num)
+                self.check_indent_level(string, indents[-1] + 1, line_num)
                 indents.append(indents[-1] + 1)
             elif tok_type == tokenize.DEDENT:
                 # there's nothing we need to check here!  what's important is
                 # that when the run of DEDENTs ends, the indentation of the
                 # program statement (or ENDMARKER) that triggered the run is
                 # equal to what's left at the top of the indents stack
                 check_equal = True
@@ -434,18 +434,18 @@
                 # for this statement; in the case of ENDMARKER, line is an empty
                 # string, so will properly match the empty string with which the
                 # "indents" stack was seeded
                 if check_equal:
                     check_equal = False
                     self.check_indent_level(line, indents[-1], line_num)
 
-            if tok_type == tokenize.NUMBER and token.endswith("l"):
+            if tok_type == tokenize.NUMBER and string.endswith("l"):
                 self.add_message("lowercase-l-suffix", line=line_num)
 
-            if token in _KEYWORD_TOKENS:
+            if string in _KEYWORD_TOKENS:
                 self._check_keyword_parentheses(tokens, idx)
 
         line_num -= 1  # to be ok with "wc -l"
         if line_num > self.linter.config.max_module_lines:
             # Get the line where the too-many-lines (or its message id)
             # was disabled or default to 1.
             message_definition = self.linter.msgs_store.get_message_definitions(
@@ -463,15 +463,15 @@
             )
 
         # See if there are any trailing lines.  Do not complain about empty
         # files like __init__.py markers.
         if line_num == last_blank_line_num and line_num > 0:
             self.add_message("trailing-newlines", line=line_num)
 
-    def _check_line_ending(self, line_ending, line_num):
+    def _check_line_ending(self, line_ending: str, line_num: int) -> None:
         # check if line endings are mixed
         if self._last_line_ending is not None:
             # line_ending == "" indicates a synthetic newline added at
             # the end of a file that does not, in fact, end with a
             # newline.
             if line_ending and line_ending != self._last_line_ending:
                 self.add_message("mixed-line-endings", line=line_num)
@@ -521,23 +521,23 @@
         if line in self._visited_lines:
             return
         try:
             tolineno = node.blockstart_tolineno
         except AttributeError:
             tolineno = node.tolineno
         assert tolineno, node
-        lines = []
-        for line in range(line, tolineno + 1):
+        lines: list[str] = []
+        for line in range(line, tolineno + 1):  # noqa: B020
             self._visited_lines[line] = 1
             try:
                 lines.append(self._lines[line].rstrip())
             except KeyError:
                 lines.append("")
 
-    def _check_multi_statement_line(self, node, line):
+    def _check_multi_statement_line(self, node: nodes.NodeNG, line: int) -> None:
         """Check for lines containing multiple statements."""
         # Do not warn about multiple nested context managers
         # in with statements.
         if isinstance(node, nodes.With):
             return
         # For try... except... finally..., the two nodes
         # appear to be on the same line due to how the AST is built.
@@ -554,65 +554,62 @@
         if (
             isinstance(node.parent, nodes.ClassDef)
             and len(node.parent.body) == 1
             and self.linter.config.single_line_class_stmt
         ):
             return
 
-        # Function overloads that use ``Ellipsis`` are exempted.
+        # Functions stubs with ``Ellipsis`` as body are exempted.
         if (
-            isinstance(node, nodes.Expr)
+            isinstance(node.parent, nodes.FunctionDef)
+            and isinstance(node, nodes.Expr)
             and isinstance(node.value, nodes.Const)
             and node.value.value is Ellipsis
         ):
-            frame = node.frame(future=True)
-            if is_overload_stub(frame) or is_protocol_class(node_frame_class(frame)):
-                return
+            return
 
         self.add_message("multiple-statements", node=node)
         self._visited_lines[line] = 2
 
-    def check_line_ending(self, line: str, i: int) -> None:
-        """Check that the final newline is not missing and that there is no trailing
-        white-space.
-        """
-        if not line.endswith("\n"):
-            self.add_message("missing-final-newline", line=i)
-            return
+    def check_trailing_whitespace_ending(self, line: str, i: int) -> None:
+        """Check that there is no trailing white-space."""
         # exclude \f (formfeed) from the rstrip
         stripped_line = line.rstrip("\t\n\r\v ")
         if line[len(stripped_line) :] not in ("\n", "\r\n"):
             self.add_message(
-                "trailing-whitespace", line=i, col_offset=len(stripped_line)
+                "trailing-whitespace",
+                line=i,
+                col_offset=len(stripped_line),
+                confidence=HIGH,
             )
 
     def check_line_length(self, line: str, i: int, checker_off: bool) -> None:
         """Check that the line length is less than the authorized value."""
         max_chars = self.linter.config.max_line_length
         ignore_long_line = self.linter.config.ignore_long_lines
         line = line.rstrip()
         if len(line) > max_chars and not ignore_long_line.search(line):
             if checker_off:
                 self.linter.add_ignored_message("line-too-long", i)
             else:
                 self.add_message("line-too-long", line=i, args=(len(line), max_chars))
 
     @staticmethod
-    def remove_pylint_option_from_lines(options_pattern_obj) -> str:
+    def remove_pylint_option_from_lines(options_pattern_obj: Match[str]) -> str:
         """Remove the `# pylint ...` pattern from lines."""
         lines = options_pattern_obj.string
         purged_lines = (
             lines[: options_pattern_obj.start(1)].rstrip()
             + lines[options_pattern_obj.end(1) :]
         )
         return purged_lines
 
     @staticmethod
-    def is_line_length_check_activated(pylint_pattern_match_object) -> bool:
-        """Return true if the line length check is activated."""
+    def is_line_length_check_activated(pylint_pattern_match_object: Match[str]) -> bool:
+        """Return True if the line length check is activated."""
         try:
             for pragma in parse_pragma(pylint_pattern_match_object.group(2)):
                 if pragma.action == "disable" and "line-too-long" in pragma.messages:
                     return False
         except PragmaParserError:
             # Printing useful information dealing with this error is done in the lint package
             pass
@@ -629,28 +626,30 @@
             "\x1c",
             "\x1d",
             "\x1e",
             "\x85",
             "\u2028",
             "\u2029",
         }
-        res = []
+        res: list[str] = []
         buffer = ""
         for atomic_line in lines.splitlines(True):
             if atomic_line[-1] not in unsplit_ends:
                 res.append(buffer + atomic_line)
                 buffer = ""
             else:
                 buffer += atomic_line
         return res
 
-    def check_lines(self, lines: str, lineno: int) -> None:
+    def check_lines(
+        self, tokens: TokenWrapper, line_start: int, lines: str, lineno: int
+    ) -> None:
         """Check given lines for potential messages.
 
-        Check lines have :
+        Check if lines have:
         - a final newline
         - no trailing white-space
         - less than a maximum number of characters
         """
         # we're first going to do a rough check whether any lines in this set
         # go over the line limit. If none of them do, then we don't need to
         # parse out the pylint options later on and can just assume that these
@@ -660,25 +659,28 @@
         # unless the line lengths are suspect
 
         max_chars = self.linter.config.max_line_length
 
         split_lines = self.specific_splitlines(lines)
 
         for offset, line in enumerate(split_lines):
-            self.check_line_ending(line, lineno + offset)
-
-        # hold onto the initial lineno for later
-        potential_line_length_warning = False
-        for offset, line in enumerate(split_lines):
-            # this check is purposefully simple and doesn't rstrip
-            # since this is running on every line you're checking it's
-            # advantageous to avoid doing a lot of work
-            if len(line) > max_chars:
-                potential_line_length_warning = True
-                break
+            if not line.endswith("\n"):
+                self.add_message("missing-final-newline", line=lineno + offset)
+                continue
+            # We don't test for trailing whitespaces in strings
+            # See https://github.com/pylint-dev/pylint/issues/6936
+            # and https://github.com/pylint-dev/pylint/issues/3822
+            if tokens.type(line_start) != tokenize.STRING:
+                self.check_trailing_whitespace_ending(line, lineno + offset)
+
+        # This check is purposefully simple and doesn't rstrip since this is running
+        # on every line you're checking it's advantageous to avoid doing a lot of work
+        potential_line_length_warning = any(
+            len(line) > max_chars for line in split_lines
+        )
 
         # if there were no lines passing the max_chars config, we don't bother
         # running the full line check (as we've met an even more strict condition)
         if not potential_line_length_warning:
             return
 
         # Line length check may be deactivated through `pylint: disable` comment
@@ -690,15 +692,15 @@
             # The 'pylint: disable whatever' should not be taken into account for line length count
             lines = self.remove_pylint_option_from_lines(mobj)
 
         # here we re-run specific_splitlines since we have filtered out pylint options above
         for offset, line in enumerate(self.specific_splitlines(lines)):
             self.check_line_length(line, lineno + offset, checker_off)
 
-    def check_indent_level(self, string, expected, line_num):
+    def check_indent_level(self, string: str, expected: int, line_num: int) -> None:
         """Return the indent level of the string."""
         indent = self.linter.config.indent_string
         if indent == "\\t":  # \t is not interpreted in the configuration file
             indent = "\t"
         level = 0
         unit_size = len(indent)
         while string[:unit_size] == indent:
```

### Comparing `pylint-3.0.0a5/pylint/checkers/imports.py` & `pylint-3.0.0a6/pylint/checkers/imports.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,61 +1,70 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Imports checkers for Python code."""
 
 from __future__ import annotations
 
 import collections
 import copy
 import os
 import sys
-from typing import TYPE_CHECKING, Any
+from collections import defaultdict
+from collections.abc import ItemsView, Sequence
+from typing import TYPE_CHECKING, Any, Dict, List, Union
 
 import astroid
 from astroid import nodes
+from astroid.nodes._base_nodes import ImportNode
 
 from pylint.checkers import BaseChecker, DeprecatedMixin
 from pylint.checkers.utils import (
     get_import_name,
+    in_type_checking_block,
     is_from_fallback_block,
-    is_node_in_guarded_import_block,
-    is_typing_guard,
+    is_sys_guard,
     node_ignores_exception,
 )
 from pylint.exceptions import EmptyReportError
 from pylint.graph import DotBackend, get_cycles
+from pylint.interfaces import HIGH
 from pylint.reporters.ureports.nodes import Paragraph, Section, VerbatimText
 from pylint.typing import MessageDefinitionTuple
 from pylint.utils import IsortDriver
+from pylint.utils.linterstats import LinterStats
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
+# The dictionary with Any should actually be a _ImportTree again
+# but mypy doesn't support recursive types yet
+_ImportTree = Dict[str, Union[List[Dict[str, Any]], List[str]]]
 
 DEPRECATED_MODULES = {
     (0, 0, 0): {"tkinter.tix", "fpectl"},
     (3, 2, 0): {"optparse"},
     (3, 3, 0): {"xml.etree.cElementTree"},
     (3, 4, 0): {"imp"},
     (3, 5, 0): {"formatter"},
     (3, 6, 0): {"asynchat", "asyncore", "smtpd"},
     (3, 7, 0): {"macpath"},
     (3, 9, 0): {"lib2to3", "parser", "symbol", "binhex"},
-    (3, 10, 0): {"distutils"},
+    (3, 10, 0): {"distutils", "typing.io", "typing.re"},
     (3, 11, 0): {
         "aifc",
         "audioop",
         "cgi",
         "cgitb",
         "chunk",
         "crypt",
         "imghdr",
         "msilib",
+        "mailcap",
         "nis",
         "nntplib",
         "ossaudiodev",
         "pipes",
         "sndhdr",
         "spwd",
         "sunau",
@@ -65,106 +74,134 @@
         "telnetlib",
         "uu",
         "xdrlib",
     },
 }
 
 
-def _qualified_names(modname):
+def _qualified_names(modname: str | None) -> list[str]:
     """Split the names of the given module into subparts.
 
     For example,
         _qualified_names('pylint.checkers.ImportsChecker')
     returns
         ['pylint', 'pylint.checkers', 'pylint.checkers.ImportsChecker']
     """
-    names = modname.split(".")
+    names = modname.split(".") if modname is not None else ""
     return [".".join(names[0 : i + 1]) for i in range(len(names))]
 
 
-def _get_first_import(node, context, name, base, level, alias):
+def _get_first_import(
+    node: ImportNode,
+    context: nodes.LocalsDictNodeNG,
+    name: str,
+    base: str | None,
+    level: int | None,
+    alias: str | None,
+) -> tuple[nodes.Import | nodes.ImportFrom | None, str | None]:
     """Return the node where [base.]<name> is imported or None if not found."""
     fullname = f"{base}.{name}" if base else name
 
     first = None
     found = False
+    msg = "reimported"
+
     for first in context.body:
         if first is node:
             continue
         if first.scope() is node.scope() and first.fromlineno > node.fromlineno:
             continue
         if isinstance(first, nodes.Import):
             if any(fullname == iname[0] for iname in first.names):
                 found = True
                 break
+            for imported_name, imported_alias in first.names:
+                if not imported_alias and imported_name == alias:
+                    found = True
+                    msg = "shadowed-import"
+                    break
+            if found:
+                break
         elif isinstance(first, nodes.ImportFrom):
             if level == first.level:
                 for imported_name, imported_alias in first.names:
                     if fullname == f"{first.modname}.{imported_name}":
                         found = True
                         break
                     if (
                         name != "*"
                         and name == imported_name
                         and not (alias or imported_alias)
                     ):
                         found = True
                         break
+                    if not imported_alias and imported_name == alias:
+                        found = True
+                        msg = "shadowed-import"
+                        break
                 if found:
                     break
     if found and not astroid.are_exclusive(first, node):
-        return first
-    return None
+        return first, msg
+    return None, None
 
 
-def _ignore_import_failure(node, modname, ignored_modules):
+def _ignore_import_failure(
+    node: ImportNode,
+    modname: str | None,
+    ignored_modules: Sequence[str],
+) -> bool:
     for submodule in _qualified_names(modname):
         if submodule in ignored_modules:
             return True
 
-    if is_node_in_guarded_import_block(node):
-        # Ignore import failure if part of guarded import block
-        # I.e. `sys.version_info` or `typing.TYPE_CHECKING`
+    # Ignore import failure if part of guarded import block
+    # I.e. `sys.version_info` or `typing.TYPE_CHECKING`
+    if in_type_checking_block(node):
+        return True
+    if isinstance(node.parent, nodes.If) and is_sys_guard(node.parent):
         return True
 
     return node_ignores_exception(node, ImportError)
 
 
 # utilities to represents import dependencies as tree and dot graph ###########
 
 
-def _make_tree_defs(mod_files_list):
+def _make_tree_defs(mod_files_list: ItemsView[str, set[str]]) -> _ImportTree:
     """Get a list of 2-uple (module, list_of_files_which_import_this_module),
     it will return a dictionary to represent this as a tree.
     """
-    tree_defs = {}
+    tree_defs: _ImportTree = {}
     for mod, files in mod_files_list:
-        node = (tree_defs, ())
+        node: list[_ImportTree | list[str]] = [tree_defs, []]
         for prefix in mod.split("."):
-            node = node[0].setdefault(prefix, [{}, []])
-        node[1] += files
+            assert isinstance(node[0], dict)
+            node = node[0].setdefault(prefix, ({}, []))  # type: ignore[arg-type,assignment]
+        assert isinstance(node[1], list)
+        node[1].extend(files)
     return tree_defs
 
 
-def _repr_tree_defs(data, indent_str=None):
+def _repr_tree_defs(data: _ImportTree, indent_str: str | None = None) -> str:
     """Return a string which represents imports as a tree."""
     lines = []
     nodes_items = data.items()
     for i, (mod, (sub, files)) in enumerate(sorted(nodes_items, key=lambda x: x[0])):
-        files = "" if not files else f"({','.join(sorted(files))})"
+        files_list = "" if not files else f"({','.join(sorted(files))})"
         if indent_str is None:
-            lines.append(f"{mod} {files}")
+            lines.append(f"{mod} {files_list}")
             sub_indent_str = "  "
         else:
-            lines.append(rf"{indent_str}\-{mod} {files}")
+            lines.append(rf"{indent_str}\-{mod} {files_list}")
             if i == len(nodes_items) - 1:
                 sub_indent_str = f"{indent_str}  "
             else:
                 sub_indent_str = f"{indent_str}| "
-        if sub:
+        if sub and isinstance(sub, dict):
             lines.append(_repr_tree_defs(sub, sub_indent_str))
     return "\n".join(lines)
 
 
 def _dependencies_graph(filename: str, dep_info: dict[str, set[str]]) -> str:
     """Write dependencies as a dot (graphviz) file."""
     done = {}
@@ -182,26 +219,25 @@
         for modname in sorted(dependencies):
             printer.emit_edge(modname, depmodname)
     return printer.generate(filename)
 
 
 def _make_graph(
     filename: str, dep_info: dict[str, set[str]], sect: Section, gtype: str
-):
+) -> None:
     """Generate a dependencies graph and add some information about it in the
     report's section.
     """
     outputfile = _dependencies_graph(filename, dep_info)
     sect.append(Paragraph((f"{gtype}imports graph has been written to {outputfile}",)))
 
 
 # the import checker itself ###################################################
 
 MSGS: dict[str, MessageDefinitionTuple] = {
-    **{k: v for k, v in DeprecatedMixin.msgs.items() if k[1:3] == "04"},
     "E0401": (
         "Unable to import %s",
         "import-error",
         "Used when pylint has been unable to import a module.",
         {"old_names": [("F0401", "old-import-error")]},
     ),
     "E0402": (
@@ -215,27 +251,27 @@
         "cyclic-import",
         "Used when a cyclic import between two or more modules is detected.",
     ),
     "R0402": (
         "Use 'from %s import %s' instead",
         "consider-using-from-import",
         "Emitted when a submodule of a package is imported and "
-        "aliased with the same name. "
-        "E.g., instead of ``import concurrent.futures as futures`` use "
-        "``from concurrent import futures``",
+        "aliased with the same name, "
+        "e.g., instead of ``import concurrent.futures as futures`` use "
+        "``from concurrent import futures``.",
     ),
     "W0401": (
         "Wildcard import %s",
         "wildcard-import",
         "Used when `from module import *` is detected.",
     ),
     "W0404": (
         "Reimport %r (imported line %s)",
         "reimported",
-        "Used when a module is reimported multiple times.",
+        "Used when a module is imported more than once.",
     ),
     "W0406": (
         "Module import itself",
         "import-self",
         "Used when a module is importing itself.",
     ),
     "W0407": (
@@ -254,38 +290,43 @@
         "multiple-imports",
         "Used when import statement importing multiple modules is detected.",
     ),
     "C0411": (
         "%s should be placed before %s",
         "wrong-import-order",
         "Used when PEP8 import order is not respected (standard imports "
-        "first, then third-party libraries, then local imports)",
+        "first, then third-party libraries, then local imports).",
     ),
     "C0412": (
         "Imports from package %s are not grouped",
         "ungrouped-imports",
-        "Used when imports are not grouped by packages",
+        "Used when imports are not grouped by packages.",
     ),
     "C0413": (
         'Import "%s" should be placed at the top of the module',
         "wrong-import-position",
-        "Used when code and imports are mixed",
+        "Used when code and imports are mixed.",
     ),
     "C0414": (
         "Import alias does not rename original package",
         "useless-import-alias",
-        "Used when an import alias is same as original package."
-        "e.g using import numpy as numpy instead of import numpy as np",
+        "Used when an import alias is same as original package, "
+        "e.g., using import numpy as numpy instead of import numpy as np.",
     ),
     "C0415": (
         "Import outside toplevel (%s)",
         "import-outside-toplevel",
         "Used when an import statement is used anywhere other than the module "
         "toplevel. Move this import to the top of the file.",
     ),
+    "W0416": (
+        "Shadowed %r (imported line %s)",
+        "shadowed-import",
+        "Used when a module is aliased with a name that shadows another import.",
+    ),
 }
 
 
 DEFAULT_STANDARD_LIBRARY = ()
 DEFAULT_KNOWN_THIRD_PARTY = ("enchant",)
 DEFAULT_PREFERRED_MODULES = ()
 
@@ -298,15 +339,15 @@
     * relative / wildcard imports
     * cyclic imports
     * uses of deprecated modules
     * uses of modules instead of preferred modules
     """
 
     name = "imports"
-    msgs = MSGS
+    msgs = {**DeprecatedMixin.DEPRECATED_MODULE_MESSAGE, **MSGS}
     default_deprecated_modules = ()
 
     options = (
         (
             "deprecated-modules",
             {
                 "default": default_deprecated_modules,
@@ -396,53 +437,64 @@
             {
                 "default": False,
                 "type": "yn",
                 "metavar": "<y or n>",
                 "help": "Allow wildcard imports from modules that define __all__.",
             },
         ),
+        (
+            "allow-reexport-from-package",
+            {
+                "default": False,
+                "type": "yn",
+                "metavar": "<y or n>",
+                "help": "Allow explicit reexports by alias from a package __init__.",
+            },
+        ),
     )
 
     def __init__(self, linter: PyLinter) -> None:
         BaseChecker.__init__(self, linter)
-        self.import_graph: collections.defaultdict = collections.defaultdict(set)
-        self._imports_stack: list[tuple[Any, Any]] = []
+        self.import_graph: defaultdict[str, set[str]] = defaultdict(set)
+        self._imports_stack: list[tuple[ImportNode, str]] = []
         self._first_non_import_node = None
         self._module_pkg: dict[
             Any, Any
         ] = {}  # mapping of modules to the pkg they belong in
         self._allow_any_import_level: set[Any] = set()
         self.reports = (
             ("RP0401", "External dependencies", self._report_external_dependencies),
             ("RP0402", "Modules dependencies graph", self._report_dependencies_graph),
         )
 
-    def open(self):
+    def open(self) -> None:
         """Called before visiting project (i.e set of modules)."""
         self.linter.stats.dependencies = {}
         self.linter.stats = self.linter.stats
-        self.import_graph = collections.defaultdict(set)
+        self.import_graph = defaultdict(set)
         self._module_pkg = {}  # mapping of modules to the pkg they belong in
-        self._excluded_edges = collections.defaultdict(set)
-        self._ignored_modules = self.linter.config.ignored_modules
+        self._current_module_package = False
+        self._excluded_edges: defaultdict[str, set[str]] = defaultdict(set)
+        self._ignored_modules: Sequence[str] = self.linter.config.ignored_modules
         # Build a mapping {'module': 'preferred-module'}
         self.preferred_modules = dict(
             module.split(":")
             for module in self.linter.config.preferred_modules
             if ":" in module
         )
         self._allow_any_import_level = set(self.linter.config.allow_any_import_level)
+        self._allow_reexport_package = self.linter.config.allow_reexport_from_package
 
-    def _import_graph_without_ignored_edges(self):
+    def _import_graph_without_ignored_edges(self) -> defaultdict[str, set[str]]:
         filtered_graph = copy.deepcopy(self.import_graph)
         for node in filtered_graph:
             filtered_graph[node].difference_update(self._excluded_edges[node])
         return filtered_graph
 
-    def close(self):
+    def close(self) -> None:
         """Called before visiting project (i.e set of modules)."""
         if self.linter.is_message_enabled("cyclic-import"):
             graph = self._import_graph_without_ignored_edges()
             vertices = list(graph)
             for cycle in get_cycles(graph, vertices=vertices):
                 self.add_message("cyclic-import", args=" -> ".join(cycle))
 
@@ -452,14 +504,18 @@
         all_deprecated_modules = set(self.linter.config.deprecated_modules)
         # Now get the hard-coded ones from the stdlib
         for since_vers, mod_set in DEPRECATED_MODULES.items():
             if since_vers <= sys.version_info:
                 all_deprecated_modules = all_deprecated_modules.union(mod_set)
         return all_deprecated_modules
 
+    def visit_module(self, node: nodes.Module) -> None:
+        """Store if current module is a package, i.e. an __init__ file."""
+        self._current_module_package = node.package
+
     def visit_import(self, node: nodes.Import) -> None:
         """Triggered when an import statement is seen."""
         self._check_reimport(node)
         self._check_import_as_rename(node)
         self._check_toplevel(node)
 
         names = [name for name, _ in node.names]
@@ -520,28 +576,42 @@
         for import_node, import_name in std_imports + ext_imports + loc_imports:
             met = met_from if isinstance(import_node, nodes.ImportFrom) else met_import
             package, _, _ = import_name.partition(".")
             if (
                 current_package
                 and current_package != package
                 and package in met
-                and is_node_in_guarded_import_block(import_node) is False
+                and not in_type_checking_block(import_node)
+                and not (
+                    isinstance(import_node.parent, nodes.If)
+                    and is_sys_guard(import_node.parent)
+                )
             ):
                 self.add_message("ungrouped-imports", node=import_node, args=package)
             current_package = package
             if not self.linter.is_message_enabled(
                 "ungrouped-imports", import_node.fromlineno
             ):
                 continue
             met.add(package)
 
         self._imports_stack = []
         self._first_non_import_node = None
 
-    def compute_first_non_import_node(self, node):
+    def compute_first_non_import_node(
+        self,
+        node: nodes.If
+        | nodes.Expr
+        | nodes.Comprehension
+        | nodes.IfExp
+        | nodes.Assign
+        | nodes.AssignAttr
+        | nodes.TryExcept
+        | nodes.TryFinally,
+    ) -> None:
         # if the node does not contain an import instruction, and if it is the
         # first node of the module, keep a track of it (all the import positions
         # of the module will be compared to the position of this first
         # instruction)
         if self._first_non_import_node:
             return
         if not isinstance(node.parent, nodes.Module):
@@ -573,15 +643,17 @@
         visit_assignattr
     ) = (
         visit_assign
     ) = (
         visit_ifexp
     ) = visit_comprehension = visit_expr = visit_if = compute_first_non_import_node
 
-    def visit_functiondef(self, node: nodes.FunctionDef) -> None:
+    def visit_functiondef(
+        self, node: nodes.FunctionDef | nodes.While | nodes.For | nodes.ClassDef
+    ) -> None:
         # If it is the first non import instruction of the module, record it.
         if self._first_non_import_node:
             return
 
         # Check if the node belongs to an `If` or a `Try` block. If they
         # contain imports, skip recording this node.
         if not isinstance(node.parent.scope(), nodes.Module):
@@ -595,36 +667,36 @@
             if any(root.nodes_of_class((nodes.Import, nodes.ImportFrom))):
                 return
 
         self._first_non_import_node = node
 
     visit_classdef = visit_for = visit_while = visit_functiondef
 
-    def _check_misplaced_future(self, node):
+    def _check_misplaced_future(self, node: nodes.ImportFrom) -> None:
         basename = node.modname
         if basename == "__future__":
             # check if this is the first non-docstring statement in the module
             prev = node.previous_sibling()
             if prev:
                 # consecutive future statements are possible
                 if not (
                     isinstance(prev, nodes.ImportFrom) and prev.modname == "__future__"
                 ):
                     self.add_message("misplaced-future", node=node)
             return
 
-    def _check_same_line_imports(self, node):
+    def _check_same_line_imports(self, node: nodes.ImportFrom) -> None:
         # Detect duplicate imports on the same line.
         names = (name for name, _ in node.names)
         counter = collections.Counter(names)
         for name, count in counter.items():
             if count > 1:
                 self.add_message("reimported", node=node, args=(name, node.fromlineno))
 
-    def _check_position(self, node):
+    def _check_position(self, node: ImportNode) -> None:
         """Check `node` import or importfrom node position is correct.
 
         Send a message  if `node` comes before another instruction
         """
         # if a first non-import instruction has already been encountered,
         # it means the import comes after it and therefore is not well placed
         if self._first_non_import_node:
@@ -635,15 +707,19 @@
                     "wrong-import-position", node=node, args=node.as_string()
                 )
             else:
                 self.linter.add_ignored_message(
                     "wrong-import-position", node.fromlineno, node
                 )
 
-    def _record_import(self, node, importedmodnode):
+    def _record_import(
+        self,
+        node: ImportNode,
+        importedmodnode: nodes.Module | None,
+    ) -> None:
         """Record the package `node` imports from."""
         if isinstance(node, nodes.ImportFrom):
             importedname = node.modname
         else:
             importedname = importedmodnode.name if importedmodnode else None
         if not importedname:
             importedname = node.names[0][0].split(".")[0]
@@ -657,32 +733,41 @@
             #  'from . import my_package2'
             #  the output should be '.my_package2' instead of '{pyfile}'
             importedname = "." + importedname
 
         self._imports_stack.append((node, importedname))
 
     @staticmethod
-    def _is_fallback_import(node, imports):
+    def _is_fallback_import(
+        node: ImportNode, imports: list[tuple[ImportNode, str]]
+    ) -> bool:
         imports = [import_node for (import_node, _) in imports]
         return any(astroid.are_exclusive(import_node, node) for import_node in imports)
 
-    def _check_imports_order(self, _module_node):
+    # pylint: disable = too-many-statements
+    def _check_imports_order(
+        self, _module_node: nodes.Module
+    ) -> tuple[
+        list[tuple[ImportNode, str]],
+        list[tuple[ImportNode, str]],
+        list[tuple[ImportNode, str]],
+    ]:
         """Checks imports of module `node` are grouped by category.
 
         Imports must follow this order: standard, 3rd party, local
         """
-        std_imports = []
-        third_party_imports = []
-        first_party_imports = []
+        std_imports: list[tuple[ImportNode, str]] = []
+        third_party_imports: list[tuple[ImportNode, str]] = []
+        first_party_imports: list[tuple[ImportNode, str]] = []
         # need of a list that holds third or first party ordered import
-        external_imports = []
-        local_imports = []
-        third_party_not_ignored = []
-        first_party_not_ignored = []
-        local_not_ignored = []
+        external_imports: list[tuple[ImportNode, str]] = []
+        local_imports: list[tuple[ImportNode, str]] = []
+        third_party_not_ignored: list[tuple[ImportNode, str]] = []
+        first_party_not_ignored: list[tuple[ImportNode, str]] = []
+        local_not_ignored: list[tuple[ImportNode, str]] = []
         isort_driver = IsortDriver(self.linter.config)
         for node, modname in self._imports_stack:
             if modname.startswith("."):
                 package = "." + modname.split(".")[1]
             else:
                 package = modname.split(".")[0]
             nested = not isinstance(node.parent, nodes.Module)
@@ -756,24 +841,28 @@
                         local_not_ignored.append((node, package))
                     else:
                         self.linter.add_ignored_message(
                             "wrong-import-order", node.fromlineno, node
                         )
         return std_imports, external_imports, local_imports
 
-    def _get_imported_module(self, importnode, modname):
+    def _get_imported_module(
+        self, importnode: ImportNode, modname: str | None
+    ) -> nodes.Module | None:
         try:
             return importnode.do_import_module(modname)
         except astroid.TooManyLevelsError:
             if _ignore_import_failure(importnode, modname, self._ignored_modules):
                 return None
             self.add_message("relative-beyond-top-level", node=importnode)
         except astroid.AstroidSyntaxError as exc:
-            message = f"Cannot import {modname!r} due to syntax error {str(exc.error)!r}"  # pylint: disable=no-member; false positive
-            self.add_message("syntax-error", line=importnode.lineno, args=message)
+            message = f"Cannot import {modname!r} due to '{exc.error}'"
+            self.add_message(
+                "syntax-error", line=importnode.lineno, args=message, confidence=HIGH
+            )
 
         except astroid.AstroidBuildingError:
             if not self.linter.is_message_enabled("import-error"):
                 return None
             if _ignore_import_failure(importnode, modname, self._ignored_modules):
                 return None
             if (
@@ -784,117 +873,143 @@
 
             dotted_modname = get_import_name(importnode, modname)
             self.add_message("import-error", args=repr(dotted_modname), node=importnode)
         except Exception as e:  # pragma: no cover
             raise astroid.AstroidError from e
         return None
 
-    def _add_imported_module(
-        self, node: nodes.Import | nodes.ImportFrom, importedmodname: str
-    ) -> None:
+    def _add_imported_module(self, node: ImportNode, importedmodname: str) -> None:
         """Notify an imported module, used to analyze dependencies."""
         module_file = node.root().file
         context_name = node.root().name
         base = os.path.splitext(os.path.basename(module_file))[0]
 
         try:
             importedmodname = astroid.modutils.get_module_part(
                 importedmodname, module_file
             )
         except ImportError:
             pass
 
-        in_type_checking_block = isinstance(node.parent, nodes.If) and is_typing_guard(
-            node.parent
-        )
-
         if context_name == importedmodname:
             self.add_message("import-self", node=node)
 
-        elif not astroid.modutils.is_standard_module(importedmodname):
+        elif not astroid.modutils.is_stdlib_module(importedmodname):
             # if this is not a package __init__ module
             if base != "__init__" and context_name not in self._module_pkg:
                 # record the module's parent, or the module itself if this is
                 # a top level module, as the package it belongs to
                 self._module_pkg[context_name] = context_name.rsplit(".", 1)[0]
 
             # handle dependencies
             dependencies_stat: dict[str, set[str]] = self.linter.stats.dependencies
             importedmodnames = dependencies_stat.setdefault(importedmodname, set())
             if context_name not in importedmodnames:
                 importedmodnames.add(context_name)
 
             # update import graph
             self.import_graph[context_name].add(importedmodname)
-            if (
-                not self.linter.is_message_enabled("cyclic-import", line=node.lineno)
-                or in_type_checking_block
-            ):
+            if not self.linter.is_message_enabled(
+                "cyclic-import", line=node.lineno
+            ) or in_type_checking_block(node):
                 self._excluded_edges[context_name].add(importedmodname)
 
-    def _check_preferred_module(self, node, mod_path):
+    def _check_preferred_module(self, node: ImportNode, mod_path: str) -> None:
         """Check if the module has a preferred replacement."""
-        if mod_path in self.preferred_modules:
+
+        mod_compare = [mod_path]
+        # build a comparison list of possible names using importfrom
+        if isinstance(node, astroid.nodes.node_classes.ImportFrom):
+            mod_compare = [f"{node.modname}.{name[0]}" for name in node.names]
+
+        # find whether there are matches with the import vs preferred_modules keys
+        matches = [
+            k
+            for k in self.preferred_modules
+            for mod in mod_compare
+            # exact match
+            if k == mod
+            # checks for base module matches
+            or k in mod.split(".")[0]
+        ]
+
+        # if we have matches, add message
+        if matches:
             self.add_message(
                 "preferred-module",
                 node=node,
-                args=(self.preferred_modules[mod_path], mod_path),
+                args=(self.preferred_modules[matches[0]], matches[0]),
             )
 
-    def _check_import_as_rename(self, node: nodes.Import | nodes.ImportFrom) -> None:
+    def _check_import_as_rename(self, node: ImportNode) -> None:
         names = node.names
         for name in names:
             if not all(name):
                 return
 
             splitted_packages = name[0].rsplit(".", maxsplit=1)
             import_name = splitted_packages[-1]
             aliased_name = name[1]
             if import_name != aliased_name:
                 continue
 
-            if len(splitted_packages) == 1:
-                self.add_message("useless-import-alias", node=node)
+            if len(splitted_packages) == 1 and (
+                self._allow_reexport_package is False
+                or self._current_module_package is False
+            ):
+                self.add_message("useless-import-alias", node=node, confidence=HIGH)
             elif len(splitted_packages) == 2:
                 self.add_message(
                     "consider-using-from-import",
                     node=node,
                     args=(splitted_packages[0], import_name),
                 )
 
-    def _check_reimport(self, node, basename=None, level=None):
-        """Check if the import is necessary (i.e. not already done)."""
-        if not self.linter.is_message_enabled("reimported"):
+    def _check_reimport(
+        self,
+        node: ImportNode,
+        basename: str | None = None,
+        level: int | None = None,
+    ) -> None:
+        """Check if a module with the same name is already imported or aliased."""
+        if not self.linter.is_message_enabled(
+            "reimported"
+        ) and not self.linter.is_message_enabled("shadowed-import"):
             return
 
         frame = node.frame(future=True)
         root = node.root()
         contexts = [(frame, level)]
         if root is not frame:
             contexts.append((root, None))
 
         for known_context, known_level in contexts:
             for name, alias in node.names:
-                first = _get_first_import(
+                first, msg = _get_first_import(
                     node, known_context, name, basename, known_level, alias
                 )
-                if first is not None:
+                if first is not None and msg is not None:
+                    name = name if msg == "reimported" else alias
                     self.add_message(
-                        "reimported", node=node, args=(name, first.fromlineno)
+                        msg, node=node, args=(name, first.fromlineno), confidence=HIGH
                     )
 
-    def _report_external_dependencies(self, sect, _, _dummy):
+    def _report_external_dependencies(
+        self, sect: Section, _: LinterStats, _dummy: LinterStats | None
+    ) -> None:
         """Return a verbatim layout for displaying dependencies."""
         dep_info = _make_tree_defs(self._external_dependencies_info().items())
         if not dep_info:
             raise EmptyReportError()
         tree_str = _repr_tree_defs(dep_info)
         sect.append(VerbatimText(tree_str))
 
-    def _report_dependencies_graph(self, sect, _, _dummy):
+    def _report_dependencies_graph(
+        self, sect: Section, _: LinterStats, _dummy: LinterStats | None
+    ) -> None:
         """Write dependencies as a dot (graphviz) file."""
         dep_info = self.linter.stats.dependencies
         if not dep_info or not (
             self.linter.config.import_graph
             or self.linter.config.ext_import_graph
             or self.linter.config.int_import_graph
         ):
@@ -905,57 +1020,59 @@
         filename = self.linter.config.ext_import_graph
         if filename:
             _make_graph(filename, self._external_dependencies_info(), sect, "external ")
         filename = self.linter.config.int_import_graph
         if filename:
             _make_graph(filename, self._internal_dependencies_info(), sect, "internal ")
 
-    def _filter_dependencies_graph(self, internal):
+    def _filter_dependencies_graph(self, internal: bool) -> defaultdict[str, set[str]]:
         """Build the internal or the external dependency graph."""
-        graph = collections.defaultdict(set)
+        graph: defaultdict[str, set[str]] = defaultdict(set)
         for importee, importers in self.linter.stats.dependencies.items():
             for importer in importers:
                 package = self._module_pkg.get(importer, importer)
                 is_inside = importee.startswith(package)
                 if is_inside and internal or not is_inside and not internal:
                     graph[importee].add(importer)
         return graph
 
     @astroid.decorators.cached
-    def _external_dependencies_info(self):
+    def _external_dependencies_info(self) -> defaultdict[str, set[str]]:
         """Return cached external dependencies information or build and
         cache them.
         """
         return self._filter_dependencies_graph(internal=False)
 
     @astroid.decorators.cached
-    def _internal_dependencies_info(self):
+    def _internal_dependencies_info(self) -> defaultdict[str, set[str]]:
         """Return cached internal dependencies information or build and
         cache them.
         """
         return self._filter_dependencies_graph(internal=True)
 
-    def _check_wildcard_imports(self, node, imported_module):
+    def _check_wildcard_imports(
+        self, node: nodes.ImportFrom, imported_module: nodes.Module | None
+    ) -> None:
         if node.root().package:
             # Skip the check if in __init__.py issue #2026
             return
 
         wildcard_import_is_allowed = self._wildcard_import_is_allowed(imported_module)
         for name, _ in node.names:
             if name == "*" and not wildcard_import_is_allowed:
                 self.add_message("wildcard-import", args=node.modname, node=node)
 
-    def _wildcard_import_is_allowed(self, imported_module):
+    def _wildcard_import_is_allowed(self, imported_module: nodes.Module | None) -> bool:
         return (
             self.linter.config.allow_wildcard_with_all
             and imported_module is not None
             and "__all__" in imported_module.locals
         )
 
-    def _check_toplevel(self, node):
+    def _check_toplevel(self, node: ImportNode) -> None:
         """Check whether the import is made outside the module toplevel."""
         # If the scope of the import is a module, then obviously it is
         # not outside the module toplevel.
         if isinstance(node.scope(), nodes.Module):
             return
 
         module_names = [
```

### Comparing `pylint-3.0.0a5/pylint/checkers/lambda_expressions.py` & `pylint-3.0.0a6/pylint/checkers/lambda_expressions.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from itertools import zip_longest
 from typing import TYPE_CHECKING
 
 from astroid import nodes
```

### Comparing `pylint-3.0.0a5/pylint/checkers/logging.py` & `pylint-3.0.0a6/pylint/checkers/logging.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,26 +1,33 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checker for use of Python logging."""
 
 from __future__ import annotations
 
 import string
+import sys
 from typing import TYPE_CHECKING
 
 import astroid
-from astroid import nodes
+from astroid import bases, nodes
+from astroid.typing import InferenceResult
 
 from pylint import checkers
 from pylint.checkers import utils
 from pylint.checkers.utils import infer_all
 from pylint.typing import MessageDefinitionTuple
 
+if sys.version_info >= (3, 8):
+    from typing import Literal
+else:
+    from typing_extensions import Literal
+
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 MSGS: dict[
     str, MessageDefinitionTuple
 ] = {  # pylint: disable=consider-using-namedtuple-or-dataclass
     "W1201": (
@@ -94,25 +101,29 @@
     "exception",
     "fatal",
     "info",
     "warn",
     "warning",
 }
 
+MOST_COMMON_FORMATTING = frozenset(["%s", "%d", "%f", "%r"])
+
 
-def is_method_call(func, types=(), methods=()):
+def is_method_call(
+    func: bases.BoundMethod, types: tuple[str, ...] = (), methods: tuple[str, ...] = ()
+) -> bool:
     """Determines if a BoundMethod node represents a method call.
 
     Args:
-      func (astroid.BoundMethod): The BoundMethod AST node to check.
-      types (Optional[String]): Optional sequence of caller type names to restrict check.
-      methods (Optional[String]): Optional sequence of method names to restrict check.
+      func: The BoundMethod AST node to check.
+      types: Optional sequence of caller type names to restrict check.
+      methods: Optional sequence of method names to restrict check.
 
     Returns:
-      bool: true if the node represents a method call for the given type and
+      true if the node represents a method call for the given type and
       method names, False otherwise.
     """
     return (
         isinstance(func, astroid.BoundMethod)
         and isinstance(func.bound, astroid.Instance)
         and (func.bound.name in types if types else True)
         and (func.name in methods if methods else True)
@@ -181,22 +192,22 @@
         for module, as_name in node.names:
             if module in self._logging_modules:
                 self._logging_names.add(as_name or module)
 
     def visit_call(self, node: nodes.Call) -> None:
         """Checks calls to logging methods."""
 
-        def is_logging_name():
+        def is_logging_name() -> bool:
             return (
                 isinstance(node.func, nodes.Attribute)
                 and isinstance(node.func.expr, nodes.Name)
                 and node.func.expr.name in self._logging_names
             )
 
-        def is_logger_class():
+        def is_logger_class() -> tuple[bool, str | None]:
             for inferred in infer_all(node.func):
                 if isinstance(inferred, astroid.BoundMethod):
                     parent = inferred._proxied.parent
                     if isinstance(parent, nodes.ClassDef) and (
                         parent.qname() == "logging.Logger"
                         or any(
                             ancestor.qname() == "logging.Logger"
@@ -210,59 +221,62 @@
             name = node.func.attrname
         else:
             result, name = is_logger_class()
             if not result:
                 return
         self._check_log_method(node, name)
 
-    def _check_log_method(self, node, name):
+    def _check_log_method(self, node: nodes.Call, name: str) -> None:
         """Checks calls to logging.log(level, format, *format_args)."""
         if name == "log":
             if node.starargs or node.kwargs or len(node.args) < 2:
                 # Either a malformed call, star args, or double-star args. Beyond
                 # the scope of this checker.
                 return
-            format_pos = 1
+            format_pos: Literal[0, 1] = 1
         elif name in CHECKED_CONVENIENCE_FUNCTIONS:
             if node.starargs or node.kwargs or not node.args:
                 # Either no args, star args, or double-star args. Beyond the
                 # scope of this checker.
                 return
             format_pos = 0
         else:
             return
 
-        if isinstance(node.args[format_pos], nodes.BinOp):
-            binop = node.args[format_pos]
+        format_arg = node.args[format_pos]
+        if isinstance(format_arg, nodes.BinOp):
+            binop = format_arg
             emit = binop.op == "%"
             if binop.op == "+":
                 total_number_of_strings = sum(
                     1
                     for operand in (binop.left, binop.right)
                     if self._is_operand_literal_str(utils.safe_infer(operand))
                 )
                 emit = total_number_of_strings > 0
             if emit:
                 self.add_message(
                     "logging-not-lazy",
                     node=node,
                     args=(self._helper_string(node),),
                 )
-        elif isinstance(node.args[format_pos], nodes.Call):
-            self._check_call_func(node.args[format_pos])
-        elif isinstance(node.args[format_pos], nodes.Const):
+        elif isinstance(format_arg, nodes.Call):
+            self._check_call_func(format_arg)
+        elif isinstance(format_arg, nodes.Const):
             self._check_format_string(node, format_pos)
-        elif isinstance(node.args[format_pos], nodes.JoinedStr):
+        elif isinstance(format_arg, nodes.JoinedStr):
+            if str_formatting_in_f_string(format_arg):
+                return
             self.add_message(
                 "logging-fstring-interpolation",
                 node=node,
                 args=(self._helper_string(node),),
             )
 
-    def _helper_string(self, node):
+    def _helper_string(self, node: nodes.Call) -> str:
         """Create a string that lists the valid types of formatting for this node."""
         valid_types = ["lazy %"]
 
         if not self.linter.is_message_enabled(
             "logging-fstring-formatting", node.fromlineno
         ):
             valid_types.append("fstring")
@@ -272,19 +286,19 @@
             valid_types.append(".format()")
         if not self.linter.is_message_enabled("logging-not-lazy", node.fromlineno):
             valid_types.append("%")
 
         return " or ".join(valid_types)
 
     @staticmethod
-    def _is_operand_literal_str(operand):
+    def _is_operand_literal_str(operand: InferenceResult | None) -> bool:
         """Return True if the operand in argument is a literal string."""
         return isinstance(operand, nodes.Const) and operand.name == "str"
 
-    def _check_call_func(self, node: nodes.Call):
+    def _check_call_func(self, node: nodes.Call) -> None:
         """Checks that function call is not format_string.format()."""
         func = utils.safe_infer(node.func)
         types = ("str", "unicode")
         methods = ("format",)
         if (
             isinstance(func, astroid.BoundMethod)
             and is_method_call(func, types, methods)
@@ -292,20 +306,20 @@
         ):
             self.add_message(
                 "logging-format-interpolation",
                 node=node,
                 args=(self._helper_string(node),),
             )
 
-    def _check_format_string(self, node, format_arg):
+    def _check_format_string(self, node: nodes.Call, format_arg: Literal[0, 1]) -> None:
         """Checks that format string tokens match the supplied arguments.
 
         Args:
-          node (nodes.NodeNG): AST node to be checked.
-          format_arg (int): Index of the format string in the node arguments.
+          node: AST node to be checked.
+          format_arg: Index of the format string in the node arguments.
         """
         num_args = _count_supplied_tokens(node.args[format_arg + 1 :])
         if not num_args:
             # If no args were supplied the string is not interpolated and can contain
             # formatting characters - it's used verbatim. Don't check any further.
             return
 
@@ -327,15 +341,15 @@
                     (
                         keyword_arguments,
                         implicit_pos_args,
                         explicit_pos_args,
                     ) = utils.parse_format_method_string(format_string)
 
                     keyword_args_cnt = len(
-                        {k for k, l in keyword_arguments if not isinstance(k, int)}
+                        {k for k, _ in keyword_arguments if not isinstance(k, int)}
                     )
                     required_num_args = (
                         keyword_args_cnt + implicit_pos_args + explicit_pos_args
                     )
             except utils.UnsupportedFormatCharacter as ex:
                 char = format_string[ex.index]
                 self.add_message(
@@ -364,25 +378,38 @@
         parsed = list(string.Formatter().parse(inferred.value))
     except ValueError:
         # This format string is invalid
         return False
     return any(format_spec for (_, _, format_spec, _) in parsed)
 
 
-def _count_supplied_tokens(args):
+def _count_supplied_tokens(args: list[nodes.NodeNG]) -> int:
     """Counts the number of tokens in an args list.
 
     The Python log functions allow for special keyword arguments: func,
     exc_info and extra. To handle these cases correctly, we only count
     arguments that aren't keywords.
 
     Args:
-      args (list): AST nodes that are arguments for a log format string.
+      args: AST nodes that are arguments for a log format string.
 
     Returns:
-      int: Number of AST nodes that aren't keywords.
+      Number of AST nodes that aren't keywords.
     """
     return sum(1 for arg in args if not isinstance(arg, nodes.Keyword))
 
 
+def str_formatting_in_f_string(node: nodes.JoinedStr) -> bool:
+    """Determine whether the node represents an f-string with string formatting.
+
+    For example: `f'Hello %s'`
+    """
+    # Check "%" presence first for performance.
+    return any(
+        "%" in val.value and any(x in val.value for x in MOST_COMMON_FORMATTING)
+        for val in node.values
+        if isinstance(val, nodes.Const)
+    )
+
+
 def register(linter: PyLinter) -> None:
     linter.register_checker(LoggingChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/checkers/misc.py` & `pylint-3.0.0a6/pylint/checkers/misc.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,24 +1,23 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Check source code is ascii only or has an encoding declaration (PEP 263)."""
 
 from __future__ import annotations
 
 import re
 import tokenize
 from typing import TYPE_CHECKING
 
 from astroid import nodes
 
 from pylint.checkers import BaseRawFileChecker, BaseTokenChecker
 from pylint.typing import ManagedMessage
-from pylint.utils.pragma_parser import OPTION_PO, PragmaParserError, parse_pragma
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
 class ByIdManagedMessagesChecker(BaseRawFileChecker):
 
@@ -39,15 +38,15 @@
 
     def _get_by_id_managed_msgs(self) -> list[ManagedMessage]:
         return self.linter._by_id_managed_msgs
 
     def process_module(self, node: nodes.Module) -> None:
         """Inspect the source file to find messages activated or deactivated by id."""
         managed_msgs = self._get_by_id_managed_msgs()
-        for (mod_name, msgid, symbol, lineno, is_disabled) in managed_msgs:
+        for mod_name, msgid, symbol, lineno, is_disabled in managed_msgs:
             if mod_name == node.name:
                 verb = "disable" if is_disabled else "enable"
                 txt = f"'{msgid}' is cryptic: use '# pylint: {verb}={symbol}' instead"
                 self.add_message("use-symbolic-message-instead", line=lineno, args=txt)
         self._clear_by_id_managed_msgs()
 
 
@@ -130,52 +129,23 @@
             for lineno, line in enumerate(stream):
                 self._check_encoding(lineno + 1, line, encoding)
 
     def process_tokens(self, tokens: list[tokenize.TokenInfo]) -> None:
         """Inspect the source to find fixme problems."""
         if not self.linter.config.notes:
             return
-        comments = (
-            token_info for token_info in tokens if token_info.type == tokenize.COMMENT
-        )
-        for comment in comments:
-            comment_text = comment.string[1:].lstrip()  # trim '#' and white-spaces
-
-            # handle pylint disable clauses
-            disable_option_match = OPTION_PO.search(comment_text)
-            if disable_option_match:
-                try:
-                    values = []
-                    try:
-                        for pragma_repr in (
-                            p_rep
-                            for p_rep in parse_pragma(disable_option_match.group(2))
-                            if p_rep.action == "disable"
-                        ):
-                            values.extend(pragma_repr.messages)
-                    except PragmaParserError:
-                        # Printing useful information dealing with this error is done in the lint package
-                        pass
-                except ValueError:
-                    self.add_message(
-                        "bad-inline-option",
-                        args=disable_option_match.group(1).strip(),
-                        line=comment.start[0],
-                    )
-                    continue
-                self.linter.add_ignored_message("fixme", line=comment.start[0])
+        for token_info in tokens:
+            if token_info.type != tokenize.COMMENT:
                 continue
-
-            # emit warnings if necessary
-            match = self._fixme_pattern.search("#" + comment_text.lower())
-            if match:
+            comment_text = token_info.string[1:].lstrip()  # trim '#' and white-spaces
+            if self._fixme_pattern.search("#" + comment_text.lower()):
                 self.add_message(
                     "fixme",
-                    col_offset=comment.start[1] + 1,
+                    col_offset=token_info.start[1] + 1,
                     args=comment_text,
-                    line=comment.start[0],
+                    line=token_info.start[0],
                 )
 
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(EncodingChecker(linter))
     linter.register_checker(ByIdManagedMessagesChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/checkers/newstyle.py` & `pylint-3.0.0a6/pylint/checkers/newstyle.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Check for new / old style related problems."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
@@ -104,15 +104,17 @@
                     continue
 
                 try:
                     supcls = call.args and next(call.args[0].infer(), None)
                 except astroid.InferenceError:
                     continue
 
-                if klass is not supcls:
+                # If the supcls is in the ancestors of klass super can be used to skip
+                # a step in the mro() and get a method from a higher parent
+                if klass is not supcls and all(i != supcls for i in klass.ancestors()):
                     name = None
                     # if supcls is not Uninferable, then supcls was inferred
                     # and use its name. Otherwise, try to look
                     # for call.args[0].name
                     if supcls:
                         name = supcls.name
                     elif call.args and hasattr(call.args[0], "name"):
```

### Comparing `pylint-3.0.0a5/pylint/checkers/non_ascii_names.py` & `pylint-3.0.0a6/pylint/checkers/non_ascii_names.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """All alphanumeric unicode character are allowed in Python but due
 to similarities in how they look they can be confused.
 
 See: https://peps.python.org/pep-0672/#confusing-features
 
 The following checkers are intended to make users are aware of these issues.
@@ -39,30 +39,22 @@
             '%s name "%s" contains a non-ASCII character, consider renaming it.',
             "non-ascii-name",
             NON_ASCII_HELP,
             {"old_names": [("C0144", "old-non-ascii-name")]},
         ),
         # First %s will always be "file"
         "W2402": (
-            (
-                '%s name "%s" contains a non-ASCII character. PEP 3131 only allows '
-                "non-ascii identifiers, not file names."
-            ),
+            '%s name "%s" contains a non-ASCII character.',
             "non-ascii-file-name",
             (
                 # Some = PyCharm at the time of writing didn't display the non_ascii_name_lo
-                # files and had big troubles with git.
-                # Probably only a bug shows the problem quite good.
-                # That's also why this is a warning and not only a convention!
-                "Some editors don't support non-ASCII file names properly. "
-                "Even though Python supports UTF-8 files since Python 3.5 this isn't "
-                "recommended for interoperability. Further reading:\n"
-                "- https://peps.python.org/pep-0489/#export-hook-name\n"
-                "- https://peps.python.org/pep-0672/#confusing-features\n"
-                "- https://bugs.python.org/issue20485"
+                # files. That's also why this is a warning and not only a convention!
+                "Under python 3.5, PEP 3131 allows non-ascii identifiers, but not non-ascii file names."
+                "Since Python 3.5, even though Python supports UTF-8 files, some editors or tools "
+                "don't."
             ),
         ),
         # First %s will always be "module"
         "C2403": (
             '%s name "%s" contains a non-ASCII character, use an ASCII-only alias for import.',
             "non-ascii-module-import",
             NON_ASCII_HELP,
```

### Comparing `pylint-3.0.0a5/pylint/checkers/raw_metrics.py` & `pylint-3.0.0a6/pylint/checkers/raw_metrics.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import sys
 import tokenize
 from typing import TYPE_CHECKING, Any, cast
```

### Comparing `pylint-3.0.0a5/pylint/checkers/refactoring/__init__.py` & `pylint-3.0.0a6/pylint/checkers/refactoring/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Looks for code which can be refactored."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
```

### Comparing `pylint-3.0.0a5/pylint/checkers/refactoring/implicit_booleaness_checker.py` & `pylint-3.0.0a6/pylint/checkers/refactoring/implicit_booleaness_checker.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,18 +1,19 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import astroid
-from astroid import bases, nodes
+from astroid import bases, nodes, util
 
 from pylint import checkers
 from pylint.checkers import utils
+from pylint.interfaces import HIGH, INFERENCE
 
 
 class ImplicitBooleanessChecker(checkers.BaseChecker):
     """Checks for incorrect usage of comparisons or len() inside conditions.
 
     Incorrect usage of len()
     Pep8 states:
@@ -46,32 +47,31 @@
             if variable != empty_literal:
 
     Problems detected:
     * comparison such as variable == empty_literal:
     * comparison such as variable != empty_literal:
     """
 
-    # configuration section name
     name = "refactoring"
     msgs = {
         "C1802": (
             "Do not use `len(SEQUENCE)` without comparison to determine if a sequence is empty",
             "use-implicit-booleaness-not-len",
             "Used when Pylint detects that len(sequence) is being used "
             "without explicit comparison inside a condition to determine if a sequence is empty. "
             "Instead of coercing the length to a boolean, either "
             "rely on the fact that empty sequences are false or "
             "compare the length against a scalar.",
             {"old_names": [("C1801", "len-as-condition")]},
         ),
         "C1803": (
-            "'%s' can be simplified to '%s' as an empty sequence is falsey",
+            "'%s' can be simplified to '%s' as an empty %s is falsey",
             "use-implicit-booleaness-not-comparison",
             "Used when Pylint detects that collection literal comparison is being "
-            "used to check for emptiness; Use implicit booleaness instead"
+            "used to check for emptiness; Use implicit booleaness instead "
             "of a collection classes; empty collections are considered as false",
         ),
     }
 
     options = ()
 
     @utils.only_required_for_messages("use-implicit-booleaness-not-len")
@@ -95,29 +95,37 @@
             nodes.ListComp,
             nodes.SetComp,
             nodes.DictComp,
             nodes.GeneratorExp,
         )
         if isinstance(len_arg, generator_or_comprehension):
             # The node is a generator or comprehension as in len([x for x in ...])
-            self.add_message("use-implicit-booleaness-not-len", node=node)
+            self.add_message(
+                "use-implicit-booleaness-not-len",
+                node=node,
+                confidence=HIGH,
+            )
             return
         try:
             instance = next(len_arg.infer())
         except astroid.InferenceError:
             # Probably undefined-variable, abort check
             return
         mother_classes = self.base_names_of_instance(instance)
         affected_by_pep8 = any(
             t in mother_classes for t in ("str", "tuple", "list", "set")
         )
         if "range" in mother_classes or (
             affected_by_pep8 and not self.instance_has_bool(instance)
         ):
-            self.add_message("use-implicit-booleaness-not-len", node=node)
+            self.add_message(
+                "use-implicit-booleaness-not-len",
+                node=node,
+                confidence=INFERENCE,
+            )
 
     @staticmethod
     def instance_has_bool(class_def: nodes.ClassDef) -> bool:
         try:
             class_def.getattr("__bool__")
             return True
         except astroid.AttributeInferenceError:
@@ -130,15 +138,17 @@
         condition or something else (boolean expression) e.g. `if not len(S):`.
         """
         if (
             isinstance(node, nodes.UnaryOp)
             and node.op == "not"
             and utils.is_call_of_name(node.operand, "len")
         ):
-            self.add_message("use-implicit-booleaness-not-len", node=node)
+            self.add_message(
+                "use-implicit-booleaness-not-len", node=node, confidence=HIGH
+            )
 
     @utils.only_required_for_messages("use-implicit-booleaness-not-comparison")
     def visit_compare(self, node: nodes.Compare) -> None:
         self._check_use_implicit_booleaness_not_comparison(node)
 
     def _check_use_implicit_booleaness_not_comparison(
         self, node: nodes.Compare
@@ -173,45 +183,54 @@
                 if not is_base_comprehension_type and self.instance_has_bool(
                     target_instance
                 ):
                     continue
 
                 # No need to check for operator when visiting compare node
                 if operator in {"==", "!=", ">=", ">", "<=", "<"}:
-                    collection_literal = "{}"
-                    if isinstance(literal_node, nodes.List):
-                        collection_literal = "[]"
-                    if isinstance(literal_node, nodes.Tuple):
-                        collection_literal = "()"
-
-                    instance_name = "x"
-                    if isinstance(target_node, nodes.Call) and target_node.func:
-                        instance_name = f"{target_node.func.as_string()}(...)"
-                    elif isinstance(target_node, (nodes.Attribute, nodes.Name)):
-                        instance_name = target_node.as_string()
-
-                    original_comparison = (
-                        f"{instance_name} {operator} {collection_literal}"
-                    )
-                    suggestion = (
-                        f"{instance_name}"
-                        if operator == "!="
-                        else f"not {instance_name}"
-                    )
                     self.add_message(
                         "use-implicit-booleaness-not-comparison",
-                        args=(
-                            original_comparison,
-                            suggestion,
+                        args=self._implicit_booleaness_message_args(
+                            literal_node, operator, target_node
                         ),
                         node=node,
+                        confidence=HIGH,
                     )
 
+    def _get_node_description(self, node: nodes.NodeNG) -> str:
+        return {
+            nodes.List: "list",
+            nodes.Tuple: "tuple",
+            nodes.Dict: "dict",
+            nodes.Const: "str",
+        }.get(type(node), "iterable")
+
+    def _implicit_booleaness_message_args(
+        self, literal_node: nodes.NodeNG, operator: str, target_node: nodes.NodeNG
+    ) -> tuple[str, str, str]:
+        """Helper to get the right message for "use-implicit-booleaness-not-comparison"."""
+        description = self._get_node_description(literal_node)
+        collection_literal = {
+            "list": "[]",
+            "tuple": "()",
+            "dict": "{}",
+        }.get(description, "iterable")
+        instance_name = "x"
+        if isinstance(target_node, nodes.Call) and target_node.func:
+            instance_name = f"{target_node.func.as_string()}(...)"
+        elif isinstance(target_node, (nodes.Attribute, nodes.Name)):
+            instance_name = target_node.as_string()
+        original_comparison = f"{instance_name} {operator} {collection_literal}"
+        suggestion = f"{instance_name}" if operator == "!=" else f"not {instance_name}"
+        return original_comparison, suggestion, description
+
     @staticmethod
-    def base_names_of_instance(node: bases.Uninferable | bases.Instance) -> list[str]:
+    def base_names_of_instance(
+        node: util.UninferableBase | bases.Instance,
+    ) -> list[str]:
         """Return all names inherited by a class instance or those returned by a
         function.
 
         The inherited names include 'object'.
         """
         if isinstance(node, bases.Instance):
             return [node.name] + [x.name for x in node.ancestors()]
```

### Comparing `pylint-3.0.0a5/pylint/checkers/refactoring/not_checker.py` & `pylint-3.0.0a6/pylint/checkers/refactoring/not_checker.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 import astroid
 from astroid import nodes
 
 from pylint import checkers
 from pylint.checkers import utils
```

### Comparing `pylint-3.0.0a5/pylint/checkers/refactoring/recommendation_checker.py` & `pylint-3.0.0a6/pylint/checkers/refactoring/recommendation_checker.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import astroid
 from astroid import nodes
 
 from pylint import checkers
 from pylint.checkers import utils
+from pylint.interfaces import HIGH, INFERENCE
 
 
 class RecommendationChecker(checkers.BaseChecker):
-
     name = "refactoring"
     msgs = {
         "C0200": (
             "Consider using enumerate instead of iterating with range and len",
             "consider-using-enumerate",
             "Emitted when code that iterates with range and len is "
             "encountered. Such code can be simplified by using the "
@@ -63,15 +63,15 @@
     }
 
     def open(self) -> None:
         py_version = self.linter.config.py_version
         self._py36_plus = py_version >= (3, 6)
 
     @staticmethod
-    def _is_builtin(node, function):
+    def _is_builtin(node: nodes.NodeNG, function: str) -> bool:
         inferred = utils.safe_infer(node)
         if not inferred:
             return False
         return utils.is_builtin_object(inferred) and inferred.name == function
 
     @utils.only_required_for_messages(
         "consider-iterating-dictionary", "use-maxsplit-arg"
@@ -81,14 +81,18 @@
         self._check_use_maxsplit_arg(node)
 
     def _check_consider_iterating_dictionary(self, node: nodes.Call) -> None:
         if not isinstance(node.func, nodes.Attribute):
             return
         if node.func.attrname != "keys":
             return
+
+        if isinstance(node.parent, nodes.BinOp) and node.parent.op in {"&", "|", "^"}:
+            return
+
         comp_ancestor = utils.get_node_first_ancestor_of_type(node, nodes.Compare)
         if (
             isinstance(node.parent, (nodes.For, nodes.Comprehension))
             or comp_ancestor
             and any(
                 op
                 for op, comparator in comp_ancestor.ops
@@ -97,28 +101,35 @@
             )
         ):
             inferred = utils.safe_infer(node.func)
             if not isinstance(inferred, astroid.BoundMethod) or not isinstance(
                 inferred.bound, nodes.Dict
             ):
                 return
-            self.add_message("consider-iterating-dictionary", node=node)
+            self.add_message(
+                "consider-iterating-dictionary", node=node, confidence=INFERENCE
+            )
 
     def _check_use_maxsplit_arg(self, node: nodes.Call) -> None:
         """Add message when accessing first or last elements of a str.split() or
         str.rsplit().
         """
 
         # Check if call is split() or rsplit()
         if not (
             isinstance(node.func, nodes.Attribute)
             and node.func.attrname in {"split", "rsplit"}
             and isinstance(utils.safe_infer(node.func), astroid.BoundMethod)
         ):
             return
+        inferred_expr = utils.safe_infer(node.func.expr)
+        if isinstance(inferred_expr, astroid.Instance) and any(
+            inferred_expr.nodes_of_class(nodes.ClassDef)
+        ):
+            return
 
         try:
             sep = utils.get_argument_from_call(node, 0, "sep")
         except utils.NoSuchArgumentError:
             return
 
         try:
@@ -322,17 +333,24 @@
 
                 self.add_message("consider-using-dict-items", node=node)
                 return
 
     def _check_use_sequence_for_iteration(
         self, node: nodes.For | nodes.Comprehension
     ) -> None:
-        """Check if code iterates over an in-place defined set."""
-        if isinstance(node.iter, nodes.Set):
-            self.add_message("use-sequence-for-iteration", node=node.iter)
+        """Check if code iterates over an in-place defined set.
+
+        Sets using `*` are not considered in-place.
+        """
+        if isinstance(node.iter, nodes.Set) and not any(
+            utils.has_starred_node_recursive(node)
+        ):
+            self.add_message(
+                "use-sequence-for-iteration", node=node.iter, confidence=HIGH
+            )
 
     @utils.only_required_for_messages("consider-using-f-string")
     def visit_const(self, node: nodes.Const) -> None:
         if self._py36_plus:
             # f-strings require Python 3.6
             if node.pytype() == "builtins.str" and not isinstance(
                 node.parent, nodes.JoinedStr
@@ -390,14 +408,20 @@
             )
 
         elif isinstance(node.parent, nodes.BinOp) and node.parent.op == "%":
             # Backslashes can't be in f-string expressions
             if "\\" in node.parent.right.as_string():
                 return
 
+            # If % applied to another type than str, it's modulo and can't be replaced by formatting
+            if not hasattr(node.parent.left, "value") or not isinstance(
+                node.parent.left.value, str
+            ):
+                return
+
             inferred_right = utils.safe_infer(node.parent.right)
 
             # If dicts or lists of length > 1 are used
             if isinstance(inferred_right, nodes.Dict):
                 if len(inferred_right.items) > 1:
                     return
             elif isinstance(inferred_right, nodes.List):
```

### Comparing `pylint-3.0.0a5/pylint/checkers/refactoring/refactoring_checker.py` & `pylint-3.0.0a6/pylint/checkers/refactoring/refactoring_checker.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,50 +1,60 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import collections
 import copy
 import itertools
 import sys
 import tokenize
 from collections.abc import Iterator
 from functools import reduce
-from typing import NamedTuple
+from re import Pattern
+from typing import TYPE_CHECKING, Any, NamedTuple, Union, cast
 
 import astroid
-from astroid import nodes
-from astroid.util import Uninferable
+from astroid import bases, nodes
+from astroid.util import UninferableBase
 
 from pylint import checkers
 from pylint.checkers import utils
+from pylint.checkers.base.basic_error_checker import _loop_exits_early
 from pylint.checkers.utils import node_frame_class
-from pylint.interfaces import HIGH
+from pylint.interfaces import HIGH, INFERENCE, Confidence
+
+if TYPE_CHECKING:
+    from pylint.lint import PyLinter
 
 if sys.version_info >= (3, 8):
     from functools import cached_property
 else:
     from astroid.decorators import cachedproperty as cached_property
 
-KNOWN_INFINITE_ITERATORS = {"itertools.count"}
+NodesWithNestedBlocks = Union[
+    nodes.TryExcept, nodes.TryFinally, nodes.While, nodes.For, nodes.If
+]
+
+KNOWN_INFINITE_ITERATORS = {"itertools.count", "itertools.cycle"}
 BUILTIN_EXIT_FUNCS = frozenset(("quit", "exit"))
 CALLS_THAT_COULD_BE_REPLACED_BY_WITH = frozenset(
     (
         "threading.lock.acquire",
         "threading._RLock.acquire",
         "threading.Semaphore.acquire",
         "multiprocessing.managers.BaseManager.start",
         "multiprocessing.managers.SyncManager.start",
     )
 )
 CALLS_RETURNING_CONTEXT_MANAGERS = frozenset(
     (
         "_io.open",  # regular 'open()' call
+        "pathlib.Path.open",
         "codecs.open",
         "urllib.request.urlopen",
         "tempfile.NamedTemporaryFile",
         "tempfile.SpooledTemporaryFile",
         "tempfile.TemporaryDirectory",
         "tempfile.TemporaryFile",
         "zipfile.ZipFile",
@@ -55,18 +65,30 @@
         "tarfile.TarFile.open",
         "multiprocessing.context.BaseContext.Pool",
         "subprocess.Popen",
     )
 )
 
 
-def _if_statement_is_always_returning(if_node, returning_node_class) -> bool:
+def _if_statement_is_always_returning(
+    if_node: nodes.If, returning_node_class: nodes.NodeNG
+) -> bool:
     return any(isinstance(node, returning_node_class) for node in if_node.body)
 
 
+def _except_statement_is_always_returning(
+    node: nodes.TryExcept, returning_node_class: nodes.NodeNG
+) -> bool:
+    """Detect if all except statements return."""
+    return all(
+        any(isinstance(child, returning_node_class) for child in handler.body)
+        for handler in node.handlers
+    )
+
+
 def _is_trailing_comma(tokens: list[tokenize.TokenInfo], index: int) -> bool:
     """Check if the given token is a trailing comma.
 
     :param tokens: Sequence of modules tokens
     :type tokens: list[tokenize.TokenInfo]
     :param int index: Index of token under check in tokens
     :returns: True if the token is a comma which trails an expression
@@ -86,15 +108,15 @@
             # the comma is not trailing.
             if remaining_token.type not in (tokenize.NEWLINE, tokenize.COMMENT):
                 return False
 
     if not more_tokens_on_line:
         return False
 
-    def get_curline_index_start():
+    def get_curline_index_start() -> int:
         """Get the index denoting the start of the current line."""
         for subindex, token in enumerate(reversed(tokens[:index])):
             # See Lib/tokenize.py and Lib/token.py in cpython for more info
             if token.type == tokenize.NEWLINE:
                 return index - subindex
         return 0
 
@@ -133,15 +155,15 @@
     """
     frame = node.frame(future=True)
     current = node
     while current != frame:
         if isinstance(current, nodes.With):
             items_start = current.items[0][0].lineno
             items_end = current.items[-1][0].tolineno
-            return items_start <= node.lineno <= items_end
+            return items_start <= node.lineno <= items_end  # type: ignore[no-any-return]
         current = current.parent
     return False
 
 
 def _will_be_released_automatically(node: nodes.Call) -> bool:
     """Checks if a call that could be used in a ``with`` statement is used in an
     alternative construct which would ensure that its __exit__ method is called.
@@ -156,29 +178,48 @@
         return False
     func = utils.safe_infer(node.parent.func)
     if not func:
         return False
     return func.qname() in callables_taking_care_of_exit
 
 
+def _is_part_of_assignment_target(node: nodes.NodeNG) -> bool:
+    """Check whether use of a variable is happening as part of the left-hand
+    side of an assignment.
+
+    This requires recursive checking, because destructuring assignment can have
+    arbitrarily nested tuples and lists to unpack.
+    """
+    if isinstance(node.parent, nodes.Assign):
+        return node in node.parent.targets
+
+    if isinstance(node.parent, nodes.AugAssign):
+        return node == node.parent.target  # type: ignore[no-any-return]
+
+    if isinstance(node.parent, (nodes.Tuple, nodes.List)):
+        return _is_part_of_assignment_target(node.parent)
+
+    return False
+
+
 class ConsiderUsingWithStack(NamedTuple):
     """Stack for objects that may potentially trigger a R1732 message
     if they are not used in a ``with`` block later on.
     """
 
     module_scope: dict[str, nodes.NodeNG] = {}
     class_scope: dict[str, nodes.NodeNG] = {}
     function_scope: dict[str, nodes.NodeNG] = {}
 
     def __iter__(self) -> Iterator[dict[str, nodes.NodeNG]]:
         yield from (self.function_scope, self.class_scope, self.module_scope)
 
     def get_stack_for_frame(
         self, frame: nodes.FunctionDef | nodes.ClassDef | nodes.Module
-    ):
+    ) -> dict[str, nodes.NodeNG]:
         """Get the stack corresponding to the scope of the given frame."""
         if isinstance(frame, nodes.FunctionDef):
             return self.function_scope
         if isinstance(frame, nodes.ClassDef):
             return self.class_scope
         return self.module_scope
 
@@ -298,50 +339,51 @@
             "Consider using str.join(sequence) for concatenating "
             "strings from an iterable",
             "consider-using-join",
             "Using str.join(sequence) is faster, uses less memory "
             "and increases readability compared to for-loop iteration.",
         ),
         "R1714": (
-            'Consider merging these comparisons with "in" to %r',
+            "Consider merging these comparisons with 'in' by using '%s %sin (%s)'."
+            " Use a set instead if elements are hashable.",
             "consider-using-in",
-            "To check if a variable is equal to one of many values,"
-            'combine the values into a tuple and check if the variable is contained "in" it '
-            "instead of checking for equality against each of the values."
+            "To check if a variable is equal to one of many values, "
+            'combine the values into a set or tuple and check if the variable is contained "in" it '
+            "instead of checking for equality against each of the values. "
             "This is faster and less verbose.",
         ),
         "R1715": (
             "Consider using dict.get for getting values from a dict "
             "if a key is present or a default if not",
             "consider-using-get",
             "Using the builtin dict.get for getting a value from a dictionary "
             "if a key is present or a default if not, is simpler and considered "
             "more idiomatic, although sometimes a bit slower",
         ),
         "R1716": (
             "Simplify chained comparison between the operands",
             "chained-comparison",
-            "This message is emitted when pylint encounters boolean operation like"
+            "This message is emitted when pylint encounters boolean operation like "
             '"a < b and b < c", suggesting instead to refactor it to "a < b < c"',
         ),
         "R1717": (
             "Consider using a dictionary comprehension",
             "consider-using-dict-comprehension",
             "Emitted when we detect the creation of a dictionary "
             "using the dict() callable and a transient list. "
             "Although there is nothing syntactically wrong with this code, "
-            "it is hard to read and can be simplified to a dict comprehension."
+            "it is hard to read and can be simplified to a dict comprehension. "
             "Also it is faster since you don't need to create another "
             "transient list",
         ),
         "R1718": (
             "Consider using a set comprehension",
             "consider-using-set-comprehension",
             "Although there is nothing syntactically wrong with this code, "
-            "it is hard to read and can be simplified to a set comprehension."
+            "it is hard to read and can be simplified to a set comprehension. "
             "Also it is faster since you don't need to create another "
             "transient list",
         ),
         "R1719": (
             "The if expression can be replaced with %s",
             "simplifiable-if-expression",
             "Used when an if expression can be replaced with 'bool(test)' "
@@ -360,17 +402,18 @@
             "Unnecessary use of a comprehension, use %s instead.",
             "unnecessary-comprehension",
             "Instead of using an identity comprehension, "
             "consider using the list, dict or set constructor. "
             "It is faster and simpler.",
         ),
         "R1722": (
-            "Consider using sys.exit()",
+            "Consider using 'sys.exit' instead",
             "consider-using-sys-exit",
-            "Instead of using exit() or quit(), consider using the sys.exit().",
+            "Contrary to 'exit()' or 'quit()', 'sys.exit' does not rely on the "
+            "site module being available (as the 'sys' module is always available).",
         ),
         "R1723": (
             'Unnecessary "%s" after "break", %s',
             "no-else-break",
             "Used in order to highlight an unnecessary block of "
             "code following an if containing a break statement. "
             "As such, it will warn when it encounters an else "
@@ -414,15 +457,16 @@
             "consider-using-max-builtin",
             "Using the max builtin instead of a conditional improves readability and conciseness.",
         ),
         "R1732": (
             "Consider using 'with' for resource-allocating operations",
             "consider-using-with",
             "Emitted if a resource-allocating assignment or call may be replaced by a 'with' block. "
-            "By using 'with' the release of the allocated resources is ensured even in the case of an exception.",
+            "By using 'with' the release of the allocated resources is ensured even in the case "
+            "of an exception.",
         ),
         "R1733": (
             "Unnecessary dictionary index lookup, use '%s' instead",
             "unnecessary-dict-index-lookup",
             "Emitted when iterating over the dictionary items (key-item pairs) and accessing the "
             "value by index lookup. "
             "The value can be accessed directly instead.",
@@ -430,17 +474,17 @@
         "R1734": (
             "Consider using [] instead of list()",
             "use-list-literal",
             "Emitted when using list() to create an empty list instead of the literal []. "
             "The literal is faster as it avoids an additional function call.",
         ),
         "R1735": (
-            "Consider using {} instead of dict()",
+            "Consider using '%s' instead of a call to 'dict'.",
             "use-dict-literal",
-            "Emitted when using dict() to create an empty dictionary instead of the literal {}. "
+            "Emitted when using dict() to create a dictionary instead of a literal '{ ... }'. "
             "The literal is faster as it avoids an additional function call.",
         ),
         "R1736": (
             "Unnecessary list index lookup, use '%s' instead",
             "unnecessary-list-index-lookup",
             "Emitted when iterating over an enumeration and accessing the "
             "value by index lookup. "
@@ -467,46 +511,45 @@
                 "for inconsistent-return-statements if a never returning function is "
                 "called then it will be considered as an explicit return statement "
                 "and no message will be printed.",
             },
         ),
     )
 
-    def __init__(self, linter):
+    def __init__(self, linter: PyLinter) -> None:
         super().__init__(linter)
-        self._return_nodes = {}
+        self._return_nodes: dict[str, list[nodes.Return]] = {}
         self._consider_using_with_stack = ConsiderUsingWithStack()
         self._init()
-        self._never_returning_functions = None
+        self._never_returning_functions: set[str] = set()
 
-    def _init(self):
-        self._nested_blocks = []
-        self._elifs = []
-        self._nested_blocks_msg = None
-        self._reported_swap_nodes = set()
-        self._can_simplify_bool_op = False
+    def _init(self) -> None:
+        self._nested_blocks: list[NodesWithNestedBlocks] = []
+        self._elifs: list[tuple[int, int]] = []
+        self._reported_swap_nodes: set[nodes.NodeNG] = set()
+        self._can_simplify_bool_op: bool = False
         self._consider_using_with_stack.clear_all()
 
-    def open(self):
+    def open(self) -> None:
         # do this in open since config not fully initialized in __init__
         self._never_returning_functions = set(
             self.linter.config.never_returning_functions
         )
 
     @cached_property
-    def _dummy_rgx(self):
-        return self.linter.config.dummy_variables_rgx
+    def _dummy_rgx(self) -> Pattern[str]:
+        return self.linter.config.dummy_variables_rgx  # type: ignore[no-any-return]
 
     @staticmethod
-    def _is_bool_const(node):
+    def _is_bool_const(node: nodes.Return | nodes.Assign) -> bool:
         return isinstance(node.value, nodes.Const) and isinstance(
             node.value.value, bool
         )
 
-    def _is_actual_elif(self, node):
+    def _is_actual_elif(self, node: nodes.If | nodes.TryExcept) -> bool:
         """Check if the given node is an actual elif.
 
         This is a problem we're having with the builtin ast module,
         which splits `elif` branches into a separate if statement.
         Unfortunately we need to know the exact type in certain
         cases.
         """
@@ -514,15 +557,15 @@
             orelse = node.parent.orelse
             # current if node must directly follow an "else"
             if orelse and orelse == [node]:
                 if (node.lineno, node.col_offset) in self._elifs:
                     return True
         return False
 
-    def _check_simplifiable_if(self, node):
+    def _check_simplifiable_if(self, node: nodes.If) -> None:
         """Check if the given if node can be simplified.
 
         The if statement can be reduced to a boolean expression
         in some cases. For instance, if there are two branches
         and both of them return a boolean value that depends on
         the result of the statement's test, then this can be reduced
         to `bool(test)` without losing any functionality.
@@ -609,22 +652,26 @@
     def leave_module(self, _: nodes.Module) -> None:
         # check for context managers that have been created but not used
         self._emit_consider_using_with_if_needed(
             self._consider_using_with_stack.module_scope
         )
         self._init()
 
-    @utils.only_required_for_messages("too-many-nested-blocks")
-    def visit_tryexcept(self, node: nodes.TryExcept) -> None:
+    @utils.only_required_for_messages("too-many-nested-blocks", "no-else-return")
+    def visit_tryexcept(self, node: nodes.TryExcept | nodes.TryFinally) -> None:
         self._check_nested_blocks(node)
 
+        if isinstance(node, nodes.TryExcept):
+            self._check_superfluous_else_return(node)
+            self._check_superfluous_else_raise(node)
+
     visit_tryfinally = visit_tryexcept
     visit_while = visit_tryexcept
 
-    def _check_redefined_argument_from_local(self, name_node):
+    def _check_redefined_argument_from_local(self, name_node: nodes.AssignName) -> None:
         if self._dummy_rgx and self._dummy_rgx.match(name_node.name):
             return
         if not name_node.lineno:
             # Unknown position, maybe it is a manually built AST?
             return
 
         scope = name_node.scope()
@@ -663,72 +710,92 @@
     @utils.only_required_for_messages(
         "redefined-argument-from-local", "consider-using-with"
     )
     def visit_with(self, node: nodes.With) -> None:
         for var, names in node.items:
             if isinstance(var, nodes.Name):
                 for stack in self._consider_using_with_stack:
-                    # We don't need to restrict the stacks we search to the current scope and outer scopes,
-                    # as e.g. the function_scope stack will be empty when we check a ``with`` on the class level.
+                    # We don't need to restrict the stacks we search to the current scope and
+                    # outer scopes, as e.g. the function_scope stack will be empty when we
+                    # check a ``with`` on the class level.
                     if var.name in stack:
                         del stack[var.name]
                         break
             if not names:
                 continue
             for name in names.nodes_of_class(nodes.AssignName):
                 self._check_redefined_argument_from_local(name)
 
-    def _check_superfluous_else(self, node, msg_id, returning_node_class):
+    def _check_superfluous_else(
+        self,
+        node: nodes.If | nodes.TryExcept,
+        msg_id: str,
+        returning_node_class: nodes.NodeNG,
+    ) -> None:
+        if isinstance(node, nodes.TryExcept) and isinstance(
+            node.parent, nodes.TryFinally
+        ):
+            # Not interested in try/except/else/finally statements.
+            return
+
         if not node.orelse:
-            # Not interested in if statements without else.
+            # Not interested in if/try statements without else.
             return
 
         if self._is_actual_elif(node):
             # Not interested in elif nodes; only if
             return
 
-        if _if_statement_is_always_returning(node, returning_node_class):
+        if (
+            isinstance(node, nodes.If)
+            and _if_statement_is_always_returning(node, returning_node_class)
+        ) or (
+            isinstance(node, nodes.TryExcept)
+            and _except_statement_is_always_returning(node, returning_node_class)
+        ):
             orelse = node.orelse[0]
             if (orelse.lineno, orelse.col_offset) in self._elifs:
                 args = ("elif", 'remove the leading "el" from "elif"')
             else:
                 args = ("else", 'remove the "else" and de-indent the code inside it')
-            self.add_message(msg_id, node=node, args=args)
+            self.add_message(msg_id, node=node, args=args, confidence=HIGH)
 
-    def _check_superfluous_else_return(self, node):
+    def _check_superfluous_else_return(self, node: nodes.If) -> None:
         return self._check_superfluous_else(
             node, msg_id="no-else-return", returning_node_class=nodes.Return
         )
 
-    def _check_superfluous_else_raise(self, node):
+    def _check_superfluous_else_raise(self, node: nodes.If) -> None:
         return self._check_superfluous_else(
             node, msg_id="no-else-raise", returning_node_class=nodes.Raise
         )
 
-    def _check_superfluous_else_break(self, node):
+    def _check_superfluous_else_break(self, node: nodes.If) -> None:
         return self._check_superfluous_else(
             node, msg_id="no-else-break", returning_node_class=nodes.Break
         )
 
-    def _check_superfluous_else_continue(self, node):
+    def _check_superfluous_else_continue(self, node: nodes.If) -> None:
         return self._check_superfluous_else(
             node, msg_id="no-else-continue", returning_node_class=nodes.Continue
         )
 
     @staticmethod
-    def _type_and_name_are_equal(node_a, node_b):
-        for _type in (nodes.Name, nodes.AssignName):
-            if all(isinstance(_node, _type) for _node in (node_a, node_b)):
-                return node_a.name == node_b.name
-        if all(isinstance(_node, nodes.Const) for _node in (node_a, node_b)):
-            return node_a.value == node_b.value
+    def _type_and_name_are_equal(node_a: Any, node_b: Any) -> bool:
+        if isinstance(node_a, nodes.Name) and isinstance(node_b, nodes.Name):
+            return node_a.name == node_b.name  # type: ignore[no-any-return]
+        if isinstance(node_a, nodes.AssignName) and isinstance(
+            node_b, nodes.AssignName
+        ):
+            return node_a.name == node_b.name  # type: ignore[no-any-return]
+        if isinstance(node_a, nodes.Const) and isinstance(node_b, nodes.Const):
+            return node_a.value == node_b.value  # type: ignore[no-any-return]
         return False
 
-    def _is_dict_get_block(self, node):
-
+    def _is_dict_get_block(self, node: nodes.If) -> bool:
         # "if <compare node>"
         if not isinstance(node.test, nodes.Compare):
             return False
 
         # Does not have a single statement in the guard's body
         if len(node.body) != 1:
             return False
@@ -750,15 +817,15 @@
             and self._type_and_name_are_equal(slice_value, node.test.left)
         ):
             return False
 
         # The object needs to be a dictionary instance
         return isinstance(utils.safe_infer(node.test.ops[0][1]), nodes.Dict)
 
-    def _check_consider_get(self, node):
+    def _check_consider_get(self, node: nodes.If) -> None:
         if_block_ok = self._is_dict_get_block(node)
         if if_block_ok and not node.orelse:
             self.add_message("consider-using-get", node=node)
         elif (
             if_block_ok
             and len(node.orelse) == 1
             and isinstance(node.orelse[0], nodes.Assign)
@@ -786,15 +853,16 @@
         self._check_superfluous_else_return(node)
         self._check_superfluous_else_raise(node)
         self._check_superfluous_else_break(node)
         self._check_superfluous_else_continue(node)
         self._check_consider_get(node)
         self._check_consider_using_min_max_builtin(node)
 
-    def _check_consider_using_min_max_builtin(self, node: nodes.If):
+    # pylint: disable = too-many-branches
+    def _check_consider_using_min_max_builtin(self, node: nodes.If) -> None:
         """Check if the given if node can be refactored as a min/max python builtin."""
         if self._is_actual_elif(node) or node.orelse:
             # Not interested in if statements with multiple branches.
             return
 
         if len(node.body) != 1:
             return
@@ -869,15 +937,15 @@
                 "consider-using-min-builtin", node=node, args=(reduced_to,)
             )
 
     @utils.only_required_for_messages("simplifiable-if-expression")
     def visit_ifexp(self, node: nodes.IfExp) -> None:
         self._check_simplifiable_ifexp(node)
 
-    def _check_simplifiable_ifexp(self, node):
+    def _check_simplifiable_ifexp(self, node: nodes.IfExp) -> None:
         if not isinstance(node.body, nodes.Const) or not isinstance(
             node.orelse, nodes.Const
         ):
             return
 
         if not isinstance(node.body.value, bool) or not isinstance(
             node.orelse.value, bool
@@ -928,36 +996,38 @@
         )
         self._consider_using_with_stack.class_scope.clear()
 
     @utils.only_required_for_messages("stop-iteration-return")
     def visit_raise(self, node: nodes.Raise) -> None:
         self._check_stop_iteration_inside_generator(node)
 
-    def _check_stop_iteration_inside_generator(self, node):
+    def _check_stop_iteration_inside_generator(self, node: nodes.Raise) -> None:
         """Check if an exception of type StopIteration is raised inside a generator."""
         frame = node.frame(future=True)
         if not isinstance(frame, nodes.FunctionDef) or not frame.is_generator():
             return
         if utils.node_ignores_exception(node, StopIteration):
             return
         if not node.exc:
             return
         exc = utils.safe_infer(node.exc)
-        if not exc or not isinstance(exc, (astroid.Instance, nodes.ClassDef)):
+        if not exc or not isinstance(exc, (bases.Instance, nodes.ClassDef)):
             return
         if self._check_exception_inherit_from_stopiteration(exc):
-            self.add_message("stop-iteration-return", node=node)
+            self.add_message("stop-iteration-return", node=node, confidence=INFERENCE)
 
     @staticmethod
-    def _check_exception_inherit_from_stopiteration(exc):
+    def _check_exception_inherit_from_stopiteration(
+        exc: nodes.ClassDef | bases.Instance,
+    ) -> bool:
         """Return True if the exception node in argument inherit from StopIteration."""
         stopiteration_qname = f"{utils.EXCEPTIONS_MODULE}.StopIteration"
         return any(_class.qname() == stopiteration_qname for _class in exc.mro())
 
-    def _check_consider_using_comprehension_constructor(self, node):
+    def _check_consider_using_comprehension_constructor(self, node: nodes.Call) -> None:
         if (
             isinstance(node.func, nodes.Name)
             and node.args
             and isinstance(node.args[0], nodes.ListComp)
         ):
             if node.func.name == "dict":
                 element = node.args[0].elt
@@ -983,19 +1053,19 @@
 
                 message_name = "consider-using-dict-comprehension"
                 self.add_message(message_name, node=node)
             elif node.func.name == "set":
                 message_name = "consider-using-set-comprehension"
                 self.add_message(message_name, node=node)
 
-    def _check_consider_using_generator(self, node):
+    def _check_consider_using_generator(self, node: nodes.Call) -> None:
         # 'any', 'all', definitely should use generator, while 'list', 'tuple',
         # 'sum', 'max', and 'min' need to be considered first
-        # See https://github.com/PyCQA/pylint/pull/3309#discussion_r576683109
-        # https://github.com/PyCQA/pylint/pull/6595#issuecomment-1125704244
+        # See https://github.com/pylint-dev/pylint/pull/3309#discussion_r576683109
+        # https://github.com/pylint-dev/pylint/pull/6595#issuecomment-1125704244
         # and https://peps.python.org/pep-0289/
         checked_call = ["any", "all", "sum", "max", "min", "list", "tuple"]
         if (
             isinstance(node, nodes.Call)
             and node.func
             and isinstance(node.func, nodes.Name)
             and node.func.name in checked_call
@@ -1034,87 +1104,105 @@
     def visit_call(self, node: nodes.Call) -> None:
         self._check_raising_stopiteration_in_generator_next_call(node)
         self._check_consider_using_comprehension_constructor(node)
         self._check_quit_exit_call(node)
         self._check_super_with_arguments(node)
         self._check_consider_using_generator(node)
         self._check_consider_using_with(node)
-        self._check_use_list_or_dict_literal(node)
+        self._check_use_list_literal(node)
+        self._check_use_dict_literal(node)
 
     @staticmethod
-    def _has_exit_in_scope(scope):
+    def _has_exit_in_scope(scope: nodes.LocalsDictNodeNG) -> bool:
         exit_func = scope.locals.get("exit")
         return bool(
             exit_func and isinstance(exit_func[0], (nodes.ImportFrom, nodes.Import))
         )
 
-    def _check_quit_exit_call(self, node):
-
+    def _check_quit_exit_call(self, node: nodes.Call) -> None:
         if isinstance(node.func, nodes.Name) and node.func.name in BUILTIN_EXIT_FUNCS:
-            # If we have `exit` imported from `sys` in the current or global scope, exempt this instance.
+            # If we have `exit` imported from `sys` in the current or global scope,
+            # exempt this instance.
             local_scope = node.scope()
             if self._has_exit_in_scope(local_scope) or self._has_exit_in_scope(
                 node.root()
             ):
                 return
-            self.add_message("consider-using-sys-exit", node=node)
+            self.add_message("consider-using-sys-exit", node=node, confidence=HIGH)
 
-    def _check_super_with_arguments(self, node):
+    def _check_super_with_arguments(self, node: nodes.Call) -> None:
         if not isinstance(node.func, nodes.Name) or node.func.name != "super":
             return
 
         # pylint: disable=too-many-boolean-expressions
         if (
             len(node.args) != 2
             or not isinstance(node.args[1], nodes.Name)
             or node.args[1].name != "self"
             or not isinstance(node.args[0], nodes.Name)
             or not isinstance(node.args[1], nodes.Name)
             or node_frame_class(node) is None
-            or node.args[0].name != node_frame_class(node).name
+            # TODO: PY38: Use walrus operator, this will also fix the mypy issue
+            or node.args[0].name != node_frame_class(node).name  # type: ignore[union-attr]
         ):
             return
 
         self.add_message("super-with-arguments", node=node)
 
-    def _check_raising_stopiteration_in_generator_next_call(self, node):
+    def _check_raising_stopiteration_in_generator_next_call(
+        self, node: nodes.Call
+    ) -> None:
         """Check if a StopIteration exception is raised by the call to next function.
 
         If the next value has a default value, then do not add message.
 
         :param node: Check to see if this Call node is a next function
         :type node: :class:`nodes.Call`
         """
 
-        def _looks_like_infinite_iterator(param):
+        def _looks_like_infinite_iterator(param: nodes.NodeNG) -> bool:
             inferred = utils.safe_infer(param)
-            if inferred:
+            if isinstance(inferred, bases.Instance):
                 return inferred.qname() in KNOWN_INFINITE_ITERATORS
             return False
 
         if isinstance(node.func, nodes.Attribute):
             # A next() method, which is now what we want.
             return
 
+        if len(node.args) == 0:
+            # handle case when builtin.next is called without args.
+            # see https://github.com/pylint-dev/pylint/issues/7828
+            return
+
         inferred = utils.safe_infer(node.func)
-        if getattr(inferred, "name", "") == "next":
+
+        if (
+            isinstance(inferred, nodes.FunctionDef)
+            and inferred.qname() == "builtins.next"
+        ):
             frame = node.frame(future=True)
             # The next builtin can only have up to two
             # positional arguments and no keyword arguments
             has_sentinel_value = len(node.args) > 1
             if (
                 isinstance(frame, nodes.FunctionDef)
                 and frame.is_generator()
                 and not has_sentinel_value
                 and not utils.node_ignores_exception(node, StopIteration)
                 and not _looks_like_infinite_iterator(node.args[0])
             ):
-                self.add_message("stop-iteration-return", node=node)
+                self.add_message(
+                    "stop-iteration-return", node=node, confidence=INFERENCE
+                )
 
-    def _check_nested_blocks(self, node):
+    def _check_nested_blocks(
+        self,
+        node: NodesWithNestedBlocks,
+    ) -> None:
         """Update and check the number of nested blocks."""
         # only check block levels inside functions or methods
         if not isinstance(node.scope(), nodes.FunctionDef):
             return
         # messages are triggered on leaving the nested block. Here we save the
         # stack in case the current node isn't nested in the previous one
         nested_blocks = self._nested_blocks[:]
@@ -1132,37 +1220,41 @@
                     self._nested_blocks.pop()
             self._nested_blocks.append(node)
 
         # send message only once per group of nested blocks
         if len(nested_blocks) > len(self._nested_blocks):
             self._emit_nested_blocks_message_if_needed(nested_blocks)
 
-    def _emit_nested_blocks_message_if_needed(self, nested_blocks):
+    def _emit_nested_blocks_message_if_needed(
+        self, nested_blocks: list[NodesWithNestedBlocks]
+    ) -> None:
         if len(nested_blocks) > self.linter.config.max_nested_blocks:
             self.add_message(
                 "too-many-nested-blocks",
                 node=nested_blocks[0],
                 args=(len(nested_blocks), self.linter.config.max_nested_blocks),
             )
 
-    def _emit_consider_using_with_if_needed(self, stack: dict[str, nodes.NodeNG]):
+    def _emit_consider_using_with_if_needed(
+        self, stack: dict[str, nodes.NodeNG]
+    ) -> None:
         for node in stack.values():
             self.add_message("consider-using-with", node=node)
 
     @staticmethod
-    def _duplicated_isinstance_types(node):
+    def _duplicated_isinstance_types(node: nodes.BoolOp) -> dict[str, set[str]]:
         """Get the duplicated types from the underlying isinstance calls.
 
         :param nodes.BoolOp node: Node which should contain a bunch of isinstance calls.
         :returns: Dictionary of the comparison objects from the isinstance calls,
                   to duplicate values from consecutive calls.
         :rtype: dict
         """
-        duplicated_objects = set()
-        all_types = collections.defaultdict(set)
+        duplicated_objects: set[str] = set()
+        all_types: collections.defaultdict[str, set[str]] = collections.defaultdict(set)
 
         for call in node.values:
             if not isinstance(call, nodes.Call) or len(call.args) != 2:
                 continue
 
             inferred = utils.safe_infer(call.func)
             if not inferred or not utils.is_builtin_object(inferred):
@@ -1186,29 +1278,29 @@
             all_types[isinstance_object].update(elems)
 
         # Remove all keys which not duplicated
         return {
             key: value for key, value in all_types.items() if key in duplicated_objects
         }
 
-    def _check_consider_merging_isinstance(self, node):
+    def _check_consider_merging_isinstance(self, node: nodes.BoolOp) -> None:
         """Check isinstance calls which can be merged together."""
         if node.op != "or":
             return
 
         first_args = self._duplicated_isinstance_types(node)
         for duplicated_name, class_names in first_args.items():
             names = sorted(name for name in class_names)
             self.add_message(
                 "consider-merging-isinstance",
                 node=node,
                 args=(duplicated_name, ", ".join(names)),
             )
 
-    def _check_consider_using_in(self, node):
+    def _check_consider_using_in(self, node: nodes.BoolOp) -> None:
         allowed_ops = {"or": "==", "and": "!="}
 
         if node.op not in allowed_ops or len(node.values) < 2:
             return
 
         for value in node.values:
             if (
@@ -1235,34 +1327,40 @@
         common_variables = reduce(lambda a, b: a.intersection(b), variables)
 
         if not common_variables:
             return
 
         # Gather information for the suggestion
         common_variable = sorted(list(common_variables))[0]
-        comprehension = "in" if node.op == "or" else "not in"
         values = list(collections.OrderedDict.fromkeys(values))
         values.remove(common_variable)
         values_string = ", ".join(values) if len(values) != 1 else values[0] + ","
-        suggestion = f"{common_variable} {comprehension} ({values_string})"
-
-        self.add_message("consider-using-in", node=node, args=(suggestion,))
+        maybe_not = "" if node.op == "or" else "not "
+        self.add_message(
+            "consider-using-in",
+            node=node,
+            args=(common_variable, maybe_not, values_string),
+            confidence=HIGH,
+        )
 
-    def _check_chained_comparison(self, node):
+    def _check_chained_comparison(self, node: nodes.BoolOp) -> None:
         """Check if there is any chained comparison in the expression.
 
         Add a refactoring message if a boolOp contains comparison like a < b and b < c,
         which can be chained as a < b < c.
 
         Care is taken to avoid simplifying a < b < c and b < d.
         """
         if node.op != "and" or len(node.values) < 2:
             return
 
-        def _find_lower_upper_bounds(comparison_node, uses):
+        def _find_lower_upper_bounds(
+            comparison_node: nodes.Compare,
+            uses: collections.defaultdict[str, dict[str, set[nodes.Compare]]],
+        ) -> None:
             left_operand = comparison_node.left
             for operator, right_operand in comparison_node.ops:
                 for operand in (left_operand, right_operand):
                     value = None
                     if isinstance(operand, nodes.Name):
                         value = operand.name
                     elif isinstance(operand, nodes.Const):
@@ -1279,15 +1377,17 @@
                     elif operator in {">", ">="}:
                         if operand is left_operand:
                             uses[value]["upper_bound"].add(comparison_node)
                         elif operand is right_operand:
                             uses[value]["lower_bound"].add(comparison_node)
                 left_operand = right_operand
 
-        uses = collections.defaultdict(
+        uses: collections.defaultdict[
+            str, dict[str, set[nodes.Compare]]
+        ] = collections.defaultdict(
             lambda: {"lower_bound": set(), "upper_bound": set()}
         )
         for comparison_node in node.values:
             if isinstance(comparison_node, nodes.Compare):
                 _find_lower_upper_bounds(comparison_node, uses)
 
         for bounds in uses.values():
@@ -1295,25 +1395,27 @@
             num_lower_bounds = len(bounds["lower_bound"])
             num_upper_bounds = len(bounds["upper_bound"])
             if num_shared < num_lower_bounds and num_shared < num_upper_bounds:
                 self.add_message("chained-comparison", node=node)
                 break
 
     @staticmethod
-    def _apply_boolean_simplification_rules(operator, values):
+    def _apply_boolean_simplification_rules(
+        operator: str, values: list[nodes.NodeNG]
+    ) -> list[nodes.NodeNG]:
         """Removes irrelevant values or returns short-circuiting values.
 
         This function applies the following two rules:
         1) an OR expression with True in it will always be true, and the
            reverse for AND
 
         2) False values in OR expressions are only relevant if all values are
            false, and the reverse for AND
         """
-        simplified_values = []
+        simplified_values: list[nodes.NodeNG] = []
 
         for subnode in values:
             inferred_bool = None
             if not next(subnode.nodes_of_class(nodes.Name), False):
                 inferred = utils.safe_infer(subnode)
                 if inferred:
                     inferred_bool = inferred.bool_value()
@@ -1321,15 +1423,15 @@
             if not isinstance(inferred_bool, bool):
                 simplified_values.append(subnode)
             elif (operator == "or") == inferred_bool:
                 return [subnode]
 
         return simplified_values or [nodes.Const(operator == "and")]
 
-    def _simplify_boolean_operation(self, bool_op):
+    def _simplify_boolean_operation(self, bool_op: nodes.BoolOp) -> nodes.BoolOp:
         """Attempts to simplify a boolean operation.
 
         Recursively applies simplification on the operator terms,
         and keeps track of whether reductions have been made.
         """
         children = list(bool_op.get_children())
         intermediate = [
@@ -1343,15 +1445,15 @@
             self._can_simplify_bool_op = True
         if len(result) == 1:
             return result[0]
         simplified_bool_op = copy.copy(bool_op)
         simplified_bool_op.postinit(result)
         return simplified_bool_op
 
-    def _check_simplifiable_condition(self, node):
+    def _check_simplifiable_condition(self, node: nodes.BoolOp) -> None:
         """Check if a boolean condition can be simplified.
 
         Variables will not be simplified, even if the value can be inferred,
         and expressions like '3 + 4' will remain expanded.
         """
         if not utils.is_test_condition(node):
             return
@@ -1385,23 +1487,23 @@
     def visit_boolop(self, node: nodes.BoolOp) -> None:
         self._check_consider_merging_isinstance(node)
         self._check_consider_using_in(node)
         self._check_chained_comparison(node)
         self._check_simplifiable_condition(node)
 
     @staticmethod
-    def _is_simple_assignment(node):
+    def _is_simple_assignment(node: nodes.NodeNG | None) -> bool:
         return (
             isinstance(node, nodes.Assign)
             and len(node.targets) == 1
             and isinstance(node.targets[0], nodes.AssignName)
             and isinstance(node.value, nodes.Name)
         )
 
-    def _check_swap_variables(self, node):
+    def _check_swap_variables(self, node: nodes.Return | nodes.Assign) -> None:
         if not node.next_sibling() or not node.next_sibling().next_sibling():
             return
         assignments = [node, node.next_sibling(), node.next_sibling().next_sibling()]
         if not all(self._is_simple_assignment(node) for node in assignments):
             return
         if any(node in self._reported_swap_nodes for node in assignments):
             return
@@ -1423,55 +1525,57 @@
         self.visit_return(node)  # remaining checks are identical as for return nodes
 
     @utils.only_required_for_messages(
         "simplify-boolean-expression",
         "consider-using-ternary",
         "consider-swap-variables",
     )
-    def visit_return(self, node: nodes.Return) -> None:
+    def visit_return(self, node: nodes.Return | nodes.Assign) -> None:
         self._check_swap_variables(node)
         if self._is_and_or_ternary(node.value):
             cond, truth_value, false_value = self._and_or_ternary_arguments(node.value)
         else:
             return
 
         if all(
             isinstance(value, nodes.Compare) for value in (truth_value, false_value)
         ):
             return
 
-        inferred_truth_value = utils.safe_infer(truth_value)
-        if inferred_truth_value is None or inferred_truth_value == astroid.Uninferable:
-            truth_boolean_value = True
-        else:
-            truth_boolean_value = inferred_truth_value.bool_value()
+        inferred_truth_value = utils.safe_infer(truth_value, compare_constants=True)
+        if inferred_truth_value is None or isinstance(
+            inferred_truth_value, UninferableBase
+        ):
+            return
+        truth_boolean_value = inferred_truth_value.bool_value()
 
         if truth_boolean_value is False:
             message = "simplify-boolean-expression"
             suggestion = false_value.as_string()
         else:
             message = "consider-using-ternary"
             suggestion = f"{truth_value.as_string()} if {cond.as_string()} else {false_value.as_string()}"
-        self.add_message(message, node=node, args=(suggestion,))
+        self.add_message(message, node=node, args=(suggestion,), confidence=INFERENCE)
 
     def _append_context_managers_to_stack(self, node: nodes.Assign) -> None:
         if _is_inside_context_manager(node):
-            # if we are inside a context manager itself, we assume that it will handle the resource management itself.
+            # if we are inside a context manager itself, we assume that it will handle
+            # the resource management itself.
             return
         if isinstance(node.targets[0], (nodes.Tuple, nodes.List, nodes.Set)):
             assignees = node.targets[0].elts
             value = utils.safe_infer(node.value)
             if value is None or not hasattr(value, "elts"):
                 # We cannot deduce what values are assigned, so we have to skip this
                 return
             values = value.elts
         else:
             assignees = [node.targets[0]]
             values = [node.value]
-        if Uninferable in (assignees, values):
+        if any(isinstance(n, UninferableBase) for n in (assignees, values)):
             return
         for assignee, value in zip(assignees, values):
             if not isinstance(value, nodes.Call):
                 continue
             inferred = utils.safe_infer(value.func)
             if (
                 not inferred
@@ -1496,54 +1600,104 @@
                 # variable was redefined before it was used in a ``with`` block
                 self.add_message(
                     "consider-using-with",
                     node=existing_node,
                 )
             stack[varname] = value
 
-    def _check_consider_using_with(self, node: nodes.Call):
+    def _check_consider_using_with(self, node: nodes.Call) -> None:
         if _is_inside_context_manager(node) or _is_a_return_statement(node):
-            # If we are inside a context manager itself, we assume that it will handle the resource management itself.
-            # If the node is a child of a return, we assume that the caller knows he is getting a context manager
-            # he should use properly (i.e. in a ``with``).
+            # If we are inside a context manager itself, we assume that it will handle the
+            # resource management itself.
+            # If the node is a child of a return, we assume that the caller knows he is getting
+            # a context manager he should use properly (i.e. in a ``with``).
             return
         if (
             node
             in self._consider_using_with_stack.get_stack_for_frame(
                 node.frame(future=True)
             ).values()
         ):
-            # the result of this call was already assigned to a variable and will be checked when leaving the scope.
+            # the result of this call was already assigned to a variable and will be
+            # checked when leaving the scope.
             return
         inferred = utils.safe_infer(node.func)
-        if not inferred:
+        if not inferred or not isinstance(
+            inferred, (nodes.FunctionDef, nodes.ClassDef, bases.UnboundMethod)
+        ):
             return
         could_be_used_in_with = (
             # things like ``lock.acquire()``
             inferred.qname() in CALLS_THAT_COULD_BE_REPLACED_BY_WITH
             or (
                 # things like ``open("foo")`` which are not already inside a ``with`` statement
                 inferred.qname() in CALLS_RETURNING_CONTEXT_MANAGERS
                 and not _is_part_of_with_items(node)
             )
         )
         if could_be_used_in_with and not _will_be_released_automatically(node):
             self.add_message("consider-using-with", node=node)
 
-    def _check_use_list_or_dict_literal(self, node: nodes.Call) -> None:
-        """Check if empty list or dict is created by using the literal [] or {}."""
-        if node.as_string() in {"list()", "dict()"}:
+    def _check_use_list_literal(self, node: nodes.Call) -> None:
+        """Check if empty list is created by using the literal []."""
+        if node.as_string() == "list()":
             inferred = utils.safe_infer(node.func)
             if isinstance(inferred, nodes.ClassDef) and not node.args:
                 if inferred.qname() == "builtins.list":
                     self.add_message("use-list-literal", node=node)
-                elif inferred.qname() == "builtins.dict" and not node.keywords:
-                    self.add_message("use-dict-literal", node=node)
 
-    def _check_consider_using_join(self, aug_assign):
+    def _check_use_dict_literal(self, node: nodes.Call) -> None:
+        """Check if dict is created by using the literal {}."""
+        if not isinstance(node.func, astroid.Name) or node.func.name != "dict":
+            return
+        inferred = utils.safe_infer(node.func)
+        if (
+            isinstance(inferred, nodes.ClassDef)
+            and inferred.qname() == "builtins.dict"
+            and not node.args
+        ):
+            self.add_message(
+                "use-dict-literal",
+                args=(self._dict_literal_suggestion(node),),
+                node=node,
+                confidence=INFERENCE,
+            )
+
+    @staticmethod
+    def _dict_literal_suggestion(node: nodes.Call) -> str:
+        """Return a suggestion of reasonable length."""
+        elements: list[str] = []
+        for keyword in node.keywords:
+            if len(", ".join(elements)) >= 64:
+                break
+            if keyword not in node.kwargs:
+                elements.append(f'"{keyword.arg}": {keyword.value.as_string()}')
+        for keyword in node.kwargs:
+            if len(", ".join(elements)) >= 64:
+                break
+            elements.append(f"**{keyword.value.as_string()}")
+        suggestion = ", ".join(elements)
+        return f"{{{suggestion}{', ... '  if len(suggestion) > 64 else ''}}}"
+
+    @staticmethod
+    def _name_to_concatenate(node: nodes.NodeNG) -> str | None:
+        """Try to extract the name used in a concatenation loop."""
+        if isinstance(node, nodes.Name):
+            return cast("str | None", node.name)
+        if not isinstance(node, nodes.JoinedStr):
+            return None
+
+        values = [
+            value for value in node.values if isinstance(value, nodes.FormattedValue)
+        ]
+        if len(values) != 1 or not isinstance(values[0].value, nodes.Name):
+            return None
+        return cast("str | None", values[0].value.name)
+
+    def _check_consider_using_join(self, aug_assign: nodes.AugAssign) -> None:
         """We start with the augmented assignment and work our way upwards.
 
         Names of variables for nodes if match successful:
         result = ''  # assign
         for number in ['1', '2', '3']  # for_loop
             result += number  # aug_assign
         """
@@ -1562,16 +1716,15 @@
         is_concat_loop = (
             aug_assign.op == "+="
             and isinstance(aug_assign.target, nodes.AssignName)
             and len(for_loop.body) == 1
             and aug_assign.target.name in result_assign_names
             and isinstance(assign.value, nodes.Const)
             and isinstance(assign.value.value, str)
-            and isinstance(aug_assign.value, nodes.Name)
-            and aug_assign.value.name == for_loop.target.name
+            and self._name_to_concatenate(aug_assign.value) == for_loop.target.name
         )
         if is_concat_loop:
             self.add_message("consider-using-join", node=aug_assign)
 
     @utils.only_required_for_messages("consider-using-join")
     def visit_augassign(self, node: nodes.AugAssign) -> None:
         self._check_consider_using_join(node)
@@ -1664,15 +1817,15 @@
             self.add_message(
                 "unnecessary-comprehension",
                 node=node.parent,
                 args=(f"{func}({node.iter.as_string()})",),
             )
 
     @staticmethod
-    def _is_and_or_ternary(node):
+    def _is_and_or_ternary(node: nodes.NodeNG | None) -> bool:
         """Returns true if node is 'condition and true_value or false_value' form.
 
         All of: condition, true_value and false_value should not be a complex boolean expression
         """
         return (
             isinstance(node, nodes.BoolOp)
             and node.op == "or"
@@ -1681,15 +1834,17 @@
             and not isinstance(node.values[1], nodes.BoolOp)
             and node.values[0].op == "and"
             and not isinstance(node.values[0].values[1], nodes.BoolOp)
             and len(node.values[0].values) == 2
         )
 
     @staticmethod
-    def _and_or_ternary_arguments(node):
+    def _and_or_ternary_arguments(
+        node: nodes.BoolOp,
+    ) -> tuple[nodes.NodeNG, nodes.NodeNG, nodes.NodeNG]:
         false_value = node.values[1]
         condition, true_value = node.values[0].values
         return condition, true_value, false_value
 
     def visit_functiondef(self, node: nodes.FunctionDef) -> None:
         self._return_nodes[node.name] = list(
             node.nodes_of_class(nodes.Return, skip_klass=nodes.FunctionDef)
@@ -1764,15 +1919,19 @@
             return True
         if not utils.is_node_inside_try_except(node):
             # If the raise statement is not inside a try/except statement
             # then the exception is raised and cannot be caught. No need
             # to infer it.
             return True
         exc = utils.safe_infer(node.exc)
-        if exc is None or exc is astroid.Uninferable or not hasattr(exc, "pytype"):
+        if (
+            exc is None
+            or isinstance(exc, UninferableBase)
+            or not hasattr(exc, "pytype")
+        ):
             return False
         exc_name = exc.pytype().split(".")[-1]
         handlers = utils.get_exception_handlers(node, exc_name)
         handlers = list(handlers) if handlers is not None else []
         if handlers:
             # among all the handlers handling the exception at least one
             # must end with a return statement
@@ -1795,18 +1954,20 @@
         if isinstance(node, nodes.Call):
             try:
                 funcdef_node = node.func.inferred()[0]
                 if self._is_function_def_never_returning(funcdef_node):
                     return True
             except astroid.InferenceError:
                 pass
-        # Avoid the check inside while loop as we don't know
-        # if they will be completed
         if isinstance(node, nodes.While):
-            return True
+            # A while-loop is considered return-ended if it has a
+            # truthy test and no break statements
+            return (node.test.bool_value() and not _loop_exits_early(node)) or any(
+                self._is_node_return_ended(child) for child in node.orelse
+            )
         if isinstance(node, nodes.Raise):
             return self._is_raise_node_return_ended(node)
         if isinstance(node, nodes.If):
             return self._is_if_node_return_ended(node)
         if isinstance(node, nodes.TryExcept):
             handlers = {
                 _child
@@ -1851,18 +2012,18 @@
                 isinstance(node.returns, nodes.Attribute)
                 and node.returns.attrname == "NoReturn"
                 or isinstance(node.returns, nodes.Name)
                 and node.returns.name == "NoReturn"
             )
         try:
             return node.qname() in self._never_returning_functions
-        except TypeError:
+        except (TypeError, AttributeError):
             return False
 
-    def _check_return_at_the_end(self, node):
+    def _check_return_at_the_end(self, node: nodes.FunctionDef) -> None:
         """Check for presence of a *single* return statement at the end of a
         function.
 
         "return" or "return None" are useless because None is the
         default return type if they are missing.
 
         NOTE: produces a message only if there is a single return statement
@@ -1898,38 +2059,52 @@
             and node.iter.func.attrname == "items"
         ):
             inferred = utils.safe_infer(node.iter.func)
             if not isinstance(inferred, astroid.BoundMethod):
                 return
             iterating_object_name = node.iter.func.expr.as_string()
 
+            # Store potential violations. These will only be reported if we don't
+            # discover any writes to the collection during the loop.
+            messages = []
+
             # Verify that the body of the for loop uses a subscript
             # with the object that was iterated. This uses some heuristics
             # in order to make sure that the same object is used in the
             # for body.
 
             children = (
-                node.body if isinstance(node, nodes.For) else node.parent.get_children()
+                node.body
+                if isinstance(node, nodes.For)
+                else list(node.parent.get_children())
+            )
+
+            # Check if there are any for / while loops within the loop in question;
+            # If so, we will be more conservative about reporting errors as we
+            # can't yet do proper control flow analysis to be sure when
+            # reassignment will affect us
+            nested_loops = itertools.chain.from_iterable(
+                child.nodes_of_class((nodes.For, nodes.While)) for child in children
             )
+            has_nested_loops = next(nested_loops, None) is not None
+
             for child in children:
                 for subscript in child.nodes_of_class(nodes.Subscript):
                     if not isinstance(subscript.value, (nodes.Name, nodes.Attribute)):
                         continue
 
                     value = subscript.slice
 
-                    if isinstance(node, nodes.For) and (
-                        isinstance(subscript.parent, nodes.Assign)
-                        and subscript in subscript.parent.targets
-                        or isinstance(subscript.parent, nodes.AugAssign)
-                        and subscript == subscript.parent.target
+                    if isinstance(node, nodes.For) and _is_part_of_assignment_target(
+                        subscript
                     ):
                         # Ignore this subscript if it is the target of an assignment
                         # Early termination; after reassignment dict index lookup will be necessary
                         return
+
                     if isinstance(subscript.parent, nodes.Delete):
                         # Ignore this subscript if it's used with the delete keyword
                         return
 
                     # Case where .items is assigned to k,v (i.e., for k, v in d.items())
                     if isinstance(value, nodes.Name):
                         if (
@@ -1947,19 +2122,27 @@
                         ):
                             # Ignore this subscript if it has been redefined after
                             # the for loop. This checks for the line number using .lookup()
                             # to get the line number where the iterating object was last
                             # defined and compare that to the for loop's line number
                             continue
 
-                        self.add_message(
-                            "unnecessary-dict-index-lookup",
-                            node=subscript,
-                            args=(node.target.elts[1].as_string()),
-                        )
+                        if has_nested_loops:
+                            messages.append(
+                                {
+                                    "node": subscript,
+                                    "variable": node.target.elts[1].as_string(),
+                                }
+                            )
+                        else:
+                            self.add_message(
+                                "unnecessary-dict-index-lookup",
+                                node=subscript,
+                                args=(node.target.elts[1].as_string(),),
+                            )
 
                     # Case where .items is assigned to single var (i.e., for item in d.items())
                     elif isinstance(value, nodes.Subscript):
                         if (
                             not isinstance(node.target, nodes.AssignName)
                             or not isinstance(value.value, nodes.Name)
                             or node.target.name != value.value.name
@@ -1978,54 +2161,110 @@
                             # defined and compare that to the for loop's line number
                             continue
 
                         # check if subscripted by 0 (key)
                         inferred = utils.safe_infer(value.slice)
                         if not isinstance(inferred, nodes.Const) or inferred.value != 0:
                             continue
-                        self.add_message(
-                            "unnecessary-dict-index-lookup",
-                            node=subscript,
-                            args=("1".join(value.as_string().rsplit("0", maxsplit=1)),),
-                        )
+
+                        if has_nested_loops:
+                            messages.append(
+                                {
+                                    "node": subscript,
+                                    "variable": "1".join(
+                                        value.as_string().rsplit("0", maxsplit=1)
+                                    ),
+                                }
+                            )
+                        else:
+                            self.add_message(
+                                "unnecessary-dict-index-lookup",
+                                node=subscript,
+                                args=(
+                                    "1".join(value.as_string().rsplit("0", maxsplit=1)),
+                                ),
+                            )
+
+            for message in messages:
+                self.add_message(
+                    "unnecessary-dict-index-lookup",
+                    node=message["node"],
+                    args=(message["variable"],),
+                )
 
     def _check_unnecessary_list_index_lookup(
         self, node: nodes.For | nodes.Comprehension
     ) -> None:
         if (
             not isinstance(node.iter, nodes.Call)
             or not isinstance(node.iter.func, nodes.Name)
             or not node.iter.func.name == "enumerate"
-            or not node.iter.args
-            or not isinstance(node.iter.args[0], nodes.Name)
         ):
             return
 
+        try:
+            iterable_arg = utils.get_argument_from_call(
+                node.iter, position=0, keyword="iterable"
+            )
+        except utils.NoSuchArgumentError:
+            return
+
+        if not isinstance(iterable_arg, nodes.Name):
+            return
+
         if not isinstance(node.target, nodes.Tuple) or len(node.target.elts) < 2:
             # enumerate() result is being assigned without destructuring
             return
 
         if not isinstance(node.target.elts[1], nodes.AssignName):
             # The value is not being assigned to a single variable, e.g. being
             # destructured, so we can't necessarily use it.
             return
 
-        iterating_object_name = node.iter.args[0].name
+        has_start_arg, confidence = self._enumerate_with_start(node)
+        if has_start_arg:
+            # enumerate is being called with start arg/kwarg so resulting index lookup
+            # is not redundant, hence we should not report an error.
+            return
+
+        iterating_object_name = iterable_arg.name
         value_variable = node.target.elts[1]
 
+        # Store potential violations. These will only be reported if we don't
+        # discover any writes to the collection during the loop.
+        bad_nodes = []
+
         children = (
-            node.body if isinstance(node, nodes.For) else node.parent.get_children()
+            node.body
+            if isinstance(node, nodes.For)
+            else list(node.parent.get_children())
+        )
+
+        # Check if there are any for / while loops within the loop in question;
+        # If so, we will be more conservative about reporting errors as we
+        # can't yet do proper control flow analysis to be sure when
+        # reassignment will affect us
+        nested_loops = itertools.chain.from_iterable(
+            child.nodes_of_class((nodes.For, nodes.While)) for child in children
+        )
+        has_nested_loops = next(nested_loops, None) is not None
+
+        # Check if there are any if statements within the loop in question;
+        # If so, we will be more conservative about reporting errors as we
+        # can't yet do proper control flow analysis to be sure when
+        # reassignment will affect us
+        if_statements = itertools.chain.from_iterable(
+            child.nodes_of_class(nodes.If) for child in children
         )
+        has_if_statements = next(if_statements, None) is not None
+
         for child in children:
             for subscript in child.nodes_of_class(nodes.Subscript):
-                if isinstance(node, nodes.For) and (
-                    isinstance(subscript.parent, nodes.Assign)
-                    and subscript in subscript.parent.targets
-                    or isinstance(subscript.parent, nodes.AugAssign)
-                    and subscript == subscript.parent.target
+                if isinstance(node, nodes.For) and _is_part_of_assignment_target(
+                    subscript
                 ):
                     # Ignore this subscript if it is the target of an assignment
                     # Early termination; after reassignment index lookup will be necessary
                     return
 
                 if isinstance(subscript.parent, nodes.Delete):
                     # Ignore this subscript if it's used with the delete keyword
@@ -2052,13 +2291,78 @@
                         and index.lookup(value_variable.name)[1][-1].lineno
                         > node.lineno
                     ):
                         # The variable holding the value from iteration has been
                         # reassigned on a later line, so it can't be used.
                         continue
 
-                    self.add_message(
-                        "unnecessary-list-index-lookup",
-                        node=subscript,
-                        args=(node.target.elts[1].name,),
-                        confidence=HIGH,
-                    )
+                    if has_nested_loops:
+                        # Have found a likely issue, but since there are nested
+                        # loops we don't want to report this unless we get to the
+                        # end of the loop without updating the collection
+                        bad_nodes.append(subscript)
+                    elif has_if_statements:
+                        continue
+                    else:
+                        self.add_message(
+                            "unnecessary-list-index-lookup",
+                            node=subscript,
+                            args=(node.target.elts[1].name,),
+                            confidence=confidence,
+                        )
+
+        for subscript in bad_nodes:
+            self.add_message(
+                "unnecessary-list-index-lookup",
+                node=subscript,
+                args=(node.target.elts[1].name,),
+                confidence=confidence,
+            )
+
+    def _enumerate_with_start(
+        self, node: nodes.For | nodes.Comprehension
+    ) -> tuple[bool, Confidence]:
+        """Check presence of `start` kwarg or second argument to enumerate.
+
+        For example:
+
+        `enumerate([1,2,3], start=1)`
+        `enumerate([1,2,3], 1)`
+
+        If `start` is assigned to `0`, the default value, this is equivalent to
+        not calling `enumerate` with start.
+        """
+        confidence = HIGH
+
+        if len(node.iter.args) > 1:
+            # We assume the second argument to `enumerate` is the `start` int arg.
+            # It's a reasonable assumption for now as it's the only possible argument:
+            # https://docs.python.org/3/library/functions.html#enumerate
+            start_arg = node.iter.args[1]
+            start_val, confidence = self._get_start_value(start_arg)
+            if start_val is None:
+                return False, confidence
+            return not start_val == 0, confidence
+
+        for keyword in node.iter.keywords:
+            if keyword.arg == "start":
+                start_val, confidence = self._get_start_value(keyword.value)
+                if start_val is None:
+                    return False, confidence
+                return not start_val == 0, confidence
+
+        return False, confidence
+
+    def _get_start_value(self, node: nodes.NodeNG) -> tuple[int | None, Confidence]:
+        if (
+            isinstance(node, (nodes.Name, nodes.Call, nodes.Attribute))
+            or isinstance(node, nodes.UnaryOp)
+            and isinstance(node.operand, nodes.Attribute)
+        ):
+            inferred = utils.safe_infer(node)
+            start_val = inferred.value if inferred else None
+            return start_val, INFERENCE
+        if isinstance(node, nodes.UnaryOp):
+            return node.operand.value, HIGH
+        if isinstance(node, nodes.Const):
+            return node.value, HIGH
+        return None, HIGH
```

### Comparing `pylint-3.0.0a5/pylint/checkers/similar.py` & `pylint-3.0.0a6/pylint/checkers/similar.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,38 +1,48 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """A similarities / code duplication command line tool and pylint checker.
 
 The algorithm is based on comparing the hash value of n successive lines of a file.
-First the files are read and any line that doesn't fulfill requirement are removed (comments, docstrings...)
+First the files are read and any line that doesn't fulfill requirement are removed
+(comments, docstrings...)
+
 Those stripped lines are stored in the LineSet class which gives access to them.
-Then each index of the stripped lines collection is associated with the hash of n successive entries of the stripped lines starting at the current index
-(n is the minimum common lines option).
-The common hashes between both linesets are then looked for. If there are matches, then the match indices in both linesets are stored and associated
-with the corresponding couples (start line number/end line number) in both files.
-This association is then post-processed to handle the case of successive matches. For example if the minimum common lines setting is set to four, then
-the hashes are computed with four lines. If one of match indices couple (12, 34) is the successor of another one (11, 33) then it means that there are
-in fact five lines which are common.
-Once post-processed the values of association table are the result looked for, i.e start and end lines numbers of common lines in both files.
+Then each index of the stripped lines collection is associated with the hash of n
+successive entries of the stripped lines starting at the current index (n is the
+minimum common lines option).
+
+The common hashes between both linesets are then looked for. If there are matches, then
+the match indices in both linesets are stored and associated with the corresponding
+couples (start line number/end line number) in both files.
+
+This association is then post-processed to handle the case of successive matches. For
+example if the minimum common lines setting is set to four, then the hashes are
+computed with four lines. If one of match indices couple (12, 34) is the
+successor of another one (11, 33) then it means that there are in fact five lines which
+are common.
+
+Once post-processed the values of association table are the result looked for, i.e.
+start and end lines numbers of common lines in both files.
 """
 
 from __future__ import annotations
 
 import argparse
 import copy
 import functools
 import itertools
 import operator
 import re
 import sys
 import warnings
 from collections import defaultdict
-from collections.abc import Callable, Generator, Iterable
+from collections.abc import Callable, Generator, Iterable, Sequence
 from getopt import getopt
 from io import BufferedIOBase, BufferedReader, BytesIO
 from itertools import chain, groupby
 from typing import (
     TYPE_CHECKING,
     Any,
     Dict,
@@ -45,15 +55,15 @@
     Union,
 )
 
 import astroid
 from astroid import nodes
 
 from pylint.checkers import BaseChecker, BaseRawFileChecker, table_lines_from_stats
-from pylint.reporters.ureports.nodes import Table
+from pylint.reporters.ureports.nodes import Section, Table
 from pylint.typing import MessageDefinitionTuple, Options
 from pylint.utils import LinterStats, decoding_stream
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 DEFAULT_MIN_SIMILARITY_LINE = 4
@@ -181,15 +191,15 @@
     snd_lineset_index: Index
 
     def __repr__(self) -> str:
         return (
             f"<LineSetStartCouple <{self.fst_lineset_index};{self.snd_lineset_index}>>"
         )
 
-    def __eq__(self, other) -> bool:
+    def __eq__(self, other: Any) -> bool:
         if not isinstance(other, LineSetStartCouple):
             return NotImplemented
         return (
             self.fst_lineset_index == other.fst_lineset_index
             and self.snd_lineset_index == other.snd_lineset_index
         )
 
@@ -225,26 +235,24 @@
     index2lines = {}
     # Comments, docstring and other specific patterns maybe excluded -> call to stripped_lines
     # to get only what is desired
     lines = tuple(x.text for x in lineset.stripped_lines)
     # Need different iterators on same lines but each one is shifted 1 from the precedent
     shifted_lines = [iter(lines[i:]) for i in range(min_common_lines)]
 
-    for index_i, *succ_lines in enumerate(zip(*shifted_lines)):
-        start_linenumber = lineset.stripped_lines[index_i].line_number
+    for i, *succ_lines in enumerate(zip(*shifted_lines)):
+        start_linenumber = LineNumber(lineset.stripped_lines[i].line_number)
         try:
-            end_linenumber = lineset.stripped_lines[
-                index_i + min_common_lines
-            ].line_number
+            end_linenumber = lineset.stripped_lines[i + min_common_lines].line_number
         except IndexError:
-            end_linenumber = lineset.stripped_lines[-1].line_number + 1
+            end_linenumber = LineNumber(lineset.stripped_lines[-1].line_number + 1)
 
-        index = Index(index_i)
+        index = Index(i)
         index2lines[index] = SuccessiveLinesLimits(
-            start=LineNumber(start_linenumber), end=LineNumber(end_linenumber)
+            start=start_linenumber, end=end_linenumber
         )
 
         l_c = LinesChunk(lineset.name, index, *succ_lines)
         hash2index[l_c].append(index)
 
     return hash2index, index2lines
 
@@ -365,30 +373,31 @@
     ) -> None:
         """Append a file to search for similarities."""
         if isinstance(stream, BufferedIOBase):
             if encoding is None:
                 raise ValueError
             readlines = decoding_stream(stream, encoding).readlines
         else:
-            readlines = stream.readlines  # type: ignore[assignment] # hint parameter is incorrectly typed as non-optional
+            # hint parameter is incorrectly typed as non-optional
+            readlines = stream.readlines  # type: ignore[assignment]
 
         try:
             lines = readlines()
         except UnicodeDecodeError:
             lines = []
 
         self.linesets.append(
             LineSet(
                 streamid,
                 lines,
                 self.namespace.ignore_comments,
                 self.namespace.ignore_docstrings,
                 self.namespace.ignore_imports,
                 self.namespace.ignore_signatures,
-                line_enabled_callback=self.linter._is_one_message_enabled  # type: ignore[attr-defined]
+                line_enabled_callback=self.linter._is_one_message_enabled
                 if hasattr(self, "linter")
                 else None,
             )
         )
 
     def run(self) -> None:
         """Start looking for similarities and display results on stdout."""
@@ -455,28 +464,36 @@
             for line_set, start_line, end_line in couples_l:
                 report += f"=={line_set.name}:[{start_line}:{end_line}]\n"
             if line_set:
                 for line in line_set._real_lines[start_line:end_line]:
                     report += f"   {line.rstrip()}\n" if line.rstrip() else "\n"
             duplicated_line_number += number * (len(couples_l) - 1)
         total_line_number: int = sum(len(lineset) for lineset in self.linesets)
-        report += f"TOTAL lines={total_line_number} duplicates={duplicated_line_number} percent={duplicated_line_number * 100.0 / total_line_number:.2f}\n"
+        report += (
+            f"TOTAL lines={total_line_number} "
+            f"duplicates={duplicated_line_number} "
+            f"percent={duplicated_line_number * 100.0 / total_line_number:.2f}\n"
+        )
         return report
 
+    # pylint: disable = too-many-locals
     def _find_common(
         self, lineset1: LineSet, lineset2: LineSet
     ) -> Generator[Commonality, None, None]:
         """Find similarities in the two given linesets.
 
-        This the core of the algorithm.
-        The idea is to compute the hashes of a minimal number of successive lines of each lineset and then compare the hashes.
-        Every match of such comparison is stored in a dict that links the couple of starting indices in both linesets to
-        the couple of corresponding starting and ending lines in both files.
-        Last regroups all successive couples in a bigger one. It allows to take into account common chunk of lines that have more
-        than the minimal number of successive lines required.
+        This the core of the algorithm. The idea is to compute the hashes of a
+        minimal number of successive lines of each lineset and then compare the
+        hashes. Every match of such comparison is stored in a dict that links the
+        couple of starting indices in both linesets to the couple of corresponding
+        starting and ending lines in both files.
+
+        Last regroups all successive couples in a bigger one. It allows to take into
+        account common chunk of lines that have more than the minimal number of
+        successive lines required.
         """
         hash_to_index_1: HashToIndex_T
         hash_to_index_2: HashToIndex_T
         index_to_lines_1: IndexToLines_T
         index_to_lines_2: IndexToLines_T
         hash_to_index_1, index_to_lines_1 = hash_lineset(
             lineset1, self.namespace.min_similarity_lines
@@ -538,23 +555,23 @@
         """Iterate on similarities among all files, by making a Cartesian
         product.
         """
         for idx, lineset in enumerate(self.linesets[:-1]):
             for lineset2 in self.linesets[idx + 1 :]:
                 yield from self._find_common(lineset, lineset2)
 
-    def get_map_data(self):
+    def get_map_data(self) -> list[LineSet]:
         """Returns the data we can use for a map/reduce process.
 
         In this case we are returning this instance's Linesets, that is all file
         information that will later be used for vectorisation.
         """
         return self.linesets
 
-    def combine_mapreduce_data(self, linesets_collection):
+    def combine_mapreduce_data(self, linesets_collection: list[list[LineSet]]) -> None:
         """Reduces and recombines data into a format that we can report on.
 
         The partner function of get_map_data()
         """
         self.linesets = [line for lineset in linesets_collection for line in lineset]
 
 
@@ -570,28 +587,29 @@
     any ignored code features removed.
 
     :param lines: a collection of lines
     :param ignore_comments: if true, any comment in the lines collection is removed from the result
     :param ignore_docstrings: if true, any line that is a docstring is removed from the result
     :param ignore_imports: if true, any line that is an import is removed from the result
     :param ignore_signatures: if true, any line that is part of a function signature is removed from the result
-    :param line_enabled_callback: If called with "R0801" and a line number, a return value of False will disregard the line
+    :param line_enabled_callback: If called with "R0801" and a line number, a return value of False will disregard
+           the line
     :return: the collection of line/line number/line type tuples
     """
     if ignore_imports or ignore_signatures:
         tree = astroid.parse("".join(lines))
     if ignore_imports:
         node_is_import_by_lineno = (
             (node.lineno, isinstance(node, (nodes.Import, nodes.ImportFrom)))
             for node in tree.body
         )
         line_begins_import = {
             lineno: all(is_import for _, is_import in node_is_import_group)
             for lineno, node_is_import_group in groupby(
-                node_is_import_by_lineno, key=lambda x: x[0]
+                node_is_import_by_lineno, key=lambda x: x[0]  # type: ignore[no-any-return]
             )
         }
         current_line_is_import = False
     if ignore_signatures:
 
         def _get_functions(
             functions: list[nodes.NodeNG], tree: nodes.NodeNG
@@ -687,40 +705,40 @@
             ignore_comments,
             ignore_docstrings,
             ignore_imports,
             ignore_signatures,
             line_enabled_callback=line_enabled_callback,
         )
 
-    def __str__(self):
+    def __str__(self) -> str:
         return f"<Lineset for {self.name}>"
 
-    def __len__(self):
+    def __len__(self) -> int:
         return len(self._real_lines)
 
-    def __getitem__(self, index):
+    def __getitem__(self, index: int) -> LineSpecifs:
         return self._stripped_lines[index]
 
-    def __lt__(self, other):
+    def __lt__(self, other: LineSet) -> bool:
         return self.name < other.name
 
-    def __hash__(self):
+    def __hash__(self) -> int:
         return id(self)
 
-    def __eq__(self, other):
+    def __eq__(self, other: Any) -> bool:
         if not isinstance(other, LineSet):
             return False
         return self.__dict__ == other.__dict__
 
     @property
-    def stripped_lines(self):
+    def stripped_lines(self) -> list[LineSpecifs]:
         return self._stripped_lines
 
     @property
-    def real_lines(self):
+    def real_lines(self) -> list[str]:
         return self._real_lines
 
 
 MSGS: dict[str, MessageDefinitionTuple] = {
     "R0801": (
         "Similar lines in %s files\n%s",
         "duplicate-code",
@@ -728,15 +746,15 @@
         "among multiple file. This usually means that the code should "
         "be refactored to avoid this duplication.",
     )
 }
 
 
 def report_similarities(
-    sect,
+    sect: Section,
     stats: LinterStats,
     old_stats: LinterStats | None,
 ) -> None:
     """Make a layout with some stats about duplication."""
     lines = ["", "now", "previous", "difference"]
     lines += table_lines_from_stats(stats, old_stats, "duplicated_lines")
     sect.append(Table(children=lines, cols=4, rheaders=1, cheaders=1))
@@ -813,38 +831,40 @@
             min_lines=self.linter.config.min_similarity_lines,
             ignore_comments=self.linter.config.ignore_comments,
             ignore_docstrings=self.linter.config.ignore_docstrings,
             ignore_imports=self.linter.config.ignore_imports,
             ignore_signatures=self.linter.config.ignore_signatures,
         )
 
-    def open(self):
+    def open(self) -> None:
         """Init the checkers: reset linesets and statistics information."""
         self.linesets = []
         self.linter.stats.reset_duplicated_lines()
 
     def process_module(self, node: nodes.Module) -> None:
         """Process a module.
 
         the module's content is accessible via the stream object
 
         stream must implement the readlines method
         """
         if self.linter.current_name is None:
+            # TODO: 3.0 Fix current_name
             warnings.warn(
                 (
                     "In pylint 3.0 the current_name attribute of the linter object should be a string. "
                     "If unknown it should be initialized as an empty string."
                 ),
                 DeprecationWarning,
+                stacklevel=2,
             )
         with node.stream() as stream:
-            self.append_stream(self.linter.current_name, stream, node.file_encoding)  # type: ignore[arg-type]
+            self.append_stream(self.linter.current_name, stream, node.file_encoding)
 
-    def close(self):
+    def close(self) -> None:
         """Compute and display similarities on closing (i.e. end of parsing)."""
         total = sum(len(lineset) for lineset in self.linesets)
         duplicated = 0
         stats = self.linter.stats
         for num, couples in self._compute_sims():
             msg = []
             lineset = start_line = end_line = None
@@ -857,42 +877,42 @@
                     msg.append(line.rstrip())
 
             self.add_message("R0801", args=(len(couples), "\n".join(msg)))
             duplicated += num * (len(couples) - 1)
         stats.nb_duplicated_lines += int(duplicated)
         stats.percent_duplicated_lines += float(total and duplicated * 100.0 / total)
 
-    def get_map_data(self):
+    def get_map_data(self) -> list[LineSet]:
         """Passthru override."""
         return Similar.get_map_data(self)
 
-    def reduce_map_data(self, linter, data):
+    def reduce_map_data(self, linter: PyLinter, data: list[list[LineSet]]) -> None:
         """Reduces and recombines data into a format that we can report on.
 
         The partner function of get_map_data()
         """
         Similar.combine_mapreduce_data(self, linesets_collection=data)
 
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(SimilarChecker(linter))
 
 
-def usage(status=0):
+def usage(status: int = 0) -> NoReturn:
     """Display command line usage information."""
     print("finds copy pasted blocks in a set of files")
     print()
     print(
         "Usage: symilar [-d|--duplicates min_duplicated_lines] \
 [-i|--ignore-comments] [--ignore-docstrings] [--ignore-imports] [--ignore-signatures] file1..."
     )
     sys.exit(status)
 
 
-def Run(argv=None) -> NoReturn:
+def Run(argv: Sequence[str] | None = None) -> NoReturn:
     """Standalone command line access point."""
     if argv is None:
         argv = sys.argv[1:]
 
     s_opts = "hdi"
     l_opts = [
         "help",
@@ -903,15 +923,15 @@
         "ignore-signatures",
     ]
     min_lines = DEFAULT_MIN_SIMILARITY_LINE
     ignore_comments = False
     ignore_docstrings = False
     ignore_imports = False
     ignore_signatures = False
-    opts, args = getopt(argv, s_opts, l_opts)
+    opts, args = getopt(list(argv), s_opts, l_opts)
     for opt, val in opts:
         if opt in {"-d", "--duplicates"}:
             min_lines = int(val)
         elif opt in {"-h", "--help"}:
             usage()
         elif opt in {"-i", "--ignore-comments"}:
             ignore_comments = True
```

### Comparing `pylint-3.0.0a5/pylint/checkers/spelling.py` & `pylint-3.0.0a6/pylint/checkers/spelling.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,103 +1,130 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checker for spelling errors in comments and docstrings."""
 
 from __future__ import annotations
 
 import re
+import sys
 import tokenize
 from re import Pattern
-from typing import TYPE_CHECKING
+from typing import TYPE_CHECKING, Any
 
 from astroid import nodes
 
 from pylint.checkers import BaseTokenChecker
 from pylint.checkers.utils import only_required_for_messages
 
+if sys.version_info >= (3, 8):
+    from typing import Literal
+else:
+    from typing_extensions import Literal
+
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 try:
     import enchant
     from enchant.tokenize import (
         Chunker,
         EmailFilter,
         Filter,
         URLFilter,
         WikiWordFilter,
         get_tokenizer,
     )
-except ImportError:
+
+    PYENCHANT_AVAILABLE = True
+except ImportError:  # pragma: no cover
     enchant = None
+    PYENCHANT_AVAILABLE = False
 
     class EmailFilter:  # type: ignore[no-redef]
         ...
 
     class URLFilter:  # type: ignore[no-redef]
         ...
 
     class WikiWordFilter:  # type: ignore[no-redef]
         ...
 
     class Filter:  # type: ignore[no-redef]
-        def _skip(self, word):
+        def _skip(self, word: str) -> bool:
             raise NotImplementedError
 
     class Chunker:  # type: ignore[no-redef]
         pass
 
     def get_tokenizer(
-        tag=None, chunkers=None, filters=None
-    ):  # pylint: disable=unused-argument
+        tag: str | None = None,  # pylint: disable=unused-argument
+        chunkers: list[Chunker] | None = None,  # pylint: disable=unused-argument
+        filters: list[Filter] | None = None,  # pylint: disable=unused-argument
+    ) -> Filter:
         return Filter()
 
 
-if enchant is not None:
-    br = enchant.Broker()
-    dicts = br.list_dicts()
-    dict_choices = [""] + [d[0] for d in dicts]
-    dicts = [f"{d[0]} ({d[1].name})" for d in dicts]
-    dicts = ", ".join(dicts)
-    instr = ""
-else:
-    dicts = "none"
-    dict_choices = [""]
-    instr = " To make it work, install the 'python-enchant' package."
+def _get_enchant_dicts() -> list[tuple[Any, enchant.ProviderDesc]]:
+    # Broker().list_dicts() is not typed in enchant, but it does return tuples
+    return enchant.Broker().list_dicts() if PYENCHANT_AVAILABLE else []  # type: ignore[no-any-return]
+
+
+def _get_enchant_dict_choices(
+    inner_enchant_dicts: list[tuple[Any, enchant.ProviderDesc]]
+) -> list[str]:
+    return [""] + [d[0] for d in inner_enchant_dicts]
+
+
+def _get_enchant_dict_help(
+    inner_enchant_dicts: list[tuple[Any, enchant.ProviderDesc]],
+    pyenchant_available: bool,
+) -> str:
+    if inner_enchant_dicts:
+        dict_as_str = [f"{d[0]} ({d[1].name})" for d in inner_enchant_dicts]
+        enchant_help = f"Available dictionaries: {', '.join(dict_as_str)}"
+    else:
+        enchant_help = "No available dictionaries : You need to install "
+        if not pyenchant_available:
+            enchant_help += "both the python package and "
+        enchant_help += "the system dependency for enchant to work."
+    return f"Spelling dictionary name. {enchant_help}."
 
 
-class WordsWithDigitsFilter(Filter):
+enchant_dicts = _get_enchant_dicts()
+
+
+class WordsWithDigitsFilter(Filter):  # type: ignore[misc]
     """Skips words with digits."""
 
-    def _skip(self, word):
+    def _skip(self, word: str) -> bool:
         return any(char.isdigit() for char in word)
 
 
-class WordsWithUnderscores(Filter):
+class WordsWithUnderscores(Filter):  # type: ignore[misc]
     """Skips words with underscores.
 
     They are probably function parameter names.
     """
 
-    def _skip(self, word):
+    def _skip(self, word: str) -> bool:
         return "_" in word
 
 
-class RegExFilter(Filter):
+class RegExFilter(Filter):  # type: ignore[misc]
     """Parent class for filters using regular expressions.
 
     This filter skips any words the match the expression
     assigned to the class attribute ``_pattern``.
     """
 
     _pattern: Pattern[str]
 
-    def _skip(self, word) -> bool:
+    def _skip(self, word: str) -> bool:
         return bool(self._pattern.match(word))
 
 
 class CamelCasedWord(RegExFilter):
     r"""Filter skipping over camelCasedWords.
     This filter skips any words matching the following regular expression:
 
@@ -116,20 +143,22 @@
 
     That is, for example, :class:`BaseQuery`
     """
     # The final ` in the pattern is optional because enchant strips it out
     _pattern = re.compile(r"^(:([a-z]+)){1,2}:`([^`]+)(`)?")
 
 
-class ForwardSlashChunker(Chunker):
+class ForwardSlashChunker(Chunker):  # type: ignore[misc]
     """This chunker allows splitting words like 'before/after' into 'before' and
     'after'.
     """
 
-    def next(self):
+    _text: str
+
+    def next(self) -> tuple[str, int]:
         while True:
             if not self._text:
                 raise StopIteration()
             if "/" not in self._text:
                 text = self._text
                 self._offset = 0
                 self._text = ""
@@ -144,61 +173,45 @@
                 or not post_text[0].isalpha()
             ):
                 self._text = ""
                 self._offset = 0
                 return f"{pre_text}/{post_text}", 0
             return pre_text, 0
 
-    def _next(self):
+    def _next(self) -> tuple[str, Literal[0]]:
         while True:
             if "/" not in self._text:
                 return self._text, 0
             pre_text, post_text = self._text.split("/", 1)
             if not pre_text or not post_text:
                 break
             if not pre_text[-1].isalpha() or not post_text[0].isalpha():
                 raise StopIteration()
             self._text = pre_text + " " + post_text
         raise StopIteration()
 
 
 CODE_FLANKED_IN_BACKTICK_REGEX = re.compile(r"(\s|^)(`{1,2})([^`]+)(\2)([^`]|$)")
-MYPY_IGNORE_DIRECTIVE_RULE_REGEX = re.compile(r"(\s|^)(type\: ignore\[[^\]]+\])(.*)")
 
 
 def _strip_code_flanked_in_backticks(line: str) -> str:
     """Alter line so code flanked in back-ticks is ignored.
 
     Pyenchant automatically strips back-ticks when parsing tokens,
     so this cannot be done at the individual filter level.
     """
 
-    def replace_code_but_leave_surrounding_characters(match_obj) -> str:
+    def replace_code_but_leave_surrounding_characters(match_obj: re.Match[str]) -> str:
         return match_obj.group(1) + match_obj.group(5)
 
     return CODE_FLANKED_IN_BACKTICK_REGEX.sub(
         replace_code_but_leave_surrounding_characters, line
     )
 
 
-def _strip_mypy_ignore_directive_rule(line: str) -> str:
-    """Alter line so mypy rule name is ignored.
-
-    Pyenchant parses anything flanked by spaces as an individual token,
-    so this cannot be done at the individual filter level.
-    """
-
-    def replace_rule_name_but_leave_surrounding_characters(match_obj) -> str:
-        return match_obj.group(1) + match_obj.group(3)
-
-    return MYPY_IGNORE_DIRECTIVE_RULE_REGEX.sub(
-        replace_rule_name_but_leave_surrounding_characters, line
-    )
-
-
 class SpellingChecker(BaseTokenChecker):
     """Check spelling in comments and docstrings."""
 
     name = "spelling"
     msgs = {
         "C0401": (
             "Wrong spelling of a word '%s' in a comment:\n%s\n"
@@ -221,17 +234,16 @@
     options = (
         (
             "spelling-dict",
             {
                 "default": "",
                 "type": "choice",
                 "metavar": "<dict name>",
-                "choices": dict_choices,
-                "help": "Spelling dictionary name. "
-                f"Available dictionaries: {dicts}.{instr}",
+                "choices": _get_enchant_dict_choices(enchant_dicts),
+                "help": _get_enchant_dict_help(enchant_dicts, PYENCHANT_AVAILABLE),
             },
         ),
         (
             "spelling-ignore-words",
             {
                 "default": "",
                 "type": "string",
@@ -281,15 +293,15 @@
                 "and should not be checked.",
             },
         ),
     )
 
     def open(self) -> None:
         self.initialized = False
-        if enchant is None:
+        if not PYENCHANT_AVAILABLE:
             return
         dict_name = self.linter.config.spelling_dict
         if not dict_name:
             return
 
         self.ignore_list = [
             w.strip() for w in self.linter.config.spelling_ignore_words.split(",")
@@ -324,14 +336,15 @@
                 WordsWithUnderscores,
                 CamelCasedWord,
                 SphinxDirectives,
             ],
         )
         self.initialized = True
 
+    # pylint: disable = too-many-statements
     def _check_spelling(self, msgid: str, line: str, line_num: int) -> None:
         original_line = line
         try:
             # The mypy warning is caught by the except statement
             initial_space = re.search(r"^\s+", line).regs[0][1]  # type: ignore[union-attr]
         except (IndexError, AttributeError):
             initial_space = 0
@@ -345,15 +358,14 @@
                     line = line[(len(iter_directive) + 1) :]
                     break
             starts_with_comment = True
         else:
             starts_with_comment = False
 
         line = _strip_code_flanked_in_backticks(line)
-        line = _strip_mypy_ignore_directive_rule(line)
 
         for word, word_start_at in self.tokenizer(line.strip()):
             word_start_at += initial_space
             lower_cased_word = word.casefold()
 
             # Skip words from ignore list.
             if word in self.ignore_list or lower_cased_word in self.ignore_list:
@@ -411,59 +423,57 @@
                 self.add_message(msgid, line=line_num, args=args)
 
     def process_tokens(self, tokens: list[tokenize.TokenInfo]) -> None:
         if not self.initialized:
             return
 
         # Process tokens and look for comments.
-        for (tok_type, token, (start_row, _), _, _) in tokens:
+        for tok_type, token, (start_row, _), _, _ in tokens:
             if tok_type == tokenize.COMMENT:
                 if start_row == 1 and token.startswith("#!/"):
                     # Skip shebang lines
                     continue
                 if token.startswith("# pylint:"):
                     # Skip pylint enable/disable comments
                     continue
+                if token.startswith("# type: "):
+                    # Skip python 2 type comments and mypy type ignore comments
+                    # mypy do not support additional text in type comments
+                    continue
                 self._check_spelling("wrong-spelling-in-comment", token, start_row)
 
     @only_required_for_messages("wrong-spelling-in-docstring")
     def visit_module(self, node: nodes.Module) -> None:
-        if not self.initialized:
-            return
         self._check_docstring(node)
 
     @only_required_for_messages("wrong-spelling-in-docstring")
     def visit_classdef(self, node: nodes.ClassDef) -> None:
-        if not self.initialized:
-            return
         self._check_docstring(node)
 
     @only_required_for_messages("wrong-spelling-in-docstring")
     def visit_functiondef(
         self, node: nodes.FunctionDef | nodes.AsyncFunctionDef
     ) -> None:
-        if not self.initialized:
-            return
         self._check_docstring(node)
 
     visit_asyncfunctiondef = visit_functiondef
 
     def _check_docstring(
         self,
         node: nodes.FunctionDef
         | nodes.AsyncFunctionDef
         | nodes.ClassDef
         | nodes.Module,
     ) -> None:
-        """Check the node has any spelling errors."""
+        """Check if the node has any spelling errors."""
+        if not self.initialized:
+            return
         if not node.doc_node:
             return
-
         start_line = node.lineno + 1
-
         # Go through lines of docstring
         for idx, line in enumerate(node.doc_node.value.splitlines()):
             self._check_spelling("wrong-spelling-in-docstring", line, start_line + idx)
 
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(SpellingChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/checkers/stdlib.py` & `pylint-3.0.0a6/pylint/checkers/stdlib.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,30 +1,35 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checkers for various standard library functions."""
 
 from __future__ import annotations
 
 import sys
 from collections.abc import Iterable
-from typing import TYPE_CHECKING
+from typing import TYPE_CHECKING, Any, Dict, Set, Tuple
 
 import astroid
-from astroid import nodes
+from astroid import nodes, util
+from astroid.typing import InferenceResult
 
 from pylint import interfaces
 from pylint.checkers import BaseChecker, DeprecatedMixin, utils
+from pylint.interfaces import INFERENCE
+from pylint.typing import MessageDefinitionTuple
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
+DeprecationDict = Dict[Tuple[int, int, int], Set[str]]
+
 OPEN_FILES_MODE = ("open", "file")
-OPEN_FILES_FUNCS = OPEN_FILES_MODE + ("read_text", "write_text")
+OPEN_FILES_FUNCS = (*OPEN_FILES_MODE, "read_text", "write_text")
 UNITTEST_CASE = "unittest.case"
 THREADING_THREAD = "threading.Thread"
 COPY_COPY = "copy.copy"
 OS_ENVIRON = "os._Environ"
 ENV_GETTERS = ("os.getenv",)
 SUBPROCESS_POPEN = "subprocess.Popen"
 SUBPROCESS_RUN = "subprocess.run"
@@ -36,15 +41,17 @@
     "functools.lru_cache.decorating_function",  # Inferred for @lru_cache() on <= Python 3.7
 }
 NON_INSTANCE_METHODS = {"builtins.staticmethod", "builtins.classmethod"}
 
 
 # For modules, see ImportsChecker
 
-DEPRECATED_ARGUMENTS = {
+DEPRECATED_ARGUMENTS: dict[
+    tuple[int, int, int], dict[str, tuple[tuple[int | None, str], ...]]
+] = {
     (0, 0, 0): {
         "int": ((None, "x"),),
         "bool": ((None, "x"),),
         "float": ((None, "x"),),
     },
     (3, 8, 0): {
         "asyncio.tasks.sleep": ((None, "loop"),),
@@ -74,34 +81,36 @@
             (None, "c"),
             (None, "typeid"),
         ),
     },
     (3, 9, 0): {"random.Random.shuffle": ((1, "random"),)},
 }
 
-DEPRECATED_DECORATORS = {
+DEPRECATED_DECORATORS: DeprecationDict = {
     (3, 8, 0): {"asyncio.coroutine"},
     (3, 3, 0): {
         "abc.abstractclassmethod",
         "abc.abstractstaticmethod",
         "abc.abstractproperty",
     },
     (3, 4, 0): {"importlib.util.module_for_loader"},
 }
 
 
-DEPRECATED_METHODS: dict = {
+DEPRECATED_METHODS: dict[int, DeprecationDict] = {
     0: {
-        "cgi.parse_qs",
-        "cgi.parse_qsl",
-        "ctypes.c_buffer",
-        "distutils.command.register.register.check_metadata",
-        "distutils.command.sdist.sdist.check_metadata",
-        "tkinter.Misc.tk_menuBar",
-        "tkinter.Menu.tk_bindForTraversal",
+        (0, 0, 0): {
+            "cgi.parse_qs",
+            "cgi.parse_qsl",
+            "ctypes.c_buffer",
+            "distutils.command.register.register.check_metadata",
+            "distutils.command.sdist.sdist.check_metadata",
+            "tkinter.Misc.tk_menuBar",
+            "tkinter.Menu.tk_bindForTraversal",
+        }
     },
     2: {
         (2, 6, 0): {
             "commands.getstatus",
             "os.popen2",
             "os.popen3",
             "os.popen4",
@@ -231,23 +240,28 @@
             "threading.Thread.getName",
             "threading.Thread.isDaemon",
             "threading.Thread.setDaemon",
             "cgi.log",
         },
         (3, 11, 0): {
             "locale.getdefaultlocale",
-            "unittest.TestLoader.findTestCases",
+            "locale.resetlocale",
+            "re.template",
+            "unittest.findTestCases",
+            "unittest.makeSuite",
+            "unittest.getTestCaseNames",
+            "unittest.TestLoader.loadTestsFromModule",
             "unittest.TestLoader.loadTestsFromTestCase",
             "unittest.TestLoader.getTestCaseNames",
         },
     },
 }
 
 
-DEPRECATED_CLASSES = {
+DEPRECATED_CLASSES: dict[tuple[int, int, int], dict[str, set[str]]] = {
     (3, 2, 0): {
         "configparser": {
             "LegacyInterpolation",
             "SafeConfigParser",
         },
     },
     (3, 3, 0): {
@@ -288,22 +302,25 @@
     },
     (3, 9, 0): {
         "smtpd": {
             "MailmanProxy",
         }
     },
     (3, 11, 0): {
+        "typing": {
+            "Text",
+        },
         "webbrowser": {
             "MacOSX",
         },
     },
 }
 
 
-def _check_mode_str(mode):
+def _check_mode_str(mode: Any) -> bool:
     # check type
     if not isinstance(mode, str):
         return False
     # check syntax
     modes = set(mode)
     _mode = "rwatb+Ux"
     creating = "x" in modes
@@ -328,16 +345,19 @@
         return False
     return True
 
 
 class StdlibChecker(DeprecatedMixin, BaseChecker):
     name = "stdlib"
 
-    msgs = {
-        **{k: v for k, v in DeprecatedMixin.msgs.items() if k[1:3] == "15"},
+    msgs: dict[str, MessageDefinitionTuple] = {
+        **DeprecatedMixin.DEPRECATED_METHOD_MESSAGE,
+        **DeprecatedMixin.DEPRECATED_ARGUMENT_MESSAGE,
+        **DeprecatedMixin.DEPRECATED_CLASS_MESSAGE,
+        **DeprecatedMixin.DEPRECATED_DECORATOR_MESSAGE,
         "W1501": (
             '"%s" is not a valid mode for open.',
             "bad-open-mode",
             "Python supports: r, w, a[, x] modes with b, +, "
             "and U (only with r) options. "
             "See https://docs.python.org/3/library/functions.html#open",
         ),
@@ -358,53 +378,68 @@
             "condition will be always true. In this case a warning "
             "should be emitted.",
         ),
         "W1506": (
             "threading.Thread needs the target function",
             "bad-thread-instantiation",
             "The warning is emitted when a threading.Thread class "
-            "is instantiated without the target function being passed. "
+            "is instantiated without the target function being passed as a kwarg or as a second argument. "
             "By default, the first parameter is the group param, not the target param.",
         ),
         "W1507": (
-            "Using copy.copy(os.environ). Use os.environ.copy() instead. ",
+            "Using copy.copy(os.environ). Use os.environ.copy() instead.",
             "shallow-copy-environ",
             "os.environ is not a dict object but proxy object, so "
             "shallow copy has still effects on original object. "
             "See https://bugs.python.org/issue15373 for reference.",
         ),
         "E1507": (
             "%s does not support %s type argument",
             "invalid-envvar-value",
             "Env manipulation functions support only string type arguments. "
             "See https://docs.python.org/3/library/os.html#os.getenv.",
         ),
+        "E1519": (
+            "singledispatch decorator should not be used with methods, "
+            "use singledispatchmethod instead.",
+            "singledispatch-method",
+            "singledispatch should decorate functions and not class/instance methods. "
+            "Use singledispatchmethod for those cases.",
+        ),
+        "E1520": (
+            "singledispatchmethod decorator should not be used with functions, "
+            "use singledispatch instead.",
+            "singledispatchmethod-function",
+            "singledispatchmethod should decorate class/instance methods and not functions. "
+            "Use singledispatch for those cases.",
+        ),
         "W1508": (
             "%s default type is %s. Expected str or None.",
             "invalid-envvar-default",
             "Env manipulation functions return None or str values. "
             "Supplying anything different as a default may cause bugs. "
             "See https://docs.python.org/3/library/os.html#os.getenv.",
         ),
         "W1509": (
             "Using preexec_fn keyword which may be unsafe in the presence "
             "of threads",
             "subprocess-popen-preexec-fn",
             "The preexec_fn parameter is not safe to use in the presence "
             "of threads in your application. The child process could "
             "deadlock before exec is called. If you must use it, keep it "
-            "trivial! Minimize the number of libraries you call into."
-            "https://docs.python.org/3/library/subprocess.html#popen-constructor",
+            "trivial! Minimize the number of libraries you call into. "
+            "See https://docs.python.org/3/library/subprocess.html#popen-constructor",
         ),
         "W1510": (
-            "Using subprocess.run without explicitly set `check` is not recommended.",
+            "'subprocess.run' used without explicitly defining the value for 'check'.",
             "subprocess-run-check",
-            "The check parameter should always be used with explicitly set "
-            "`check` keyword to make clear what the error-handling behavior is."
-            "https://docs.python.org/3/library/subprocess.html#subprocess.run",
+            "The ``check`` keyword  is set to False by default. It means the process "
+            "launched by ``subprocess.run`` can exit with a non-zero exit code and "
+            "fail silently. It's better to set it explicitly to make clear what the "
+            "error-handling behavior is.",
         ),
         "W1514": (
             "Using open without explicitly specifying an encoding",
             "unspecified-encoding",
             "It is better to specify an encoding when opening documents. "
             "Using the system default implicitly can create problems on other operating systems. "
             "See https://peps.python.org/pep-0597/",
@@ -417,15 +452,15 @@
         ),
         "W1518": (
             "'lru_cache(maxsize=None)' or 'cache' will keep all method args alive indefinitely, including 'self'",
             "method-cache-max-size-none",
             "By decorating a method with lru_cache or cache the 'self' argument will be linked to "
             "the function and therefore never garbage collected. Unless your instance "
             "will never need to be garbage collected (singleton) it is recommended to refactor "
-            "code to avoid this pattern or add a maxsize to the cache."
+            "code to avoid this pattern or add a maxsize to the cache. "
             "The default value for maxsize is 128.",
             {
                 "old_names": [
                     ("W1516", "lru-cache-decorating-method"),
                     ("W1517", "cache-max-size-none"),
                 ]
             },
@@ -438,40 +473,46 @@
         self._deprecated_arguments: dict[str, tuple[tuple[int | None, str], ...]] = {}
         self._deprecated_classes: dict[str, set[str]] = {}
         self._deprecated_decorators: set[str] = set()
 
         for since_vers, func_list in DEPRECATED_METHODS[sys.version_info[0]].items():
             if since_vers <= sys.version_info:
                 self._deprecated_methods.update(func_list)
-        for since_vers, func_list in DEPRECATED_ARGUMENTS.items():
+        for since_vers, args_list in DEPRECATED_ARGUMENTS.items():
             if since_vers <= sys.version_info:
-                self._deprecated_arguments.update(func_list)
+                self._deprecated_arguments.update(args_list)
         for since_vers, class_list in DEPRECATED_CLASSES.items():
             if since_vers <= sys.version_info:
                 self._deprecated_classes.update(class_list)
         for since_vers, decorator_list in DEPRECATED_DECORATORS.items():
             if since_vers <= sys.version_info:
                 self._deprecated_decorators.update(decorator_list)
         # Modules are checked by the ImportsChecker, because the list is
         # synced with the config argument deprecated-modules
 
-    def _check_bad_thread_instantiation(self, node):
-        if not node.kwargs and not node.keywords and len(node.args) <= 1:
-            self.add_message("bad-thread-instantiation", node=node)
+    def _check_bad_thread_instantiation(self, node: nodes.Call) -> None:
+        func_kwargs = {key.arg for key in node.keywords}
+        if "target" in func_kwargs:
+            return
 
-    def _check_for_preexec_fn_in_popen(self, node):
+        if len(node.args) < 2 and (not node.kwargs or "target" not in func_kwargs):
+            self.add_message(
+                "bad-thread-instantiation", node=node, confidence=interfaces.HIGH
+            )
+
+    def _check_for_preexec_fn_in_popen(self, node: nodes.Call) -> None:
         if node.keywords:
             for keyword in node.keywords:
                 if keyword.arg == "preexec_fn":
                     self.add_message("subprocess-popen-preexec-fn", node=node)
 
-    def _check_for_check_kw_in_run(self, node):
+    def _check_for_check_kw_in_run(self, node: nodes.Call) -> None:
         kwargs = {keyword.arg for keyword in (node.keywords or ())}
         if "check" not in kwargs:
-            self.add_message("subprocess-run-check", node=node)
+            self.add_message("subprocess-run-check", node=node, confidence=INFERENCE)
 
     def _check_shallow_copy_environ(self, node: nodes.Call) -> None:
         arg = utils.get_argument_from_call(node, position=0)
         try:
             inferred_args = arg.inferred()
         except astroid.InferenceError:
             return
@@ -495,15 +536,15 @@
         "unspecified-encoding",
         "forgotten-debug-statement",
     )
     def visit_call(self, node: nodes.Call) -> None:
         """Visit a Call node."""
         self.check_deprecated_class_in_call(node)
         for inferred in utils.infer_all(node.func):
-            if inferred is astroid.Uninferable:
+            if isinstance(inferred, util.UninferableBase):
                 continue
             if inferred.root().name in OPEN_MODULE:
                 open_func_name: str | None = None
                 if isinstance(node.func, nodes.Name):
                     open_func_name = node.func.name
                 if isinstance(node.func, nodes.Attribute):
                     open_func_name = node.func.attrname
@@ -542,23 +583,33 @@
         self._check_datetime(node.test)
 
     @utils.only_required_for_messages("boolean-datetime")
     def visit_boolop(self, node: nodes.BoolOp) -> None:
         for value in node.values:
             self._check_datetime(value)
 
-    @utils.only_required_for_messages("method-cache-max-size-none")
+    @utils.only_required_for_messages(
+        "method-cache-max-size-none",
+        "singledispatch-method",
+        "singledispatchmethod-function",
+    )
     def visit_functiondef(self, node: nodes.FunctionDef) -> None:
         if node.decorators and isinstance(node.parent, nodes.ClassDef):
-            self._check_lru_cache_decorators(node.decorators)
+            self._check_lru_cache_decorators(node)
+            self._check_dispatch_decorators(node)
 
-    def _check_lru_cache_decorators(self, decorators: nodes.Decorators) -> None:
+    def _check_lru_cache_decorators(self, node: nodes.FunctionDef) -> None:
         """Check if instance methods are decorated with functools.lru_cache."""
+        if any(utils.is_enum(ancestor) for ancestor in node.parent.ancestors()):
+            # method of class inheriting from Enum is exempt from this check.
+            return
+
         lru_cache_nodes: list[nodes.NodeNG] = []
-        for d_node in decorators.nodes:
+        for d_node in node.decorators.nodes:
+            # pylint: disable = too-many-try-statements
             try:
                 for infered_node in d_node.infer():
                     q_name = infered_node.qname()
                     if q_name in NON_INSTANCE_METHODS:
                         return
 
                     # Check if there is a maxsize argument set to None in the call
@@ -584,28 +635,58 @@
         for lru_cache_node in lru_cache_nodes:
             self.add_message(
                 "method-cache-max-size-none",
                 node=lru_cache_node,
                 confidence=interfaces.INFERENCE,
             )
 
-    def _check_redundant_assert(self, node, infer):
+    def _check_dispatch_decorators(self, node: nodes.FunctionDef) -> None:
+        decorators_map: dict[str, tuple[nodes.NodeNG, interfaces.Confidence]] = {}
+
+        for decorator in node.decorators.nodes:
+            if isinstance(decorator, nodes.Name) and decorator.name:
+                decorators_map[decorator.name] = (decorator, interfaces.HIGH)
+            elif utils.is_registered_in_singledispatch_function(node):
+                decorators_map["singledispatch"] = (decorator, interfaces.INFERENCE)
+            elif utils.is_registered_in_singledispatchmethod_function(node):
+                decorators_map["singledispatchmethod"] = (
+                    decorator,
+                    interfaces.INFERENCE,
+                )
+
+        if "singledispatch" in decorators_map and "classmethod" in decorators_map:
+            self.add_message(
+                "singledispatch-method",
+                node=decorators_map["singledispatch"][0],
+                confidence=decorators_map["singledispatch"][1],
+            )
+        elif (
+            "singledispatchmethod" in decorators_map
+            and "staticmethod" in decorators_map
+        ):
+            self.add_message(
+                "singledispatchmethod-function",
+                node=decorators_map["singledispatchmethod"][0],
+                confidence=decorators_map["singledispatchmethod"][1],
+            )
+
+    def _check_redundant_assert(self, node: nodes.Call, infer: InferenceResult) -> None:
         if (
             isinstance(infer, astroid.BoundMethod)
             and node.args
             and isinstance(node.args[0], nodes.Const)
             and infer.name in {"assertTrue", "assertFalse"}
         ):
             self.add_message(
                 "redundant-unittest-assert",
                 args=(infer.name, node.args[0].value),
                 node=node,
             )
 
-    def _check_datetime(self, node):
+    def _check_datetime(self, node: nodes.NodeNG) -> None:
         """Check that a datetime was inferred, if so, emit boolean-datetime warning."""
         try:
             inferred = next(node.infer())
         except astroid.InferenceError:
             return
         if (
             isinstance(inferred, astroid.Instance)
@@ -673,15 +754,15 @@
 
             if encoding_arg:
                 encoding_arg = utils.safe_infer(encoding_arg)
 
                 if isinstance(encoding_arg, nodes.Const) and encoding_arg.value is None:
                     self.add_message("unspecified-encoding", node=node)
 
-    def _check_env_function(self, node, infer):
+    def _check_env_function(self, node: nodes.Call, infer: nodes.FunctionDef) -> None:
         env_name_kwarg = "key"
         env_value_kwarg = "default"
         if node.keywords:
             kwargs = {keyword.arg: keyword.value for keyword in node.keywords}
         else:
             kwargs = None
         if node.args:
@@ -712,38 +793,45 @@
                 node=node,
                 infer=infer,
                 message="invalid-envvar-default",
                 call_arg=utils.safe_infer(env_value_arg),
                 allow_none=True,
             )
 
-    def _check_invalid_envvar_value(self, node, infer, message, call_arg, allow_none):
-        if call_arg in (astroid.Uninferable, None):
+    def _check_invalid_envvar_value(
+        self,
+        node: nodes.Call,
+        infer: nodes.FunctionDef,
+        message: str,
+        call_arg: InferenceResult | None,
+        allow_none: bool,
+    ) -> None:
+        if call_arg is None or isinstance(call_arg, util.UninferableBase):
             return
 
         name = infer.qname()
         if isinstance(call_arg, nodes.Const):
             emit = False
             if call_arg.value is None:
                 emit = not allow_none
             elif not isinstance(call_arg.value, str):
                 emit = True
             if emit:
                 self.add_message(message, node=node, args=(name, call_arg.pytype()))
         else:
             self.add_message(message, node=node, args=(name, call_arg.pytype()))
 
-    def deprecated_methods(self):
+    def deprecated_methods(self) -> set[str]:
         return self._deprecated_methods
 
-    def deprecated_arguments(self, method: str):
+    def deprecated_arguments(self, method: str) -> tuple[tuple[int | None, str], ...]:
         return self._deprecated_arguments.get(method, ())
 
-    def deprecated_classes(self, module: str):
+    def deprecated_classes(self, module: str) -> Iterable[str]:
         return self._deprecated_classes.get(module, ())
 
-    def deprecated_decorators(self) -> Iterable:
+    def deprecated_decorators(self) -> Iterable[str]:
         return self._deprecated_decorators
 
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(StdlibChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/checkers/strings.py` & `pylint-3.0.0a6/pylint/checkers/strings.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,34 +1,41 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checker for string formatting operations."""
 
 from __future__ import annotations
 
 import collections
-import numbers
 import re
+import sys
 import tokenize
 from collections import Counter
 from collections.abc import Iterable, Sequence
 from typing import TYPE_CHECKING
 
 import astroid
-from astroid import nodes
+from astroid import bases, nodes, util
+from astroid.typing import SuccessfulInferenceResult
 
 from pylint.checkers import BaseChecker, BaseRawFileChecker, BaseTokenChecker, utils
 from pylint.checkers.utils import only_required_for_messages
 from pylint.interfaces import HIGH
 from pylint.typing import MessageDefinitionTuple
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
+if sys.version_info >= (3, 8):
+    from typing import Literal
+else:
+    from typing_extensions import Literal
+
+
 _AST_NODE_STR_TYPES = ("__builtin__.unicode", "__builtin__.str", "builtins.str")
 # Prefixes for both strings and bytes literals per
 # https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals
 _PREFIXES = {
     "r",
     "u",
     "R",
@@ -196,28 +203,30 @@
     nodes.FunctionDef,
     nodes.ListComp,
     nodes.SetComp,
     nodes.GeneratorExp,
 )
 
 
-def get_access_path(key, parts):
+def get_access_path(key: str | Literal[0], parts: list[tuple[bool, str]]) -> str:
     """Given a list of format specifiers, returns
     the final access path (e.g. a.b.c[0][1]).
     """
     path = []
     for is_attribute, specifier in parts:
         if is_attribute:
             path.append(f".{specifier}")
         else:
             path.append(f"[{specifier!r}]")
     return str(key) + "".join(path)
 
 
-def arg_matches_format_type(arg_type, format_type):
+def arg_matches_format_type(
+    arg_type: SuccessfulInferenceResult, format_type: str
+) -> bool:
     if format_type in "sr":
         # All types can be printed with %s and %r
         return True
     if isinstance(arg_type, astroid.Instance):
         arg_type = arg_type.pytype()
         if arg_type == "builtins.str":
             return format_type == "c"
@@ -234,15 +243,15 @@
     """Checks string formatting operations to ensure that the format string
     is valid and the arguments match the format string.
     """
 
     name = "string"
     msgs = MSGS
 
-    # pylint: disable=too-many-branches
+    # pylint: disable = too-many-branches, too-many-locals, too-many-statements
     @only_required_for_messages(
         "bad-format-character",
         "truncated-format-string",
         "mixed-format-string",
         "bad-format-string-key",
         "missing-format-string-key",
         "unused-format-string-key",
@@ -324,15 +333,15 @@
                     if not isinstance(key, nodes.Const):
                         continue
                     format_type = required_key_types.get(key.value, None)
                     arg_type = utils.safe_infer(arg)
                     if (
                         format_type is not None
                         and arg_type
-                        and arg_type != astroid.Uninferable
+                        and not isinstance(arg_type, util.UninferableBase)
                         and not arg_matches_format_type(arg_type, format_type)
                     ):
                         self.add_message(
                             "bad-string-format-type",
                             node=node,
                             args=(arg_type.pytype(), format_type),
                         )
@@ -382,15 +391,15 @@
                     self.add_message("too-few-format-args", node=node)
                 for arg, format_type in zip(args_elts, required_arg_types):
                     if not arg:
                         continue
                     arg_type = utils.safe_infer(arg)
                     if (
                         arg_type
-                        and arg_type != astroid.Uninferable
+                        and not isinstance(arg_type, util.UninferableBase)
                         and not arg_matches_format_type(arg_type, format_type)
                     ):
                         self.add_message(
                             "bad-string-format-type",
                             node=node,
                             args=(arg_type.pytype(), format_type),
                         )
@@ -423,26 +432,28 @@
                         "bad-str-strip-call",
                         node=node,
                         args=(func.bound.name, func.name),
                     )
             elif func.name == "format":
                 self._check_new_format(node, func)
 
-    def _detect_vacuous_formatting(self, node, positional_arguments):
+    def _detect_vacuous_formatting(
+        self, node: nodes.Call, positional_arguments: list[SuccessfulInferenceResult]
+    ) -> None:
         counter = collections.Counter(
             arg.name for arg in positional_arguments if isinstance(arg, nodes.Name)
         )
         for name, count in counter.items():
             if count == 1:
                 continue
             self.add_message(
                 "duplicate-string-formatting-argument", node=node, args=(name,)
             )
 
-    def _check_new_format(self, node, func):
+    def _check_new_format(self, node: nodes.Call, func: bases.BoundMethod) -> None:
         """Check the new string formatting."""
         # Skip format nodes which don't have an explicit string on the
         # left side of the format operation.
         # We do this because our inference engine can't properly handle
         # redefinition of the original string.
         # Note that there may not be any left side at all, if the format method
         # has been assigned to another variable. See issue 351. For example:
@@ -479,30 +490,30 @@
         named_fields = {field[0] for field in fields if isinstance(field[0], str)}
         if num_args and manual_pos:
             self.add_message("format-combined-specification", node=node)
             return
 
         check_args = False
         # Consider "{[0]} {[1]}" as num_args.
-        num_args += sum(1 for field in named_fields if field == "")
+        num_args += sum(1 for field in named_fields if not field)
         if named_fields:
             for field in named_fields:
                 if field and field not in named_arguments:
                     self.add_message(
                         "missing-format-argument-key", node=node, args=(field,)
                     )
             for field in named_arguments:
                 if field not in named_fields:
                     self.add_message(
                         "unused-format-string-argument", node=node, args=(field,)
                     )
             # num_args can be 0 if manual_pos is not.
             num_args = num_args or manual_pos
             if positional_arguments or num_args:
-                empty = any(field == "" for field in named_fields)
+                empty = not all(field for field in named_fields)
                 if named_arguments or empty:
                     # Verify the required number of positional arguments
                     # only if the .format got at least one keyword argument.
                     # This means that the format strings accepts both
                     # positional and named fields and we should warn
                     # when one of them is missing or is extra.
                     check_args = True
@@ -518,53 +529,60 @@
                 self.add_message("too-many-format-args", node=node)
             elif len(positional_arguments) < num_args:
                 self.add_message("too-few-format-args", node=node)
 
         self._detect_vacuous_formatting(node, positional_arguments)
         self._check_new_format_specifiers(node, fields, named_arguments)
 
-    def _check_new_format_specifiers(self, node, fields, named):
+    # pylint: disable = too-many-statements
+    def _check_new_format_specifiers(
+        self,
+        node: nodes.Call,
+        fields: list[tuple[str, list[tuple[bool, str]]]],
+        named: dict[str, SuccessfulInferenceResult],
+    ) -> None:
         """Check attribute and index access in the format
         string ("{0.a}" and "{0[a]}").
         """
+        key: Literal[0] | str
         for key, specifiers in fields:
             # Obtain the argument. If it can't be obtained
             # or inferred, skip this check.
-            if key == "":
+            if not key:
                 # {[0]} will have an unnamed argument, defaulting
                 # to 0. It will not be present in `named`, so use the value
                 # 0 for it.
                 key = 0
-            if isinstance(key, numbers.Number):
+            if isinstance(key, int):
                 try:
                     argname = utils.get_argument_from_call(node, key)
                 except utils.NoSuchArgumentError:
                     continue
             else:
                 if key not in named:
                     continue
                 argname = named[key]
-            if argname in (astroid.Uninferable, None):
+            if argname is None or isinstance(argname, util.UninferableBase):
                 continue
             try:
                 argument = utils.safe_infer(argname)
             except astroid.InferenceError:
                 continue
             if not specifiers or not argument:
                 # No need to check this key if it doesn't
                 # use attribute / item access
                 continue
             if argument.parent and isinstance(argument.parent, nodes.Arguments):
                 # Ignore any object coming from an argument,
                 # because we can't infer its value properly.
                 continue
             previous = argument
-            parsed = []
+            parsed: list[tuple[bool, str]] = []
             for is_attribute, specifier in specifiers:
-                if previous is astroid.Uninferable:
+                if isinstance(previous, util.UninferableBase):
                     break
                 parsed.append((is_attribute, specifier))
                 if is_attribute:
                     try:
                         previous = previous.getattr(specifier)[0]
                     except astroid.NotFoundError:
                         if (
@@ -589,15 +607,15 @@
                             astroid.AstroidIndexError,
                             astroid.AstroidTypeError,
                             astroid.AttributeInferenceError,
                         ):
                             warn_error = True
                         except astroid.InferenceError:
                             break
-                        if previous is astroid.Uninferable:
+                        if isinstance(previous, util.UninferableBase):
                             break
                     else:
                         try:
                             # Lookup __getitem__ in the current node,
                             # but skip further checks, because we can't
                             # retrieve the looked object
                             previous.getattr("__getitem__")
@@ -688,17 +706,20 @@
     # Unicode or byte strings.
     ESCAPE_CHARACTERS = "abfnrtvx\n\r\t\\'\"01234567"
 
     # Characters that have a special meaning after a backslash but only in
     # Unicode strings.
     UNICODE_ESCAPE_CHARACTERS = "uUN"
 
-    def __init__(self, linter):
+    def __init__(self, linter: PyLinter) -> None:
         super().__init__(linter)
-        self.string_tokens = {}  # token position -> (token value, next token)
+        self.string_tokens: dict[
+            tuple[int, int], tuple[str, tokenize.TokenInfo | None]
+        ] = {}
+        """Token position -> (token value, next token)."""
 
     def process_module(self, node: nodes.Module) -> None:
         self._unicode_literals = "unicode_literals" in node.future_imports
 
     def process_tokens(self, tokens: list[tokenize.TokenInfo]) -> None:
         encoding = "ascii"
         for i, (token_type, token, start, _, line) in enumerate(tokens):
@@ -791,15 +812,15 @@
                 continue
             if elt.col_offset < 0:
                 # This can happen in case of escaped newlines
                 continue
             token_index = (elt.lineno, elt.col_offset)
             if token_index not in self.string_tokens:
                 # This may happen with Latin1 encoding
-                # cf. https://github.com/PyCQA/pylint/issues/2610
+                # cf. https://github.com/pylint-dev/pylint/issues/2610
                 continue
             matching_token, next_token = self.string_tokens[token_index]
             # We detect string concatenation: the AST Const is the
             # combination of 2 string tokens
             if matching_token != elt.value and next_token is not None:
                 if next_token.type == tokenize.STRING and (
                     next_token.start[0] == elt.lineno
@@ -808,26 +829,26 @@
                     self.add_message(
                         "implicit-str-concat",
                         line=elt.lineno,
                         args=(iterable_type,),
                         confidence=HIGH,
                     )
 
-    def process_string_token(self, token, start_row, start_col):
+    def process_string_token(self, token: str, start_row: int, start_col: int) -> None:
         quote_char = None
-        index = None
-        for index, char in enumerate(token):
+        for _index, char in enumerate(token):
             if char in "'\"":
                 quote_char = char
                 break
         if quote_char is None:
             return
-
-        prefix = token[:index].lower()  # markers like u, b, r.
-        after_prefix = token[index:]
+        # pylint: disable=undefined-loop-variable
+        prefix = token[:_index].lower()  # markers like u, b, r.
+        after_prefix = token[_index:]
+        # pylint: enable=undefined-loop-variable
         # Chop off quotes
         quote_length = (
             3 if after_prefix[:3] == after_prefix[-3:] == 3 * quote_char else 1
         )
         string_body = after_prefix[quote_length:-quote_length]
         # No special checks on raw strings at the moment.
         if "r" not in prefix:
@@ -835,23 +856,23 @@
                 prefix,
                 string_body,
                 start_row,
                 start_col + len(prefix) + quote_length,
             )
 
     def process_non_raw_string_token(
-        self, prefix, string_body, start_row, string_start_col
-    ):
+        self, prefix: str, string_body: str, start_row: int, string_start_col: int
+    ) -> None:
         """Check for bad escapes in a non-raw string.
 
         prefix: lowercase string of string prefix markers ('ur').
         string_body: the un-parsed body of the string, not including the quote
         marks.
-        start_row: integer line number in the source.
-        string_start_col: integer col number of the string start in the source.
+        start_row: line number in the source.
+        string_start_col: col number of the string start in the source.
         """
         # Walk through the string; if we see a backslash then escape the next
         # character, and skip over it.  If we see a non-escaped character,
         # alert, and continue.
         #
         # Accept a backslash when it escapes a backslash, or a quote, or
         # end-of-line, or one of the letters that introduce a special escape
@@ -903,30 +924,30 @@
     @only_required_for_messages("redundant-u-string-prefix")
     def visit_const(self, node: nodes.Const) -> None:
         if node.pytype() == "builtins.str" and not isinstance(
             node.parent, nodes.JoinedStr
         ):
             self._detect_u_string_prefix(node)
 
-    def _detect_u_string_prefix(self, node: nodes.Const):
+    def _detect_u_string_prefix(self, node: nodes.Const) -> None:
         """Check whether strings include a 'u' prefix like u'String'."""
         if node.kind == "u":
             self.add_message(
                 "redundant-u-string-prefix",
                 line=node.lineno,
                 col_offset=node.col_offset,
             )
 
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(StringFormatChecker(linter))
     linter.register_checker(StringConstantChecker(linter))
 
 
-def str_eval(token):
+def str_eval(token: str) -> str:
     """Mostly replicate `ast.literal_eval(token)` manually to avoid any performance hit.
 
     This supports f-strings, contrary to `ast.literal_eval`.
     We have to support all string literal notations:
     https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals
     """
     if token[0:2].lower() in {"fr", "rf"}:
```

### Comparing `pylint-3.0.0a5/pylint/checkers/threading_checker.py` & `pylint-3.0.0a6/pylint/checkers/threading_checker.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from astroid import nodes
 
@@ -40,15 +40,14 @@
             "Used when a new lock instance is created by using with statement "
             "which has no effect. Instead, an existing instance should be used to acquire lock.",
         ),
     }
 
     @only_required_for_messages("useless-with-lock")
     def visit_with(self, node: nodes.With) -> None:
-
         context_managers = (c for c, _ in node.items if isinstance(c, nodes.Call))
         for context_manager in context_managers:
             if isinstance(context_manager, nodes.Call):
                 infered_function = safe_infer(context_manager.func)
                 if infered_function is None:
                     continue
                 qname = infered_function.qname()
```

### Comparing `pylint-3.0.0a5/pylint/checkers/typecheck.py` & `pylint-3.0.0a6/pylint/checkers/typecheck.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,215 +1,220 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Try to find more bugs in the code using astroid inference capabilities."""
 
 from __future__ import annotations
 
-import fnmatch
 import heapq
 import itertools
 import operator
 import re
 import shlex
 import sys
 import types
-from collections import deque
-from collections.abc import Callable, Iterator, Sequence
+from collections.abc import Callable, Iterable, Iterator, Sequence
 from functools import singledispatch
 from re import Pattern
-from typing import TYPE_CHECKING, Any, Union
+from typing import TYPE_CHECKING, Any, TypeVar, Union
 
+import astroid
 import astroid.exceptions
-from astroid import bases, nodes
+import astroid.helpers
+from astroid import arguments, bases, nodes, util
+from astroid.typing import InferenceResult, SuccessfulInferenceResult
 
 from pylint.checkers import BaseChecker, utils
 from pylint.checkers.utils import (
     decorated_with,
     decorated_with_property,
     has_known_bases,
     is_builtin_object,
-    is_classdef_type,
     is_comprehension,
+    is_hashable,
     is_inside_abstract_class,
     is_iterable,
     is_mapping,
+    is_module_ignored,
     is_node_in_type_annotation_context,
     is_overload_stub,
     is_postponed_evaluation_enabled,
     is_super,
     node_ignores_exception,
     only_required_for_messages,
     safe_infer,
     supports_delitem,
     supports_getitem,
     supports_membership_test,
     supports_setitem,
 )
-from pylint.interfaces import INFERENCE
+from pylint.constants import PY310_PLUS
+from pylint.interfaces import HIGH, INFERENCE
 from pylint.typing import MessageDefinitionTuple
 
 if sys.version_info >= (3, 8):
     from functools import cached_property
+    from typing import Literal
 else:
     from astroid.decorators import cachedproperty as cached_property
+    from typing_extensions import Literal
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 CallableObjects = Union[
     bases.BoundMethod,
     bases.UnboundMethod,
     nodes.FunctionDef,
     nodes.Lambda,
     nodes.ClassDef,
 ]
 
+_T = TypeVar("_T")
+
 STR_FORMAT = {"builtins.str.format"}
 ASYNCIO_COROUTINE = "asyncio.coroutines.coroutine"
 BUILTIN_TUPLE = "builtins.tuple"
 TYPE_ANNOTATION_NODES_TYPES = (
     nodes.AnnAssign,
     nodes.Arguments,
     nodes.FunctionDef,
 )
 
 
-def _unflatten(iterable):
+class VERSION_COMPATIBLE_OVERLOAD:
+    pass
+
+
+VERSION_COMPATIBLE_OVERLOAD_SENTINEL = VERSION_COMPATIBLE_OVERLOAD()
+
+
+def _unflatten(iterable: Iterable[_T]) -> Iterator[_T]:
     for index, elem in enumerate(iterable):
         if isinstance(elem, Sequence) and not isinstance(elem, str):
             yield from _unflatten(elem)
         elif elem and not index:
             # We're interested only in the first element.
-            yield elem
+            yield elem  # type: ignore[misc]
 
 
-def _flatten_container(iterable):
+def _flatten_container(iterable: Iterable[_T]) -> Iterator[_T]:
     # Flatten nested containers into a single iterable
     for item in iterable:
         if isinstance(item, (list, tuple, types.GeneratorType)):
             yield from _flatten_container(item)
         else:
             yield item
 
 
-def _is_owner_ignored(owner, attrname, ignored_classes, ignored_modules):
+def _is_owner_ignored(
+    owner: SuccessfulInferenceResult,
+    attrname: str | None,
+    ignored_classes: Iterable[str],
+    ignored_modules: Iterable[str],
+) -> bool:
     """Check if the given owner should be ignored.
 
     This will verify if the owner's module is in *ignored_modules*
     or the owner's module fully qualified name is in *ignored_modules*
     or if the *ignored_modules* contains a pattern which catches
     the fully qualified name of the module.
 
     Also, similar checks are done for the owner itself, if its name
     matches any name from the *ignored_classes* or if its qualified
     name can be found in *ignored_classes*.
     """
-    ignored_modules = set(ignored_modules)
-    module_name = owner.root().name
-    module_qname = owner.root().qname()
-
-    for ignore in ignored_modules:
-        # Try to match the module name / fully qualified name directly
-        if module_qname in ignored_modules or module_name in ignored_modules:
-            return True
-
-        # Try to see if the ignores pattern match against the module name.
-        if fnmatch.fnmatch(module_qname, ignore):
-            return True
-
-        # Otherwise, we might have a root module name being ignored,
-        # and the qualified owner has more levels of depth.
-        parts = deque(module_name.split("."))
-        current_module = ""
-
-        while parts:
-            part = parts.popleft()
-            if not current_module:
-                current_module = part
-            else:
-                current_module += f".{part}"
-            if current_module in ignored_modules:
-                return True
+    if is_module_ignored(owner.root(), ignored_modules):
+        return True
 
     # Match against ignored classes.
     ignored_classes = set(ignored_classes)
     qname = owner.qname() if hasattr(owner, "qname") else ""
     return any(ignore in (attrname, qname) for ignore in ignored_classes)
 
 
 @singledispatch
-def _node_names(node):
+def _node_names(node: SuccessfulInferenceResult) -> Iterable[str]:
     if not hasattr(node, "locals"):
         return []
-    return node.locals.keys()
+    return node.locals.keys()  # type: ignore[no-any-return]
 
 
 @_node_names.register(nodes.ClassDef)
 @_node_names.register(astroid.Instance)
-def _(node):
+def _(node: nodes.ClassDef | bases.Instance) -> Iterable[str]:
     values = itertools.chain(node.instance_attrs.keys(), node.locals.keys())
 
     try:
         mro = node.mro()[1:]
     except (NotImplementedError, TypeError, astroid.MroError):
         mro = node.ancestors()
 
     other_values = [value for cls in mro for value in _node_names(cls)]
     return itertools.chain(values, other_values)
 
 
-def _string_distance(seq1, seq2):
+def _string_distance(seq1: str, seq2: str) -> int:
     seq2_length = len(seq2)
 
-    row = list(range(1, seq2_length + 1)) + [0]
+    row = [*list(range(1, seq2_length + 1)), 0]
     for seq1_index, seq1_char in enumerate(seq1):
         last_row = row
         row = [0] * seq2_length + [seq1_index + 1]
 
         for seq2_index, seq2_char in enumerate(seq2):
             row[seq2_index] = min(
                 last_row[seq2_index] + 1,
                 row[seq2_index - 1] + 1,
                 last_row[seq2_index - 1] + (seq1_char != seq2_char),
             )
 
     return row[seq2_length - 1]
 
 
-def _similar_names(owner, attrname, distance_threshold, max_choices):
+def _similar_names(
+    owner: SuccessfulInferenceResult,
+    attrname: str | None,
+    distance_threshold: int,
+    max_choices: int,
+) -> list[str]:
     """Given an owner and a name, try to find similar names.
 
     The similar names are searched given a distance metric and only
     a given number of choices will be returned.
     """
-    possible_names = []
+    possible_names: list[tuple[str, int]] = []
     names = _node_names(owner)
 
     for name in names:
         if name == attrname:
             continue
 
-        distance = _string_distance(attrname, name)
+        distance = _string_distance(attrname or "", name)
         if distance <= distance_threshold:
             possible_names.append((name, distance))
 
     # Now get back the values with a minimum, up to the given
     # limit or choices.
     picked = [
         name
         for (name, _) in heapq.nsmallest(
             max_choices, possible_names, key=operator.itemgetter(1)
         )
     ]
     return sorted(picked)
 
 
-def _missing_member_hint(owner, attrname, distance_threshold, max_choices):
+def _missing_member_hint(
+    owner: SuccessfulInferenceResult,
+    attrname: str | None,
+    distance_threshold: int,
+    max_choices: int,
+) -> str:
     names = _similar_names(owner, attrname, distance_threshold, max_choices)
     if not names:
         # No similar name.
         return ""
 
     names = [repr(name) for name in names]
     if len(names) == 1:
@@ -349,30 +354,37 @@
     "E1139": (
         "Invalid metaclass %r used",
         "invalid-metaclass",
         "Emitted whenever we can detect that a class is using, "
         "as a metaclass, something which might be invalid for using as "
         "a metaclass.",
     ),
-    "E1140": (
-        "Dict key is unhashable",
-        "unhashable-dict-key",
-        "Emitted when a dict key is not hashable "
-        "(i.e. doesn't define __hash__ method).",
-    ),
     "E1141": (
         "Unpacking a dictionary in iteration without calling .items()",
         "dict-iter-missing-items",
         "Emitted when trying to iterate through a dict without calling .items()",
     ),
     "E1142": (
         "'await' should be used within an async function",
         "await-outside-async",
         "Emitted when await is used outside an async function.",
     ),
+    "E1143": (
+        "'%s' is unhashable and can't be used as a %s in a %s",
+        "unhashable-member",
+        "Emitted when a dict key or set member is not hashable "
+        "(i.e. doesn't define __hash__ method).",
+        {"old_names": [("E1140", "unhashable-dict-key")]},
+    ),
+    "E1144": (
+        "Slice step cannot be 0",
+        "invalid-slice-step",
+        "Used when a slice step is 0 and the object doesn't implement "
+        "a custom __getitem__ method.",
+    ),
     "W1113": (
         "Keyword argument before variable positional arguments list "
         "in the definition of %s function",
         "keyword-arg-before-vararg",
         "When defining a keyword argument before variable positional arguments, one can "
         "end up in having multiple values passed for the aforementioned parameter in "
         "case the method is called with keyword arguments.",
@@ -406,34 +418,34 @@
     "range",
     "bytes",
     "memoryview",
 }
 
 
 def _emit_no_member(
-    node,
-    owner,
-    owner_name,
+    node: nodes.Attribute | nodes.AssignAttr | nodes.DelAttr,
+    owner: InferenceResult,
+    owner_name: str | None,
     mixin_class_rgx: Pattern[str],
-    ignored_mixins=True,
-    ignored_none=True,
-):
+    ignored_mixins: bool = True,
+    ignored_none: bool = True,
+) -> bool:
     """Try to see if no-member should be emitted for the given owner.
 
     The following cases are ignored:
 
         * the owner is a function and it has decorators.
         * the owner is an instance and it has __getattr__, __getattribute__ implemented
         * the module is explicitly ignored from no-member checks
         * the owner is a class and the name can be found in its metaclass.
         * The access node is protected by an except handler, which handles
           AttributeError, Exception or bare except.
         * The node is guarded behind and `IF` or `IFExp` node
     """
-    # pylint: disable=too-many-return-statements
+    # pylint: disable = too-many-return-statements, too-many-branches
     if node_ignores_exception(node, AttributeError):
         return False
     if ignored_none and isinstance(owner, nodes.Const) and owner.value is None:
         return False
     if is_super(owner) or getattr(owner, "type", None) == "metaclass":
         return False
     if owner_name and ignored_mixins and mixin_class_rgx.match(owner_name):
@@ -447,18 +459,18 @@
             # Issue #2565: Don't ignore enums, as they have a `__getattr__` but it's not
             # invoked at this point.
             try:
                 metaclass = owner.metaclass()
             except astroid.MroError:
                 return False
             if metaclass:
-                if _enum_has_attribute(owner, node):
-                    return False
                 # Renamed in Python 3.10 to `EnumType`
-                return metaclass.qname() in {"enum.EnumMeta", "enum.EnumType"}
+                if metaclass.qname() in {"enum.EnumMeta", "enum.EnumType"}:
+                    return not _enum_has_attribute(owner, node)
+                return False
             return False
         if not has_known_bases(owner):
             return False
 
         # Exclude typed annotations, since these might actually exist
         # at some point during the runtime of the program.
         if utils.is_attribute_typed_annotation(owner, node.attrname):
@@ -484,24 +496,15 @@
         # Test if an attribute has been mangled ('private' attribute)
         unmangled_name = node.attrname.split("_" + owner_name)[-1]
         try:
             if owner.getattr(unmangled_name, context=None) is not None:
                 return False
         except astroid.NotFoundError:
             return True
-    if (
-        owner.parent
-        and isinstance(owner.parent, nodes.ClassDef)
-        and owner.parent.name == "EnumMeta"
-        and owner_name == "__members__"
-        and node.attrname in {"items", "values", "keys"}
-    ):
-        # Avoid false positive on Enum.__members__.{items(), values, keys}
-        # See https://github.com/PyCQA/pylint/issues/4123
-        return False
+
     # Don't emit no-member if guarded behind `IF` or `IFExp`
     #   * Walk up recursively until if statement is found.
     #   * Check if condition can be inferred as `Const`,
     #       would evaluate as `False`,
     #       and whether the node is part of the `body`.
     #   * Continue checking until scope of node is reached.
     scope: nodes.NodeNG = node.scope()
@@ -579,15 +582,15 @@
     # Find attributes defined in __new__
     if dunder_new:
         # Get the object returned in __new__
         returned_obj_name = next(
             (c.value for c in dunder_new.get_children() if isinstance(c, nodes.Return)),
             None,
         )
-        if returned_obj_name is not None:
+        if isinstance(returned_obj_name, nodes.Name):
             # Find all attribute assignments to the returned object
             enum_attributes |= _get_all_attribute_assignments(
                 dunder_new, returned_obj_name.name
             )
 
     # Find attributes defined in __init__
     if dunder_init and dunder_init.body and dunder_init.args:
@@ -649,43 +652,56 @@
             raise ValueError
         # both have an extra implicit 'cls'/'self' argument.
         return callable_obj, parameters, "constructor"
 
     raise ValueError
 
 
-def _has_parent_of_type(node, node_type, statement):
+def _has_parent_of_type(
+    node: nodes.Call,
+    node_type: nodes.Keyword | nodes.Starred,
+    statement: nodes.Statement,
+) -> bool:
     """Check if the given node has a parent of the given type."""
     parent = node.parent
     while not isinstance(parent, node_type) and statement.parent_of(parent):
         parent = parent.parent
     return isinstance(parent, node_type)
 
 
-def _no_context_variadic_keywords(node, scope):
+def _no_context_variadic_keywords(node: nodes.Call, scope: nodes.Lambda) -> bool:
     statement = node.statement(future=True)
-    variadics = ()
+    variadics = []
 
-    if isinstance(scope, nodes.Lambda) and not isinstance(scope, nodes.FunctionDef):
+    if (
+        isinstance(scope, nodes.Lambda)
+        and not isinstance(scope, nodes.FunctionDef)
+        or isinstance(statement, nodes.With)
+    ):
         variadics = list(node.keywords or []) + node.kwargs
     elif isinstance(statement, (nodes.Return, nodes.Expr, nodes.Assign)) and isinstance(
         statement.value, nodes.Call
     ):
         call = statement.value
         variadics = list(call.keywords or []) + call.kwargs
 
     return _no_context_variadic(node, scope.args.kwarg, nodes.Keyword, variadics)
 
 
-def _no_context_variadic_positional(node, scope):
+def _no_context_variadic_positional(node: nodes.Call, scope: nodes.Lambda) -> bool:
     variadics = node.starargs + node.kwargs
     return _no_context_variadic(node, scope.args.vararg, nodes.Starred, variadics)
 
 
-def _no_context_variadic(node, variadic_name, variadic_type, variadics):
+def _no_context_variadic(
+    node: nodes.Call,
+    variadic_name: str | None,
+    variadic_type: nodes.Keyword | nodes.Starred,
+    variadics: list[nodes.Keyword | nodes.Starred],
+) -> bool:
     """Verify if the given call node has variadic nodes without context.
 
     This is a workaround for handling cases of nested call functions
     which don't have the specific call context at hand.
     Variadic arguments (variable positional arguments and variable
     keyword arguments) are inferred, inherently wrong, by astroid
     as a Tuple, respectively a Dict with empty elements.
@@ -723,27 +739,22 @@
                 for variadic in variadics
             )
             if is_in_starred_context or used_as_starred_argument:
                 return True
     return False
 
 
-def _is_invalid_metaclass(metaclass):
-    try:
-        mro = metaclass.mro()
-    except NotImplementedError:
-        # Cannot have a metaclass which is not a newstyle class.
-        return True
-    else:
-        if not any(is_builtin_object(cls) and cls.name == "type" for cls in mro):
-            return True
-    return False
+def _is_invalid_metaclass(metaclass: nodes.ClassDef) -> bool:
+    mro = metaclass.mro()
+    return not any(is_builtin_object(cls) and cls.name == "type" for cls in mro)
 
 
-def _infer_from_metaclass_constructor(cls, func: nodes.FunctionDef):
+def _infer_from_metaclass_constructor(
+    cls: nodes.ClassDef, func: nodes.FunctionDef
+) -> InferenceResult | None:
     """Try to infer what the given *func* constructor is building.
 
     :param astroid.FunctionDef func:
         A metaclass constructor. Metaclass definitions can be
         functions, which should accept three arguments, the name of
         the class, the bases of the class and the attributes.
         The function could return anything, but usually it should
@@ -772,33 +783,42 @@
     try:
         inferred = next(func.infer_call_result(func, context), None)
     except astroid.InferenceError:
         return None
     return inferred or None
 
 
-def _is_c_extension(module_node):
+def _is_c_extension(module_node: InferenceResult) -> bool:
     return (
-        not astroid.modutils.is_standard_module(module_node.name)
+        isinstance(module_node, nodes.Module)
+        and not astroid.modutils.is_stdlib_module(module_node.name)
         and not module_node.fully_defined()
     )
 
 
-def _is_invalid_isinstance_type(arg):
+def _is_invalid_isinstance_type(arg: nodes.NodeNG) -> bool:
     # Return True if we are sure that arg is not a type
+    if PY310_PLUS and isinstance(arg, nodes.BinOp) and arg.op == "|":
+        return _is_invalid_isinstance_type(arg.left) or _is_invalid_isinstance_type(
+            arg.right
+        )
     inferred = utils.safe_infer(arg)
     if not inferred:
         # Cannot infer it so skip it.
         return False
     if isinstance(inferred, nodes.Tuple):
         return any(_is_invalid_isinstance_type(elt) for elt in inferred.elts)
     if isinstance(inferred, nodes.ClassDef):
         return False
     if isinstance(inferred, astroid.Instance) and inferred.qname() == BUILTIN_TUPLE:
         return False
+    if PY310_PLUS and isinstance(inferred, bases.UnionType):
+        return _is_invalid_isinstance_type(
+            inferred.left
+        ) or _is_invalid_isinstance_type(inferred.right)
     return True
 
 
 class TypeChecker(BaseChecker):
     """Try to find bugs in the code using type inference."""
 
     # configuration section name
@@ -954,19 +974,19 @@
 
     def open(self) -> None:
         py_version = self.linter.config.py_version
         self._py310_plus = py_version >= (3, 10)
         self._mixin_class_rgx = self.linter.config.mixin_class_rgx
 
     @cached_property
-    def _suggestion_mode(self):
-        return self.linter.config.suggestion_mode
+    def _suggestion_mode(self) -> bool:
+        return self.linter.config.suggestion_mode  # type: ignore[no-any-return]
 
     @cached_property
-    def _compiled_generated_members(self) -> tuple[Pattern, ...]:
+    def _compiled_generated_members(self) -> tuple[Pattern[str], ...]:
         # do this lazily since config not fully initialized in __init__
         # generated_members may contain regular expressions
         # (surrounded by quote `"` and followed by a comma `,`)
         # REQUEST,aq_parent,"[a-zA-Z]+_set{1,2}"' =>
         # ('REQUEST', 'aq_parent', '[a-zA-Z]+_set{1,2}')
         generated_members = self.linter.config.generated_members
         if isinstance(generated_members, str):
@@ -982,23 +1002,23 @@
         if node.args.vararg and node.args.defaults:
             self.add_message("keyword-arg-before-vararg", node=node, args=(node.name))
 
     visit_asyncfunctiondef = visit_functiondef
 
     @only_required_for_messages("invalid-metaclass")
     def visit_classdef(self, node: nodes.ClassDef) -> None:
-        def _metaclass_name(metaclass):
+        def _metaclass_name(metaclass: InferenceResult) -> str | None:
             # pylint: disable=unidiomatic-typecheck
             if isinstance(metaclass, (nodes.ClassDef, nodes.FunctionDef)):
-                return metaclass.name
+                return metaclass.name  # type: ignore[no-any-return]
             if type(metaclass) is bases.Instance:
                 # Really do mean type, not isinstance, since subclasses of bases.Instance
                 # like Const or Dict should use metaclass.as_string below.
                 return str(metaclass)
-            return metaclass.as_string()
+            return metaclass.as_string()  # type: ignore[no-any-return]
 
         metaclass = node.declared_metaclass()
         if not metaclass:
             return
 
         if isinstance(metaclass, nodes.FunctionDef):
             # Try to infer the result.
@@ -1020,16 +1040,19 @@
     def visit_assignattr(self, node: nodes.AssignAttr) -> None:
         if isinstance(node.assign_type(), nodes.AugAssign):
             self.visit_attribute(node)
 
     def visit_delattr(self, node: nodes.DelAttr) -> None:
         self.visit_attribute(node)
 
+    # pylint: disable = too-many-branches
     @only_required_for_messages("no-member", "c-extension-no-member")
-    def visit_attribute(self, node: nodes.Attribute) -> None:
+    def visit_attribute(
+        self, node: nodes.Attribute | nodes.AssignAttr | nodes.DelAttr
+    ) -> None:
         """Check that the accessed attribute exists.
 
         to avoid too much false positives for now, we'll consider the code as
         correct if a single of the inferred nodes has the accessed attribute.
 
         function/method, super call and metaclasses are ignored
         """
@@ -1047,20 +1070,20 @@
 
         try:
             inferred = list(node.expr.infer())
         except astroid.InferenceError:
             return
 
         # list of (node, nodename) which are missing the attribute
-        missingattr = set()
+        missingattr: set[tuple[SuccessfulInferenceResult, str | None]] = set()
 
-        non_opaque_inference_results = [
+        non_opaque_inference_results: list[SuccessfulInferenceResult] = [
             owner
             for owner in inferred
-            if owner is not astroid.Uninferable and not isinstance(owner, nodes.Unknown)
+            if not isinstance(owner, (nodes.Unknown, util.UninferableBase))
         ]
         if (
             len(non_opaque_inference_results) != len(inferred)
             and self.linter.config.ignore_on_opaque_inference
         ):
             # There is an ambiguity in the inference. Since we can't
             # make sure that we won't emit a false positive, we just stop
@@ -1112,14 +1135,17 @@
             else:
                 for attr_node in attr_nodes:
                     attr_parent = attr_node.parent
                     # Skip augmented assignments
                     try:
                         if isinstance(
                             attr_node.statement(future=True), nodes.AugAssign
+                        ) or (
+                            isinstance(attr_parent, nodes.Assign)
+                            and utils.is_augmented_assign(attr_parent)[0]
                         ):
                             continue
                     except astroid.exceptions.StatementMissing:
                         break
                     # Skip self-referencing assignments
                     if attr_parent is node.parent:
                         continue
@@ -1146,15 +1172,19 @@
                 self.add_message(
                     msg,
                     node=node,
                     args=(owner.display_type(), name, node.attrname, hint),
                     confidence=INFERENCE,
                 )
 
-    def _get_nomember_msgid_hint(self, node, owner):
+    def _get_nomember_msgid_hint(
+        self,
+        node: nodes.Attribute | nodes.AssignAttr | nodes.DelAttr,
+        owner: SuccessfulInferenceResult,
+    ) -> tuple[Literal["c-extension-no-member", "no-member"], str]:
         suggestions_are_possible = self._suggestion_mode and isinstance(
             owner, nodes.Module
         )
         if suggestions_are_possible and _is_c_extension(owner):
             msg = "c-extension-no-member"
             hint = ""
         else:
@@ -1164,15 +1194,15 @@
                     owner,
                     node.attrname,
                     self.linter.config.missing_member_hint_distance,
                     self.linter.config.missing_member_max_choices,
                 )
             else:
                 hint = ""
-        return msg, hint
+        return msg, hint  # type: ignore[return-value]
 
     @only_required_for_messages(
         "assignment-from-no-return",
         "assignment-from-none",
         "non-str-assignment-to-dunder-name",
     )
     def visit_assign(self, node: nodes.Assign) -> None:
@@ -1247,15 +1277,15 @@
     def _is_list_sort_method(node: nodes.Call) -> bool:
         return (
             isinstance(node.func, nodes.Attribute)
             and node.func.attrname == "sort"
             and isinstance(utils.safe_infer(node.func.expr), nodes.List)
         )
 
-    def _check_dundername_is_string(self, node) -> None:
+    def _check_dundername_is_string(self, node: nodes.Assign) -> None:
         """Check a string is assigned to self.__name__."""
 
         # Check the left-hand side of the assignment is <something>.__name__
         lhs = node.targets[0]
         if not isinstance(lhs, nodes.AssignAttr):
             return
         if not lhs.attrname == "__name__":
@@ -1268,67 +1298,68 @@
         inferred = utils.safe_infer(rhs)
         if not inferred:
             return
         if not (isinstance(inferred, nodes.Const) and isinstance(inferred.value, str)):
             # Add the message
             self.add_message("non-str-assignment-to-dunder-name", node=node)
 
-    def _check_uninferable_call(self, node):
+    def _check_uninferable_call(self, node: nodes.Call) -> None:
         """Check that the given uninferable Call node does not
         call an actual function.
         """
         if not isinstance(node.func, nodes.Attribute):
             return
 
         # Look for properties. First, obtain
         # the lhs of the Attribute node and search the attribute
         # there. If that attribute is a property or a subclass of properties,
         # then most likely it's not callable.
 
         expr = node.func.expr
         klass = safe_infer(expr)
-        if (
-            klass is None
-            or klass is astroid.Uninferable
-            or not isinstance(klass, astroid.Instance)
-        ):
+        if not isinstance(klass, astroid.Instance):
             return
 
         try:
             attrs = klass._proxied.getattr(node.func.attrname)
         except astroid.NotFoundError:
             return
 
         for attr in attrs:
-            if attr is astroid.Uninferable:
-                continue
             if not isinstance(attr, nodes.FunctionDef):
                 continue
 
             # Decorated, see if it is decorated with a property.
             # Also, check the returns and see if they are callable.
             if decorated_with_property(attr):
                 try:
                     call_results = list(attr.infer_call_result(node))
                 except astroid.InferenceError:
                     continue
 
                 if all(
-                    return_node is astroid.Uninferable for return_node in call_results
+                    isinstance(return_node, util.UninferableBase)
+                    for return_node in call_results
                 ):
                     # We were unable to infer return values of the call, skipping
                     continue
 
                 if any(return_node.callable() for return_node in call_results):
                     # Only raise this issue if *all* the inferred values are not callable
                     continue
 
                 self.add_message("not-callable", node=node, args=node.func.as_string())
 
-    def _check_argument_order(self, node, call_site, called, called_param_names):
+    def _check_argument_order(
+        self,
+        node: nodes.Call,
+        call_site: arguments.CallSite,
+        called: CallableObjects,
+        called_param_names: list[str | None],
+    ) -> None:
         """Match the supplied argument names against the function parameters.
 
         Warn if some argument names are not in the same order as they are in
         the function signature.
         """
         # Check for called function being an object instance function
         # If so, ignore the initial 'self' argument in the signature
@@ -1360,24 +1391,28 @@
         if arg_set != param_set:
             return
 
         # Warn based on the equality of argument ordering
         if calling_parg_names != called_param_names[: len(calling_parg_names)]:
             self.add_message("arguments-out-of-order", node=node, args=())
 
-    def _check_isinstance_args(self, node):
+    def _check_isinstance_args(self, node: nodes.Call) -> None:
         if len(node.args) != 2:
             # isinstance called with wrong number of args
             return
 
         second_arg = node.args[1]
         if _is_invalid_isinstance_type(second_arg):
-            self.add_message("isinstance-second-argument-not-valid-type", node=node)
+            self.add_message(
+                "isinstance-second-argument-not-valid-type",
+                node=node,
+                confidence=INFERENCE,
+            )
 
-    # pylint: disable=too-many-branches,too-many-locals
+    # pylint: disable = too-many-branches, too-many-locals, too-many-statements
     def visit_call(self, node: nodes.Call) -> None:
         """Check that called functions/methods are inferred to callable objects,
         and that passed arguments match the parameters in the inferred function.
         """
         called = safe_infer(node.func)
 
         self._check_not_callable(node, called)
@@ -1440,18 +1475,31 @@
         # These are coming from the functools.partial implementation in astroid
         already_filled_positionals = getattr(called, "filled_positionals", 0)
         already_filled_keywords = getattr(called, "filled_keywords", {})
 
         keyword_args += list(already_filled_keywords)
         num_positional_args += implicit_args + already_filled_positionals
 
+        # Decrement `num_positional_args` by 1 when a function call is assigned to a class attribute
+        # inside the class where the function is defined.
+        # This avoids emitting `too-many-function-args` since `num_positional_args`
+        # includes an implicit `self` argument which is not present in `called.args`.
+        if (
+            isinstance(node.frame(), nodes.ClassDef)
+            and isinstance(node.parent, (nodes.Assign, nodes.AnnAssign))
+            and isinstance(called, nodes.FunctionDef)
+            and called in node.frame().body
+            and num_positional_args > 0
+        ):
+            num_positional_args -= 1
+
         # Analyze the list of formal parameters.
         args = list(itertools.chain(called.args.posonlyargs or (), called.args.args))
         num_mandatory_parameters = len(args) - len(called.args.defaults)
-        parameters: list[list[Any]] = []
+        parameters: list[tuple[tuple[str | None, nodes.NodeNG | None], bool]] = []
         parameter_name_to_index = {}
         for i, arg in enumerate(args):
             if isinstance(arg, nodes.Tuple):
                 name = None
                 # Don't store any parameter names within the tuple, since those
                 # are not assignable from keyword arguments.
             else:
@@ -1460,15 +1508,15 @@
                 #    def f( (a), (b) ): pass
                 name = arg.name
                 parameter_name_to_index[name] = i
             if i >= num_mandatory_parameters:
                 defval = called.args.defaults[i - num_mandatory_parameters]
             else:
                 defval = None
-            parameters.append([(name, defval), False])
+            parameters.append(((name, defval), False))
 
         kwparams = {}
         for i, arg in enumerate(called.args.kwonlyargs):
             if isinstance(arg, nodes.Keyword):
                 name = arg.arg
             else:
                 assert isinstance(arg, nodes.AssignName)
@@ -1478,15 +1526,15 @@
         self._check_argument_order(
             node, call_site, called, [p[0][0] for p in parameters]
         )
 
         # 1. Match the positional arguments.
         for i in range(num_positional_args):
             if i < len(parameters):
-                parameters[i][1] = True
+                parameters[i] = (parameters[i][0], True)
             elif called.args.vararg is not None:
                 # The remaining positional arguments get assigned to the *args
                 # parameter.
                 break
             elif not overload_function:
                 # Too many positional arguments.
                 self.add_message(
@@ -1509,15 +1557,15 @@
                     if not (keyword == "self" and called.qname() in STR_FORMAT):
                         self.add_message(
                             "redundant-keyword-arg",
                             node=node,
                             args=(keyword, callable_name),
                         )
                 else:
-                    parameters[i][1] = True
+                    parameters[i] = (parameters[i][0], True)
             elif keyword in kwparams:
                 if kwparams[keyword][1]:
                     # Duplicate definition of function parameter.
                     self.add_message(
                         "redundant-keyword-arg",
                         node=node,
                         args=(keyword, callable_name),
@@ -1535,19 +1583,19 @@
                 # Unexpected keyword argument.
                 self.add_message(
                     "unexpected-keyword-arg", node=node, args=(keyword, callable_name)
                 )
 
         # 3. Match the **kwargs, if any.
         if node.kwargs:
-            for i, [(name, defval), assigned] in enumerate(parameters):
+            for i, [(name, _defval), _assigned] in enumerate(parameters):
                 # Assume that *kwargs provides values for all remaining
                 # unassigned named parameters.
                 if name is not None:
-                    parameters[i][1] = True
+                    parameters[i] = (parameters[i][0], True)
                 else:
                     # **kwargs can't assign to tuples.
                     pass
 
         # Check that any parameters without a default have been assigned
         # values.
         for [(name, defval), assigned] in parameters:
@@ -1564,15 +1612,20 @@
             defval, assigned = val
             if (
                 defval is None
                 and not assigned
                 and not has_no_context_keywords_variadic
                 and not overload_function
             ):
-                self.add_message("missing-kwoa", node=node, args=(name, callable_name))
+                self.add_message(
+                    "missing-kwoa",
+                    node=node,
+                    args=(name, callable_name),
+                    confidence=INFERENCE,
+                )
 
     @staticmethod
     def _keyword_argument_is_in_all_decorator_returns(
         func: nodes.FunctionDef, keyword: str
     ) -> bool:
         """Check if the keyword argument exists in all signatures of the
         return values of all decorators of the function.
@@ -1606,15 +1659,15 @@
                 if return_value.args.is_argument(keyword):
                     continue
 
                 return False
 
         return True
 
-    def _check_invalid_sequence_index(self, subscript: nodes.Subscript):
+    def _check_invalid_sequence_index(self, subscript: nodes.Subscript) -> None:
         # Look for index operations where the parent is a sequence type.
         # If the types can be determined, only allow indices to be int,
         # slice or instances with __index__.
         parent_type = safe_infer(subscript.value)
         if not isinstance(
             parent_type, (nodes.ClassDef, astroid.Instance)
         ) or not has_known_bases(parent_type):
@@ -1632,15 +1685,15 @@
 
         # Check if this instance's __getitem__, __setitem__, or __delitem__, as
         # appropriate to the statement, is implemented in a builtin sequence
         # type. This way we catch subclasses of sequence types but skip classes
         # that override __getitem__ and which may allow non-integer indices.
         try:
             methods = astroid.interpreter.dunder_lookup.lookup(parent_type, methodname)
-            if methods is astroid.Uninferable:
+            if isinstance(methods, util.UninferableBase):
                 return None
             itemmethod = methods[0]
         except (
             astroid.AttributeInferenceError,
             IndexError,
         ):
             return None
@@ -1648,22 +1701,16 @@
             not isinstance(itemmethod, nodes.FunctionDef)
             or itemmethod.root().name != "builtins"
             or not itemmethod.parent
             or itemmethod.parent.frame().name not in SEQUENCE_TYPES
         ):
             return None
 
-        # For ExtSlice objects coming from visit_extslice, no further
-        # inference is necessary, since if we got this far the ExtSlice
-        # is an error.
-        if isinstance(subscript.value, nodes.ExtSlice):
-            index_type = subscript.value
-        else:
-            index_type = safe_infer(subscript.slice)
-        if index_type is None or index_type is astroid.Uninferable:
+        index_type = safe_infer(subscript.slice)
+        if index_type is None or isinstance(index_type, util.UninferableBase):
             return None
         # Constants must be of type int
         if isinstance(index_type, nodes.Const):
             if isinstance(index_type.value, int):
                 return None
         # Instance values must be int, slice, or have an __index__ method
         elif isinstance(index_type, astroid.Instance):
@@ -1711,31 +1758,23 @@
                 return
             # NamedTuple instances are callable
             if inferred_call.qname() == "typing.NamedTuple":
                 return
 
         self.add_message("not-callable", node=node, args=node.func.as_string())
 
-    @only_required_for_messages("invalid-sequence-index")
-    def visit_extslice(self, node: nodes.ExtSlice) -> None:
-        if not node.parent or not hasattr(node.parent, "value"):
-            return None
-        # Check extended slice objects as if they were used as a sequence
-        # index to check if the object being sliced can support them
-        return self._check_invalid_sequence_index(node.parent)
-
     def _check_invalid_slice_index(self, node: nodes.Slice) -> None:
         # Check the type of each part of the slice
         invalid_slices_nodes: list[nodes.NodeNG] = []
         for index in (node.lower, node.upper, node.step):
             if index is None:
                 continue
 
             index_type = safe_infer(index)
-            if index_type is None or index_type is astroid.Uninferable:
+            if index_type is None or isinstance(index_type, util.UninferableBase):
                 continue
 
             # Constants must be of type int or None
             if isinstance(index_type, nodes.Const):
                 if isinstance(index_type.value, (int, type(None))):
                     continue
             # Instance values must be of type int, None or an object
@@ -1747,46 +1786,56 @@
                 try:
                     index_type.getattr("__index__")
                     return
                 except astroid.NotFoundError:
                     pass
             invalid_slices_nodes.append(index)
 
-        if not invalid_slices_nodes:
+        invalid_slice_step = (
+            node.step and isinstance(node.step, nodes.Const) and node.step.value == 0
+        )
+
+        if not (invalid_slices_nodes or invalid_slice_step):
             return
 
         # Anything else is an error, unless the object that is indexed
         # is a custom object, which knows how to handle this kind of slices
         parent = node.parent
-        if isinstance(parent, nodes.ExtSlice):
-            parent = parent.parent
         if isinstance(parent, nodes.Subscript):
             inferred = safe_infer(parent.value)
-            if inferred is None or inferred is astroid.Uninferable:
+            if inferred is None or isinstance(inferred, util.UninferableBase):
                 # Don't know what this is
                 return
             known_objects = (
                 nodes.List,
                 nodes.Dict,
                 nodes.Tuple,
                 astroid.objects.FrozenSet,
                 nodes.Set,
             )
-            if not isinstance(inferred, known_objects):
+            if not (
+                isinstance(inferred, known_objects)
+                or isinstance(inferred, nodes.Const)
+                and inferred.pytype() in {"builtins.str", "builtins.bytes"}
+                or isinstance(inferred, astroid.bases.Instance)
+                and inferred.pytype() == "builtins.range"
+            ):
                 # Might be an instance that knows how to handle this slice object
                 return
         for snode in invalid_slices_nodes:
             self.add_message("invalid-slice-index", node=snode)
+        if invalid_slice_step:
+            self.add_message("invalid-slice-step", node=node.step, confidence=HIGH)
 
     @only_required_for_messages("not-context-manager")
     def visit_with(self, node: nodes.With) -> None:
         for ctx_mgr, _ in node.items:
             context = astroid.context.InferenceContext()
             inferred = safe_infer(ctx_mgr, context=context)
-            if inferred is None or inferred is astroid.Uninferable:
+            if inferred is None or isinstance(inferred, util.UninferableBase):
                 continue
 
             if isinstance(inferred, astroid.bases.Generator):
                 # Check if we are dealing with a function decorated
                 # with contextlib.contextmanager.
                 if decorated_with(
                     inferred.parent, self.linter.config.contextmanager_decorators
@@ -1897,56 +1946,101 @@
                         break
                     parent_node = parent_node.parent
                     if isinstance(parent_node, nodes.Module):
                         break
             if not allowed_nested_syntax:
                 self._check_unsupported_alternative_union_syntax(node)
 
+    def _includes_version_compatible_overload(self, attrs: list[nodes.NodeNG]) -> bool:
+        """Check if a set of overloads of an operator includes one that
+        can be relied upon for our configured Python version.
+
+        If we are running under a Python 3.10+ runtime but configured for
+        pre-3.10 compatibility then Astroid will have inferred the
+        existence of __or__ / __ror__ on builtins.type, but these aren't
+        available in the configured version of Python.
+        """
+        is_py310_builtin = all(
+            isinstance(attr, (nodes.FunctionDef, astroid.BoundMethod))
+            and attr.parent.qname() == "builtins.type"
+            for attr in attrs
+        )
+        return not is_py310_builtin or self._py310_plus
+
+    def _recursive_search_for_classdef_type(
+        self, node: nodes.ClassDef, operation: Literal["__or__", "__ror__"]
+    ) -> bool | VERSION_COMPATIBLE_OVERLOAD:
+        if not isinstance(node, nodes.ClassDef):
+            return False
+        try:
+            attrs = node.getattr(operation)
+        except astroid.NotFoundError:
+            return True
+        if self._includes_version_compatible_overload(attrs):
+            return VERSION_COMPATIBLE_OVERLOAD_SENTINEL
+        return True
+
     def _check_unsupported_alternative_union_syntax(self, node: nodes.BinOp) -> None:
-        """Check if left or right node is of type `type`."""
+        """Check if left or right node is of type `type`.
+
+        If either is, and doesn't support an or operator via a metaclass,
+        infer that this is a mistaken attempt to use alternative union
+        syntax when not supported.
+        """
         msg = "unsupported operand type(s) for |"
-        for n in (node.left, node.right):
-            n = astroid.helpers.object_type(n)
-            if isinstance(n, nodes.ClassDef) and is_classdef_type(n):
-                self.add_message("unsupported-binary-operation", args=msg, node=node)
-                break
+        left_obj = astroid.helpers.object_type(node.left)
+        right_obj = astroid.helpers.object_type(node.right)
+        left_is_type = self._recursive_search_for_classdef_type(left_obj, "__or__")
+        if left_is_type is VERSION_COMPATIBLE_OVERLOAD_SENTINEL:
+            return
+        right_is_type = self._recursive_search_for_classdef_type(right_obj, "__ror__")
+        if right_is_type is VERSION_COMPATIBLE_OVERLOAD_SENTINEL:
+            return
+
+        if left_is_type or right_is_type:
+            self.add_message(
+                "unsupported-binary-operation",
+                args=msg,
+                node=node,
+                confidence=INFERENCE,
+            )
 
     # TODO: This check was disabled (by adding the leading underscore)
     # due to false positives several years ago - can we re-enable it?
-    # https://github.com/PyCQA/pylint/issues/6359
+    # https://github.com/pylint-dev/pylint/issues/6359
     @only_required_for_messages("unsupported-binary-operation")
     def _visit_binop(self, node: nodes.BinOp) -> None:
         """Detect TypeErrors for binary arithmetic operands."""
         self._check_binop_errors(node)
 
     # TODO: This check was disabled (by adding the leading underscore)
     # due to false positives several years ago - can we re-enable it?
-    # https://github.com/PyCQA/pylint/issues/6359
+    # https://github.com/pylint-dev/pylint/issues/6359
     @only_required_for_messages("unsupported-binary-operation")
     def _visit_augassign(self, node: nodes.AugAssign) -> None:
         """Detect TypeErrors for augmented binary arithmetic operands."""
         self._check_binop_errors(node)
 
-    def _check_binop_errors(self, node):
+    def _check_binop_errors(self, node: nodes.BinOp | nodes.AugAssign) -> None:
         for error in node.type_errors():
             # Let the error customize its output.
             if any(
                 isinstance(obj, nodes.ClassDef) and not has_known_bases(obj)
                 for obj in (error.left_type, error.right_type)
             ):
                 continue
             self.add_message("unsupported-binary-operation", args=str(error), node=node)
 
-    def _check_membership_test(self, node):
+    def _check_membership_test(self, node: nodes.NodeNG) -> None:
         if is_inside_abstract_class(node):
             return
         if is_comprehension(node):
             return
         inferred = safe_infer(node)
-        if inferred is None or inferred is astroid.Uninferable:
+        if inferred is None or isinstance(inferred, util.UninferableBase):
             return
         if not supports_membership_test(inferred):
             self.add_message(
                 "unsupported-membership-test", args=node.as_string(), node=node
             )
 
     @only_required_for_messages("unsupported-membership-test")
@@ -1954,40 +2048,61 @@
         if len(node.ops) != 1:
             return
 
         op, right = node.ops[0]
         if op in {"in", "not in"}:
             self._check_membership_test(right)
 
+    @only_required_for_messages("unhashable-member")
+    def visit_dict(self, node: nodes.Dict) -> None:
+        for k, _ in node.items:
+            if not is_hashable(k):
+                self.add_message(
+                    "unhashable-member",
+                    node=k,
+                    args=(k.as_string(), "key", "dict"),
+                    confidence=INFERENCE,
+                )
+
+    @only_required_for_messages("unhashable-member")
+    def visit_set(self, node: nodes.Set) -> None:
+        for element in node.elts:
+            if not is_hashable(element):
+                self.add_message(
+                    "unhashable-member",
+                    node=element,
+                    args=(element.as_string(), "member", "set"),
+                    confidence=INFERENCE,
+                )
+
     @only_required_for_messages(
         "unsubscriptable-object",
         "unsupported-assignment-operation",
         "unsupported-delete-operation",
-        "unhashable-dict-key",
+        "unhashable-member",
         "invalid-sequence-index",
         "invalid-slice-index",
+        "invalid-slice-step",
     )
     def visit_subscript(self, node: nodes.Subscript) -> None:
         self._check_invalid_sequence_index(node)
 
         supported_protocol: Callable[[Any, Any], bool] | None = None
         if isinstance(node.value, (nodes.ListComp, nodes.DictComp)):
             return
 
         if isinstance(node.value, nodes.Dict):
             # Assert dict key is hashable
-            inferred = safe_infer(node.slice)
-            if inferred and inferred != astroid.Uninferable:
-                try:
-                    hash_fn = next(inferred.igetattr("__hash__"))
-                except astroid.InferenceError:
-                    pass
-                else:
-                    if getattr(hash_fn, "value", True) is None:
-                        self.add_message("unhashable-dict-key", node=node.value)
+            if not is_hashable(node.slice):
+                self.add_message(
+                    "unhashable-member",
+                    node=node.value,
+                    args=(node.slice.as_string(), "key", "dict"),
+                    confidence=INFERENCE,
+                )
 
         if node.ctx == astroid.Load:
             supported_protocol = supports_getitem
             msg = "unsubscriptable-object"
         elif node.ctx == astroid.Store:
             supported_protocol = supports_setitem
             msg = "unsupported-assignment-operation"
@@ -2000,15 +2115,15 @@
             return
 
         if is_inside_abstract_class(node):
             return
 
         inferred = safe_infer(node.value)
 
-        if inferred is None or inferred is astroid.Uninferable:
+        if inferred is None or isinstance(inferred, util.UninferableBase):
             return
 
         if getattr(inferred, "decorators", None):
             first_decorator = astroid.helpers.safe_infer(inferred.decorators.nodes[0])
             if isinstance(first_decorator, nodes.ClassDef):
                 inferred = first_decorator.instantiate_class()
             else:
@@ -2090,15 +2205,15 @@
             "not-a-mapping",
             "Used when a non-mapping value is used in place where "
             "mapping is expected",
         ),
     }
 
     @staticmethod
-    def _is_asyncio_coroutine(node):
+    def _is_asyncio_coroutine(node: nodes.NodeNG) -> bool:
         if not isinstance(node, nodes.Call):
             return False
 
         inferred_func = safe_infer(node.func)
         if not isinstance(inferred_func, nodes.FunctionDef):
             return False
         if not inferred_func.decorators:
@@ -2108,30 +2223,30 @@
             if not isinstance(inferred_decorator, nodes.FunctionDef):
                 continue
             if inferred_decorator.qname() != ASYNCIO_COROUTINE:
                 continue
             return True
         return False
 
-    def _check_iterable(self, node, check_async=False):
+    def _check_iterable(self, node: nodes.NodeNG, check_async: bool = False) -> None:
         if is_inside_abstract_class(node):
             return
         inferred = safe_infer(node)
         if not inferred or is_comprehension(inferred):
             return
         if not is_iterable(inferred, check_async=check_async):
             self.add_message("not-an-iterable", args=node.as_string(), node=node)
 
-    def _check_mapping(self, node):
+    def _check_mapping(self, node: nodes.NodeNG) -> None:
         if is_inside_abstract_class(node):
             return
         if isinstance(node, nodes.DictComp):
             return
         inferred = safe_infer(node)
-        if inferred is None or inferred is astroid.Uninferable:
+        if inferred is None or isinstance(inferred, util.UninferableBase):
             return
         if not is_mapping(inferred):
             self.add_message("not-a-mapping", args=node.as_string(), node=node)
 
     @only_required_for_messages("not-an-iterable")
     def visit_for(self, node: nodes.For) -> None:
         self._check_iterable(node.iter)
```

### Comparing `pylint-3.0.0a5/pylint/checkers/unicode.py` & `pylint-3.0.0a6/pylint/checkers/unicode.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Unicode and some other ASCII characters can be used to create programs that run
 much different compared to what a human reader would expect from them.
 
 PEP 672 lists some examples.
 See: https://www.python.org/dev/peps/pep-0672/
 
@@ -214,15 +214,15 @@
 def _normalize_codec_name(codec: str) -> str:
     """Make sure the codec name is always given as defined in the BOM dict."""
     return UTF_NAME_REGEX_COMPILED.sub(r"utf-\1\2", codec).lower()
 
 
 def _remove_bom(encoded: bytes, encoding: str) -> bytes:
     """Remove the bom if given from a line."""
-    if not encoding.startswith("utf"):
+    if encoding not in UNICODE_BOMS:
         return encoded
     bom = UNICODE_BOMS[encoding]
     if encoded.startswith(bom):
         return encoded[len(bom) :]
     return encoded
 
 
@@ -326,15 +326,15 @@
             # UTF-16/UTF-32 (if at all)
             "UTF-16 and UTF-32 aren't backward compatible. Use UTF-8 instead",
             "invalid-unicode-codec",
             (
                 "For compatibility use UTF-8 instead of UTF-16/UTF-32. "
                 "See also https://bugs.python.org/issue1503789 for a history "
                 "of this issue. And "
-                "https://softwareengineering.stackexchange.com/questions/102205/should-utf-16-be-considered-harmful "
+                "https://softwareengineering.stackexchange.com/questions/102205/ "
                 "for some possible problems when using UTF-16 for instance."
             ),
         ),
         "E2502": (
             (
                 "Contains control characters that can permit obfuscated code "
                 "executed differently than displayed"
@@ -343,15 +343,16 @@
             (
                 "bidirectional unicode are typically not displayed characters required "
                 "to display right-to-left (RTL) script "
                 "(i.e. Chinese, Japanese, Arabic, Hebrew, ...) correctly. "
                 "So can you trust this code? "
                 "Are you sure it displayed correctly in all editors? "
                 "If you did not write it or your language is not RTL,"
-                " remove the special characters, as they could be used to trick you into executing code, "
+                " remove the special characters, as they could be used to trick you into "
+                "executing code, "
                 "that does something else than what it looks like.\n"
                 "More Information:\n"
                 "https://en.wikipedia.org/wiki/Bidirectional_text\n"
                 "https://trojansource.codes/"
             ),
         ),
         "C2503": (
@@ -520,15 +521,15 @@
         with node.stream() as stream:
             codec, codec_line = self._determine_codec(stream)
             self._check_codec(codec, codec_line)
 
             stream.seek(0)
 
             # Check for invalid content (controls/chars)
-            for (lineno, line) in enumerate(
+            for lineno, line in enumerate(
                 _fix_utf16_32_line_stream(stream, codec), start=1
             ):
                 if lineno == 1:
                     line = _remove_bom(line, codec)
                 self._check_bidi_chars(line, lineno, codec)
                 self._check_invalid_chars(line, lineno, codec)
```

### Comparing `pylint-3.0.0a5/pylint/checkers/unsupported_version.py` & `pylint-3.0.0a6/pylint/checkers/unsupported_version.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checker for features used that are not supported by all python versions
 indicated by the py-version setting.
 """
 
 from __future__ import annotations
```

### Comparing `pylint-3.0.0a5/pylint/checkers/utils.py` & `pylint-3.0.0a6/pylint/checkers/utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,35 +1,38 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Some functions that may be useful for various checkers."""
 
 from __future__ import annotations
 
 import builtins
+import fnmatch
 import itertools
 import numbers
 import re
 import string
-import warnings
-from collections.abc import Iterable
+from collections import deque
+from collections.abc import Iterable, Iterator
 from functools import lru_cache, partial
 from re import Match
-from typing import TYPE_CHECKING, Callable, TypeVar
+from typing import TYPE_CHECKING, Any, Callable, TypeVar
 
 import _string
 import astroid.objects
-from astroid import TooManyLevelsError, nodes
+from astroid import TooManyLevelsError, nodes, util
 from astroid.context import InferenceContext
 from astroid.exceptions import AstroidError
-
-from pylint.constants import TYPING_TYPE_CHECKS_GUARDS
+from astroid.nodes._base_nodes import ImportNode
+from astroid.typing import InferenceResult, SuccessfulInferenceResult
 
 if TYPE_CHECKING:
+    from functools import _lru_cache_wrapper
+
     from pylint.checkers import BaseChecker
 
 _NodeT = TypeVar("_NodeT", bound=nodes.NodeNG)
 _CheckerT = TypeVar("_CheckerT", bound="BaseChecker")
 AstCallbackMethod = Callable[[_CheckerT, _NodeT], None]
 
 COMP_NODE_TYPES = (
@@ -45,14 +48,15 @@
     "abc.abstractmethod",
     "abc.abstractclassmethod",
     "abc.abstractstaticmethod",
 }
 TYPING_PROTOCOLS = frozenset(
     {"typing.Protocol", "typing_extensions.Protocol", ".Protocol"}
 )
+COMMUTATIVE_OPERATORS = frozenset({"*", "+", "^", "&", "|"})
 ITER_METHOD = "__iter__"
 AITER_METHOD = "__aiter__"
 NEXT_METHOD = "__next__"
 GETITEM_METHOD = "__getitem__"
 CLASS_GETITEM_METHOD = "__class_getitem__"
 SETITEM_METHOD = "__setitem__"
 DELITEM_METHOD = "__delitem__"
@@ -225,33 +229,29 @@
         "contextlib.AbstractContextManager",
         "contextlib.AbstractAsyncContextManager",
         "re.Pattern",
         "re.Match",
     )
 )
 
+SINGLETON_VALUES = {True, False, None}
+
+TERMINATING_FUNCS_QNAMES = frozenset(
+    {"_sitebuiltins.Quitter", "sys.exit", "posix._exit", "nt._exit"}
+)
+
 
 class NoSuchArgumentError(Exception):
     pass
 
 
 class InferredTypeError(Exception):
     pass
 
 
-def is_inside_lambda(node: nodes.NodeNG) -> bool:
-    """Return whether the given node is inside a lambda."""
-    warnings.warn(
-        "utils.is_inside_lambda will be removed in favour of calling "
-        "utils.get_node_first_ancestor_of_type(x, nodes.Lambda) in pylint 3.0",
-        DeprecationWarning,
-    )
-    return any(isinstance(parent, nodes.Lambda) for parent in node.node_ancestors())
-
-
 def get_all_elements(
     node: nodes.NodeNG,
 ) -> Iterable[nodes.NodeNG]:
     """Recursively returns all atoms in nested lists and tuples."""
     if isinstance(node, (nodes.Tuple, nodes.List)):
         for child in node.elts:
             yield from get_all_elements(child)
@@ -273,82 +273,122 @@
 
 builtins = builtins.__dict__.copy()  # type: ignore[assignment]
 SPECIAL_BUILTINS = ("__builtins__",)  # '__path__', '__file__')
 
 
 def is_builtin_object(node: nodes.NodeNG) -> bool:
     """Returns True if the given node is an object from the __builtin__ module."""
-    return node and node.root().name == "builtins"
+    return node and node.root().name == "builtins"  # type: ignore[no-any-return]
 
 
 def is_builtin(name: str) -> bool:
     """Return true if <name> could be considered as a builtin defined by python."""
-    return name in builtins or name in SPECIAL_BUILTINS  # type: ignore[attr-defined]
+    return name in builtins or name in SPECIAL_BUILTINS  # type: ignore[operator]
 
 
 def is_defined_in_scope(
     var_node: nodes.NodeNG,
     varname: str,
     scope: nodes.NodeNG,
 ) -> bool:
+    return defnode_in_scope(var_node, varname, scope) is not None
+
+
+# pylint: disable = too-many-branches
+def defnode_in_scope(
+    var_node: nodes.NodeNG,
+    varname: str,
+    scope: nodes.NodeNG,
+) -> nodes.NodeNG | None:
     if isinstance(scope, nodes.If):
         for node in scope.body:
-            if (
-                isinstance(node, nodes.Assign)
-                and any(
-                    isinstance(target, nodes.AssignName) and target.name == varname
-                    for target in node.targets
-                )
-            ) or (isinstance(node, nodes.Nonlocal) and varname in node.names):
-                return True
+            if isinstance(node, nodes.Nonlocal) and varname in node.names:
+                return node
+            if isinstance(node, nodes.Assign):
+                for target in node.targets:
+                    if isinstance(target, nodes.AssignName) and target.name == varname:
+                        return target
     elif isinstance(scope, (COMP_NODE_TYPES, nodes.For)):
         for ass_node in scope.nodes_of_class(nodes.AssignName):
             if ass_node.name == varname:
-                return True
+                return ass_node
     elif isinstance(scope, nodes.With):
         for expr, ids in scope.items:
             if expr.parent_of(var_node):
                 break
             if ids and isinstance(ids, nodes.AssignName) and ids.name == varname:
-                return True
+                return ids
     elif isinstance(scope, (nodes.Lambda, nodes.FunctionDef)):
         if scope.args.is_argument(varname):
             # If the name is found inside a default value
             # of a function, then let the search continue
             # in the parent's tree.
             if scope.args.parent_of(var_node):
                 try:
                     scope.args.default_value(varname)
                     scope = scope.parent
-                    is_defined_in_scope(var_node, varname, scope)
+                    defnode = defnode_in_scope(var_node, varname, scope)
                 except astroid.NoDefault:
                     pass
-            return True
+                else:
+                    return defnode
+            return scope
         if getattr(scope, "name", None) == varname:
-            return True
+            return scope
     elif isinstance(scope, nodes.ExceptHandler):
         if isinstance(scope.name, nodes.AssignName):
             ass_node = scope.name
             if ass_node.name == varname:
-                return True
-    return False
+                return ass_node
+    return None
 
 
 def is_defined_before(var_node: nodes.Name) -> bool:
     """Check if the given variable node is defined before.
 
     Verify that the variable node is defined by a parent node
+    (e.g. if or with) earlier than `var_node`, or is defined by a
     (list, set, dict, or generator comprehension, lambda)
     or in a previous sibling node on the same line
     (statement_defining ; statement_using).
     """
     varname = var_node.name
     for parent in var_node.node_ancestors():
-        if is_defined_in_scope(var_node, varname, parent):
+        defnode = defnode_in_scope(var_node, varname, parent)
+        if defnode is None:
+            continue
+        defnode_scope = defnode.scope()
+        if isinstance(defnode_scope, (*COMP_NODE_TYPES, nodes.Lambda)):
+            # Avoid the case where var_node_scope is a nested function
+            # FunctionDef is a Lambda until https://github.com/pylint-dev/astroid/issues/291
+            if isinstance(defnode_scope, nodes.FunctionDef):
+                var_node_scope = var_node.scope()
+                if var_node_scope is not defnode_scope and isinstance(
+                    var_node_scope, nodes.FunctionDef
+                ):
+                    return False
             return True
+        if defnode.lineno < var_node.lineno:
+            return True
+        # `defnode` and `var_node` on the same line
+        for defnode_anc in defnode.node_ancestors():
+            if defnode_anc.lineno != var_node.lineno:
+                continue
+            if isinstance(
+                defnode_anc,
+                (
+                    nodes.For,
+                    nodes.While,
+                    nodes.With,
+                    nodes.TryExcept,
+                    nodes.TryFinally,
+                    nodes.ExceptHandler,
+                ),
+            ):
+                return True
     # possibly multiple statements on the same line using semicolon separator
     stmt = var_node.statement(future=True)
     _node = stmt.previous_sibling()
     lineno = stmt.fromlineno
     while _node and _node.fromlineno == lineno:
         for assign_node in _node.nodes_of_class(nodes.AssignName):
             if assign_node.name == varname:
@@ -443,38 +483,20 @@
     This decorator only has an effect on ``visit_*`` and ``leave_*`` methods
     of a class inheriting from ``BaseChecker``.
     """
 
     def store_messages(
         func: AstCallbackMethod[_CheckerT, _NodeT]
     ) -> AstCallbackMethod[_CheckerT, _NodeT]:
-        setattr(func, "checks_msgs", messages)
+        func.checks_msgs = messages  # type: ignore[attr-defined]
         return func
 
     return store_messages
 
 
-def check_messages(
-    *messages: str,
-) -> Callable[
-    [AstCallbackMethod[_CheckerT, _NodeT]], AstCallbackMethod[_CheckerT, _NodeT]
-]:
-    """Kept for backwards compatibility, deprecated.
-
-    Use only_required_for_messages instead, which conveys the intent of the decorator much clearer.
-    """
-    warnings.warn(
-        "utils.check_messages will be removed in favour of calling "
-        "utils.only_required_for_messages in pylint 3.0",
-        DeprecationWarning,
-    )
-
-    return only_required_for_messages(*messages)
-
-
 class IncompleteFormatString(Exception):
     """A format string ended in the middle of a format specifier."""
 
 
 class UnsupportedFormatCharacter(Exception):
     """A format character in a format string is not one of the supported
     format characters.
@@ -561,26 +583,27 @@
     return keys, num_args, key_types, pos_types
 
 
 def split_format_field_names(
     format_string: str,
 ) -> tuple[str, Iterable[tuple[bool, str]]]:
     try:
-        return _string.formatter_field_name_split(format_string)
+        return _string.formatter_field_name_split(format_string)  # type: ignore[no-any-return]
     except ValueError as e:
         raise IncompleteFormatString() from e
 
 
 def collect_string_fields(format_string: str) -> Iterable[str | None]:
     """Given a format string, return an iterator
     of all the valid format fields.
 
     It handles nested fields as well.
     """
     formatter = string.Formatter()
+    # pylint: disable = too-many-try-statements
     try:
         parseiterator = formatter.parse(format_string)
         for result in parseiterator:
             if all(item is None for item in result[1:]):
                 # not a replacement format
                 continue
             name = result[1]
@@ -675,15 +698,15 @@
     return parent_klass if isinstance(parent_klass, astroid.ClassDef) else None
 
 
 def is_attr_private(attrname: str) -> Match[str] | None:
     """Check that attribute name is private (at least two leading underscores,
     at most one trailing underscore).
     """
-    regex = re.compile("^_{2,}.*[^_]+_?$")
+    regex = re.compile("^_{2,10}.*[^_]+_?$")
     return regex.match(attrname)
 
 
 def get_argument_from_call(
     call_node: nodes.Call, position: int | None = None, keyword: str | None = None
 ) -> nodes.Name:
     """Returns the specified argument from a function call.
@@ -745,15 +768,15 @@
         return error
 
     if not isinstance(error_type, tuple):
         error_type = (error_type,)
     expected_errors = {stringify_error(error) for error in error_type}
     if not handler.type:
         return False
-    return handler.catch(expected_errors)
+    return handler.catch(expected_errors)  # type: ignore[no-any-return]
 
 
 def decorated_with_property(node: nodes.FunctionDef) -> bool:
     """Detect if the given function node is decorated with a property."""
     if not node.decorators:
         return False
     for decorator in node.decorators.nodes:
@@ -761,35 +784,35 @@
             if _is_property_decorator(decorator):
                 return True
         except astroid.InferenceError:
             pass
     return False
 
 
-def _is_property_kind(node, *kinds: str) -> bool:
+def _is_property_kind(node: nodes.NodeNG, *kinds: str) -> bool:
     if not isinstance(node, (astroid.UnboundMethod, nodes.FunctionDef)):
         return False
     if node.decorators:
         for decorator in node.decorators.nodes:
             if isinstance(decorator, nodes.Attribute) and decorator.attrname in kinds:
                 return True
     return False
 
 
-def is_property_setter(node) -> bool:
+def is_property_setter(node: nodes.NodeNG) -> bool:
     """Check if the given node is a property setter."""
     return _is_property_kind(node, "setter")
 
 
-def is_property_deleter(node) -> bool:
+def is_property_deleter(node: nodes.NodeNG) -> bool:
     """Check if the given node is a property deleter."""
     return _is_property_kind(node, "deleter")
 
 
-def is_property_setter_or_deleter(node) -> bool:
+def is_property_setter_or_deleter(node: nodes.NodeNG) -> bool:
     """Check if the given node is either a property setter or a deleter."""
     return _is_property_kind(node, "setter", "deleter")
 
 
 def _is_property_decorator(decorator: nodes.Name) -> bool:
     for inferred in decorator.infer():
         if isinstance(inferred, nodes.ClassDef):
@@ -829,15 +852,15 @@
         if isinstance(decorator_node, nodes.Call):
             # We only want to infer the function name
             decorator_node = decorator_node.func
         try:
             if any(
                 i.name in qnames or i.qname() in qnames
                 for i in decorator_node.infer()
-                if i is not None and i != astroid.Uninferable
+                if i is not None and not isinstance(i, util.UninferableBase)
             ):
                 return True
         except astroid.InferenceError:
             continue
     return False
 
 
@@ -880,44 +903,38 @@
         is_from_import = ("final" in import_names) and import_node.modname == "typing"
 
         # Check if the import is of the form: `import typing`
         is_import = ("typing" in import_names) and getattr(
             decorator, "attrname", None
         ) == "final"
 
-        if (is_from_import or is_import) and safe_infer(decorator) in [
-            astroid.Uninferable,
-            None,
-        ]:
-            decorators.append(decorator)
+        if is_from_import or is_import:
+            inferred = safe_infer(decorator)
+            if inferred is None or isinstance(inferred, util.UninferableBase):
+                decorators.append(decorator)
     return decorators
 
 
 @lru_cache(maxsize=1024)
 def unimplemented_abstract_methods(
     node: nodes.ClassDef, is_abstract_cb: nodes.FunctionDef = None
-) -> dict[str, nodes.NodeNG]:
+) -> dict[str, nodes.FunctionDef]:
     """Get the unimplemented abstract methods for the given *node*.
 
     A method can be considered abstract if the callback *is_abstract_cb*
     returns a ``True`` value. The check defaults to verifying that
     a method is decorated with abstract methods.
-    The function will work only for new-style classes. For old-style
-    classes, it will simply return an empty dictionary.
-    For the rest of them, it will return a dictionary of abstract method
+    It will return a dictionary of abstract method
     names and their inferred objects.
     """
     if is_abstract_cb is None:
         is_abstract_cb = partial(decorated_with, qnames=ABC_METHODS)
-    visited: dict[str, nodes.NodeNG] = {}
+    visited: dict[str, nodes.FunctionDef] = {}
     try:
         mro = reversed(node.mro())
-    except NotImplementedError:
-        # Old style class, it will not have a mro.
-        return {}
     except astroid.ResolveError:
         # Probably inconsistent hierarchy, don't try to figure this out here.
         return {}
     for ancestor in mro:
         for obj in ancestor.values():
             inferred = obj
             if isinstance(obj, nodes.AssignName):
@@ -1010,15 +1027,15 @@
     exceptions: tuple[type[ImportError], type[ModuleNotFoundError]],
 ) -> bool:
     func = partial(error_of_type, error_type=exceptions)
     return any(func(handler) for handler in handlers)
 
 
 def get_exception_handlers(
-    node: nodes.NodeNG, exception: type[Exception] = Exception
+    node: nodes.NodeNG, exception: type[Exception] | str = Exception
 ) -> list[nodes.ExceptHandler] | None:
     """Return the collections of handlers handling the exception in arguments.
 
     Args:
         node (nodes.NodeNG): A node that is potentially wrapped in a try except.
         exception (builtin.Exception or str): exception or name of the exception.
 
@@ -1029,14 +1046,67 @@
     if isinstance(context, nodes.TryExcept):
         return [
             handler for handler in context.handlers if error_of_type(handler, exception)
         ]
     return []
 
 
+def get_contextlib_with_statements(node: nodes.NodeNG) -> Iterator[nodes.With]:
+    """Get all contextlib.with statements in the ancestors of the given node."""
+    for with_node in node.node_ancestors():
+        if isinstance(with_node, nodes.With):
+            yield with_node
+
+
+def _suppresses_exception(
+    call: nodes.Call, exception: type[Exception] | str = Exception
+) -> bool:
+    """Check if the given node suppresses the given exception."""
+    if not isinstance(exception, str):
+        exception = exception.__name__
+    for arg in call.args:
+        inferred = safe_infer(arg)
+        if isinstance(inferred, nodes.ClassDef):
+            if inferred.name == exception:
+                return True
+        elif isinstance(inferred, nodes.Tuple):
+            for elt in inferred.elts:
+                inferred_elt = safe_infer(elt)
+                if (
+                    isinstance(inferred_elt, nodes.ClassDef)
+                    and inferred_elt.name == exception
+                ):
+                    return True
+    return False
+
+
+def get_contextlib_suppressors(
+    node: nodes.NodeNG, exception: type[Exception] | str = Exception
+) -> Iterator[nodes.With]:
+    """Return the contextlib suppressors handling the exception.
+
+    Args:
+        node (nodes.NodeNG): A node that is potentially wrapped in a contextlib.suppress.
+        exception (builtin.Exception): exception or name of the exception.
+
+    Yields:
+        nodes.With: A with node that is suppressing the exception.
+    """
+    for with_node in get_contextlib_with_statements(node):
+        for item, _ in with_node.items:
+            if isinstance(item, nodes.Call):
+                inferred = safe_infer(item.func)
+                if (
+                    isinstance(inferred, nodes.ClassDef)
+                    and inferred.qname() == "contextlib.suppress"
+                ):
+                    if _suppresses_exception(item, exception):
+                        yield with_node
+
+
 def is_node_inside_try_except(node: nodes.Raise) -> bool:
     """Check if the node is directly under a Try/Except statement
     (but not under an ExceptHandler!).
 
     Args:
         node (nodes.Raise): the node raising the exception.
 
@@ -1044,31 +1114,35 @@
         bool: True if the node is inside a try/except statement, False otherwise.
     """
     context = find_try_except_wrapper_node(node)
     return isinstance(context, nodes.TryExcept)
 
 
 def node_ignores_exception(
-    node: nodes.NodeNG, exception: type[Exception] = Exception
+    node: nodes.NodeNG, exception: type[Exception] | str = Exception
 ) -> bool:
     """Check if the node is in a TryExcept which handles the given exception.
 
     If the exception is not given, the function is going to look for bare
     excepts.
     """
     managing_handlers = get_exception_handlers(node, exception)
-    if not managing_handlers:
-        return False
-    return any(managing_handlers)
+    if managing_handlers:
+        return True
+    return any(get_contextlib_suppressors(node, exception))
 
 
 def class_is_abstract(node: nodes.ClassDef) -> bool:
     """Return true if the given class node should be considered as an abstract
     class.
     """
+    # Protocol classes are considered "abstract"
+    if is_protocol_class(node):
+        return True
+
     # Only check for explicit metaclass=ABCMeta on this specific class
     meta = node.declared_metaclass()
     if meta is not None:
         if meta.name == "ABCMeta" and meta.root().name in ABC_MODULES:
             return True
 
     for ancestor in node.ancestors():
@@ -1243,39 +1317,53 @@
     if callable(pytype):
         return pytype()
     return None
 
 
 @lru_cache(maxsize=1024)
 def safe_infer(
-    node: nodes.NodeNG, context: InferenceContext | None = None
-) -> nodes.NodeNG | type[astroid.Uninferable] | None:
+    node: nodes.NodeNG,
+    context: InferenceContext | None = None,
+    *,
+    compare_constants: bool = False,
+) -> InferenceResult | None:
     """Return the inferred value for the given node.
 
     Return None if inference failed or if there is some ambiguity (more than
     one node has been inferred of different types).
+
+    If compare_constants is True and if multiple constants are inferred,
+    unequal inferred values are also considered ambiguous and return None.
     """
     inferred_types: set[str | None] = set()
     try:
         infer_gen = node.infer(context=context)
         value = next(infer_gen)
     except astroid.InferenceError:
         return None
     except Exception as e:  # pragma: no cover
         raise AstroidError from e
 
-    if value is not astroid.Uninferable:
+    if not isinstance(value, util.UninferableBase):
         inferred_types.add(_get_python_type_of_node(value))
 
+    # pylint: disable = too-many-try-statements
     try:
         for inferred in infer_gen:
             inferred_type = _get_python_type_of_node(inferred)
             if inferred_type not in inferred_types:
                 return None  # If there is ambiguity on the inferred node.
             if (
+                compare_constants
+                and isinstance(inferred, nodes.Const)
+                and isinstance(value, nodes.Const)
+                and inferred.value != value.value
+            ):
+                return None
+            if (
                 isinstance(inferred, nodes.FunctionDef)
                 and inferred.args.args is not None
                 and isinstance(value, nodes.FunctionDef)
                 and value.args.args is not None
                 and len(inferred.args.args) != len(value.args.args)
             ):
                 return None  # Different number of arguments indicates ambiguity
@@ -1286,30 +1374,30 @@
     except Exception as e:  # pragma: no cover
         raise AstroidError from e
     return value if len(inferred_types) <= 1 else None
 
 
 @lru_cache(maxsize=512)
 def infer_all(
-    node: nodes.NodeNG, context: InferenceContext = None
-) -> list[nodes.NodeNG]:
+    node: nodes.NodeNG, context: InferenceContext | None = None
+) -> list[InferenceResult]:
     try:
         return list(node.infer(context=context))
     except astroid.InferenceError:
         return []
     except Exception as e:  # pragma: no cover
         raise AstroidError from e
 
 
 def has_known_bases(
     klass: nodes.ClassDef, context: InferenceContext | None = None
 ) -> bool:
     """Return true if all base classes of a class could be inferred."""
     try:
-        return klass._all_bases_known
+        return klass._all_bases_known  # type: ignore[no-any-return]
     except AttributeError:
         pass
     for base in klass.bases:
         result = safe_infer(base, context=context)
         if (
             not isinstance(result, nodes.ClassDef)
             or result is klass
@@ -1325,26 +1413,26 @@
     return (
         node is None
         or (isinstance(node, nodes.Const) and node.value is None)
         or (isinstance(node, nodes.Name) and node.name == "None")
     )
 
 
-def node_type(node: nodes.NodeNG) -> nodes.NodeNG | None:
+def node_type(node: nodes.NodeNG) -> SuccessfulInferenceResult | None:
     """Return the inferred type for `node`.
 
     If there is more than one possible type, or if inferred type is Uninferable or None,
     return None
     """
     # check there is only one possible type for the assign node. Else we
     # don't handle it for now
-    types: set[nodes.NodeNG] = set()
+    types: set[SuccessfulInferenceResult] = set()
     try:
         for var_type in node.infer():
-            if var_type == astroid.Uninferable or is_none(var_type):
+            if isinstance(var_type, util.UninferableBase) or is_none(var_type):
                 continue
             types.add(var_type)
             if len(types) > 1:
                 return None
     except astroid.InferenceError:
         return None
     return types.pop() if types else None
@@ -1359,33 +1447,74 @@
     )
 
     if not isinstance(node, nodes.FunctionDef):
         return False
 
     decorators = node.decorators.nodes if node.decorators else []
     for decorator in decorators:
-        # func.register are function calls
-        if not isinstance(decorator, nodes.Call):
+        # func.register are function calls or register attributes
+        # when the function is annotated with types
+        if isinstance(decorator, nodes.Call):
+            func = decorator.func
+        elif isinstance(decorator, nodes.Attribute):
+            func = decorator
+        else:
             continue
 
-        func = decorator.func
         if not isinstance(func, nodes.Attribute) or func.attrname != "register":
             continue
 
         try:
             func_def = next(func.expr.infer())
         except astroid.InferenceError:
             continue
 
         if isinstance(func_def, nodes.FunctionDef):
             return decorated_with(func_def, singledispatch_qnames)
 
     return False
 
 
+def find_inferred_fn_from_register(node: nodes.NodeNG) -> nodes.FunctionDef | None:
+    # func.register are function calls or register attributes
+    # when the function is annotated with types
+    if isinstance(node, nodes.Call):
+        func = node.func
+    elif isinstance(node, nodes.Attribute):
+        func = node
+    else:
+        return None
+
+    if not isinstance(func, nodes.Attribute) or func.attrname != "register":
+        return None
+
+    func_def = safe_infer(func.expr)
+    if not isinstance(func_def, nodes.FunctionDef):
+        return None
+
+    return func_def
+
+
+def is_registered_in_singledispatchmethod_function(node: nodes.FunctionDef) -> bool:
+    """Check if the given function node is a singledispatchmethod function."""
+
+    singledispatchmethod_qnames = (
+        "functools.singledispatchmethod",
+        "singledispatch.singledispatchmethod",
+    )
+
+    decorators = node.decorators.nodes if node.decorators else []
+    for decorator in decorators:
+        func_def = find_inferred_fn_from_register(decorator)
+        if func_def:
+            return decorated_with(func_def, singledispatchmethod_qnames)
+
+    return False
+
+
 def get_node_last_lineno(node: nodes.NodeNG) -> int:
     """Get the last lineno of the given node.
 
     For a simple statement this will just be node.lineno,
     but for a node that has child statements (e.g. a method) this will be the lineno of the last
     child statement recursively.
     """
@@ -1399,43 +1528,23 @@
     # try statements have the 'handlers' last if there is no 'orelse' or 'finalbody'
     if getattr(node, "handlers", False):
         return get_node_last_lineno(node.handlers[-1])
     # All compound statements have a 'body'
     if getattr(node, "body", False):
         return get_node_last_lineno(node.body[-1])
     # Not a compound statement
-    return node.lineno
+    return node.lineno  # type: ignore[no-any-return]
 
 
 def is_postponed_evaluation_enabled(node: nodes.NodeNG) -> bool:
     """Check if the postponed evaluation of annotations is enabled."""
     module = node.root()
     return "annotations" in module.future_imports
 
 
-def is_class_subscriptable_pep585_with_postponed_evaluation_enabled(
-    value: nodes.ClassDef, node: nodes.NodeNG
-) -> bool:
-    """Check if class is subscriptable with PEP 585 and
-    postponed evaluation enabled.
-    """
-    warnings.warn(
-        "'is_class_subscriptable_pep585_with_postponed_evaluation_enabled' has been "
-        "deprecated and will be removed in pylint 3.0. "
-        "Use 'is_postponed_evaluation_enabled(node) and "
-        "is_node_in_type_annotation_context(node)' instead.",
-        DeprecationWarning,
-    )
-    return (
-        is_postponed_evaluation_enabled(node)
-        and value.qname() in SUBSCRIPTABLE_CLASSES_PEP585
-        and is_node_in_type_annotation_context(node)
-    )
-
-
 def is_node_in_type_annotation_context(node: nodes.NodeNG) -> bool:
     """Check if node is in type annotation context.
 
     Check for 'AnnAssign', function 'Arguments',
     or part of function return type annotation.
     """
     # pylint: disable=too-many-boolean-expressions
@@ -1492,22 +1601,31 @@
     return bool(decorators and decorated_with(node, ["typing.overload", "overload"]))
 
 
 def is_protocol_class(cls: nodes.NodeNG) -> bool:
     """Check if the given node represents a protocol class.
 
     :param cls: The node to check
-    :returns: True if the node is a typing protocol class, false otherwise.
+    :returns: True if the node is or inherits from typing.Protocol directly, false otherwise.
     """
     if not isinstance(cls, nodes.ClassDef):
         return False
 
-    # Use .ancestors() since not all protocol classes can have
-    # their mro deduced.
-    return any(parent.qname() in TYPING_PROTOCOLS for parent in cls.ancestors())
+    # Return if klass is protocol
+    if cls.qname() in TYPING_PROTOCOLS:
+        return True
+
+    for base in cls.bases:
+        try:
+            for inf_base in base.infer():
+                if inf_base.qname() in TYPING_PROTOCOLS:
+                    return True
+        except astroid.InferenceError:
+            continue
+    return False
 
 
 def is_call_of_name(node: nodes.NodeNG, name: str) -> bool:
     """Checks if node is a function call with the given name."""
     return (
         isinstance(node, nodes.Call)
         and isinstance(node.func, nodes.Name)
@@ -1555,14 +1673,18 @@
             and isinstance(inferred, nodes.ClassDef)
             and is_attribute_typed_annotation(inferred, attr_name)
         ):
             return True
     return False
 
 
+def is_enum(node: nodes.ClassDef) -> bool:
+    return node.name == "Enum" and node.root().name == "enum"  # type: ignore[no-any-return]
+
+
 def is_assign_name_annotated_with(node: nodes.AssignName, typing_name: str) -> bool:
     """Test if AssignName node has `typing_name` annotation.
 
     Especially useful to check for `typing._SpecialForm` instances
     like: `Union`, `Optional`, `Literal`, `ClassVar`, `Final`.
     """
     if not isinstance(node.parent, nodes.AnnAssign):
@@ -1592,22 +1714,22 @@
         isinstance(node.iter, nodes.Call)
         and isinstance(node.iter.func, nodes.Attribute)
         and node.iter.func.attrname == "keys"
     ):
         inferred = safe_infer(node.iter.func)
         if not isinstance(inferred, astroid.BoundMethod):
             return None
-        return node.iter.as_string().rpartition(".keys")[0]
+        return node.iter.as_string().rpartition(".keys")[0]  # type: ignore[no-any-return]
 
     # Is it a dictionary?
     if isinstance(node.iter, (nodes.Name, nodes.Attribute)):
         inferred = safe_infer(node.iter)
         if not isinstance(inferred, nodes.Dict):
             return None
-        return node.iter.as_string()
+        return node.iter.as_string()  # type: ignore[no-any-return]
 
     return None
 
 
 def get_subscript_const_value(node: nodes.Subscript) -> nodes.Const:
     """Returns the value 'subscript.slice' of a Subscript node.
 
@@ -1618,15 +1740,15 @@
     inferred = safe_infer(node.slice)
     if not isinstance(inferred, nodes.Const):
         raise InferredTypeError("Subscript.slice cannot be inferred as a nodes.Const")
 
     return inferred
 
 
-def get_import_name(importnode: nodes.Import | nodes.ImportFrom, modname: str) -> str:
+def get_import_name(importnode: ImportNode, modname: str | None) -> str | None:
     """Get a prepared module name from the given import node.
 
     In the case of relative imports, this will return the
     absolute qualified module name, which might be useful
     for debugging. Otherwise, the initial module name
     is returned unchanged.
 
@@ -1635,15 +1757,17 @@
     :returns: absolute qualified module name of the module
         used in import.
     """
     if isinstance(importnode, nodes.ImportFrom) and importnode.level:
         root = importnode.root()
         if isinstance(root, nodes.Module):
             try:
-                return root.relative_to_absolute_name(modname, level=importnode.level)
+                return root.relative_to_absolute_name(  # type: ignore[no-any-return]
+                    modname, level=importnode.level
+                )
             except TooManyLevelsError:
                 return modname
     return modname
 
 
 def is_sys_guard(node: nodes.If) -> bool:
     """Return True if IF stmt is a sys.version_info guard.
@@ -1663,41 +1787,14 @@
             and value.as_string() == "sys.version_info"
         ):
             return True
 
     return False
 
 
-def is_typing_guard(node: nodes.If) -> bool:
-    """Return True if IF stmt is a typing guard.
-
-    >>> from typing import TYPE_CHECKING
-    >>> if TYPE_CHECKING:
-    >>>     from xyz import a
-    """
-    return isinstance(
-        node.test, (nodes.Name, nodes.Attribute)
-    ) and node.test.as_string().endswith("TYPE_CHECKING")
-
-
-def is_node_in_typing_guarded_import_block(node: nodes.NodeNG) -> bool:
-    """Return True if node is part for guarded `typing.TYPE_CHECKING` if block."""
-    return isinstance(node.parent, nodes.If) and is_typing_guard(node.parent)
-
-
-def is_node_in_guarded_import_block(node: nodes.NodeNG) -> bool:
-    """Return True if node is part for guarded if block.
-
-    I.e. `sys.version_info` or `typing.TYPE_CHECKING`
-    """
-    return isinstance(node.parent, nodes.If) and (
-        is_sys_guard(node.parent) or is_typing_guard(node.parent)
-    )
-
-
 def is_reassigned_after_current(node: nodes.NodeNG, varname: str) -> bool:
     """Check if the given variable name is reassigned in the same scope after the
     current node.
     """
     return any(
         a.name == varname and a.lineno > node.lineno
         for a in node.scope().nodes_of_class(
@@ -1738,29 +1835,38 @@
 def is_empty_str_literal(node: nodes.NodeNG | None) -> bool:
     return (
         isinstance(node, nodes.Const) and isinstance(node.value, str) and not node.value
     )
 
 
 def returns_bool(node: nodes.NodeNG) -> bool:
-    """Returns true if a node is a return that returns a constant boolean."""
+    """Returns true if a node is a nodes.Return that returns a constant boolean."""
     return (
         isinstance(node, nodes.Return)
         and isinstance(node.value, nodes.Const)
-        and node.value.value in {True, False}
+        and isinstance(node.value.value, bool)
+    )
+
+
+def assigned_bool(node: nodes.NodeNG) -> bool:
+    """Returns true if a node is a nodes.Assign that returns a constant boolean."""
+    return (
+        isinstance(node, nodes.Assign)
+        and isinstance(node.value, nodes.Const)
+        and isinstance(node.value.value, bool)
     )
 
 
 def get_node_first_ancestor_of_type(
     node: nodes.NodeNG, ancestor_type: type[_NodeT] | tuple[type[_NodeT], ...]
 ) -> _NodeT | None:
     """Return the first parent node that is any of the provided types (or None)."""
     for ancestor in node.node_ancestors():
         if isinstance(ancestor, ancestor_type):
-            return ancestor
+            return ancestor  # type: ignore[no-any-return]
     return None
 
 
 def get_node_first_ancestor_of_type_and_its_child(
     node: nodes.NodeNG, ancestor_type: type[_NodeT] | tuple[type[_NodeT], ...]
 ) -> tuple[None, None] | tuple[_NodeT, nodes.NodeNG]:
     """Modified version of get_node_first_ancestor_of_type to also return the
@@ -1774,21 +1880,331 @@
         if isinstance(ancestor, ancestor_type):
             return (ancestor, child)
         child = ancestor
     return None, None
 
 
 def in_type_checking_block(node: nodes.NodeNG) -> bool:
-    """Check if a node is guarded by a TYPE_CHECKS guard."""
-    return any(
-        isinstance(ancestor, nodes.If)
-        and ancestor.test.as_string() in TYPING_TYPE_CHECKS_GUARDS
-        for ancestor in node.node_ancestors()
-    )
+    """Check if a node is guarded by a TYPE_CHECKING guard."""
+    for ancestor in node.node_ancestors():
+        if not isinstance(ancestor, nodes.If):
+            continue
+        if isinstance(ancestor.test, nodes.Name):
+            if ancestor.test.name != "TYPE_CHECKING":
+                continue
+            lookup_result = ancestor.test.lookup(ancestor.test.name)[1]
+            if not lookup_result:
+                return False
+            maybe_import_from = lookup_result[0]
+            if (
+                isinstance(maybe_import_from, nodes.ImportFrom)
+                and maybe_import_from.modname == "typing"
+            ):
+                return True
+            inferred = safe_infer(ancestor.test)
+            if isinstance(inferred, nodes.Const) and inferred.value is False:
+                return True
+        elif isinstance(ancestor.test, nodes.Attribute):
+            if ancestor.test.attrname != "TYPE_CHECKING":
+                continue
+            inferred_module = safe_infer(ancestor.test.expr)
+            if (
+                isinstance(inferred_module, nodes.Module)
+                and inferred_module.name == "typing"
+            ):
+                return True
+
+    return False
+
+
+def is_typing_member(node: nodes.NodeNG, names_to_check: tuple[str, ...]) -> bool:
+    """Check if `node` is a member of the `typing` module and has one of the names from
+    `names_to_check`.
+    """
+    if isinstance(node, nodes.Name):
+        try:
+            import_from = node.lookup(node.name)[1][0]
+        except IndexError:
+            return False
+
+        if isinstance(import_from, nodes.ImportFrom):
+            return (
+                import_from.modname == "typing"
+                and import_from.real_name(node.name) in names_to_check
+            )
+    elif isinstance(node, nodes.Attribute):
+        inferred_module = safe_infer(node.expr)
+        return (
+            isinstance(inferred_module, nodes.Module)
+            and inferred_module.name == "typing"
+            and node.attrname in names_to_check
+        )
+    return False
 
 
 @lru_cache()
 def in_for_else_branch(parent: nodes.NodeNG, stmt: nodes.Statement) -> bool:
     """Returns True if stmt is inside the else branch for a parent For stmt."""
     return isinstance(parent, nodes.For) and any(
         else_stmt.parent_of(stmt) or else_stmt == stmt for else_stmt in parent.orelse
     )
+
+
+def find_assigned_names_recursive(
+    target: nodes.AssignName | nodes.BaseContainer,
+) -> Iterator[str]:
+    """Yield the names of assignment targets, accounting for nested ones."""
+    if isinstance(target, nodes.AssignName):
+        if target.name is not None:
+            yield target.name
+    elif isinstance(target, nodes.BaseContainer):
+        for elt in target.elts:
+            yield from find_assigned_names_recursive(elt)
+
+
+def has_starred_node_recursive(
+    node: nodes.For | nodes.Comprehension | nodes.Set,
+) -> Iterator[bool]:
+    """Yield ``True`` if a Starred node is found recursively."""
+    if isinstance(node, nodes.Starred):
+        yield True
+    elif isinstance(node, nodes.Set):
+        for elt in node.elts:
+            yield from has_starred_node_recursive(elt)
+    elif isinstance(node, (nodes.For, nodes.Comprehension)):
+        for elt in node.iter.elts:
+            yield from has_starred_node_recursive(elt)
+
+
+def is_hashable(node: nodes.NodeNG) -> bool:
+    """Return whether any inferred value of `node` is hashable.
+
+    When finding ambiguity, return True.
+    """
+    # pylint: disable = too-many-try-statements
+    try:
+        for inferred in node.infer():
+            if isinstance(inferred, (nodes.ClassDef, util.UninferableBase)):
+                return True
+            if not hasattr(inferred, "igetattr"):
+                return True
+            hash_fn = next(inferred.igetattr("__hash__"))
+            if hash_fn.parent is inferred:
+                return True
+            if getattr(hash_fn, "value", True) is not None:
+                return True
+        return False
+    except astroid.InferenceError:
+        return True
+
+
+def _is_target_name_in_binop_side(
+    target: nodes.AssignName | nodes.AssignAttr, side: nodes.NodeNG | None
+) -> bool:
+    """Determine whether the target name-like node is referenced in the side node."""
+    if isinstance(side, nodes.Name):
+        if isinstance(target, nodes.AssignName):
+            return target.name == side.name  # type: ignore[no-any-return]
+        return False
+    if isinstance(side, nodes.Attribute) and isinstance(target, nodes.AssignAttr):
+        return target.as_string() == side.as_string()  # type: ignore[no-any-return]
+    return False
+
+
+def is_augmented_assign(node: nodes.Assign) -> tuple[bool, str]:
+    """Determine if the node is assigning itself (with modifications) to itself.
+
+    For example: x = 1 + x
+    """
+    if not isinstance(node.value, nodes.BinOp):
+        return False, ""
+
+    binop = node.value
+    target = node.targets[0]
+
+    if not isinstance(target, (nodes.AssignName, nodes.AssignAttr)):
+        return False, ""
+
+    # We don't want to catch x = "1" + x or x = "%s" % x
+    if isinstance(binop.left, nodes.Const) and isinstance(
+        binop.left.value, (str, bytes)
+    ):
+        return False, ""
+
+    # This could probably be improved but for now we disregard all assignments from calls
+    if isinstance(binop.left, nodes.Call) or isinstance(binop.right, nodes.Call):
+        return False, ""
+
+    if _is_target_name_in_binop_side(target, binop.left):
+        return True, binop.op
+    if (
+        # Unless an operator is commutative, we should not raise (i.e. x = 3/x)
+        binop.op in COMMUTATIVE_OPERATORS
+        and _is_target_name_in_binop_side(target, binop.right)
+    ):
+        inferred_left = safe_infer(binop.left)
+        if isinstance(inferred_left, nodes.Const) and isinstance(
+            inferred_left.value, int
+        ):
+            return True, binop.op
+        return False, ""
+    return False, ""
+
+
+def is_module_ignored(
+    module: nodes.Module,
+    ignored_modules: Iterable[str],
+) -> bool:
+    ignored_modules = set(ignored_modules)
+    module_name = module.name
+    module_qname = module.qname()
+
+    for ignore in ignored_modules:
+        # Try to match the module name / fully qualified name directly
+        if module_qname in ignored_modules or module_name in ignored_modules:
+            return True
+
+        # Try to see if the ignores pattern match against the module name.
+        if fnmatch.fnmatch(module_qname, ignore):
+            return True
+
+        # Otherwise, we might have a root module name being ignored,
+        # and the qualified owner has more levels of depth.
+        parts = deque(module_name.split("."))
+        current_module = ""
+
+        while parts:
+            part = parts.popleft()
+            if not current_module:
+                current_module = part
+            else:
+                current_module += f".{part}"
+            if current_module in ignored_modules:
+                return True
+
+    return False
+
+
+def is_singleton_const(node: nodes.NodeNG) -> bool:
+    return isinstance(node, nodes.Const) and any(
+        node.value is value for value in SINGLETON_VALUES
+    )
+
+
+def is_terminating_func(node: nodes.Call) -> bool:
+    """Detect call to exit(), quit(), os._exit(), or sys.exit()."""
+    if (
+        not isinstance(node.func, nodes.Attribute)
+        and not (isinstance(node.func, nodes.Name))
+        or isinstance(node.parent, nodes.Lambda)
+    ):
+        return False
+
+    try:
+        for inferred in node.func.infer():
+            if (
+                hasattr(inferred, "qname")
+                and inferred.qname() in TERMINATING_FUNCS_QNAMES
+            ):
+                return True
+    except (StopIteration, astroid.InferenceError):
+        pass
+
+    return False
+
+
+def is_class_attr(name: str, klass: nodes.ClassDef) -> bool:
+    try:
+        klass.getattr(name)
+        return True
+    except astroid.NotFoundError:
+        return False
+
+
+def get_inverse_comparator(op: str) -> str:
+    """Returns the inverse comparator given a comparator.
+
+    E.g. when given "==", returns "!="
+
+    :param str op: the comparator to look up.
+
+    :returns: The inverse of the comparator in string format
+    :raises KeyError: if input is not recognized as a comparator
+    """
+    return {
+        "==": "!=",
+        "!=": "==",
+        "<": ">=",
+        ">": "<=",
+        "<=": ">",
+        ">=": "<",
+        "in": "not in",
+        "not in": "in",
+        "is": "is not",
+        "is not": "is",
+    }[op]
+
+
+def not_condition_as_string(
+    test_node: nodes.Compare | nodes.Name | nodes.UnaryOp | nodes.BoolOp | nodes.BinOp,
+) -> str:
+    msg = f"not {test_node.as_string()}"
+    if isinstance(test_node, nodes.UnaryOp):
+        msg = test_node.operand.as_string()
+    elif isinstance(test_node, nodes.BoolOp):
+        msg = f"not ({test_node.as_string()})"
+    elif isinstance(test_node, nodes.Compare):
+        lhs = test_node.left
+        ops, rhs = test_node.ops[0]
+        lower_priority_expressions = (
+            nodes.Lambda,
+            nodes.UnaryOp,
+            nodes.BoolOp,
+            nodes.IfExp,
+            nodes.NamedExpr,
+        )
+        lhs = (
+            f"({lhs.as_string()})"
+            if isinstance(lhs, lower_priority_expressions)
+            else lhs.as_string()
+        )
+        rhs = (
+            f"({rhs.as_string()})"
+            if isinstance(rhs, lower_priority_expressions)
+            else rhs.as_string()
+        )
+        msg = f"{lhs} {get_inverse_comparator(ops)} {rhs}"
+    return msg
+
+
+@lru_cache(maxsize=1000)
+def overridden_method(
+    klass: nodes.LocalsDictNodeNG, name: str | None
+) -> nodes.FunctionDef | None:
+    """Get overridden method if any."""
+    try:
+        parent = next(klass.local_attr_ancestors(name))
+    except (StopIteration, KeyError):
+        return None
+    try:
+        meth_node = parent[name]
+    except KeyError:  # pragma: no cover
+        # We have found an ancestor defining <name> but it's not in the local
+        # dictionary. This may happen with astroid built from living objects.
+        return None
+    if isinstance(meth_node, nodes.FunctionDef):
+        return meth_node
+    return None  # pragma: no cover
+
+
+def clear_lru_caches() -> None:
+    """Clear caches holding references to AST nodes."""
+    caches_holding_node_references: list[_lru_cache_wrapper[Any]] = [
+        in_for_else_branch,
+        infer_all,
+        is_overload_stub,
+        overridden_method,
+        unimplemented_abstract_methods,
+        safe_infer,
+    ]
+    for lru in caches_holding_node_references:
+        lru.cache_clear()
```

### Comparing `pylint-3.0.0a5/pylint/checkers/variables.py` & `pylint-3.0.0a6/pylint/checkers/variables.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,36 +1,39 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Variables checkers for Python code."""
 
 from __future__ import annotations
 
 import collections
 import copy
 import itertools
 import os
 import re
 import sys
 from collections import defaultdict
-from collections.abc import Iterable, Iterator
+from collections.abc import Generator, Iterable, Iterator
 from enum import Enum
-from functools import lru_cache
 from typing import TYPE_CHECKING, Any, NamedTuple
 
 import astroid
-from astroid import nodes
+from astroid import bases, extract_node, nodes, util
+from astroid.nodes import _base_nodes
+from astroid.typing import InferenceResult
 
 from pylint.checkers import BaseChecker, utils
 from pylint.checkers.utils import (
     in_type_checking_block,
     is_postponed_evaluation_enabled,
+    is_sys_guard,
+    overridden_method,
 )
-from pylint.constants import PY39_PLUS, TYPING_TYPE_CHECKS_GUARDS
+from pylint.constants import PY39_PLUS, TYPING_NEVER, TYPING_NORETURN
 from pylint.interfaces import CONTROL_FLOW, HIGH, INFERENCE, INFERENCE_FAILURE
 from pylint.typing import MessageDefinitionTuple
 
 if sys.version_info >= (3, 8):
     from functools import cached_property
 else:
     from astroid.decorators import cachedproperty as cached_property
@@ -102,75 +105,82 @@
         "AnyStr",
         "Text",
         "Pattern",
         "BinaryIO",
     }
 )
 
+DICT_TYPES = (
+    astroid.objects.DictValues,
+    astroid.objects.DictKeys,
+    astroid.objects.DictItems,
+    astroid.nodes.node_classes.Dict,
+)
+
+NODES_WITH_VALUE_ATTR = (
+    nodes.Assign,
+    nodes.AnnAssign,
+    nodes.AugAssign,
+    nodes.Expr,
+    nodes.Return,
+    nodes.Match,
+)
+
 
 class VariableVisitConsumerAction(Enum):
     """Reported by _check_consumer() and its sub-methods to determine the
     subsequent action to take in _undefined_and_used_before_checker().
 
     Continue -> continue loop to next consumer
     Return -> return and thereby break the loop
     """
 
     CONTINUE = 0
     RETURN = 1
 
 
-def _is_from_future_import(stmt, name):
+def _is_from_future_import(stmt: nodes.ImportFrom, name: str) -> bool | None:
     """Check if the name is a future import from another module."""
     try:
         module = stmt.do_import_module(stmt.modname)
     except astroid.AstroidBuildingException:
         return None
 
     for local_node in module.locals.get(name, []):
         if isinstance(local_node, nodes.ImportFrom) and local_node.modname == FUTURE:
             return True
     return None
 
 
-@lru_cache(maxsize=1000)
-def overridden_method(klass, name):
-    """Get overridden method if any."""
-    try:
-        parent = next(klass.local_attr_ancestors(name))
-    except (StopIteration, KeyError):
-        return None
-    try:
-        meth_node = parent[name]
-    except KeyError:
-        # We have found an ancestor defining <name> but it's not in the local
-        # dictionary. This may happen with astroid built from living objects.
-        return None
-    if isinstance(meth_node, nodes.FunctionDef):
-        return meth_node
-    return None
-
-
-def _get_unpacking_extra_info(node, inferred):
+def _get_unpacking_extra_info(node: nodes.Assign, inferred: InferenceResult) -> str:
     """Return extra information to add to the message for unpacking-non-sequence
-    and unbalanced-tuple-unpacking errors.
+    and unbalanced-tuple/dict-unpacking errors.
     """
     more = ""
+    if isinstance(inferred, DICT_TYPES):
+        if isinstance(node, nodes.Assign):
+            more = node.value.as_string()
+        elif isinstance(node, nodes.For):
+            more = node.iter.as_string()
+        return more
+
     inferred_module = inferred.root().name
     if node.root().name == inferred_module:
         if node.lineno == inferred.lineno:
-            more = f" {inferred.as_string()}"
+            more = f"'{inferred.as_string()}'"
         elif inferred.lineno:
-            more = f" defined at line {inferred.lineno}"
+            more = f"defined at line {inferred.lineno}"
     elif inferred.lineno:
-        more = f" defined at line {inferred.lineno} of {inferred_module}"
+        more = f"defined at line {inferred.lineno} of {inferred_module}"
     return more
 
 
-def _detect_global_scope(node, frame, defframe):
+def _detect_global_scope(
+    node: nodes.Name, frame: nodes.LocalsDictNodeNG, defframe: nodes.LocalsDictNodeNG
+) -> bool:
     """Detect that the given frames share a global scope.
 
     Two frames share a global scope when neither
     of them are hidden under a function scope, as well
     as any parent scope of them, until the root scope.
     In this case, depending from something defined later on
     will only work if guarded by a nested function definition.
@@ -200,19 +210,20 @@
         and scope is utils.get_node_first_ancestor_of_type(node, nodes.FunctionDef)
     ):
         # If the current node's scope is a class nested under a function,
         # and the def_scope is something else, then they aren't shared.
         return False
     if isinstance(frame, nodes.FunctionDef):
         # If the parent of the current node is a
-        # function, then it can be under its scope
-        # (defined in, which doesn't concern us) or
+        # function, then it can be under its scope (defined in); or
         # the `->` part of annotations. The same goes
         # for annotations of function arguments, they'll have
         # their parent the Arguments node.
+        if frame.parent_of(defframe):
+            return node.lineno < defframe.lineno  # type: ignore[no-any-return]
         if not isinstance(node.parent, (nodes.FunctionDef, nodes.Arguments)):
             return False
     elif any(
         not isinstance(f, (nodes.ClassDef, nodes.Module)) for f in (frame, defframe)
     ):
         # Not interested in other frames, since they are already
         # not in a global scope.
@@ -238,32 +249,36 @@
         # that the two frames (frame and defframe) share the same scope,
         # and we could apply our lineno analysis over them.
         # For instance, this works when they are inside a function, the node
         # that uses a definition and the definition itself.
         return False
     # At this point, we are certain that frame and defframe share a scope
     # and the definition of the first depends on the second.
-    return frame.lineno < defframe.lineno
+    return frame.lineno < defframe.lineno  # type: ignore[no-any-return]
 
 
-def _infer_name_module(node, name):
+def _infer_name_module(
+    node: nodes.Import, name: str
+) -> Generator[InferenceResult, None, None]:
     context = astroid.context.InferenceContext()
     context.lookupname = name
-    return node.infer(context, asname=False)
+    return node.infer(context, asname=False)  # type: ignore[no-any-return]
 
 
-def _fix_dot_imports(not_consumed):
+def _fix_dot_imports(
+    not_consumed: dict[str, list[nodes.NodeNG]]
+) -> list[tuple[str, _base_nodes.ImportNode]]:
     """Try to fix imports with multiple dots, by returning a dictionary
     with the import names expanded.
 
     The function unflattens root imports,
     like 'xml' (when we have both 'xml.etree' and 'xml.sax'), to 'xml.etree'
     and 'xml.sax' respectively.
     """
-    names = {}
+    names: dict[str, _base_nodes.ImportNode] = {}
     for name, stmts in not_consumed.items():
         if any(
             isinstance(stmt, nodes.AssignName)
             and isinstance(stmt.assign_type(), nodes.AugAssign)
             for stmt in stmts
         ):
             continue
@@ -288,37 +303,42 @@
                     if name_matches_dotted_import or name in imports:
                         # Most likely something like 'xml.etree',
                         # which will appear in the .locals as 'xml'.
                         # Only pick the name if it wasn't consumed.
                         second_name = import_module_name
                 if second_name and second_name not in names:
                     names[second_name] = stmt
-    return sorted(names.items(), key=lambda a: a[1].fromlineno)
+    return sorted(names.items(), key=lambda a: a[1].fromlineno)  # type: ignore[no-any-return]
 
 
-def _find_frame_imports(name, frame):
+def _find_frame_imports(name: str, frame: nodes.LocalsDictNodeNG) -> bool:
     """Detect imports in the frame, with the required *name*.
 
-    Such imports can be considered assignments.
+    Such imports can be considered assignments if they are not globals.
     Returns True if an import for the given name was found.
     """
+    if name in _flattened_scope_names(frame.nodes_of_class(nodes.Global)):
+        return False
+
     imports = frame.nodes_of_class((nodes.Import, nodes.ImportFrom))
     for import_node in imports:
         for import_name, import_alias in import_node.names:
             # If the import uses an alias, check only that.
             # Otherwise, check only the import name.
             if import_alias:
                 if import_alias == name:
                     return True
             elif import_name and import_name == name:
                 return True
-    return None
+    return False
 
 
-def _import_name_is_global(stmt, global_names):
+def _import_name_is_global(
+    stmt: nodes.Global | _base_nodes.ImportNode, global_names: set[str]
+) -> bool:
     for import_name, import_alias in stmt.names:
         # If the import uses an alias, check only that.
         # Otherwise, check only the import name.
         if import_alias:
             if import_alias in global_names:
                 return True
         elif import_name in global_names:
@@ -329,21 +349,24 @@
 def _flattened_scope_names(
     iterator: Iterator[nodes.Global | nodes.Nonlocal],
 ) -> set[str]:
     values = (set(stmt.names) for stmt in iterator)
     return set(itertools.chain.from_iterable(values))
 
 
-def _assigned_locally(name_node):
+def _assigned_locally(name_node: nodes.Name) -> bool:
     """Checks if name_node has corresponding assign statement in same scope."""
-    assign_stmts = name_node.scope().nodes_of_class(nodes.AssignName)
-    return any(a.name == name_node.name for a in assign_stmts)
+    name_node_scope = name_node.scope()
+    assign_stmts = name_node_scope.nodes_of_class(nodes.AssignName)
+    return any(a.name == name_node.name for a in assign_stmts) or _find_frame_imports(
+        name_node.name, name_node_scope
+    )
 
 
-def _has_locals_call_after_node(stmt, scope):
+def _has_locals_call_after_node(stmt: nodes.NodeNG, scope: nodes.FunctionDef) -> bool:
     skip_nodes = (
         nodes.FunctionDef,
         nodes.ClassDef,
         nodes.Import,
         nodes.ImportFrom,
     )
     for call in scope.nodes_of_class(nodes.Call, skip_klass=skip_nodes):
@@ -397,29 +420,30 @@
         "global-variable-undefined",
         'Used when a variable is defined through the "global" statement '
         "but the variable is not defined in the module scope.",
     ),
     "W0602": (
         "Using global for %r but no assignment is done",
         "global-variable-not-assigned",
-        'Used when a variable is defined through the "global" statement '
-        "but no assignment to this variable is done.",
+        "When a variable defined in the global scope is modified in an inner scope, "
+        "the 'global' keyword is required in the inner scope only if there is an "
+        "assignment operation done in the inner scope.",
     ),
     "W0603": (
         "Using the global statement",  # W0121
         "global-statement",
         'Used when you use the "global" statement to update a global '
-        "variable. Pylint just try to discourage this "
-        "usage. That doesn't mean you cannot use it !",
+        "variable. Pylint discourages its usage. That doesn't mean you cannot "
+        "use it!",
     ),
     "W0604": (
         "Using the global statement at the module level",  # W0103
         "global-at-module-level",
         'Used when you use the "global" statement at the module level '
-        "since it has no effect",
+        "since it has no effect.",
     ),
     "W0611": (
         "Unused %s",
         "unused-import",
         "Used when an imported module or variable is not used.",
     ),
     "W0612": (
@@ -452,26 +476,24 @@
         "Using possibly undefined loop variable %r",
         "undefined-loop-variable",
         "Used when a loop variable (i.e. defined by a for loop or "
         "a list comprehension or a generator expression) is used outside "
         "the loop.",
     ),
     "W0632": (
-        "Possible unbalanced tuple unpacking with "
-        "sequence%s: "
-        "left side has %d label(s), right side has %d value(s)",
+        "Possible unbalanced tuple unpacking with sequence %s: left side has %d "
+        "label%s, right side has %d value%s",
         "unbalanced-tuple-unpacking",
         "Used when there is an unbalanced tuple unpacking in assignment",
         {"old_names": [("E0632", "old-unbalanced-tuple-unpacking")]},
     ),
     "E0633": (
         "Attempting to unpack a non-sequence%s",
         "unpacking-non-sequence",
-        "Used when something which is not "
-        "a sequence is used in an unpack assignment",
+        "Used when something which is not a sequence is used in an unpack assignment",
         {"old_names": [("W0633", "old-unpacking-non-sequence")]},
     ),
     "W0640": (
         "Cell variable %s defined in loop",
         "cell-var-from-loop",
         "A variable used in a closure is defined in a loop. "
         "This will result in all closures using the same value for "
@@ -492,14 +514,20 @@
     ),
     "E0643": (
         "Invalid index for iterable length",
         "potential-index-error",
         "Emitted when an index used on an iterable goes beyond the length of that "
         "iterable.",
     ),
+    "W0644": (
+        "Possible unbalanced dict unpacking with %s: "
+        "left side has %d label%s, right side has %d value%s",
+        "unbalanced-dict-unpacking",
+        "Used when there is an unbalanced dict unpacking in assignment or for loop",
+    ),
 }
 
 
 class ScopeConsumer(NamedTuple):
     """Store nodes and their consumption states."""
 
     to_consume: dict[str, list[nodes.NodeNG]]
@@ -507,45 +535,45 @@
     consumed_uncertain: defaultdict[str, list[nodes.NodeNG]]
     scope_type: str
 
 
 class NamesConsumer:
     """A simple class to handle consumed, to consume and scope type info of node locals."""
 
-    def __init__(self, node, scope_type):
+    def __init__(self, node: nodes.NodeNG, scope_type: str) -> None:
         self._atomic = ScopeConsumer(
             copy.copy(node.locals), {}, collections.defaultdict(list), scope_type
         )
         self.node = node
 
-    def __repr__(self):
-        to_consumes = [f"{k}->{v}" for k, v in self._atomic.to_consume.items()]
-        consumed = [f"{k}->{v}" for k, v in self._atomic.consumed.items()]
-        consumed_uncertain = [
+    def __repr__(self) -> str:
+        _to_consumes = [f"{k}->{v}" for k, v in self._atomic.to_consume.items()]
+        _consumed = [f"{k}->{v}" for k, v in self._atomic.consumed.items()]
+        _consumed_uncertain = [
             f"{k}->{v}" for k, v in self._atomic.consumed_uncertain.items()
         ]
-        to_consumes = ", ".join(to_consumes)
-        consumed = ", ".join(consumed)
-        consumed_uncertain = ", ".join(consumed_uncertain)
+        to_consumes = ", ".join(_to_consumes)
+        consumed = ", ".join(_consumed)
+        consumed_uncertain = ", ".join(_consumed_uncertain)
         return f"""
 to_consume : {to_consumes}
 consumed : {consumed}
 consumed_uncertain: {consumed_uncertain}
 scope_type : {self._atomic.scope_type}
 """
 
-    def __iter__(self):
+    def __iter__(self) -> Iterator[Any]:
         return iter(self._atomic)
 
     @property
-    def to_consume(self):
+    def to_consume(self) -> dict[str, list[nodes.NodeNG]]:
         return self._atomic.to_consume
 
     @property
-    def consumed(self):
+    def consumed(self) -> dict[str, list[nodes.NodeNG]]:
         return self._atomic.consumed
 
     @property
     def consumed_uncertain(self) -> defaultdict[str, list[nodes.NodeNG]]:
         """Retrieves nodes filtered out by get_next_to_consume() that may not
         have executed.
 
@@ -553,18 +581,18 @@
         in try blocks (when evaluating their corresponding except and finally
         blocks). Checkers that want to treat the statements as executed
         (e.g. for unused-variable) may need to add them back.
         """
         return self._atomic.consumed_uncertain
 
     @property
-    def scope_type(self):
+    def scope_type(self) -> str:
         return self._atomic.scope_type
 
-    def mark_as_consumed(self, name, consumed_nodes):
+    def mark_as_consumed(self, name: str, consumed_nodes: list[nodes.NodeNG]) -> None:
         """Mark the given nodes as consumed for the name.
 
         If all of the nodes for the name were consumed, delete the name from
         the to_consume dictionary
         """
         unconsumed = [n for n in self.to_consume[name] if n not in set(consumed_nodes)]
         self.consumed[name] = consumed_nodes
@@ -609,14 +637,21 @@
         ):
             return found_nodes
 
         # And no comprehension is under the node's frame
         if VariablesChecker._comprehension_between_frame_and_node(node):
             return found_nodes
 
+        # Filter out assignments guarded by always false conditions
+        if found_nodes:
+            uncertain_nodes = self._uncertain_nodes_in_false_tests(found_nodes, node)
+            self.consumed_uncertain[node.name] += uncertain_nodes
+            uncertain_nodes_set = set(uncertain_nodes)
+            found_nodes = [n for n in found_nodes if n not in uncertain_nodes_set]
+
         # Filter out assignments in ExceptHandlers that node is not contained in
         if found_nodes:
             found_nodes = [
                 n
                 for n in found_nodes
                 if not isinstance(n.statement(future=True), nodes.ExceptHandler)
                 or n.statement(future=True).parent_of(node)
@@ -655,14 +690,139 @@
             self.consumed_uncertain[node.name] += uncertain_nodes
             uncertain_nodes_set = set(uncertain_nodes)
             found_nodes = [n for n in found_nodes if n not in uncertain_nodes_set]
 
         return found_nodes
 
     @staticmethod
+    def _inferred_to_define_name_raise_or_return(name: str, node: nodes.NodeNG) -> bool:
+        """Return True if there is a path under this `if_node`
+        that is inferred to define `name`, raise, or return.
+        """
+        # Handle try and with
+        if isinstance(node, (nodes.TryExcept, nodes.TryFinally)):
+            # Allow either a path through try/else/finally OR a path through ALL except handlers
+            try_except_node = node
+            if isinstance(node, nodes.TryFinally):
+                try_except_node = next(
+                    (child for child in node.nodes_of_class(nodes.TryExcept)),
+                    None,
+                )
+            handlers = try_except_node.handlers if try_except_node else []
+            return NamesConsumer._defines_name_raises_or_returns_recursive(
+                name, node
+            ) or all(
+                NamesConsumer._defines_name_raises_or_returns_recursive(name, handler)
+                for handler in handlers
+            )
+
+        if isinstance(node, (nodes.With, nodes.For, nodes.While)):
+            return NamesConsumer._defines_name_raises_or_returns_recursive(name, node)
+
+        if not isinstance(node, nodes.If):
+            return False
+
+        # Be permissive if there is a break
+        if any(node.nodes_of_class(nodes.Break)):
+            return True
+
+        # Is there an assignment in this node itself, e.g. in named expression?
+        if NamesConsumer._defines_name_raises_or_returns(name, node):
+            return True
+
+        test = node.test.value if isinstance(node.test, nodes.NamedExpr) else node.test
+        all_inferred = utils.infer_all(test)
+        only_search_if = False
+        only_search_else = True
+
+        for inferred in all_inferred:
+            if not isinstance(inferred, nodes.Const):
+                only_search_else = False
+                continue
+            val = inferred.value
+            only_search_if = only_search_if or (val != NotImplemented and val)
+            only_search_else = only_search_else and not val
+
+        # Only search else branch when test condition is inferred to be false
+        if all_inferred and only_search_else:
+            return NamesConsumer._branch_handles_name(name, node.orelse)
+        # Only search if branch when test condition is inferred to be true
+        if all_inferred and only_search_if:
+            return NamesConsumer._branch_handles_name(name, node.body)
+        # Search both if and else branches
+        return NamesConsumer._branch_handles_name(
+            name, node.body
+        ) or NamesConsumer._branch_handles_name(name, node.orelse)
+
+    @staticmethod
+    def _branch_handles_name(name: str, body: Iterable[nodes.NodeNG]) -> bool:
+        return any(
+            NamesConsumer._defines_name_raises_or_returns(name, if_body_stmt)
+            or isinstance(
+                if_body_stmt,
+                (
+                    nodes.If,
+                    nodes.TryExcept,
+                    nodes.TryFinally,
+                    nodes.With,
+                    nodes.For,
+                    nodes.While,
+                ),
+            )
+            and NamesConsumer._inferred_to_define_name_raise_or_return(
+                name, if_body_stmt
+            )
+            for if_body_stmt in body
+        )
+
+    def _uncertain_nodes_in_false_tests(
+        self, found_nodes: list[nodes.NodeNG], node: nodes.NodeNG
+    ) -> list[nodes.NodeNG]:
+        """Identify nodes of uncertain execution because they are defined under
+        tests that evaluate false.
+
+        Don't identify a node if there is a path that is inferred to
+        define the name, raise, or return (e.g. any executed if/elif/else branch).
+        """
+        uncertain_nodes = []
+        for other_node in found_nodes:
+            if isinstance(other_node, nodes.AssignName):
+                name = other_node.name
+            elif isinstance(other_node, (nodes.Import, nodes.ImportFrom)):
+                name = node.name
+            else:
+                continue
+
+            all_if = [
+                n
+                for n in other_node.node_ancestors()
+                if isinstance(n, nodes.If) and not n.parent_of(node)
+            ]
+            if not all_if:
+                continue
+
+            closest_if = all_if[0]
+            if (
+                isinstance(node, nodes.AssignName)
+                and node.frame() is not closest_if.frame()
+            ):
+                continue
+            if closest_if.parent_of(node):
+                continue
+
+            outer_if = all_if[-1]
+            # Name defined in the if/else control flow
+            if NamesConsumer._inferred_to_define_name_raise_or_return(name, outer_if):
+                continue
+
+            uncertain_nodes.append(other_node)
+
+        return uncertain_nodes
+
+    @staticmethod
     def _uncertain_nodes_in_except_blocks(
         found_nodes: list[nodes.NodeNG],
         node: nodes.NodeNG,
         node_statement: nodes.Statement,
     ) -> list[nodes.NodeNG]:
         """Return any nodes in ``found_nodes`` that should be treated as uncertain
         because they are in an except block.
@@ -676,98 +836,134 @@
             )
             if not closest_except_handler:
                 continue
             # If the other node is in the same scope as this node, assume it executes
             if closest_except_handler.parent_of(node):
                 continue
             closest_try_except: nodes.TryExcept = closest_except_handler.parent
+            # If the try or else blocks return, assume the except blocks execute.
             try_block_returns = any(
                 isinstance(try_statement, nodes.Return)
                 for try_statement in closest_try_except.body
             )
-            # If the try block returns, assume the except blocks execute.
-            if try_block_returns:
+            else_block_returns = any(
+                isinstance(else_statement, nodes.Return)
+                for else_statement in closest_try_except.orelse
+            )
+            else_block_exits = any(
+                isinstance(else_statement, nodes.Expr)
+                and isinstance(else_statement.value, nodes.Call)
+                and utils.is_terminating_func(else_statement.value)
+                for else_statement in closest_try_except.orelse
+            )
+
+            if try_block_returns or else_block_returns or else_block_exits:
                 # Exception: if this node is in the final block of the other_node_statement,
                 # it will execute before returning. Assume the except statements are uncertain.
                 if (
                     isinstance(node_statement.parent, nodes.TryFinally)
                     and node_statement in node_statement.parent.finalbody
                     and closest_try_except.parent.parent_of(node_statement)
                 ):
                     uncertain_nodes.append(other_node)
+                # Or the node_statement is in the else block of the relevant TryExcept
+                elif (
+                    isinstance(node_statement.parent, nodes.TryExcept)
+                    and node_statement in node_statement.parent.orelse
+                    and closest_try_except.parent.parent_of(node_statement)
+                ):
+                    uncertain_nodes.append(other_node)
                 # Assume the except blocks execute, so long as each handler
                 # defines the name, raises, or returns.
                 elif all(
-                    NamesConsumer._defines_name_raises_or_returns(node.name, handler)
+                    NamesConsumer._defines_name_raises_or_returns_recursive(
+                        node.name, handler
+                    )
                     for handler in closest_try_except.handlers
                 ):
                     continue
 
             if NamesConsumer._check_loop_finishes_via_except(node, closest_try_except):
                 continue
 
             # Passed all tests for uncertain execution
             uncertain_nodes.append(other_node)
         return uncertain_nodes
 
     @staticmethod
-    def _defines_name_raises_or_returns(
-        name: str, handler: nodes.ExceptHandler
+    def _defines_name_raises_or_returns(name: str, node: nodes.NodeNG) -> bool:
+        if isinstance(node, (nodes.Raise, nodes.Assert, nodes.Return)):
+            return True
+        if (
+            isinstance(node, nodes.AnnAssign)
+            and node.value
+            and isinstance(node.target, nodes.AssignName)
+            and node.target.name == name
+        ):
+            return True
+        if isinstance(node, nodes.Assign):
+            for target in node.targets:
+                for elt in utils.get_all_elements(target):
+                    if isinstance(elt, nodes.Starred):
+                        elt = elt.value
+                    if isinstance(elt, nodes.AssignName) and elt.name == name:
+                        return True
+        if isinstance(node, nodes.If):
+            if any(
+                child_named_expr.target.name == name
+                for child_named_expr in node.nodes_of_class(nodes.NamedExpr)
+            ):
+                return True
+        if isinstance(node, (nodes.Import, nodes.ImportFrom)) and any(
+            (node_name[1] and node_name[1] == name) or (node_name[0] == name)
+            for node_name in node.names
+        ):
+            return True
+        if isinstance(node, nodes.With) and any(
+            isinstance(item[1], nodes.AssignName) and item[1].name == name
+            for item in node.items
+        ):
+            return True
+        if isinstance(node, (nodes.ClassDef, nodes.FunctionDef)) and node.name == name:
+            return True
+        return False
+
+    @staticmethod
+    def _defines_name_raises_or_returns_recursive(
+        name: str, node: nodes.NodeNG
     ) -> bool:
-        """Return True if some child of `handler` defines the name `name`,
+        """Return True if some child of `node` defines the name `name`,
         raises, or returns.
         """
-
-        def _define_raise_or_return(stmt: nodes.NodeNG) -> bool:
-            if isinstance(stmt, (nodes.Raise, nodes.Return)):
-                return True
-            if isinstance(stmt, nodes.Assign):
-                for target in stmt.targets:
-                    for elt in utils.get_all_elements(target):
-                        if isinstance(elt, nodes.AssignName) and elt.name == name:
-                            return True
-            if isinstance(stmt, nodes.If):
-                # Check for assignments inside the test
-                if (
-                    isinstance(stmt.test, nodes.NamedExpr)
-                    and stmt.test.target.name == name
-                ):
-                    return True
-                if isinstance(stmt.test, nodes.Call):
-                    for arg_or_kwarg in stmt.test.args + [
-                        kw.value for kw in stmt.test.keywords
-                    ]:
-                        if (
-                            isinstance(arg_or_kwarg, nodes.NamedExpr)
-                            and arg_or_kwarg.target.name == name
-                        ):
-                            return True
-            return False
-
-        for stmt in handler.get_children():
-            if _define_raise_or_return(stmt):
+        for stmt in node.get_children():
+            if NamesConsumer._defines_name_raises_or_returns(name, stmt):
                 return True
             if isinstance(stmt, (nodes.If, nodes.With)):
                 if any(
-                    _define_raise_or_return(nested_stmt)
+                    NamesConsumer._defines_name_raises_or_returns(name, nested_stmt)
                     for nested_stmt in stmt.get_children()
                 ):
                     return True
+            if isinstance(
+                stmt, nodes.TryExcept
+            ) and NamesConsumer._defines_name_raises_or_returns_recursive(name, stmt):
+                return True
         return False
 
     @staticmethod
     def _check_loop_finishes_via_except(
         node: nodes.NodeNG, other_node_try_except: nodes.TryExcept
     ) -> bool:
-        """Check for a case described in https://github.com/PyCQA/pylint/issues/5683.
+        """Check for a specific control flow scenario.
 
-        It consists of a specific control flow scenario where the only
-        non-break exit from a loop consists of the very except handler we are
-        examining, such that code in the `else` branch of the loop can depend on it
-        being assigned.
+        Described in https://github.com/pylint-dev/pylint/issues/5683.
+
+        A scenario where the only non-break exit from a loop consists of the very
+        except handler we are examining, such that code in the `else` branch of
+        the loop can depend on it being assigned.
 
         Example:
 
         for _ in range(3):
             try:
                 do_something()
             except:
@@ -1025,16 +1221,15 @@
         ),
         (
             "ignored-argument-names",
             {
                 "default": IGNORED_ARGUMENT_NAMES,
                 "type": "regexp",
                 "metavar": "<regexp>",
-                "help": "Argument names that match this expression will be "
-                "ignored. Default to name with leading underscore.",
+                "help": "Argument names that match this expression will be ignored.",
             },
         ),
         (
             "allow-global-unused-variables",
             {
                 "default": True,
                 "type": "yn",
@@ -1049,33 +1244,58 @@
                 "type": "csv",
                 "metavar": "<comma separated list>",
                 "help": "List of names allowed to shadow builtins",
             },
         ),
     )
 
-    def __init__(self, linter=None):
+    def __init__(self, linter: PyLinter) -> None:
         super().__init__(linter)
         self._to_consume: list[NamesConsumer] = []
-        self._checking_mod_attr = None
-        self._type_annotation_names = []
+        self._type_annotation_names: list[str] = []
         self._except_handler_names_queue: list[
             tuple[nodes.ExceptHandler, nodes.AssignName]
         ] = []
         """This is a queue, last in first out."""
         self._postponed_evaluation_enabled = False
 
-    def open(self) -> None:
-        """Called when loading the checker."""
-        self._is_undefined_variable_enabled = self.linter.is_message_enabled(
-            "undefined-variable"
-        )
-        self._is_undefined_loop_variable_enabled = self.linter.is_message_enabled(
-            "undefined-loop-variable"
-        )
+    @utils.only_required_for_messages(
+        "unbalanced-dict-unpacking",
+    )
+    def visit_for(self, node: nodes.For) -> None:
+        if not isinstance(node.target, nodes.Tuple):
+            return
+
+        targets = node.target.elts
+
+        inferred = utils.safe_infer(node.iter)
+        if not isinstance(inferred, DICT_TYPES):
+            return
+
+        values = self._nodes_to_unpack(inferred)
+        if not values:
+            # no dict items returned
+            return
+
+        if isinstance(inferred, astroid.objects.DictItems):
+            # dict.items() is a bit special because values will be a tuple
+            # So as long as there are always 2 targets and values each are
+            # a tuple with two items, this will unpack correctly.
+            # Example: `for key, val in {1: 2, 3: 4}.items()`
+            if len(targets) == 2 and all(len(x.elts) == 2 for x in values):
+                return
+
+            # Starred nodes indicate ambiguous unpacking
+            # if `dict.items()` is used so we won't flag them.
+            if any(isinstance(target, nodes.Starred) for target in targets):
+                return
+
+        if len(targets) != len(values):
+            details = _get_unpacking_extra_info(node, inferred)
+            self._report_unbalanced_unpacking(node, inferred, targets, values, details)
 
     def leave_for(self, node: nodes.For) -> None:
         self._store_type_annotation_names(node)
 
     def visit_module(self, node: nodes.Module) -> None:
         """Visit module : update consumption analysis variable
         checks globals doesn't overrides builtins.
@@ -1113,22 +1333,38 @@
         self._check_globals(not_consumed)
 
         # don't check unused imports in __init__ files
         if not self.linter.config.init_import and node.package:
             return
 
         self._check_imports(not_consumed)
+        self._type_annotation_names = []
 
     def visit_classdef(self, node: nodes.ClassDef) -> None:
         """Visit class: update consumption analysis variable."""
         self._to_consume.append(NamesConsumer(node, "class"))
 
-    def leave_classdef(self, _: nodes.ClassDef) -> None:
+    def leave_classdef(self, node: nodes.ClassDef) -> None:
         """Leave class: update consumption analysis variable."""
-        # do not check for not used locals here (no sense)
+        # Check for hidden ancestor names
+        # e.g. "six" in: Class X(six.with_metaclass(ABCMeta, object)):
+        for name_node in node.nodes_of_class(nodes.Name):
+            if (
+                isinstance(name_node.parent, nodes.Call)
+                and isinstance(name_node.parent.func, nodes.Attribute)
+                and isinstance(name_node.parent.func.expr, nodes.Name)
+            ):
+                hidden_name_node = name_node.parent.func.expr
+                for consumer in self._to_consume:
+                    if hidden_name_node.name in consumer.to_consume:
+                        consumer.mark_as_consumed(
+                            hidden_name_node.name,
+                            consumer.to_consume[hidden_name_node.name],
+                        )
+                        break
         self._to_consume.pop()
 
     def visit_lambda(self, node: nodes.Lambda) -> None:
         """Visit lambda: update consumption analysis variable."""
         self._to_consume.append(NamesConsumer(node, "lambda"))
 
     def leave_lambda(self, _: nodes.Lambda) -> None:
@@ -1181,17 +1417,15 @@
                 ):
                     # It is a __future__ directive, not a symbol.
                     continue
 
                 # Do not take in account redefined names for the purpose
                 # of type checking.:
                 if any(
-                    isinstance(definition.parent, nodes.If)
-                    and definition.parent.test.as_string() in TYPING_TYPE_CHECKS_GUARDS
-                    for definition in globs[name]
+                    in_type_checking_block(definition) for definition in globs[name]
                 ):
                     continue
 
                 line = definition.fromlineno
                 if not self._is_name_ignored(stmt, name):
                     self.add_message(
                         "redefined-outer-name", args=(name, line), node=stmt
@@ -1230,21 +1464,20 @@
         # Don't check arguments of abstract methods or within an interface.
         is_method = node.is_method()
         if is_method and node.is_abstract():
             return
 
         global_names = _flattened_scope_names(node.nodes_of_class(nodes.Global))
         nonlocal_names = _flattened_scope_names(node.nodes_of_class(nodes.Nonlocal))
-        comprehension_target_names: list[str] = []
+        comprehension_target_names: set[str] = set()
 
         for comprehension_scope in node.nodes_of_class(nodes.ComprehensionScope):
             for generator in comprehension_scope.generators:
-                self._find_assigned_names_recursive(
-                    generator.target, comprehension_target_names
-                )
+                for name in utils.find_assigned_names_recursive(generator.target):
+                    comprehension_target_names.add(name)
 
         for name, stmts in not_consumed.items():
             self._check_is_unused(
                 name,
                 node,
                 stmts[0],
                 global_names,
@@ -1262,36 +1495,42 @@
         "global-at-module-level",
         "redefined-builtin",
     )
     def visit_global(self, node: nodes.Global) -> None:
         """Check names imported exists in the global scope."""
         frame = node.frame(future=True)
         if isinstance(frame, nodes.Module):
-            self.add_message("global-at-module-level", node=node)
+            self.add_message("global-at-module-level", node=node, confidence=HIGH)
             return
 
         module = frame.root()
         default_message = True
         locals_ = node.scope().locals
         for name in node.names:
             try:
                 assign_nodes = module.getattr(name)
             except astroid.NotFoundError:
                 # unassigned global, skip
                 assign_nodes = []
 
             not_defined_locally_by_import = not any(
-                isinstance(local, nodes.Import) for local in locals_.get(name, ())
+                isinstance(local, (nodes.Import, nodes.ImportFrom))
+                for local in locals_.get(name, ())
             )
             if (
                 not utils.is_reassigned_after_current(node, name)
                 and not utils.is_deleted_after_current(node, name)
                 and not_defined_locally_by_import
             ):
-                self.add_message("global-variable-not-assigned", args=name, node=node)
+                self.add_message(
+                    "global-variable-not-assigned",
+                    args=name,
+                    node=node,
+                    confidence=HIGH,
+                )
                 default_message = False
                 continue
 
             for anode in assign_nodes:
                 if (
                     isinstance(anode, nodes.AssignName)
                     and anode.name in module.special_attributes
@@ -1306,42 +1545,46 @@
                     and anode.parent is module
                 ):
                     # module level function assignment
                     break
             else:
                 if not_defined_locally_by_import:
                     # global undefined at the module scope
-                    self.add_message("global-variable-undefined", args=name, node=node)
+                    self.add_message(
+                        "global-variable-undefined",
+                        args=name,
+                        node=node,
+                        confidence=HIGH,
+                    )
                     default_message = False
 
         if default_message:
-            self.add_message("global-statement", node=node)
+            self.add_message("global-statement", node=node, confidence=HIGH)
 
     def visit_assignname(self, node: nodes.AssignName) -> None:
         if isinstance(node.assign_type(), nodes.AugAssign):
             self.visit_name(node)
 
     def visit_delname(self, node: nodes.DelName) -> None:
         self.visit_name(node)
 
-    def visit_name(self, node: nodes.Name) -> None:
+    def visit_name(self, node: nodes.Name | nodes.AssignName | nodes.DelName) -> None:
         """Don't add the 'utils.only_required_for_messages' decorator here!
 
         It's important that all 'Name' nodes are visited, otherwise the
         'NamesConsumers' won't be correct.
         """
         stmt = node.statement(future=True)
         if stmt.fromlineno is None:
             # name node from an astroid built from live code, skip
             assert not stmt.root().file.endswith(".py")
             return
 
         self._undefined_and_used_before_checker(node, stmt)
-        if self._is_undefined_loop_variable_enabled:
-            self._loopvar_name(node)
+        self._loopvar_name(node)
 
     @utils.only_required_for_messages("redefined-outer-name")
     def visit_excepthandler(self, node: nodes.ExceptHandler) -> None:
         if not node.name or not isinstance(node.name, nodes.AssignName):
             return
 
         for outer_except, outer_except_assign_name in self._except_handler_names_queue:
@@ -1390,28 +1633,27 @@
             if action is VariableVisitConsumerAction.CONTINUE:
                 continue
             if action is VariableVisitConsumerAction.RETURN:
                 return
 
         # we have not found the name, if it isn't a builtin, that's an
         # undefined name !
-        if (
-            self._is_undefined_variable_enabled
-            and not (
-                node.name in nodes.Module.scope_attrs
-                or utils.is_builtin(node.name)
-                or node.name in self.linter.config.additional_builtins
-                or (
-                    node.name == "__class__"
-                    and isinstance(frame, nodes.FunctionDef)
-                    and frame.is_method()
+        if not (
+            node.name in nodes.Module.scope_attrs
+            or utils.is_builtin(node.name)
+            or node.name in self.linter.config.additional_builtins
+            or (
+                node.name == "__class__"
+                and any(
+                    i.is_method()
+                    for i in node.node_ancestors()
+                    if isinstance(i, nodes.FunctionDef)
                 )
             )
-            and not utils.node_ignores_exception(node, NameError)
-        ):
+        ) and not utils.node_ignores_exception(node, NameError):
             self.add_message("undefined-variable", args=node.name, node=node)
 
     def _should_node_be_skipped(
         self, node: nodes.Name, consumer: NamesConsumer, is_start_index: bool
     ) -> bool:
         """Tests a consumer and node for various conditions in which the node shouldn't
         be checked for the undefined-variable and used-before-assignment checks.
@@ -1445,79 +1687,73 @@
         elif consumer.scope_type == "lambda" and utils.is_default_argument(
             node, consumer.node
         ):
             return True
 
         return False
 
-    def _find_assigned_names_recursive(
-        self,
-        target: nodes.AssignName | nodes.BaseContainer,
-        target_names: list[str],
-    ) -> None:
-        """Update `target_names` in place with the names of assignment
-        targets, recursively (to account for nested assignments).
-        """
-        if isinstance(target, nodes.AssignName):
-            target_names.append(target.name)
-        elif isinstance(target, nodes.BaseContainer):
-            for elt in target.elts:
-                self._find_assigned_names_recursive(elt, target_names)
-
-    # pylint: disable=too-many-return-statements
+    # pylint: disable = too-many-return-statements, too-many-branches
     def _check_consumer(
         self,
         node: nodes.Name,
         stmt: nodes.NodeNG,
         frame: nodes.LocalsDictNodeNG,
         current_consumer: NamesConsumer,
-        base_scope_type: Any,
+        base_scope_type: str,
     ) -> tuple[VariableVisitConsumerAction, list[nodes.NodeNG] | None]:
         """Checks a consumer for conditions that should trigger messages."""
         # If the name has already been consumed, only check it's not a loop
         # variable used outside the loop.
         if node.name in current_consumer.consumed:
             # Avoid the case where there are homonyms inside function scope and
             # comprehension current scope (avoid bug #1731)
             if utils.is_func_decorator(current_consumer.node) or not isinstance(
                 node, nodes.ComprehensionScope
             ):
                 self._check_late_binding_closure(node)
-                self._loopvar_name(node)
                 return (VariableVisitConsumerAction.RETURN, None)
 
         found_nodes = current_consumer.get_next_to_consume(node)
         if found_nodes is None:
             return (VariableVisitConsumerAction.CONTINUE, None)
         if not found_nodes:
-            if node.name in current_consumer.consumed_uncertain:
-                confidence = CONTROL_FLOW
-            else:
-                confidence = HIGH
-            self.add_message(
-                "used-before-assignment",
-                args=node.name,
-                node=node,
-                confidence=confidence,
-            )
+            if (
+                not (
+                    self._postponed_evaluation_enabled
+                    and utils.is_node_in_type_annotation_context(node)
+                )
+                and not self._is_builtin(node.name)
+                and not self._is_variable_annotation_in_function(node)
+            ):
+                confidence = (
+                    CONTROL_FLOW
+                    if node.name in current_consumer.consumed_uncertain
+                    else HIGH
+                )
+                self.add_message(
+                    "used-before-assignment",
+                    args=node.name,
+                    node=node,
+                    confidence=confidence,
+                )
             # Mark for consumption any nodes added to consumed_uncertain by
             # get_next_to_consume() because they might not have executed.
             return (
                 VariableVisitConsumerAction.RETURN,
                 current_consumer.consumed_uncertain[node.name],
             )
 
         self._check_late_binding_closure(node)
 
         defnode = utils.assign_parent(found_nodes[0])
         defstmt = defnode.statement(future=True)
         defframe = defstmt.frame(future=True)
 
         # The class reuses itself in the class scope.
-        is_recursive_klass = (
+        is_recursive_klass: bool = (
             frame is defframe
             and defframe.parent_of(node)
             and isinstance(defframe, nodes.ClassDef)
             and node.name == defframe.name
         )
 
         if (
@@ -1566,27 +1802,25 @@
             return (VariableVisitConsumerAction.CONTINUE, None)
 
         if (
             maybe_before_assign
             and not utils.is_defined_before(node)
             and not astroid.are_exclusive(stmt, defstmt, ("NameError",))
         ):
-
             # Used and defined in the same place, e.g `x += 1` and `del x`
             defined_by_stmt = defstmt is stmt and isinstance(
                 node, (nodes.DelName, nodes.AssignName)
             )
             if (
                 is_recursive_klass
                 or defined_by_stmt
                 or annotation_return
                 or isinstance(defstmt, nodes.Delete)
             ):
                 if not utils.node_ignores_exception(node, NameError):
-
                     # Handle postponed evaluation of annotations
                     if not (
                         self._postponed_evaluation_enabled
                         and isinstance(
                             stmt,
                             (
                                 nodes.AnnAssign,
@@ -1599,18 +1833,22 @@
                         if defined_by_stmt:
                             return (VariableVisitConsumerAction.CONTINUE, [node])
                         return (VariableVisitConsumerAction.CONTINUE, None)
 
             elif base_scope_type != "lambda":
                 # E0601 may *not* occurs in lambda scope.
 
-                # Handle postponed evaluation of annotations
+                # Skip postponed evaluation of annotations
+                # and unevaluated annotations inside a function body
                 if not (
                     self._postponed_evaluation_enabled
                     and isinstance(stmt, (nodes.AnnAssign, nodes.FunctionDef))
+                ) and not (
+                    isinstance(stmt, nodes.AnnAssign)
+                    and utils.get_node_first_ancestor_of_type(stmt, nodes.FunctionDef)
                 ):
                     self.add_message(
                         "used-before-assignment",
                         args=node.name,
                         node=node,
                         confidence=HIGH,
                     )
@@ -1634,15 +1872,17 @@
                     self.add_message(
                         "used-before-assignment",
                         args=node.name,
                         node=node,
                         confidence=HIGH,
                     )
 
-        elif self._is_only_type_assignment(node, defstmt):
+        elif not self._is_builtin(node.name) and self._is_only_type_assignment(
+            node, defstmt
+        ):
             if node.scope().locals.get(node.name):
                 self.add_message(
                     "used-before-assignment", args=node.name, node=node, confidence=HIGH
                 )
             else:
                 self.add_message(
                     "undefined-variable", args=node.name, node=node, confidence=HIGH
@@ -1668,17 +1908,18 @@
     @utils.only_required_for_messages("no-name-in-module")
     def visit_import(self, node: nodes.Import) -> None:
         """Check modules attribute accesses."""
         if not self._analyse_fallback_blocks and utils.is_from_fallback_block(node):
             # No need to verify this, since ImportError is already
             # handled by the client code.
             return
-        if utils.is_node_in_guarded_import_block(node) is True:
-            # Don't verify import if part of guarded import block
-            # I.e. `sys.version_info` or `typing.TYPE_CHECKING`
+        # Don't verify import if part of guarded import block
+        if in_type_checking_block(node):
+            return
+        if isinstance(node.parent, nodes.If) and is_sys_guard(node.parent):
             return
 
         for name, _ in node.names:
             parts = name.split(".")
             try:
                 module = next(_infer_name_module(node, parts[0]))
             except astroid.ResolveError:
@@ -1690,17 +1931,19 @@
     @utils.only_required_for_messages("no-name-in-module")
     def visit_importfrom(self, node: nodes.ImportFrom) -> None:
         """Check modules attribute accesses."""
         if not self._analyse_fallback_blocks and utils.is_from_fallback_block(node):
             # No need to verify this, since ImportError is already
             # handled by the client code.
             return
-        if utils.is_node_in_guarded_import_block(node) is True:
-            # Don't verify import if part of guarded import block
-            # I.e. `sys.version_info` or `typing.TYPE_CHECKING`
+        # Don't verify import if part of guarded import block
+        # I.e. `sys.version_info` or `typing.TYPE_CHECKING`
+        if in_type_checking_block(node):
+            return
+        if isinstance(node.parent, nodes.If) and is_sys_guard(node.parent):
             return
 
         name_parts = node.modname.split(".")
         try:
             module = node.do_import_module(name_parts[0])
         except astroid.AstroidBuildingException:
             return
@@ -1709,25 +1952,33 @@
             return
         for name, _ in node.names:
             if name == "*":
                 continue
             self._check_module_attrs(node, module, name.split("."))
 
     @utils.only_required_for_messages(
-        "unbalanced-tuple-unpacking", "unpacking-non-sequence", "self-cls-assignment"
+        "unbalanced-tuple-unpacking",
+        "unpacking-non-sequence",
+        "self-cls-assignment",
+        "unbalanced_dict_unpacking",
     )
     def visit_assign(self, node: nodes.Assign) -> None:
         """Check unbalanced tuple unpacking for assignments and unpacking
         non-sequences as well as in case self/cls get assigned.
         """
         self._check_self_cls_assign(node)
         if not isinstance(node.targets[0], (nodes.Tuple, nodes.List)):
             return
 
         targets = node.targets[0].itered()
+
+        # Check if we have starred nodes.
+        if any(isinstance(target, nodes.Starred) for target in targets):
+            return
+
         try:
             inferred = utils.safe_infer(node.value)
             if inferred is not None:
                 self._check_unpacking(inferred, node, targets)
         except astroid.InferenceError:
             return
 
@@ -1749,27 +2000,29 @@
 
     def visit_arguments(self, node: nodes.Arguments) -> None:
         for annotation in node.type_comment_args:
             self._store_type_annotation_node(annotation)
 
     # Relying on other checker's options, which might not have been initialized yet.
     @cached_property
-    def _analyse_fallback_blocks(self):
-        return self.linter.config.analyse_fallback_blocks
+    def _analyse_fallback_blocks(self) -> bool:
+        return bool(self.linter.config.analyse_fallback_blocks)
 
     @cached_property
-    def _ignored_modules(self):
-        return self.linter.config.ignored_modules
+    def _ignored_modules(self) -> Iterable[str]:
+        return self.linter.config.ignored_modules  # type: ignore[no-any-return]
 
     @cached_property
-    def _allow_global_unused_variables(self):
-        return self.linter.config.allow_global_unused_variables
+    def _allow_global_unused_variables(self) -> bool:
+        return bool(self.linter.config.allow_global_unused_variables)
 
     @staticmethod
-    def _defined_in_function_definition(node, frame):
+    def _defined_in_function_definition(
+        node: nodes.NodeNG, frame: nodes.NodeNG
+    ) -> bool:
         in_annotation_or_default_or_decorator = False
         if (
             isinstance(frame, nodes.FunctionDef)
             and node.statement(future=True) is frame
         ):
             in_annotation_or_default_or_decorator = (
                 (
@@ -1815,23 +2068,22 @@
             child = parent
             parent = parent.parent
         return False
 
     @staticmethod
     def _is_variable_violation(
         node: nodes.Name,
-        defnode,
+        defnode: nodes.NodeNG,
         stmt: nodes.Statement,
         defstmt: nodes.Statement,
-        frame,  # scope of statement of node
-        defframe,
-        base_scope_type,
-        is_recursive_klass,
+        frame: nodes.LocalsDictNodeNG,  # scope of statement of node
+        defframe: nodes.LocalsDictNodeNG,
+        base_scope_type: str,
+        is_recursive_klass: bool,
     ) -> tuple[bool, bool, bool]:
-        # pylint: disable=too-many-nested-blocks
         maybe_before_assign = True
         annotation_return = False
         use_outer_definition = False
         if frame is not defframe:
             maybe_before_assign = _detect_global_scope(node, frame, defframe)
         elif defframe.parent is None:
             # we are at the module level, check the name is not
@@ -1864,15 +2116,14 @@
                 )
 
         if (
             base_scope_type == "lambda"
             and isinstance(frame, nodes.ClassDef)
             and node.name in frame.locals
         ):
-
             # This rule verifies that if the definition node of the
             # checked name is an Arguments node and if the name
             # is used a default value in the arguments defaults
             # and the actual definition of the variable label
             # is happening before the Arguments definition.
             #
             # bar = None
@@ -1916,24 +2167,15 @@
                     and defframe.parent_of(node)
                     and stmt is not defstmt
                 ):
                     # Single statement function, with the statement on the
                     # same line as the function definition
                     maybe_before_assign = False
                 elif (
-                    isinstance(
-                        defstmt,
-                        (
-                            nodes.Assign,
-                            nodes.AnnAssign,
-                            nodes.AugAssign,
-                            nodes.Expr,
-                            nodes.Return,
-                        ),
-                    )
+                    isinstance(defstmt, NODES_WITH_VALUE_ATTR)
                     and VariablesChecker._maybe_used_and_assigned_at_once(defstmt)
                     and frame is defframe
                     and defframe.parent_of(node)
                     and stmt is defstmt
                 ):
                     # Single statement if, with assignment expression on same
                     # line as assignment
@@ -1967,80 +2209,71 @@
                                     nodes.Return,
                                 ),
                             )
                             and isinstance(defstmt.value, nodes.JoinedStr)
                         )
                     )
                 ):
-                    # Expressions, with assignment expressions
-                    # Use only after assignment
-                    # b = (c := 2) and c
-                    maybe_before_assign = False
-
-            # Look for type checking definitions inside a type checking guard.
-            if isinstance(defstmt, (nodes.Import, nodes.ImportFrom)):
-                defstmt_parent = defstmt.parent
-
-                if (
-                    isinstance(defstmt_parent, nodes.If)
-                    and defstmt_parent.test.as_string() in TYPING_TYPE_CHECKS_GUARDS
-                ):
-                    # Exempt those definitions that are used inside the type checking
-                    # guard or that are defined in both type checking guard branches.
-                    used_in_branch = defstmt_parent.parent_of(node)
-                    defined_in_or_else = False
-
-                    for definition in defstmt_parent.orelse:
-                        if isinstance(definition, nodes.Assign):
-                            defined_in_or_else = any(
-                                target.name == node.name
-                                for target in definition.targets
-                                if isinstance(target, nodes.AssignName)
-                            )
-                            if defined_in_or_else:
-                                break
-
-                    if not used_in_branch and not defined_in_or_else:
-                        maybe_before_assign = True
+                    # Relation of a name to the same name in a named expression
+                    # Could be used before assignment if self-referencing:
+                    # (b := b)
+                    # Otherwise, safe if used after assignment:
+                    # (b := 2) and b
+                    maybe_before_assign = defnode.value is node or any(
+                        anc is defnode.value for anc in node.node_ancestors()
+                    )
 
         return maybe_before_assign, annotation_return, use_outer_definition
 
     @staticmethod
     def _maybe_used_and_assigned_at_once(defstmt: nodes.Statement) -> bool:
         """Check if `defstmt` has the potential to use and assign a name in the
         same statement.
         """
-        if isinstance(defstmt.value, nodes.BaseContainer) and defstmt.value.elts:
-            # The assignment must happen as part of the first element
-            # e.g. "assert (x:= True), x"
-            # NOT "assert x, (x:= True)"
-            value = defstmt.value.elts[0]
-        else:
-            value = defstmt.value
+        if isinstance(defstmt, nodes.Match):
+            return any(case.guard for case in defstmt.cases)
+        if isinstance(defstmt, nodes.IfExp):
+            return True
+        if isinstance(defstmt.value, nodes.BaseContainer):
+            return any(
+                VariablesChecker._maybe_used_and_assigned_at_once(elt)
+                for elt in defstmt.value.elts
+                if isinstance(elt, (*NODES_WITH_VALUE_ATTR, nodes.IfExp, nodes.Match))
+            )
+        value = defstmt.value
         if isinstance(value, nodes.IfExp):
             return True
         if isinstance(value, nodes.Lambda) and isinstance(value.body, nodes.IfExp):
             return True
-        return isinstance(value, nodes.Call) and (
-            any(isinstance(kwarg.value, nodes.IfExp) for kwarg in value.keywords)
-            or any(isinstance(arg, nodes.IfExp) for arg in value.args)
+        if isinstance(value, nodes.Dict) and any(
+            isinstance(item[0], nodes.IfExp) or isinstance(item[1], nodes.IfExp)
+            for item in value.items
+        ):
+            return True
+        if not isinstance(value, nodes.Call):
+            return False
+        return any(
+            any(isinstance(kwarg.value, nodes.IfExp) for kwarg in call.keywords)
+            or any(isinstance(arg, nodes.IfExp) for arg in call.args)
+            or (
+                isinstance(call.func, nodes.Attribute)
+                and isinstance(call.func.expr, nodes.IfExp)
+            )
+            for call in value.nodes_of_class(klass=nodes.Call)
         )
 
-    def _is_only_type_assignment(
-        self, node: nodes.Name, defstmt: nodes.Statement
-    ) -> bool:
+    def _is_builtin(self, name: str) -> bool:
+        return name in self.linter.config.additional_builtins or utils.is_builtin(name)
+
+    @staticmethod
+    def _is_only_type_assignment(node: nodes.Name, defstmt: nodes.Statement) -> bool:
         """Check if variable only gets assigned a type and never a value."""
         if not isinstance(defstmt, nodes.AnnAssign) or defstmt.value:
             return False
 
-        if node.name in self.linter.config.additional_builtins or utils.is_builtin(
-            node.name
-        ):
-            return False
-
         defstmt_frame = defstmt.frame(future=True)
         node_frame = node.frame(future=True)
 
         parent = node
         while parent is not defstmt_frame.parent:
             parent_scope = parent.scope()
 
@@ -2070,14 +2303,22 @@
                 # If the parent of the local reference is anything but an AnnAssign
                 # Or if the AnnAssign adds a value the variable will now have a value
                 #     var = 1  # OR
                 #     var: int = 1
                 if (
                     not isinstance(ref_node.parent, nodes.AnnAssign)
                     or ref_node.parent.value
+                ) and not (
+                    # EXCEPTION: will not have a value if a self-referencing named expression
+                    # var: int
+                    # if (var := var * var)  <-- "var" still undefined
+                    isinstance(ref_node.parent, nodes.NamedExpr)
+                    and any(
+                        anc is ref_node.parent.value for anc in node.node_ancestors()
+                    )
                 ):
                     return False
             parent = parent_scope.parent
         return True
 
     @staticmethod
     def _is_first_level_self_reference(
@@ -2113,14 +2354,24 @@
         if isinstance(inferred_test, nodes.Const):
             if inferred_test.value is True and defnode == defnode_parent.orelse:
                 return True
             if inferred_test.value is False and defnode == defnode_parent.body:
                 return True
         return False
 
+    @staticmethod
+    def _is_variable_annotation_in_function(node: nodes.NodeNG) -> bool:
+        is_annotation = utils.get_node_first_ancestor_of_type(node, nodes.AnnAssign)
+        return (
+            is_annotation
+            and utils.get_node_first_ancestor_of_type(  # type: ignore[return-value]
+                is_annotation, nodes.FunctionDef
+            )
+        )
+
     def _ignore_class_scope(self, node: nodes.NodeNG) -> bool:
         """Return True if the node is in a local class scope, as an assignment.
 
         Detect if we are in a local class scope, as an assignment.
         For example, the following is fair game.
 
         class A:
@@ -2153,39 +2404,39 @@
             frame_locals = frame.locals
         return not (
             (isinstance(frame, nodes.ClassDef) or in_annotation_or_default_or_decorator)
             and not self._in_lambda_or_comprehension_body(node, frame)
             and name in frame_locals
         )
 
+    # pylint: disable = too-many-branches
     def _loopvar_name(self, node: astroid.Name) -> None:
         # filter variables according to node's scope
         astmts = [s for s in node.lookup(node.name)[1] if hasattr(s, "assign_type")]
         # If this variable usage exists inside a function definition
         # that exists in the same loop,
         # the usage is safe because the function will not be defined either if
         # the variable is not defined.
         scope = node.scope()
         # FunctionDef subclasses Lambda due to a curious ontology. Check both.
-        # See https://github.com/PyCQA/astroid/issues/291
+        # See https://github.com/pylint-dev/astroid/issues/291
         # TODO: Revisit when astroid 3.0 includes the change
         if isinstance(scope, nodes.Lambda) and any(
             asmt.scope().parent_of(scope) for asmt in astmts
         ):
             return
         # Filter variables according to their respective scope. Test parent
         # and statement to avoid #74747. This is not a total fix, which would
         # introduce a mechanism similar to special attribute lookup in
         # modules. Also, in order to get correct inference in this case, the
         # scope lookup rules would need to be changed to return the initial
         # assignment (which does not exist in code per se) as well as any later
         # modifications.
-        # pylint: disable-next=too-many-boolean-expressions
         if (
-            not astmts
+            not astmts  # pylint: disable=too-many-boolean-expressions
             or (
                 astmts[0].parent == astmts[0].root()
                 and astmts[0].parent.parent_of(node)
             )
             or (
                 astmts[0].is_statement
                 or not isinstance(astmts[0].parent, nodes.Module)
@@ -2211,30 +2462,75 @@
             and assign.statement(future=True) is not node.statement(future=True)
         ):
             return
 
         if not isinstance(assign, nodes.For):
             self.add_message("undefined-loop-variable", args=node.name, node=node)
             return
-        if any(
-            isinstance(else_stmt, (nodes.Return, nodes.Raise))
-            for else_stmt in assign.orelse
-        ):
-            return
+        for else_stmt in assign.orelse:
+            if isinstance(
+                else_stmt, (nodes.Return, nodes.Raise, nodes.Break, nodes.Continue)
+            ):
+                return
+            # TODO: 3.0: Consider using RefactoringChecker._is_function_def_never_returning
+            if isinstance(else_stmt, nodes.Expr) and isinstance(
+                else_stmt.value, nodes.Call
+            ):
+                inferred_func = utils.safe_infer(else_stmt.value.func)
+                if (
+                    isinstance(inferred_func, nodes.FunctionDef)
+                    and inferred_func.returns
+                ):
+                    inferred_return = utils.safe_infer(inferred_func.returns)
+                    if isinstance(
+                        inferred_return, nodes.FunctionDef
+                    ) and inferred_return.qname() in {
+                        *TYPING_NORETURN,
+                        *TYPING_NEVER,
+                        "typing._SpecialForm",
+                    }:
+                        return
+                    # typing_extensions.NoReturn returns a _SpecialForm
+                    if (
+                        isinstance(inferred_return, bases.Instance)
+                        and inferred_return.qname() == "typing._SpecialForm"
+                    ):
+                        return
+
+        maybe_walrus = utils.get_node_first_ancestor_of_type(node, nodes.NamedExpr)
+        if maybe_walrus:
+            maybe_comprehension = utils.get_node_first_ancestor_of_type(
+                maybe_walrus, nodes.Comprehension
+            )
+            if maybe_comprehension:
+                comprehension_scope = utils.get_node_first_ancestor_of_type(
+                    maybe_comprehension, nodes.ComprehensionScope
+                )
+                if comprehension_scope is None:
+                    # Should not be possible.
+                    pass
+                elif (
+                    comprehension_scope.parent.scope() is scope
+                    and node.name in comprehension_scope.locals
+                ):
+                    return
 
         # For functions we can do more by inferring the length of the itered object
         try:
             inferred = next(assign.iter.infer())
             # Prefer the target of enumerate() rather than the enumerate object itself
             if (
                 isinstance(inferred, astroid.Instance)
                 and inferred.qname() == "builtins.enumerate"
-                and assign.iter.args
             ):
-                inferred = next(assign.iter.args[0].infer())
+                likely_call = assign.iter
+                if isinstance(assign.iter, nodes.IfExp):
+                    likely_call = assign.iter.body
+                if isinstance(likely_call, nodes.Call):
+                    inferred = next(likely_call.args[0].infer())
         except astroid.InferenceError:
             self.add_message("undefined-loop-variable", args=node.name, node=node)
         else:
             if (
                 isinstance(inferred, astroid.Instance)
                 and inferred.qname() == BUILTIN_RANGE
             ):
@@ -2253,22 +2549,23 @@
                 self.add_message("undefined-loop-variable", args=node.name, node=node)
                 return
 
             elements = getattr(inferred, "elts", getattr(inferred, "items", []))
             if not elements:
                 self.add_message("undefined-loop-variable", args=node.name, node=node)
 
+    # pylint: disable = too-many-branches
     def _check_is_unused(
         self,
-        name,
-        node,
-        stmt,
-        global_names,
+        name: str,
+        node: nodes.FunctionDef,
+        stmt: nodes.NodeNG,
+        global_names: set[str],
         nonlocal_names: Iterable[str],
-        comprehension_target_names: list[str],
+        comprehension_target_names: Iterable[str],
     ) -> None:
         # Ignore some special names specified by user configuration.
         if self._is_name_ignored(stmt, name):
             return
         # Ignore names that were added dynamically to the Function scope
         if (
             isinstance(node, nodes.FunctionDef)
@@ -2284,21 +2581,25 @@
             if global_names and _import_name_is_global(stmt, global_names):
                 return
 
         # Ignore names in comprehension targets
         if name in comprehension_target_names:
             return
 
+        # Ignore names in string literal type annotation.
+        if name in self._type_annotation_names:
+            return
+
         argnames = node.argnames()
         # Care about functions with unknown argument (builtins)
         if name in argnames:
             self._check_unused_arguments(name, node, stmt, argnames, nonlocal_names)
         else:
             if stmt.parent and isinstance(
-                stmt.parent, (nodes.Assign, nodes.AnnAssign, nodes.Tuple)
+                stmt.parent, (nodes.Assign, nodes.AnnAssign, nodes.Tuple, nodes.For)
             ):
                 if name in nonlocal_names:
                     return
 
             qname = asname = None
             if isinstance(stmt, (nodes.Import, nodes.ImportFrom)):
                 # Need the complete name, which we don't have in .locals.
@@ -2342,29 +2643,39 @@
             if isinstance(stmt.parent, nodes.ExceptHandler) and any(
                 n.name == name for n in stmt.parent.nodes_of_class(nodes.Name)
             ):
                 return
 
             self.add_message(message_name, args=name, node=stmt)
 
-    def _is_name_ignored(self, stmt, name):
+    def _is_name_ignored(
+        self, stmt: nodes.NodeNG, name: str
+    ) -> re.Pattern[str] | re.Match[str] | None:
         authorized_rgx = self.linter.config.dummy_variables_rgx
         if (
             isinstance(stmt, nodes.AssignName)
             and isinstance(stmt.parent, nodes.Arguments)
             or isinstance(stmt, nodes.Arguments)
         ):
-            regex = self.linter.config.ignored_argument_names
+            regex: re.Pattern[str] = self.linter.config.ignored_argument_names
         else:
             regex = authorized_rgx
+        # See https://stackoverflow.com/a/47007761/2519059 to
+        # understand what this function return. Please do NOT use
+        # this elsewhere, this is confusing for no benefit
         return regex and regex.match(name)
 
     def _check_unused_arguments(
-        self, name, node, stmt, argnames, nonlocal_names: Iterable[str]
-    ):
+        self,
+        name: str,
+        node: nodes.FunctionDef,
+        stmt: nodes.NodeNG,
+        argnames: list[str],
+        nonlocal_names: Iterable[str],
+    ) -> None:
         is_method = node.is_method()
         klass = node.parent.frame(future=True)
         if is_method and isinstance(klass, nodes.ClassDef):
             confidence = (
                 INFERENCE if utils.has_known_bases(klass) else INFERENCE_FAILURE
             )
         else:
@@ -2452,35 +2763,35 @@
                     and maybe_for.parent_of(node_scope)
                     and not utils.is_being_called(node_scope)
                     and node_scope.parent
                     and not isinstance(node_scope.statement(future=True), nodes.Return)
                 ):
                     self.add_message("cell-var-from-loop", node=node, args=node.name)
 
-    def _should_ignore_redefined_builtin(self, stmt):
+    def _should_ignore_redefined_builtin(self, stmt: nodes.NodeNG) -> bool:
         if not isinstance(stmt, nodes.ImportFrom):
             return False
         return stmt.modname in self.linter.config.redefining_builtins_modules
 
-    def _allowed_redefined_builtin(self, name):
+    def _allowed_redefined_builtin(self, name: str) -> bool:
         return name in self.linter.config.allowed_redefined_builtins
 
     @staticmethod
     def _comprehension_between_frame_and_node(node: nodes.Name) -> bool:
         """Return True if a ComprehensionScope intervenes between `node` and its
         frame.
         """
         closest_comprehension_scope = utils.get_node_first_ancestor_of_type(
             node, nodes.ComprehensionScope
         )
         return closest_comprehension_scope is not None and node.frame(
             future=True
         ).parent_of(closest_comprehension_scope)
 
-    def _store_type_annotation_node(self, type_annotation):
+    def _store_type_annotation_node(self, type_annotation: nodes.NodeNG) -> None:
         """Given a type annotation, store all the name nodes it refers to."""
         if isinstance(type_annotation, nodes.Name):
             self._type_annotation_names.append(type_annotation.name)
             return
 
         if isinstance(type_annotation, nodes.Attribute):
             self._store_type_annotation_node(type_annotation.expr)
@@ -2497,15 +2808,17 @@
             self._type_annotation_names.append(TYPING_MODULE)
             return
 
         self._type_annotation_names.extend(
             annotation.name for annotation in type_annotation.nodes_of_class(nodes.Name)
         )
 
-    def _store_type_annotation_names(self, node):
+    def _store_type_annotation_names(
+        self, node: nodes.For | nodes.Assign | nodes.With
+    ) -> None:
         type_annotation = node.type_annotation
         if not type_annotation:
             return
         self._store_type_annotation_node(node.type_annotation)
 
     def _check_self_cls_assign(self, node: nodes.Assign) -> None:
         """Check that self/cls don't get assigned."""
@@ -2533,79 +2846,103 @@
         argument_names = scope.argnames()
         if not argument_names:
             return
         self_cls_name = argument_names[0]
         if self_cls_name in assign_names:
             self.add_message("self-cls-assignment", node=node, args=(self_cls_name,))
 
-    def _check_unpacking(self, inferred, node, targets):
+    def _check_unpacking(
+        self, inferred: InferenceResult, node: nodes.Assign, targets: list[nodes.NodeNG]
+    ) -> None:
         """Check for unbalanced tuple unpacking
         and unpacking non sequences.
         """
         if utils.is_inside_abstract_class(node):
             return
         if utils.is_comprehension(node):
             return
-        if inferred is astroid.Uninferable:
+        if isinstance(inferred, util.UninferableBase):
             return
         if (
             isinstance(inferred.parent, nodes.Arguments)
             and isinstance(node.value, nodes.Name)
             and node.value.name == inferred.parent.vararg
         ):
             # Variable-length argument, we can't determine the length.
             return
 
         # Attempt to check unpacking is properly balanced
         values = self._nodes_to_unpack(inferred)
+        details = _get_unpacking_extra_info(node, inferred)
+
         if values is not None:
             if len(targets) != len(values):
-                # Check if we have starred nodes.
-                if any(isinstance(target, nodes.Starred) for target in targets):
-                    return
-                self.add_message(
-                    "unbalanced-tuple-unpacking",
-                    node=node,
-                    args=(
-                        _get_unpacking_extra_info(node, inferred),
-                        len(targets),
-                        len(values),
-                    ),
+                self._report_unbalanced_unpacking(
+                    node, inferred, targets, values, details
                 )
         # attempt to check unpacking may be possible (i.e. RHS is iterable)
         elif not utils.is_iterable(inferred):
-            self.add_message(
-                "unpacking-non-sequence",
-                node=node,
-                args=(_get_unpacking_extra_info(node, inferred),),
-            )
+            self._report_unpacking_non_sequence(node, details)
 
     @staticmethod
     def _nodes_to_unpack(node: nodes.NodeNG) -> list[nodes.NodeNG] | None:
         """Return the list of values of the `Assign` node."""
-        if isinstance(node, (nodes.Tuple, nodes.List)):
-            return node.itered()
+        if isinstance(node, (nodes.Tuple, nodes.List, *DICT_TYPES)):
+            return node.itered()  # type: ignore[no-any-return]
         if isinstance(node, astroid.Instance) and any(
             ancestor.qname() == "typing.NamedTuple" for ancestor in node.ancestors()
         ):
             return [i for i in node.values() if isinstance(i, nodes.AssignName)]
         return None
 
-    def _check_module_attrs(self, node, module, module_names):
+    def _report_unbalanced_unpacking(
+        self,
+        node: nodes.NodeNG,
+        inferred: InferenceResult,
+        targets: list[nodes.NodeNG],
+        values: list[nodes.NodeNG],
+        details: str,
+    ) -> None:
+        args = (
+            details,
+            len(targets),
+            "" if len(targets) == 1 else "s",
+            len(values),
+            "" if len(values) == 1 else "s",
+        )
+
+        symbol = (
+            "unbalanced-dict-unpacking"
+            if isinstance(inferred, DICT_TYPES)
+            else "unbalanced-tuple-unpacking"
+        )
+        self.add_message(symbol, node=node, args=args, confidence=INFERENCE)
+
+    def _report_unpacking_non_sequence(self, node: nodes.NodeNG, details: str) -> None:
+        if details and not details.startswith(" "):
+            details = f" {details}"
+        self.add_message("unpacking-non-sequence", node=node, args=details)
+
+    def _check_module_attrs(
+        self,
+        node: _base_nodes.ImportNode,
+        module: nodes.Module,
+        module_names: list[str],
+    ) -> nodes.Module | None:
         """Check that module_names (list of string) are accessible through the
         given module, if the latest access name corresponds to a module, return it.
         """
         while module_names:
             name = module_names.pop(0)
             if name == "__dict__":
                 module = None
                 break
             try:
                 module = next(module.getattr(name)[0].infer())
-                if module is astroid.Uninferable:
+                if not isinstance(module, nodes.Module):
                     return None
             except astroid.NotFoundError:
                 if module.name in self._ignored_modules:
                     return None
                 self.add_message(
                     "no-name-in-module", args=(name, module.name), node=node
                 )
@@ -2618,28 +2955,30 @@
                 "no-name-in-module", node=node, args=(".".join(module_names), modname)
             )
             return None
         if isinstance(module, nodes.Module):
             return module
         return None
 
-    def _check_all(self, node: nodes.Module, not_consumed):
+    def _check_all(
+        self, node: nodes.Module, not_consumed: dict[str, list[nodes.NodeNG]]
+    ) -> None:
         assigned = next(node.igetattr("__all__"))
-        if assigned is astroid.Uninferable:
+        if isinstance(assigned, util.UninferableBase):
             return
-        if not assigned.pytype() in {"builtins.list", "builtins.tuple"}:
+        if assigned.pytype() not in {"builtins.list", "builtins.tuple"}:
             line, col = assigned.tolineno, assigned.col_offset
             self.add_message("invalid-all-format", line=line, col_offset=col, node=node)
             return
         for elt in getattr(assigned, "elts", ()):
             try:
                 elt_name = next(elt.infer())
             except astroid.InferenceError:
                 continue
-            if elt_name is astroid.Uninferable:
+            if isinstance(elt_name, util.UninferableBase):
                 continue
             if not elt_name.parent:
                 continue
 
             if not isinstance(elt_name, nodes.Const) or not isinstance(
                 elt_name.value, str
             ):
@@ -2669,22 +3008,23 @@
                             )
                         except SyntaxError:
                             # don't yield a syntax-error warning,
                             # because it will be later yielded
                             # when the file will be checked
                             pass
 
-    def _check_globals(self, not_consumed):
+    def _check_globals(self, not_consumed: dict[str, nodes.NodeNG]) -> None:
         if self._allow_global_unused_variables:
             return
         for name, node_lst in not_consumed.items():
             for node in node_lst:
                 self.add_message("unused-variable", args=(name,), node=node)
 
-    def _check_imports(self, not_consumed):
+    # pylint: disable = too-many-branches
+    def _check_imports(self, not_consumed: dict[str, list[nodes.NodeNG]]) -> None:
         local_names = _fix_dot_imports(not_consumed)
         checked = set()
         unused_wildcard_imports: defaultdict[
             tuple[str, nodes.ImportFrom], list[str]
         ] = collections.defaultdict(list)
         for name, stmt in local_names:
             for imports in stmt.names:
@@ -2758,35 +3098,37 @@
                     f"{', '.join(i for i in unused_list[:-1])} and {unused_list[-1]}"
                 )
             self.add_message(
                 "unused-wildcard-import", args=(arg_string, module[0]), node=module[1]
             )
         del self._to_consume
 
-    def _check_metaclasses(self, node):
+    def _check_metaclasses(self, node: nodes.Module | nodes.FunctionDef) -> None:
         """Update consumption analysis for metaclasses."""
-        consumed = []  # [(scope_locals, consumed_key)]
+        consumed: list[tuple[dict[str, list[nodes.NodeNG]], str]] = []
 
         for child_node in node.get_children():
             if isinstance(child_node, nodes.ClassDef):
                 consumed.extend(self._check_classdef_metaclasses(child_node, node))
 
         # Pop the consumed items, in order to avoid having
         # unused-import and unused-variable false positives
         for scope_locals, name in consumed:
             scope_locals.pop(name, None)
 
-    def _check_classdef_metaclasses(self, klass, parent_node):
+    def _check_classdef_metaclasses(
+        self, klass: nodes.ClassDef, parent_node: nodes.Module | nodes.FunctionDef
+    ) -> list[tuple[dict[str, list[nodes.NodeNG]], str]]:
         if not klass._metaclass:
             # Skip if this class doesn't use explicitly a metaclass, but inherits it from ancestors
             return []
 
-        consumed = []  # [(scope_locals, consumed_key)]
+        consumed: list[tuple[dict[str, list[nodes.NodeNG]], str]] = []
         metaclass = klass.metaclass()
-        name = None
+        name = ""
         if isinstance(klass._metaclass, nodes.Name):
             name = klass._metaclass.name
         elif isinstance(klass._metaclass, nodes.Attribute) and klass._metaclass.expr:
             attr = klass._metaclass.expr
             while not isinstance(attr, nodes.Name):
                 attr = attr.expr
             name = attr.name
@@ -2847,10 +3189,44 @@
             # Add 1 because iterables are 0-indexed
             if len(node.value.elts) < inferred_slice.value + 1:
                 self.add_message(
                     "potential-index-error", node=node, confidence=INFERENCE
                 )
             return
 
+    @utils.only_required_for_messages(
+        "unused-import",
+        "unused-variable",
+    )
+    def visit_const(self, node: nodes.Const) -> None:
+        """Take note of names that appear inside string literal type annotations
+        unless the string is a parameter to `typing.Literal` or `typing.Annotation`.
+        """
+        if node.pytype() != "builtins.str":
+            return
+        if not utils.is_node_in_type_annotation_context(node):
+            return
+
+        # Check if parent's or grandparent's first child is typing.Literal
+        parent = node.parent
+        if isinstance(parent, nodes.Tuple):
+            parent = parent.parent
+        if isinstance(parent, nodes.Subscript):
+            origin = next(parent.get_children(), None)
+            if origin is not None and utils.is_typing_member(
+                origin, ("Annotated", "Literal")
+            ):
+                return
+
+        try:
+            annotation = extract_node(node.value)
+            self._store_type_annotation_node(annotation)
+        except ValueError:
+            # e.g. node.value is white space
+            pass
+        except astroid.AstroidSyntaxError:
+            # e.g. "?" or ":" in typing.Literal["?", ":"]
+            pass
+
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(VariablesChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/config/_pylint_config/generate_command.py` & `pylint-3.0.0a6/pylint/config/_pylint_config/generate_command.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,41 +1,39 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Everything related to the 'pylint-config generate' command."""
 
 
 from __future__ import annotations
 
-import warnings
 from io import StringIO
 from typing import TYPE_CHECKING
 
 from pylint.config._pylint_config import utils
 from pylint.config._pylint_config.help_message import get_subparser_help
 
 if TYPE_CHECKING:
     from pylint.lint.pylinter import PyLinter
 
 
 def generate_interactive_config(linter: PyLinter) -> None:
     print("Starting interactive pylint configuration generation")
 
     format_type = utils.get_and_validate_format()
+    minimal = format_type == "toml" and utils.get_minimal_setting()
     to_file, output_file_name = utils.get_and_validate_output_file()
 
     if format_type == "toml":
-        config_string = linter._generate_config_file()
+        config_string = linter._generate_config_file(minimal=minimal)
     else:
         output_stream = StringIO()
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", category=DeprecationWarning)
-            linter.generate_config(stream=output_stream, skipsections=("Commands",))
-            config_string = output_stream.getvalue()
+        linter._generate_config(stream=output_stream, skipsections=("Commands",))
+        config_string = output_stream.getvalue()
 
     if to_file:
         with open(output_file_name, "w", encoding="utf-8") as f:
             print(config_string, file=f)
         print(f"Wrote configuration file to {output_file_name.resolve()}")
     else:
         print(config_string)
```

### Comparing `pylint-3.0.0a5/pylint/config/_pylint_config/help_message.py` & `pylint-3.0.0a6/pylint/config/_pylint_config/help_message.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Everything related to the 'pylint-config -h' command and subcommands."""
 
 
 from __future__ import annotations
 
 import argparse
```

### Comparing `pylint-3.0.0a5/pylint/config/_pylint_config/main.py` & `pylint-3.0.0a6/pylint/config/_pylint_config/main.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Everything related to the 'pylint-config' command."""
 
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
```

### Comparing `pylint-3.0.0a5/pylint/config/_pylint_config/setup.py` & `pylint-3.0.0a6/pylint/config/_pylint_config/setup.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Everything related to the setup of the 'pylint-config' command."""
 
 
 from __future__ import annotations
 
 import argparse
```

### Comparing `pylint-3.0.0a5/pylint/config/_pylint_config/utils.py` & `pylint-3.0.0a6/pylint/config/_pylint_config/utils.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,30 +1,32 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Utils for the 'pylint-config' command."""
 
 from __future__ import annotations
 
 import sys
 from collections.abc import Callable
 from pathlib import Path
+from typing import TypeVar
 
 if sys.version_info >= (3, 8):
     from typing import Literal
 else:
     from typing_extensions import Literal
 
 if sys.version_info >= (3, 10):
     from typing import ParamSpec
 else:
     from typing_extensions import ParamSpec
 
 _P = ParamSpec("_P")
+_ReturnValueT = TypeVar("_ReturnValueT", bool, str)
 
 SUPPORTED_FORMATS = {"t", "toml", "i", "ini"}
 YES_NO_ANSWERS = {"y", "yes", "n", "no"}
 
 
 class InvalidUserInput(Exception):
     """Raised whenever a user input is invalid."""
@@ -32,19 +34,19 @@
     def __init__(self, valid_input: str, input_value: str, *args: object) -> None:
         self.valid = valid_input
         self.input = input_value
         super().__init__(*args)
 
 
 def should_retry_after_invalid_input(
-    func: Callable[_P, str | bool]
-) -> Callable[_P, str | bool]:
+    func: Callable[_P, _ReturnValueT]
+) -> Callable[_P, _ReturnValueT]:
     """Decorator that handles InvalidUserInput exceptions and retries."""
 
-    def inner_function(*args: _P.args, **kwargs: _P.kwargs) -> str | bool:
+    def inner_function(*args: _P.args, **kwargs: _P.kwargs) -> _ReturnValueT:
         called_once = False
         while True:
             try:
                 return func(*args, **kwargs)
             except InvalidUserInput as exc:
                 if called_once and exc.input == "exit()":
                     print("Stopping 'pylint-config'.")
@@ -77,23 +79,30 @@
     """Validate that a yes or no answer is correct."""
     question = f"{question} (y)es or (n)o "
     if default:
         question += f" (default={default}) "
     # pylint: disable-next=bad-builtin
     answer = input(question).lower()
 
-    if answer == "" and default:
+    if not answer and default:
         answer = default
 
     if answer not in YES_NO_ANSWERS:
         raise InvalidUserInput(", ".join(sorted(YES_NO_ANSWERS)), answer)
 
     return answer.startswith("y")
 
 
+def get_minimal_setting() -> bool:
+    """Ask the user if they want to use the minimal setting."""
+    return validate_yes_no(
+        "Do you want a minimal configuration without comments or default values?", "no"
+    )
+
+
 def get_and_validate_output_file() -> tuple[bool, Path]:
     """Make sure that the output file is correct."""
     to_file = validate_yes_no("Do you want to write the output to a file?", "no")
 
     if not to_file:
         return False, Path()
```

### Comparing `pylint-3.0.0a5/pylint/config/argument.py` & `pylint-3.0.0a6/pylint/config/argument.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,24 +1,25 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Definition of an Argument class and transformers for various argument types.
 
 An Argument instance represents a pylint option to be handled by an argparse.ArgumentParser
 """
 
 from __future__ import annotations
 
 import argparse
 import os
 import pathlib
 import re
 import sys
 from collections.abc import Callable
+from glob import glob
 from typing import Any, Pattern, Sequence, Tuple, Union
 
 from pylint import interfaces
 from pylint import utils as pylint_utils
 from pylint.config.callback_actions import _CallbackAction, _ExtendAction
 from pylint.config.deprecation_actions import _NewNamesAction, _OldNamesAction
 from pylint.constants import PY38_PLUS
@@ -84,30 +85,49 @@
 
 
 def _path_transformer(value: str) -> str:
     """Expand user and variables in a path."""
     return os.path.expandvars(os.path.expanduser(value))
 
 
+def _glob_paths_csv_transformer(value: str) -> Sequence[str]:
+    """Transforms a comma separated list of paths while expanding user and
+    variables and glob patterns.
+    """
+    paths: list[str] = []
+    for path in _csv_transformer(value):
+        paths.extend(glob(_path_transformer(path), recursive=True))
+    return paths
+
+
 def _py_version_transformer(value: str) -> tuple[int, ...]:
     """Transforms a version string into a version tuple."""
     try:
         version = tuple(int(val) for val in value.replace(",", ".").split("."))
     except ValueError:
         raise argparse.ArgumentTypeError(
             f"{value} has an invalid format, should be a version string. E.g., '3.8'"
         ) from None
     return version
 
 
+def _regex_transformer(value: str) -> Pattern[str]:
+    """Return `re.compile(value)`."""
+    try:
+        return re.compile(value)
+    except re.error as e:
+        msg = f"Error in provided regular expression: {value} beginning at index {e.pos}: {e.msg}"
+        raise argparse.ArgumentTypeError(msg) from e
+
+
 def _regexp_csv_transfomer(value: str) -> Sequence[Pattern[str]]:
     """Transforms a comma separated list of regular expressions."""
     patterns: list[Pattern[str]] = []
     for pattern in _csv_transformer(value):
-        patterns.append(re.compile(pattern))
+        patterns.append(_regex_transformer(pattern))
     return patterns
 
 
 def _regexp_paths_csv_transfomer(value: str) -> Sequence[Pattern[str]]:
     """Transforms a comma separated list of regular expressions paths."""
     patterns: list[Pattern[str]] = []
     for pattern in _csv_transformer(value):
@@ -125,16 +145,17 @@
     "choice": str,
     "csv": _csv_transformer,
     "float": float,
     "int": int,
     "confidence": _confidence_transformer,
     "non_empty_string": _non_empty_string_transformer,
     "path": _path_transformer,
+    "glob_paths_csv": _glob_paths_csv_transformer,
     "py_version": _py_version_transformer,
-    "regexp": re.compile,
+    "regexp": _regex_transformer,
     "regexp_csv": _regexp_csv_transfomer,
     "regexp_paths_csv": _regexp_paths_csv_transfomer,
     "string": pylint_utils._unquote,
     "yn": _yn_transformer,
 }
 """Type transformers for all argument types.
 
@@ -259,15 +280,15 @@
     argparse.ArgumentsParser.
 
     This is based on the parameters passed to argparse.ArgumentsParser.add_message.
     See:
     https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument
     """
 
-    # pylint: disable-next=useless-super-delegation # We narrow down the type of action
+    # pylint: disable-next=useless-parent-delegation # We narrow down the type of action
     def __init__(
         self,
         *,
         flags: list[str],
         action: Literal["store_true"],
         default: _ArgumentTypes,
         arg_help: str,
@@ -352,17 +373,17 @@
         hide_help: bool,
         section: str | None,
         choices: list[str] | None,
         dest: str | None,
     ) -> None:
         # The extend action is included in the stdlib from 3.8+
         if PY38_PLUS:
-            action_class = argparse._ExtendAction  # type: ignore[attr-defined]
+            action_class = argparse._ExtendAction
         else:
-            action_class = _ExtendAction
+            action_class = _ExtendAction  # type: ignore[assignment]
 
         self.dest = dest
         """The destination of the argument."""
 
         super().__init__(
             flags=flags,
             action=action_class,
```

### Comparing `pylint-3.0.0a5/pylint/config/callback_actions.py` & `pylint-3.0.0a6/pylint/config/callback_actions.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,22 +1,21 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 # pylint: disable=too-many-arguments, redefined-builtin, duplicate-code
 
 """Callback actions for various options."""
 
 from __future__ import annotations
 
 import abc
 import argparse
 import sys
-import warnings
-from collections.abc import Sequence
+from collections.abc import Callable, Sequence
 from pathlib import Path
 from typing import TYPE_CHECKING, Any
 
 from pylint import exceptions, extensions, interfaces, utils
 
 if TYPE_CHECKING:
     from pylint.config.help_formatter import _HelpFormatter
@@ -154,15 +153,19 @@
         self,
         parser: argparse.ArgumentParser,
         namespace: argparse.Namespace,
         values: str | Sequence[str] | None,
         option_string: str | None = "--help-msg",
     ) -> None:
         assert isinstance(values, (list, tuple))
-        self.run.linter.msgs_store.help_message(values)
+        values_to_print: list[str] = []
+        for msg in values:
+            assert isinstance(msg, str)
+            values_to_print += utils._check_csv(msg)
+        self.run.linter.msgs_store.help_message(values_to_print)
         sys.exit(0)
 
 
 class _ListMessagesAction(_AccessRunObjectAction):
     """Display all available messages."""
 
     def __call__(
@@ -257,18 +260,17 @@
     def __call__(
         self,
         parser: argparse.ArgumentParser,
         namespace: argparse.Namespace,
         values: str | Sequence[Any] | None,
         option_string: str | None = "--generate-rcfile",
     ) -> None:
-        # TODO: 2.15: Deprecate this after discussion about this removal has been completed.
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", category=DeprecationWarning)
-            self.run.linter.generate_config(skipsections=("Commands",))
+        # TODO: 3.x: Deprecate this after the auto-upgrade functionality of
+        # pylint-config is sufficient.
+        self.run.linter._generate_config(skipsections=("Commands",))
         sys.exit(0)
 
 
 class _GenerateConfigFileAction(_AccessRunObjectAction):
     """Generate a .toml format configuration file."""
 
     def __call__(
@@ -361,54 +363,74 @@
         namespace: argparse.Namespace,
         values: str | Sequence[Any] | None,
         option_string: str | None = None,
     ) -> None:
         raise NotImplementedError  # pragma: no cover
 
 
-class _DisableAction(_AccessLinterObjectAction):
+class _XableAction(_AccessLinterObjectAction):
+    """Callback action for enabling or disabling a message."""
+
+    def _call(
+        self,
+        xabling_function: Callable[[str], None],
+        values: str | Sequence[Any] | None,
+        option_string: str | None,
+    ) -> None:
+        assert isinstance(values, (tuple, list))
+        for msgid in utils._check_csv(values[0]):
+            try:
+                xabling_function(msgid)
+            except (
+                exceptions.DeletedMessageError,
+                exceptions.MessageBecameExtensionError,
+            ) as e:
+                self.linter._stashed_messages[
+                    (self.linter.current_name, "useless-option-value")
+                ].append((option_string, str(e)))
+            except exceptions.UnknownMessageError:
+                self.linter._stashed_messages[
+                    (self.linter.current_name, "unknown-option-value")
+                ].append((option_string, msgid))
+
+    @abc.abstractmethod
+    def __call__(
+        self,
+        parser: argparse.ArgumentParser,
+        namespace: argparse.Namespace,
+        values: str | Sequence[Any] | None,
+        option_string: str | None = "--disable",
+    ) -> None:
+        raise NotImplementedError  # pragma: no cover
+
+
+class _DisableAction(_XableAction):
     """Callback action for disabling a message."""
 
     def __call__(
         self,
         parser: argparse.ArgumentParser,
         namespace: argparse.Namespace,
         values: str | Sequence[Any] | None,
         option_string: str | None = "--disable",
     ) -> None:
-        assert isinstance(values, (tuple, list))
-        msgids = utils._check_csv(values[0])
-        for msgid in msgids:
-            try:
-                self.linter.disable(msgid)
-            except exceptions.UnknownMessageError:
-                self.linter._stashed_bad_option_value_messages[
-                    self.linter.current_name
-                ].append((option_string, msgid))
+        self._call(self.linter.disable, values, option_string)
 
 
-class _EnableAction(_AccessLinterObjectAction):
+class _EnableAction(_XableAction):
     """Callback action for enabling a message."""
 
     def __call__(
         self,
         parser: argparse.ArgumentParser,
         namespace: argparse.Namespace,
         values: str | Sequence[Any] | None,
         option_string: str | None = "--enable",
     ) -> None:
-        assert isinstance(values, (tuple, list))
-        msgids = utils._check_csv(values[0])
-        for msgid in msgids:
-            try:
-                self.linter.enable(msgid)
-            except exceptions.UnknownMessageError:
-                self.linter._stashed_bad_option_value_messages[
-                    self.linter.current_name
-                ].append((option_string, msgid))
+        self._call(self.linter.enable, values, option_string)
 
 
 class _OutputFormatAction(_AccessLinterObjectAction):
     """Callback action for setting the output format."""
 
     def __call__(
         self,
```

### Comparing `pylint-3.0.0a5/pylint/config/config_file_parser.py` & `pylint-3.0.0a6/pylint/config/config_file_parser.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,19 +1,18 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Configuration file parser class."""
 
 from __future__ import annotations
 
 import configparser
 import os
 import sys
-import warnings
 from pathlib import Path
 from typing import TYPE_CHECKING
 
 from pylint.config.utils import _parse_rich_type_value
 
 if sys.version_info >= (3, 11):
     import tomllib
@@ -27,43 +26,42 @@
 class _ConfigurationFileParser:
     """Class to parse various formats of configuration files."""
 
     def __init__(self, verbose: bool, linter: PyLinter) -> None:
         self.verbose_mode = verbose
         self.linter = linter
 
-    @staticmethod
-    def _parse_ini_file(file_path: Path) -> tuple[dict[str, str], list[str]]:
+    def _parse_ini_file(self, file_path: Path) -> tuple[dict[str, str], list[str]]:
         """Parse and handle errors of a ini configuration file."""
         parser = configparser.ConfigParser(inline_comment_prefixes=("#", ";"))
 
         # Use this encoding in order to strip the BOM marker, if any.
         with open(file_path, encoding="utf_8_sig") as fp:
             parser.read_file(fp)
 
         config_content: dict[str, str] = {}
         options: list[str] = []
+        ini_file_with_sections = self._ini_file_with_sections(file_path)
         for section in parser.sections():
-            if "setup.cfg" in str(file_path) and not section.startswith("pylint"):
-                if section.lower() == "master":
-                    # TODO: 3.0: Remove deprecated handling of master, only allow 'pylint.' sections
-                    warnings.warn(
-                        "The use of 'MASTER' or 'master' as configuration section for pylint "
-                        "has been deprecated, as it's bad practice to not start sections titles with the "
-                        "tool name. Please use 'pylint.main' instead.",
-                        UserWarning,
-                    )
-                else:
-                    continue
-            for opt, value in parser[section].items():
-                value = value.replace("\n", "")
-                config_content[opt] = value
-                options += [f"--{opt}", value]
+            if ini_file_with_sections and not section.startswith("pylint"):
+                continue
+            for option, value in parser[section].items():
+                config_content[option] = value
+                options += [f"--{option}", value]
         return config_content, options
 
+    @staticmethod
+    def _ini_file_with_sections(file_path: Path) -> bool:
+        """Return whether the file uses sections."""
+        if "setup.cfg" in file_path.parts:
+            return True
+        if "tox.ini" in file_path.parts:
+            return True
+        return False
+
     def _parse_toml_file(self, file_path: Path) -> tuple[dict[str, str], list[str]]:
         """Parse and handle errors of a toml configuration file."""
         try:
             with open(file_path, mode="rb") as fp:
                 content = tomllib.load(fp)
         except tomllib.TOMLDecodeError as e:
             self.linter.add_message("config-parse-error", line=0, args=str(e))
```

### Comparing `pylint-3.0.0a5/pylint/config/config_initialization.py` & `pylint-3.0.0a6/pylint/config/config_initialization.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import sys
+from glob import glob
+from itertools import chain
 from pathlib import Path
 from typing import TYPE_CHECKING
 
 from pylint import reporters
 from pylint.config.config_file_parser import _ConfigurationFileParser
 from pylint.config.exceptions import _UnrecognizedOptionError
 from pylint.utils import utils
@@ -68,44 +70,66 @@
     # to allow raising messages on it
     linter.set_current_module("Command line")
 
     # Now we parse any options from the command line, so they can override
     # the configuration file
     parsed_args_list = linter._parse_command_line_configuration(args_list)
 
+    # Remove the positional arguments separator from the list of arguments if it exists
+    try:
+        parsed_args_list.remove("--")
+    except ValueError:
+        pass
+
     # Check if there are any options that we do not recognize
     unrecognized_options: list[str] = []
     for opt in parsed_args_list:
         if opt.startswith("--"):
             unrecognized_options.append(opt[2:])
         elif opt.startswith("-"):
             unrecognized_options.append(opt[1:])
     if unrecognized_options:
         msg = ", ".join(unrecognized_options)
-        linter._arg_parser.error(f"Unrecognized option found: {msg}")
+        try:
+            linter._arg_parser.error(f"Unrecognized option found: {msg}")
+        except SystemExit:
+            sys.exit(32)
 
     # Now that config file and command line options have been loaded
     # with all disables, it is safe to emit messages
     if unrecognized_options_message is not None:
         linter.set_current_module(str(config_file) if config_file else "")
         linter.add_message(
             "unrecognized-option", args=unrecognized_options_message, line=0
         )
 
-    linter._emit_bad_option_value()
+    linter._emit_stashed_messages()
 
     # Set the current module to configuration as we don't know where
     # the --load-plugins key is coming from
     linter.set_current_module("Command line or configuration file")
 
     # We have loaded configuration from config file and command line. Now, we can
     # load plugin specific configuration.
     linter.load_plugin_configuration()
 
-    # Now that plugins are loaded, get list of all fail_on messages, and enable them
+    # Now that plugins are loaded, get list of all fail_on messages, and
+    # enable them
     linter.enable_fail_on_messages()
 
     linter._parse_error_mode()
 
-    # parsed_args_list should now only be a list of files/directories to lint.
+    # Link the base Namespace object on the current directory
+    linter._directory_namespaces[Path(".").resolve()] = (linter.config, {})
+
+    # parsed_args_list should now only be a list of inputs to lint.
     # All other options have been removed from the list.
-    return parsed_args_list
+    return list(
+        chain.from_iterable(
+            # NOTE: 'or [arg]' is needed in the case the input file or directory does
+            # not exist and 'glob(arg)' cannot find anything. Without this we would
+            # not be able to output the fatal import error for this module later on,
+            # as it would get silently ignored.
+            glob(arg, recursive=True) or [arg]
+            for arg in parsed_args_list
+        )
+    )
```

### Comparing `pylint-3.0.0a5/pylint/config/deprecation_actions.py` & `pylint-3.0.0a6/pylint/config/deprecation_actions.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 # pylint: disable=too-many-arguments, redefined-builtin
 
 """Deprecated option actions."""
 
 from __future__ import annotations
 
@@ -48,15 +48,15 @@
 
     def __call__(
         self,
         parser: argparse.ArgumentParser,
         namespace: argparse.Namespace,
         values: str | Sequence[Any] | None,
         option_string: str | None = None,
-    ):
+    ) -> None:
         assert isinstance(values, list)
         setattr(namespace, self.dest, values[0])
         for old_name in self.old_names:
             setattr(namespace, old_name, values[0])
 
 
 class _NewNamesAction(argparse._StoreAction):
@@ -93,15 +93,16 @@
 
     def __call__(
         self,
         parser: argparse.ArgumentParser,
         namespace: argparse.Namespace,
         values: str | Sequence[Any] | None,
         option_string: str | None = None,
-    ):
+    ) -> None:
         assert isinstance(values, list)
         setattr(namespace, self.dest, values[0])
         warnings.warn(
             f"{self.option_strings[0]} has been deprecated. Please look into "
             f"using any of the following options: {', '.join(self.new_names)}.",
             DeprecationWarning,
+            stacklevel=2,
         )
```

### Comparing `pylint-3.0.0a5/pylint/config/exceptions.py` & `pylint-3.0.0a6/pylint/config/exceptions.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 
 class UnrecognizedArgumentAction(Exception):
     """Raised if an ArgumentManager instance tries to add an argument for which the
     action is not recognized.
```

### Comparing `pylint-3.0.0a5/pylint/config/help_formatter.py` & `pylint-3.0.0a6/pylint/config/help_formatter.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import argparse
 
 from pylint.config.callback_actions import _CallbackAction
-from pylint.constants import DEFAULT_PYLINT_HOME, OLD_DEFAULT_PYLINT_HOME
+from pylint.constants import DEFAULT_PYLINT_HOME
 
 
 class _HelpFormatter(argparse.RawDescriptionHelpFormatter):
     """Formatter for the help message emitted by argparse."""
 
     def _get_help_string(self, action: argparse.Action) -> str | None:
         """Copied from argparse.ArgumentDefaultsHelpFormatter."""
@@ -31,16 +31,15 @@
 
     @staticmethod
     def get_long_description() -> str:
         return f"""
 Environment variables:
     The following environment variables are used:
         * PYLINTHOME    Path to the directory where persistent data for the run will
-                        be stored. If not found, it defaults to '{DEFAULT_PYLINT_HOME}'
-                        or '{OLD_DEFAULT_PYLINT_HOME}' (in the current working directory).
+                        be stored. If not found, it defaults to '{DEFAULT_PYLINT_HOME}'.
         * PYLINTRC      Path to the configuration file. See the documentation for the method used
                         to search for configuration file.
 
 Output:
     Using the default text output, the message format is :
 
         MESSAGE_TYPE: LINE_NUM:[OBJECT:] MESSAGE
```

### Comparing `pylint-3.0.0a5/pylint/config/option_manager_mixin.py` & `pylint-3.0.0a6/pylint/config/arguments_manager.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,348 +1,399 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
-# pylint: disable=duplicate-code
+"""Arguments manager class used to handle command-line arguments and options."""
 
 from __future__ import annotations
 
-import collections
-import configparser
-import contextlib
-import copy
-import optparse  # pylint: disable=deprecated-module
-import os
+import argparse
+import re
 import sys
+import textwrap
 import warnings
-from pathlib import Path
-from typing import Any, TextIO
+from collections.abc import Sequence
+from typing import TYPE_CHECKING, Any, TextIO
+
+import tomlkit
 
 from pylint import utils
-from pylint.config.option import Option
-from pylint.config.option_parser import OptionParser
-from pylint.typing import OptionDict
+from pylint.config.argument import (
+    _Argument,
+    _CallableArgument,
+    _ExtendArgument,
+    _StoreArgument,
+    _StoreNewNamesArgument,
+    _StoreOldNamesArgument,
+    _StoreTrueArgument,
+)
+from pylint.config.exceptions import (
+    UnrecognizedArgumentAction,
+    _UnrecognizedOptionError,
+)
+from pylint.config.help_formatter import _HelpFormatter
+from pylint.config.utils import _convert_option_to_argument, _parse_rich_type_value
+from pylint.constants import MAIN_CHECKER_NAME
+from pylint.typing import DirectoryNamespaceDict, OptionDict
 
 if sys.version_info >= (3, 11):
     import tomllib
 else:
     import tomli as tomllib
 
 
-def _expand_default(self, option):
-    """Patch OptionParser.expand_default with custom behaviour.
+if TYPE_CHECKING:
+    from pylint.config.arguments_provider import _ArgumentsProvider
 
-    This will handle defaults to avoid overriding values in the
-    configuration file.
-    """
-    if self.parser is None or not self.default_tag:
-        return option.help
-    optname = option._long_opts[0][2:]
-    try:
-        provider = self.parser.options_manager._all_options[optname]
-    except KeyError:
-        value = None
-    else:
-        optdict = provider.get_option_def(optname)
-        optname = provider.option_attrname(optname, optdict)
-        value = getattr(provider.config, optname, optdict)
-        value = utils._format_option_value(optdict, value)
-    if value is optparse.NO_DEFAULT or not value:
-        value = self.NO_DEFAULT_VALUE
-    return option.help.replace(self.default_tag, str(value))
-
-
-@contextlib.contextmanager
-def _patch_optparse():
-    # pylint: disable = redefined-variable-type
-    orig_default = optparse.HelpFormatter
-    try:
-        optparse.HelpFormatter.expand_default = _expand_default
-        yield
-    finally:
-        optparse.HelpFormatter.expand_default = orig_default
-
-
-class OptionsManagerMixIn:
-    """Handle configuration from both a configuration file and command line options."""
-
-    def __init__(self, usage):
-        # TODO: 3.0: Remove deprecated class
-        warnings.warn(
-            "OptionsManagerMixIn has been deprecated and will be removed in pylint 3.0",
-            DeprecationWarning,
-        )
-        self.reset_parsers(usage)
-        # list of registered options providers
-        self.options_providers = []
-        # dictionary associating option name to checker
-        self._all_options = collections.OrderedDict()
-        self._short_options = {}
-        self._nocallback_options = {}
-        self._mygroups = {}
-        # verbosity
-        self._maxlevel = 0
-
-    def reset_parsers(self, usage=""):
-        # configuration file parser
-        self.cfgfile_parser = configparser.ConfigParser(
-            inline_comment_prefixes=("#", ";")
+
+class _ArgumentsManager:
+    """Arguments manager class used to handle command-line arguments and options."""
+
+    def __init__(
+        self, prog: str, usage: str | None = None, description: str | None = None
+    ) -> None:
+        self._config = argparse.Namespace()
+        """Namespace for all options."""
+
+        self._base_config = self._config
+        """Fall back Namespace object created during initialization.
+
+        This is necessary for the per-directory configuration support. Whenever we
+        fail to match a file with a directory we fall back to the Namespace object
+        created during initialization.
+        """
+
+        self._arg_parser = argparse.ArgumentParser(
+            prog=prog,
+            usage=usage or "%(prog)s [options]",
+            description=description,
+            formatter_class=_HelpFormatter,
+            # Needed to let 'pylint-config' overwrite the -h command
+            conflict_handler="resolve",
         )
-        # command line parser
-        self.cmdline_parser = OptionParser(Option, usage=usage)
-        self.cmdline_parser.options_manager = self
-        self._optik_option_attrs = set(self.cmdline_parser.option_class.ATTRS)
-
-    def register_options_provider(self, provider, own_group=True):
-        """Register an options provider."""
-        self.options_providers.append(provider)
-        non_group_spec_options = [
-            option for option in provider.options if "group" not in option[1]
-        ]
-        groups = getattr(provider, "option_groups", ())
-        if own_group and non_group_spec_options:
-            self.add_option_group(
-                provider.name.upper(),
-                provider.__doc__,
-                non_group_spec_options,
-                provider,
+        """The command line argument parser."""
+
+        self._argument_groups_dict: dict[str, argparse._ArgumentGroup] = {}
+        """Dictionary of all the argument groups."""
+
+        self._option_dicts: dict[str, OptionDict] = {}
+        """All option dictionaries that have been registered."""
+
+        self._directory_namespaces: DirectoryNamespaceDict = {}
+        """Mapping of directories and their respective namespace objects."""
+
+    @property
+    def config(self) -> argparse.Namespace:
+        """Namespace for all options."""
+        return self._config
+
+    @config.setter
+    def config(self, value: argparse.Namespace) -> None:
+        self._config = value
+
+    def _register_options_provider(self, provider: _ArgumentsProvider) -> None:
+        """Register an options provider and load its defaults."""
+        for opt, optdict in provider.options:
+            self._option_dicts[opt] = optdict
+            argument = _convert_option_to_argument(opt, optdict)
+            section = argument.section or provider.name.capitalize()
+
+            section_desc = provider.option_groups_descs.get(section, None)
+
+            # We exclude main since its docstring comes from PyLinter
+            if provider.name != MAIN_CHECKER_NAME and provider.__doc__:
+                section_desc = provider.__doc__.split("\n\n")[0]
+
+            self._add_arguments_to_parser(section, section_desc, argument)
+
+        self._load_default_argument_values()
+
+    def _add_arguments_to_parser(
+        self, section: str, section_desc: str | None, argument: _Argument
+    ) -> None:
+        """Add an argument to the correct argument section/group."""
+        try:
+            section_group = self._argument_groups_dict[section]
+        except KeyError:
+            if section_desc:
+                section_group = self._arg_parser.add_argument_group(
+                    section, section_desc
+                )
+            else:
+                section_group = self._arg_parser.add_argument_group(title=section)
+            self._argument_groups_dict[section] = section_group
+        self._add_parser_option(section_group, argument)
+
+    @staticmethod
+    def _add_parser_option(
+        section_group: argparse._ArgumentGroup, argument: _Argument
+    ) -> None:
+        """Add an argument."""
+        if isinstance(argument, _StoreArgument):
+            section_group.add_argument(
+                *argument.flags,
+                action=argument.action,
+                default=argument.default,
+                type=argument.type,  # type: ignore[arg-type] # incorrect typing in typeshed
+                help=argument.help,
+                metavar=argument.metavar,
+                choices=argument.choices,
+            )
+        elif isinstance(argument, _StoreOldNamesArgument):
+            section_group.add_argument(
+                *argument.flags,
+                **argument.kwargs,
+                action=argument.action,
+                default=argument.default,
+                type=argument.type,  # type: ignore[arg-type] # incorrect typing in typeshed
+                help=argument.help,
+                metavar=argument.metavar,
+                choices=argument.choices,
+            )
+            # We add the old name as hidden option to make it's default value gets loaded when
+            # argparse initializes all options from the checker
+            assert argument.kwargs["old_names"]
+            for old_name in argument.kwargs["old_names"]:
+                section_group.add_argument(
+                    f"--{old_name}",
+                    action="store",
+                    default=argument.default,
+                    type=argument.type,  # type: ignore[arg-type] # incorrect typing in typeshed
+                    help=argparse.SUPPRESS,
+                    metavar=argument.metavar,
+                    choices=argument.choices,
+                )
+        elif isinstance(argument, _StoreNewNamesArgument):
+            section_group.add_argument(
+                *argument.flags,
+                **argument.kwargs,
+                action=argument.action,
+                default=argument.default,
+                type=argument.type,  # type: ignore[arg-type] # incorrect typing in typeshed
+                help=argument.help,
+                metavar=argument.metavar,
+                choices=argument.choices,
+            )
+        elif isinstance(argument, _StoreTrueArgument):
+            section_group.add_argument(
+                *argument.flags,
+                action=argument.action,
+                default=argument.default,
+                help=argument.help,
+            )
+        elif isinstance(argument, _CallableArgument):
+            section_group.add_argument(
+                *argument.flags,
+                **argument.kwargs,
+                action=argument.action,
+                help=argument.help,
+                metavar=argument.metavar,
+            )
+        elif isinstance(argument, _ExtendArgument):
+            section_group.add_argument(
+                *argument.flags,
+                action=argument.action,
+                default=argument.default,
+                type=argument.type,  # type: ignore[arg-type] # incorrect typing in typeshed
+                help=argument.help,
+                metavar=argument.metavar,
+                choices=argument.choices,
+                dest=argument.dest,
             )
         else:
-            for opt, optdict in non_group_spec_options:
-                self.add_optik_option(provider, self.cmdline_parser, opt, optdict)
-        for gname, gdoc in groups:
-            gname = gname.upper()
-            goptions = [
-                option
-                for option in provider.options
-                if option[1].get("group", "").upper() == gname
-            ]
-            self.add_option_group(gname, gdoc, goptions, provider)
+            raise UnrecognizedArgumentAction
 
-    def add_option_group(self, group_name, _, options, provider):
-        # add option group to the command line parser
-        if group_name in self._mygroups:
-            group = self._mygroups[group_name]
-        else:
-            group = optparse.OptionGroup(
-                self.cmdline_parser, title=group_name.capitalize()
+    def _load_default_argument_values(self) -> None:
+        """Loads the default values of all registered options."""
+        self.config = self._arg_parser.parse_args([], self.config)
+
+    def _parse_configuration_file(self, arguments: list[str]) -> None:
+        """Parse the arguments found in a configuration file into the namespace."""
+        try:
+            self.config, parsed_args = self._arg_parser.parse_known_args(
+                arguments, self.config
             )
-            self.cmdline_parser.add_option_group(group)
-            self._mygroups[group_name] = group
-            # add section to the config file
-            if (
-                group_name != "DEFAULT"
-                and group_name not in self.cfgfile_parser._sections
-            ):
-                self.cfgfile_parser.add_section(group_name)
-        # add provider's specific options
-        for opt, optdict in options:
-            if not isinstance(optdict.get("action", "store"), str):
-                optdict["action"] = "callback"
-            self.add_optik_option(provider, group, opt, optdict)
-
-    def add_optik_option(self, provider, optikcontainer, opt, optdict):
-        args, optdict = self.optik_option(provider, opt, optdict)
-        option = optikcontainer.add_option(*args, **optdict)
-        self._all_options[opt] = provider
-        self._maxlevel = max(self._maxlevel, option.level or 0)
-
-    def optik_option(self, provider, opt, optdict):
-        """Get our personal option definition and return a suitable form for
-        use with optik/optparse.
-        """
-        optdict = copy.copy(optdict)
-        if "action" in optdict:
-            self._nocallback_options[provider] = opt
-        else:
-            optdict["action"] = "callback"
-            optdict["callback"] = self.cb_set_provider_option
-        # default is handled here and *must not* be given to optik if you
-        # want the whole machinery to work
-        if "default" in optdict:
-            if (
-                "help" in optdict
-                and optdict.get("default") is not None
-                and optdict["action"] not in ("store_true", "store_false")
-            ):
-                optdict["help"] += " [current: %default]"
-            del optdict["default"]
-        args = ["--" + str(opt)]
-        if "short" in optdict:
-            self._short_options[optdict["short"]] = opt
-            args.append("-" + optdict["short"])
-            del optdict["short"]
-        # cleanup option definition dict before giving it to optik
-        for key in list(optdict.keys()):
-            if key not in self._optik_option_attrs:
-                optdict.pop(key)
-        return args, optdict
-
-    def cb_set_provider_option(self, option, opt, value, parser):
-        """Optik callback for option setting."""
-        if opt.startswith("--"):
-            # remove -- on long option
-            opt = opt[2:]
-        else:
-            # short option, get its long equivalent
-            opt = self._short_options[opt[1:]]
-        # trick since we can't set action='store_true' on options
-        if value is None:
-            value = 1
-        self.global_set_option(opt, value)
-
-    def global_set_option(self, opt, value):
-        """Set option on the correct option provider."""
-        self._all_options[opt].set_option(opt, value)
+        except SystemExit:
+            sys.exit(32)
+        unrecognized_options: list[str] = []
+        for opt in parsed_args:
+            if opt.startswith("--"):
+                unrecognized_options.append(opt[2:])
+        if unrecognized_options:
+            raise _UnrecognizedOptionError(options=unrecognized_options)
+
+    def _parse_command_line_configuration(
+        self, arguments: Sequence[str] | None = None
+    ) -> list[str]:
+        """Parse the arguments found on the command line into the namespace."""
+        arguments = sys.argv[1:] if arguments is None else arguments
 
-    def generate_config(
+        self.config, parsed_args = self._arg_parser.parse_known_args(
+            arguments, self.config
+        )
+
+        return parsed_args
+
+    def _generate_config(
         self, stream: TextIO | None = None, skipsections: tuple[str, ...] = ()
     ) -> None:
         """Write a configuration file according to the current configuration
         into the given stream or stdout.
         """
-        options_by_section: dict[str, list[tuple[str, OptionDict, Any]]] = {}
+        options_by_section = {}
         sections = []
-        for provider in self.options_providers:
-            for section, options in provider.options_by_section():
-                if section is None:
-                    section = provider.name
-                if section in skipsections:
+        for group in sorted(
+            self._arg_parser._action_groups,
+            key=lambda x: (x.title != "Main", x.title),
+        ):
+            group_name = group.title
+            assert group_name
+            if group_name in skipsections:
+                continue
+
+            options = []
+            option_actions = [
+                i
+                for i in group._group_actions
+                if not isinstance(i, argparse._SubParsersAction)
+            ]
+            for opt in sorted(option_actions, key=lambda x: x.option_strings[0][2:]):
+                if "--help" in opt.option_strings:
+                    continue
+
+                optname = opt.option_strings[0][2:]
+
+                try:
+                    optdict = self._option_dicts[optname]
+                except KeyError:
                     continue
+
+                options.append(
+                    (
+                        optname,
+                        optdict,
+                        getattr(self.config, optname.replace("-", "_")),
+                    )
+                )
+
                 options = [
-                    (n, d, v)
-                    for (n, d, v) in options
-                    if d.get("type") is not None and not d.get("deprecated")
+                    (n, d, v) for (n, d, v) in options if not d.get("deprecated")
                 ]
-                if not options:
-                    continue
-                if section not in sections:
-                    sections.append(section)
-                all_options = options_by_section.setdefault(section, [])
-                all_options += options
+
+            if options:
+                sections.append(group_name)
+                options_by_section[group_name] = options
         stream = stream or sys.stdout
         printed = False
         for section in sections:
             if printed:
                 print("\n", file=stream)
-            utils.format_section(
-                stream, section.upper(), sorted(options_by_section[section])
-            )
+            with warnings.catch_warnings():
+                warnings.filterwarnings("ignore", category=DeprecationWarning)
+                utils.format_section(
+                    stream, section.upper(), sorted(options_by_section[section])
+                )
             printed = True
 
-    def load_provider_defaults(self):
-        """Initialize configuration using default values."""
-        for provider in self.options_providers:
-            provider.load_defaults()
-
-    def read_config_file(
-        self, config_file: Path | None = None, verbose: bool = False
-    ) -> None:
-        """Read the configuration file but do not load it (i.e. dispatching
-        values to each option's provider).
+    def help(self) -> str:
+        """Return the usage string based on the available options."""
+        return self._arg_parser.format_help()
+
+    def _generate_config_file(self, *, minimal: bool = False) -> str:
+        """Write a configuration file according to the current configuration into
+        stdout.
         """
-        if config_file:
-            config_file = Path(os.path.expandvars(config_file)).expanduser()
-            if not config_file.exists():
-                raise OSError(f"The config file {str(config_file)} doesn't exist!")
-
-            parser = self.cfgfile_parser
-            if config_file.suffix == ".toml":
-                try:
-                    self._parse_toml(config_file, parser)
-                except tomllib.TOMLDecodeError:
-                    pass
-            else:
-                # Use this encoding in order to strip the BOM marker, if any.
-                with open(config_file, encoding="utf_8_sig") as fp:
-                    parser.read_file(fp)
-                # normalize each section's title
-                for sect, values in list(parser._sections.items()):
-                    if sect.startswith("pylint."):
-                        sect = sect[len("pylint.") :]
-                    if not sect.isupper() and values:
-                        parser._sections[sect.upper()] = values
-
-        if not verbose:
-            return
-        if config_file and config_file.exists():
-            msg = f"Using config file '{config_file}'"
-        else:
-            msg = "No config file found, using default configuration"
-        print(msg, file=sys.stderr)
+        toml_doc = tomlkit.document()
+        pylint_tool_table = tomlkit.table(is_super_table=True)
+        toml_doc.add(tomlkit.key(["tool", "pylint"]), pylint_tool_table)
+
+        for group in sorted(
+            self._arg_parser._action_groups,
+            key=lambda x: (x.title != "Main", x.title),
+        ):
+            # Skip the options section with the --help option
+            if group.title in {"options", "optional arguments", "Commands"}:
+                continue
 
-    def _parse_toml(self, config_file: Path, parser: configparser.ConfigParser) -> None:
-        """Parse and handle errors of a toml configuration file."""
-        with open(config_file, mode="rb") as fp:
-            content = tomllib.load(fp)
-        try:
-            sections_values = content["tool"]["pylint"]
-        except KeyError:
-            return
-        for section, values in sections_values.items():
-            section_name = section.upper()
-            # TOML has rich types, convert values to
-            # strings as ConfigParser expects.
-            if not isinstance(values, dict):
-                # This class is a mixin: add_message comes from the `PyLinter` class
-                self.add_message(  # type: ignore[attr-defined]
-                    "bad-configuration-section", line=0, args=(section, values)
-                )
+            # Skip sections without options such as "positional arguments"
+            if not group._group_actions:
                 continue
-            for option, value in values.items():
-                if isinstance(value, bool):
-                    values[option] = "yes" if value else "no"
-                elif isinstance(value, list):
-                    values[option] = ",".join(value)
-                else:
-                    values[option] = str(value)
-            for option, value in values.items():
-                try:
-                    parser.set(section_name, option, value=value)
-                except configparser.NoSectionError:
-                    parser.add_section(section_name)
-                    parser.set(section_name, option, value=value)
-
-    def load_config_file(self):
-        """Dispatch values previously read from a configuration file to each
-        option's provider.
-        """
-        parser = self.cfgfile_parser
-        for section in parser.sections():
-            for option, value in parser.items(section):
+
+            group_table = tomlkit.table()
+            option_actions = [
+                i
+                for i in group._group_actions
+                if not isinstance(i, argparse._SubParsersAction)
+            ]
+            for action in sorted(option_actions, key=lambda x: x.option_strings[0][2:]):
+                optname = action.option_strings[0][2:]
+
+                # We skip old name options that don't have their own optdict
                 try:
-                    self.global_set_option(option, value)
-                except (KeyError, optparse.OptionError):
+                    optdict = self._option_dicts[optname]
+                except KeyError:
                     continue
 
-    def load_configuration(self, **kwargs):
-        """Override configuration according to given parameters."""
-        return self.load_configuration_from_config(kwargs)
-
-    def load_configuration_from_config(self, config):
-        for opt, opt_value in config.items():
-            opt = opt.replace("_", "-")
-            provider = self._all_options[opt]
-            provider.set_option(opt, opt_value)
+                if optdict.get("hide_from_config_file"):
+                    continue
 
-    def load_command_line_configuration(self, args=None) -> list[str]:
-        """Override configuration according to command line parameters.
+                # Add help comment
+                if not minimal:
+                    help_msg = optdict.get("help", "")
+                    assert isinstance(help_msg, str)
+                    help_text = textwrap.wrap(help_msg, width=79)
+                    for line in help_text:
+                        group_table.add(tomlkit.comment(line))
+
+                # Get current value of option
+                value = getattr(self.config, optname.replace("-", "_"))
+
+                # Create a comment if the option has no value
+                if not value:
+                    if not minimal:
+                        group_table.add(tomlkit.comment(f"{optname} ="))
+                        group_table.add(tomlkit.nl())
+                    continue
 
-        return additional arguments
-        """
-        with _patch_optparse():
-            args = sys.argv[1:] if args is None else list(args)
-            (options, args) = self.cmdline_parser.parse_args(args=args)
-            for provider in self._nocallback_options:
-                config = provider.config
-                for attr in config.__dict__.keys():
-                    value = getattr(options, attr, None)
-                    if value is None:
+                # Skip deprecated options
+                if "kwargs" in optdict:
+                    assert isinstance(optdict["kwargs"], dict)
+                    if "new_names" in optdict["kwargs"]:
                         continue
-                    setattr(config, attr, value)
-            return args
 
-    def help(self, level=0):
-        """Return the usage string for available options."""
-        self.cmdline_parser.formatter.output_level = level
-        with _patch_optparse():
-            return self.cmdline_parser.format_help()
+                # Tomlkit doesn't support regular expressions
+                if isinstance(value, re.Pattern):
+                    value = value.pattern
+                elif isinstance(value, (list, tuple)) and isinstance(
+                    value[0], re.Pattern
+                ):
+                    value = [i.pattern for i in value]
+
+                # Handle tuples that should be strings
+                if optdict.get("type") == "py_version":
+                    value = ".".join(str(i) for i in value)
+
+                # Check if it is default value if we are in minimal mode
+                if minimal and value == optdict.get("default"):
+                    continue
+
+                # Add to table
+                group_table.add(optname, value)
+                group_table.add(tomlkit.nl())
+
+            assert group.title
+            if group_table:
+                pylint_tool_table.add(group.title.lower(), group_table)
+
+        toml_string = tomlkit.dumps(toml_doc)
+
+        # Make sure the string we produce is valid toml and can be parsed
+        tomllib.loads(toml_string)
+
+        return str(toml_string)
+
+    def set_option(self, optname: str, value: Any) -> None:
+        """Set an option on the namespace object."""
+        self.config = self._arg_parser.parse_known_args(
+            [f"--{optname.replace('_', '-')}", _parse_rich_type_value(value)],
+            self.config,
+        )[0]
```

### Comparing `pylint-3.0.0a5/pylint/config/utils.py` & `pylint-3.0.0a6/pylint/config/utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,16 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Utils for arguments/options parsing and handling."""
 
 from __future__ import annotations
 
 import re
-import warnings
 from collections.abc import Callable, Sequence
 from pathlib import Path
 from typing import TYPE_CHECKING, Any
 
 from pylint import extensions, utils
 from pylint.config.argument import (
     _CallableArgument,
@@ -35,21 +34,14 @@
     | _StoreTrueArgument
     | _CallableArgument
     | _StoreOldNamesArgument
     | _StoreNewNamesArgument
     | _ExtendArgument
 ):
     """Convert an optdict to an Argument class instance."""
-    if "level" in optdict and "hide" not in optdict:
-        warnings.warn(
-            "The 'level' key in optdicts has been deprecated. "
-            "Use 'hide' with a boolean to hide an option from the help message.",
-            DeprecationWarning,
-        )
-
     # Get the long and short flags
     flags = [f"--{opt}"]
     if "short" in optdict:
         flags += [f"-{optdict['short']}"]
 
     # Get the action type
     action = optdict.get("action", "store")
@@ -69,24 +61,17 @@
             action=action,
             arg_help=optdict.get("help", ""),
             kwargs=optdict.get("kwargs", {}),
             hide_help=optdict.get("hide", False),
             section=optdict.get("group", None),
             metavar=optdict.get("metavar", None),
         )
-    try:
-        default = optdict["default"]
-    except KeyError:
-        warnings.warn(
-            "An option dictionary should have a 'default' key to specify "
-            "the option's default value. This key will be required in pylint "
-            "3.0. It is not required for 'store_true' and callable actions.",
-            DeprecationWarning,
-        )
-        default = None
+
+    default = optdict["default"]
+
     if action == "extend":
         return _ExtendArgument(
             flags=flags,
             action=action,
             default=[] if default is None else default,
             arg_type=optdict["type"],
             choices=optdict.get("choices", None),
@@ -147,15 +132,15 @@
 
 
 def _parse_rich_type_value(value: Any) -> str:
     """Parse rich (toml) types into strings."""
     if isinstance(value, (list, tuple)):
         return ",".join(_parse_rich_type_value(i) for i in value)
     if isinstance(value, re.Pattern):
-        return value.pattern
+        return str(value.pattern)
     if isinstance(value, dict):
         return ",".join(f"{k}:{v}" for k, v in value.items())
     return str(value)
 
 
 # pylint: disable-next=unused-argument
 def _init_hook(run: Run, value: str | None) -> None:
@@ -197,24 +182,38 @@
         if filename.suffix == ".py" and not filename.stem.startswith("_"):
             extension_name = f"pylint.extensions.{filename.stem}"
             if extension_name not in run._plugins:
                 run._plugins.append(extension_name)
 
 
 PREPROCESSABLE_OPTIONS: dict[
-    str, tuple[bool, Callable[[Run, str | None], None]]
+    str, tuple[bool, Callable[[Run, str | None], None], int]
 ] = {  # pylint: disable=consider-using-namedtuple-or-dataclass
-    "--init-hook": (True, _init_hook),
-    "--rcfile": (True, _set_rcfile),
-    "--output": (True, _set_output),
-    "--load-plugins": (True, _add_plugins),
-    "--verbose": (False, _set_verbose_mode),
-    "-v": (False, _set_verbose_mode),
-    "--enable-all-extensions": (False, _enable_all_extensions),
+    # pylint: disable=useless-suppression, wrong-spelling-in-comment
+    # Argparse by default allows abbreviations. It behaves differently
+    # if you turn this off, so we also turn it on. We mimic this
+    # by allowing some abbreviations or incorrect spelling here.
+    # The integer at the end of the tuple indicates how many letters
+    # should match, include the '-'. 0 indicates a full match.
+    #
+    # Clashes with --init-(import)
+    "--init-hook": (True, _init_hook, 8),
+    # Clashes with --r(ecursive)
+    "--rcfile": (True, _set_rcfile, 4),
+    # Clashes with --output(-format)
+    "--output": (True, _set_output, 0),
+    # Clashes with --lo(ng-help)
+    "--load-plugins": (True, _add_plugins, 5),
+    # Clashes with --v(ariable-rgx)
+    "--verbose": (False, _set_verbose_mode, 4),
+    "-v": (False, _set_verbose_mode, 2),
+    # Clashes with --enable
+    "--enable-all-extensions": (False, _enable_all_extensions, 9),
 }
+# pylint: enable=wrong-spelling-in-comment
 
 
 def _preprocess_options(run: Run, args: Sequence[str]) -> list[str]:
     """Pre-process options before full config parsing has started."""
     processed_args: list[str] = []
 
     i = 0
@@ -226,26 +225,35 @@
             continue
 
         try:
             option, value = argument.split("=", 1)
         except ValueError:
             option, value = argument, None
 
-        if option not in PREPROCESSABLE_OPTIONS:
+        matched_option = None
+        for option_name, data in PREPROCESSABLE_OPTIONS.items():
+            to_match = data[2]
+            if to_match == 0:
+                if option == option_name:
+                    matched_option = option_name
+            elif option.startswith(option_name[:to_match]):
+                matched_option = option_name
+
+        if matched_option is None:
             processed_args.append(argument)
             i += 1
             continue
 
-        takearg, cb = PREPROCESSABLE_OPTIONS[option]
+        takearg, cb, _ = PREPROCESSABLE_OPTIONS[matched_option]
 
         if takearg and value is None:
             i += 1
             if i >= len(args) or args[i].startswith("-"):
                 raise ArgumentPreprocessingError(f"Option {option} expects a value")
             value = args[i]
         elif not takearg and value is not None:
-            raise ArgumentPreprocessingError(f"Option {option} doesn't expects a value")
+            raise ArgumentPreprocessingError(f"Option {option} doesn't expect a value")
 
         cb(run, value)
         i += 1
 
     return processed_args
```

### Comparing `pylint-3.0.0a5/pylint/extensions/__init__.py` & `pylint-3.0.0a6/pylint/extensions/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from pylint.utils import register_plugins
```

### Comparing `pylint-3.0.0a5/pylint/extensions/_check_docs_utils.py` & `pylint-3.0.0a6/pylint/extensions/_check_docs_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,20 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Utility methods for docstring checking."""
 
 from __future__ import annotations
 
 import re
 
 import astroid
 from astroid import nodes
+from astroid.util import UninferableBase
 
 from pylint.checkers import utils
 
 
 def space_indentation(s: str) -> int:
     """The number of leading spaces in a string.
 
@@ -38,15 +39,15 @@
     decorators = node.decorators.nodes if node.decorators else []
     for decorator in decorators:
         if (
             isinstance(decorator, nodes.Attribute)
             and decorator.attrname == "setter"
             and isinstance(decorator.expr, nodes.Name)
         ):
-            return decorator.expr.name
+            return decorator.expr.name  # type: ignore[no-any-return]
     return None
 
 
 def get_setters_property(node: nodes.FunctionDef) -> nodes.FunctionDef | None:
     """Get the property node for the given setter node.
 
     :param node: The node to get the property for.
@@ -84,15 +85,15 @@
 
     if returns is None:
         return False
 
     return not (isinstance(returns, nodes.Const) and returns.value is None)
 
 
-def _get_raise_target(node):
+def _get_raise_target(node: nodes.NodeNG) -> nodes.NodeNG | UninferableBase | None:
     if isinstance(node.exc, nodes.Call):
         func = node.exc.func
         if isinstance(func, (nodes.Name, nodes.Attribute)):
             return utils.safe_infer(func)
     return None
 
 
@@ -121,15 +122,15 @@
         handler = node.parent
         while handler and not isinstance(handler, nodes.ExceptHandler):
             handler = handler.parent
 
         if handler and handler.type:
             try:
                 for exception in astroid.unpack_infer(handler.type):
-                    if exception is not astroid.Uninferable:
+                    if not isinstance(exception, UninferableBase):
                         exceptions.append(exception)
             except astroid.InferenceError:
                 pass
     else:
         target = _get_raise_target(node)
         if isinstance(target, nodes.ClassDef):
             exceptions = [target]
@@ -242,15 +243,15 @@
     re_simple_container_type = rf"""
         {re_type}                     # a container type
         [\(\[] [^\n\s]+ [\)\]]        # with the contents of the container
     """
 
     re_multiple_simple_type = r"""
         (?:{container_type}|{type})
-        (?:(?:\s+(?:of|or)\s+|\s*,\s*)(?:{container_type}|{type}))*
+        (?:(?:\s+(?:of|or)\s+|\s*,\s*|\s+\|\s+)(?:{container_type}|{type}))*
     """.format(
         type=re_type, container_type=re_simple_container_type
     )
 
     re_xref = rf"""
         (?::\w+:)?                    # optional tag
         `{re_type}`                   # what to reference
@@ -444,15 +445,15 @@
     re_container_type = rf"""
         (?:{re_type}|{re_xref})       # a container type
         [\(\[] [^\n]+ [\)\]]          # with the contents of the container
     """
 
     re_multiple_type = r"""
         (?:{container_type}|{type}|{xref})
-        (?:(?:\s+(?:of|or)\s+|\s*,\s*)(?:{container_type}|{type}|{xref}))*
+        (?:(?:\s+(?:of|or)\s+|\s*,\s*|\s+\|\s+)(?:{container_type}|{type}|{xref}))*
     """.format(
         type=re_type, xref=re_xref, container_type=re_container_type
     )
 
     _re_section_template = r"""
         ^([ ]*)   {0} \s*:   \s*$     # Google parameter header
         (  .* )                       # section
@@ -466,15 +467,15 @@
     re_keyword_param_section = re.compile(
         _re_section_template.format(r"Keyword\s(?:Args|Arguments|Parameters)"),
         re.X | re.S | re.M,
     )
 
     re_param_line = re.compile(
         rf"""
-        \s*  ((?:\\?\*{{0,2}})?\w+)     # identifier potentially with asterisks
+        \s*  ((?:\\?\*{{0,2}})?[\w\\]+) # identifier potentially with asterisks or escaped `\`
         \s*  ( [(]
             {re_multiple_type}
             (?:,\s+optional)?
             [)] )? \s* :                # optional type declaration
         \s*  (.*)                       # beginning of optional description
     """,
         re.X | re.S | re.M,
@@ -723,19 +724,33 @@
     """
 
     re_param_section = re.compile(
         _re_section_template.format(r"(?:Args|Arguments|Parameters)"),
         re.X | re.S | re.M,
     )
 
+    re_default_value = r"""((['"]\w+\s*['"])|(\d+)|(True)|(False)|(None))"""
+
     re_param_line = re.compile(
         rf"""
-        \s*  (\*{{0,2}}\w+)(\s?(:|\n))                                      # identifier with potential asterisks
-        \s*  (?:({GoogleDocstring.re_multiple_type})(?:,\s+optional)?\n)?   # optional type declaration
-        \s* (.*)                                                            # optional description
+        \s*  (?P<param_name>\*{{0,2}}\w+)(\s?(:|\n)) # identifier with potential asterisks
+        \s*
+        (?P<param_type>
+         (
+          ({GoogleDocstring.re_multiple_type})      # default type declaration
+          (,\s+optional)?                           # optional 'optional' indication
+         )?
+         (
+          {{({re_default_value},?\s*)+}}            # set of default values
+         )?
+         (?:$|\n)
+        )?
+        (
+         \s* (?P<param_desc>.*)                     # optional description
+        )?
     """,
         re.X | re.S,
     )
 
     re_raise_section = re.compile(
         _re_section_template.format(r"Raises"), re.X | re.S | re.M
     )
@@ -778,23 +793,34 @@
         entries.extend(self._parse_section(self.re_keyword_param_section))
         for entry in entries:
             match = self.re_param_line.match(entry)
             if not match:
                 continue
 
             # check if parameter has description only
-            re_only_desc = re.match(r"\s*  (\*{0,2}\w+)\s*:?\n", entry)
+            re_only_desc = re.match(r"\s*(\*{0,2}\w+)\s*:?\n\s*\w*$", entry)
             if re_only_desc:
-                param_name = match.group(1)
-                param_desc = match.group(2)
+                param_name = match.group("param_name")
+                param_desc = match.group("param_type")
                 param_type = None
             else:
-                param_name = match.group(1)
-                param_type = match.group(3)
-                param_desc = match.group(4)
+                param_name = match.group("param_name")
+                param_type = match.group("param_type")
+                param_desc = match.group("param_desc")
+                # The re_param_line pattern needs to match multi-line which removes the ability
+                # to match a single line description like 'arg : a number type.'
+                # We are not trying to determine whether 'a number type' is correct typing
+                # but we do accept it as typing as it is in the place where typing
+                # should be
+                if param_type is None and re.match(r"\s*(\*{0,2}\w+)\s*:.+$", entry):
+                    param_type = param_desc
+                # If the description is "" but we have a type description
+                # we consider the description to be the type
+                if not param_desc and param_type:
+                    param_desc = param_type
 
             if param_type:
                 params_with_type.add(param_name)
 
             if param_desc:
                 params_with_doc.add(param_name)
```

### Comparing `pylint-3.0.0a5/pylint/extensions/bad_builtin.py` & `pylint-3.0.0a6/pylint/extensions/bad_builtin.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checker for deprecated builtins."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
@@ -14,20 +14,19 @@
 from pylint.checkers.utils import only_required_for_messages
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 BAD_FUNCTIONS = ["map", "filter"]
 # Some hints regarding the use of bad builtins.
-BUILTIN_HINTS = {"map": "Using a list comprehension can be clearer."}
-BUILTIN_HINTS["filter"] = BUILTIN_HINTS["map"]
+LIST_COMP_MSG = "Using a list comprehension can be clearer."
+BUILTIN_HINTS = {"map": LIST_COMP_MSG, "filter": LIST_COMP_MSG}
 
 
 class BadBuiltinChecker(BaseChecker):
-
     name = "deprecated_builtins"
     msgs = {
         "W0141": (
             "Used builtin function %s",
             "bad-builtin",
             "Used when a disallowed builtin function is used (see the "
             "bad-function option). Usual disallowed functions are the ones "
```

### Comparing `pylint-3.0.0a5/pylint/extensions/broad_try_clause.py` & `pylint-3.0.0a6/pylint/extensions/broad_try_clause.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Looks for try/except statements with too much code in the try clause."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
@@ -42,30 +42,32 @@
                 "type": "int",
                 "metavar": "<int>",
                 "help": "Maximum number of statements allowed in a try clause",
             },
         ),
     )
 
-    def _count_statements(self, try_node):
+    def _count_statements(self, try_node: nodes.TryExcept | nodes.TryFinally) -> int:
         statement_count = len(try_node.body)
 
         for body_node in try_node.body:
             if isinstance(body_node, (nodes.For, nodes.If, nodes.While, nodes.With)):
                 statement_count += self._count_statements(body_node)
 
         return statement_count
 
     def visit_tryexcept(self, node: nodes.TryExcept | nodes.TryFinally) -> None:
         try_clause_statements = self._count_statements(node)
         if try_clause_statements > self.linter.config.max_try_statements:
-            msg = f"try clause contains {try_clause_statements} statements, expected at most {self.linter.config.max_try_statements}"
+            msg = (
+                f"try clause contains {try_clause_statements} statements, expected at"
+                f" most {self.linter.config.max_try_statements}"
+            )
             self.add_message(
                 "too-many-try-statements", node.lineno, node=node, args=msg
             )
 
-    def visit_tryfinally(self, node: nodes.TryFinally) -> None:
-        self.visit_tryexcept(node)
+    visit_tryfinally = visit_tryexcept
 
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(BroadTryClauseChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/extensions/check_elif.py` & `pylint-3.0.0a6/pylint/extensions/check_elif.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
+import tokenize
 from tokenize import TokenInfo
 from typing import TYPE_CHECKING
 
 from astroid import nodes
 
 from pylint.checkers import BaseTokenChecker
 from pylint.checkers.utils import only_required_for_messages
@@ -27,20 +28,20 @@
             "else-if-used",
             "Used when an else statement is immediately followed by "
             "an if statement and does not contain statements that "
             "would be unrelated to it.",
         )
     }
 
-    def __init__(self, linter=None):
+    def __init__(self, linter: PyLinter) -> None:
         super().__init__(linter)
         self._init()
 
-    def _init(self):
-        self._elifs = {}
+    def _init(self) -> None:
+        self._elifs: dict[tokenize._Position, str] = {}
 
     def process_tokens(self, tokens: list[TokenInfo]) -> None:
         """Process tokens and look for 'if' or 'elif'."""
         self._elifs = {
             begin: token for _, token, begin, _, _ in tokens if token in {"elif", "if"}
         }
```

### Comparing `pylint-3.0.0a5/pylint/extensions/code_style.py` & `pylint-3.0.0a6/pylint/extensions/code_style.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,21 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import sys
-from typing import TYPE_CHECKING, Tuple, Type, Union, cast
+from typing import TYPE_CHECKING, Tuple, Type, cast
 
 from astroid import nodes
 
 from pylint.checkers import BaseChecker, utils
 from pylint.checkers.utils import only_required_for_messages, safe_infer
+from pylint.interfaces import INFERENCE
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 if sys.version_info >= (3, 10):
     from typing import TypeGuard
 else:
@@ -54,14 +55,24 @@
         "R6103": (
             "Use '%s' instead",
             "consider-using-assignment-expr",
             "Emitted when an if assignment is directly followed by an if statement and "
             "both can be combined by using an assignment expression ``:=``. "
             "Requires Python 3.8 and ``py-version >= 3.8``.",
         ),
+        "R6104": (
+            "Use '%s' to do an augmented assign directly",
+            "consider-using-augmented-assign",
+            "Emitted when an assignment is referring to the object that it is assigning "
+            "to. This can be changed to be an augmented assign.\n"
+            "Disabled by default!",
+            {
+                "default_enabled": False,
+            },
+        ),
     }
     options = (
         (
             "max-line-length-suggestions",
             {
                 "type": "int",
                 "default": 0,
@@ -160,21 +171,19 @@
             for _, dict_value in node.items
         ):
             # Make sure all sublists have the same length > 0
             list_length = len(node.items[0][1].elts)
             if list_length == 0:
                 return
             for _, dict_value in node.items[1:]:
-                dict_value = cast(Union[nodes.List, nodes.Tuple], dict_value)
                 if len(dict_value.elts) != list_length:
                     return
 
             # Make sure at least one list entry isn't a dict
             for _, dict_value in node.items:
-                dict_value = cast(Union[nodes.List, nodes.Tuple], dict_value)
                 if all(isinstance(entry, nodes.Dict) for entry in dict_value.elts):
                     return
 
             self.add_message("consider-using-namedtuple-or-dataclass", node=node)
             return
 
     def _check_consider_using_assignment_expr(self, node: nodes.If) -> None:
@@ -212,15 +221,14 @@
 
         # Make sure the previous node is an assignment to the same name
         # used in `node.test`. Furthermore, ignore if assignment spans multiple lines.
         prev_sibling = node.previous_sibling()
         if CodeStyleChecker._check_prev_sibling_to_if_stmt(
             prev_sibling, node_name.name
         ):
-
             # Check if match statement would be a better fit.
             # I.e. multiple ifs that test the same name.
             if CodeStyleChecker._check_ignore_assignment_expr_suggestion(
                 node, node_name.name
             ):
                 return
 
@@ -299,10 +307,23 @@
                     or isinstance(next_if_node.test, nodes.Name)
                     and next_if_node.test.name == name
                 )
             ):
                 return True
         return False
 
+    @only_required_for_messages("consider-using-augmented-assign")
+    def visit_assign(self, node: nodes.Assign) -> None:
+        is_aug, op = utils.is_augmented_assign(node)
+        if is_aug:
+            self.add_message(
+                "consider-using-augmented-assign",
+                args=f"{op}=",
+                node=node,
+                line=node.lineno,
+                col_offset=node.col_offset,
+                confidence=INFERENCE,
+            )
+
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(CodeStyleChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/extensions/comparetozero.py` & `pylint-3.0.0a6/pylint/extensions/comparetozero.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,46 +1,50 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Looks for comparisons to zero."""
 
 from __future__ import annotations
 
 import itertools
-from collections.abc import Iterable
-from typing import TYPE_CHECKING, Any
+from typing import TYPE_CHECKING
 
 import astroid
 from astroid import nodes
 
 from pylint import checkers
 from pylint.checkers import utils
+from pylint.interfaces import HIGH
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
-def _is_constant_zero(node):
-    return isinstance(node, astroid.Const) and node.value == 0
+def _is_constant_zero(node: str | nodes.NodeNG) -> bool:
+    # We have to check that node.value is not False because node.value == 0 is True
+    # when node.value is False
+    return (
+        isinstance(node, astroid.Const) and node.value == 0 and node.value is not False
+    )
 
 
 class CompareToZeroChecker(checkers.BaseChecker):
     """Checks for comparisons to zero.
 
     Most of the time you should use the fact that integers with a value of 0 are false.
     An exception to this rule is when 0 is allowed in the program and has a
     different meaning than None!
     """
 
     # configuration section name
     name = "compare-to-zero"
     msgs = {
         "C2001": (
-            "Avoid comparisons to zero",
+            '"%s" can be simplified to "%s" as 0 is falsey',
             "compare-to-zero",
             "Used when Pylint detects comparison to a 0 constant.",
         )
     }
 
     options = ()
 
@@ -48,31 +52,44 @@
     def visit_compare(self, node: nodes.Compare) -> None:
         # pylint: disable=duplicate-code
         _operators = ["!=", "==", "is not", "is"]
         # note: astroid.Compare has the left most operand in node.left
         # while the rest are a list of tuples in node.ops
         # the format of the tuple is ('compare operator sign', node)
         # here we squash everything into `ops` to make it easier for processing later
-        ops = [("", node.left)]
+        ops: list[tuple[str, nodes.NodeNG]] = [("", node.left)]
         ops.extend(node.ops)
-        iter_ops: Iterable[Any] = iter(ops)
-        ops = list(itertools.chain(*iter_ops))
+        iter_ops = iter(ops)
+        all_ops = list(itertools.chain(*iter_ops))
 
-        for ops_idx in range(len(ops) - 2):
-            op_1 = ops[ops_idx]
-            op_2 = ops[ops_idx + 1]
-            op_3 = ops[ops_idx + 2]
+        for ops_idx in range(len(all_ops) - 2):
+            op_1 = all_ops[ops_idx]
+            op_2 = all_ops[ops_idx + 1]
+            op_3 = all_ops[ops_idx + 2]
             error_detected = False
 
             # 0 ?? X
             if _is_constant_zero(op_1) and op_2 in _operators:
                 error_detected = True
+                op = op_3
             # X ?? 0
             elif op_2 in _operators and _is_constant_zero(op_3):
                 error_detected = True
+                op = op_1
 
             if error_detected:
-                self.add_message("compare-to-zero", node=node)
+                original = f"{op_1.as_string()} {op_2} {op_3.as_string()}"
+                suggestion = (
+                    op.as_string()
+                    if op_2 in {"!=", "is not"}
+                    else f"not {op.as_string()}"
+                )
+                self.add_message(
+                    "compare-to-zero",
+                    args=(original, suggestion),
+                    node=node,
+                    confidence=HIGH,
+                )
 
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(CompareToZeroChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/extensions/comparison_placement.py` & `pylint-3.0.0a6/pylint/extensions/comparison_placement.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Checks for yoda comparisons (variable before constant)
 See https://en.wikipedia.org/wiki/Yoda_conditions.
 """
 
 from __future__ import annotations
 
@@ -41,15 +41,15 @@
 
     def _check_misplaced_constant(
         self,
         node: nodes.Compare,
         left: nodes.NodeNG,
         right: nodes.NodeNG,
         operator: str,
-    ):
+    ) -> None:
         if isinstance(right, nodes.Const):
             return
         operator = REVERSED_COMPS.get(operator, operator)
         suggestion = f"{right.as_string()} {operator} {left.value!r}"
         self.add_message("misplaced-comparison-constant", node=node, args=(suggestion,))
 
     @utils.only_required_for_messages("misplaced-comparison-constant")
```

### Comparing `pylint-3.0.0a5/pylint/extensions/confusing_elif.py` & `pylint-3.0.0a6/pylint/extensions/confusing_elif.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from astroid import nodes
 
@@ -19,32 +19,34 @@
     """Checks if "elif" is used right after an indented block that finishes with "if" or
     "elif" itself.
     """
 
     name = "confusing_elif"
     msgs = {
         "R5601": (
-            "Consecutive elif with differing indentation level, consider creating a function to separate the inner elif",
+            "Consecutive elif with differing indentation level, consider creating a function to separate the inner"
+            " elif",
             "confusing-consecutive-elif",
             "Used when an elif statement follows right after an indented block which itself ends with if or elif. "
             "It may not be ovious if the elif statement was willingly or mistakenly unindented. "
-            "Extracting the indented if statement into a separate function might avoid confusion and prevent errors.",
+            "Extracting the indented if statement into a separate function might avoid confusion and prevent "
+            "errors.",
         )
     }
 
     @only_required_for_messages("confusing-consecutive-elif")
     def visit_if(self, node: nodes.If) -> None:
         body_ends_with_if = isinstance(
             node.body[-1], nodes.If
         ) and self._has_no_else_clause(node.body[-1])
         if node.has_elif_block() and body_ends_with_if:
             self.add_message("confusing-consecutive-elif", node=node.orelse[0])
 
     @staticmethod
-    def _has_no_else_clause(node: nodes.If):
+    def _has_no_else_clause(node: nodes.If) -> bool:
         orelse = node.orelse
         while orelse and isinstance(orelse[0], nodes.If):
             orelse = orelse[0].orelse
         if not orelse or isinstance(orelse[0], nodes.If):
             return True
         return False
```

### Comparing `pylint-3.0.0a5/pylint/extensions/consider_ternary_expression.py` & `pylint-3.0.0a6/pylint/extensions/consider_ternary_expression.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Check for if / assign blocks that can be rewritten with if-expressions."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
@@ -13,15 +13,14 @@
 from pylint.checkers import BaseChecker
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
 class ConsiderTernaryExpressionChecker(BaseChecker):
-
     name = "consider_ternary_expression"
     msgs = {
         "W0160": (
             "Consider rewriting as a ternary expression",
             "consider-ternary-expression",
             "Multiple assign statements spread across if/else blocks can be "
             "rewritten with a single assignment and ternary expression",
@@ -37,15 +36,15 @@
 
         bst = node.body[0]
         ost = node.orelse[0]
 
         if not isinstance(bst, nodes.Assign) or not isinstance(ost, nodes.Assign):
             return
 
-        for (bname, oname) in zip(bst.targets, ost.targets):
+        for bname, oname in zip(bst.targets, ost.targets):
             if not isinstance(bname, nodes.AssignName) or not isinstance(
                 oname, nodes.AssignName
             ):
                 return
 
             if bname.name != oname.name:
                 return
```

### Comparing `pylint-3.0.0a5/pylint/extensions/docparams.py` & `pylint-3.0.0a6/pylint/extensions/docparams.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Pylint plugin for checking in Sphinx, Google, or Numpy style docstrings."""
 
 from __future__ import annotations
 
 import re
 from typing import TYPE_CHECKING
@@ -12,14 +12,15 @@
 import astroid
 from astroid import nodes
 
 from pylint.checkers import BaseChecker
 from pylint.checkers import utils as checker_utils
 from pylint.extensions import _check_docs_utils as utils
 from pylint.extensions._check_docs_utils import Docstring
+from pylint.interfaces import HIGH
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
 class DocstringParameterChecker(BaseChecker):
     """Checker for Sphinx, Google, or Numpy style docstrings.
@@ -212,15 +213,17 @@
 
         self.check_functiondef_params(node, node_doc)
         self.check_functiondef_returns(node, node_doc)
         self.check_functiondef_yields(node, node_doc)
 
     visit_asyncfunctiondef = visit_functiondef
 
-    def check_functiondef_params(self, node, node_doc):
+    def check_functiondef_params(
+        self, node: nodes.FunctionDef, node_doc: Docstring
+    ) -> None:
         node_allow_no_param = None
         if node.name in self.constructor_names:
             class_node = checker_utils.node_frame_class(node)
             if class_node is not None:
                 class_doc = utils.docstringify(
                     class_node.doc_node, self.linter.config.default_docstring_type
                 )
@@ -243,38 +246,47 @@
                     class_doc, node.args, class_node, class_allow_no_param
                 )
 
         self.check_arguments_in_docstring(
             node_doc, node.args, node, node_allow_no_param
         )
 
-    def check_functiondef_returns(self, node, node_doc):
+    def check_functiondef_returns(
+        self, node: nodes.FunctionDef, node_doc: Docstring
+    ) -> None:
         if (not node_doc.supports_yields and node.is_generator()) or node.is_abstract():
             return
 
         return_nodes = node.nodes_of_class(astroid.Return)
         if (node_doc.has_returns() or node_doc.has_rtype()) and not any(
             utils.returns_something(ret_node) for ret_node in return_nodes
         ):
-            self.add_message("redundant-returns-doc", node=node)
+            self.add_message("redundant-returns-doc", node=node, confidence=HIGH)
 
-    def check_functiondef_yields(self, node, node_doc):
+    def check_functiondef_yields(
+        self, node: nodes.FunctionDef, node_doc: Docstring
+    ) -> None:
         if not node_doc.supports_yields or node.is_abstract():
             return
 
         if (
             node_doc.has_yields() or node_doc.has_yields_type()
         ) and not node.is_generator():
             self.add_message("redundant-yields-doc", node=node)
 
     def visit_raise(self, node: nodes.Raise) -> None:
         func_node = node.frame(future=True)
         if not isinstance(func_node, astroid.FunctionDef):
             return
 
+        # skip functions that match the 'no-docstring-rgx' config option
+        no_docstring_rgx = self.linter.config.no_docstring_rgx
+        if no_docstring_rgx and re.match(no_docstring_rgx, func_node.name):
+            return
+
         expected_excs = utils.possible_exc_types(node)
 
         if not expected_excs:
             return
 
         if not func_node.doc_node:
             # If this is a property setter,
@@ -282,18 +294,22 @@
             property_ = utils.get_setters_property(func_node)
             if property_:
                 func_node = property_
 
         doc = utils.docstringify(
             func_node.doc_node, self.linter.config.default_docstring_type
         )
+
+        if self.linter.config.accept_no_raise_doc and not doc.exceptions():
+            return
+
         if not doc.matching_sections():
             if doc.doc:
                 missing = {exc.name for exc in expected_excs}
-                self._handle_no_raise_doc(missing, func_node)
+                self._add_raise_message(missing, func_node)
             return
 
         found_excs_full_names = doc.exceptions()
 
         # Extract just the class name, e.g. "error" from "re.error"
         found_excs_class_names = {exc.split(".")[-1] for exc in found_excs_full_names}
 
@@ -312,60 +328,65 @@
     def visit_return(self, node: nodes.Return) -> None:
         if not utils.returns_something(node):
             return
 
         if self.linter.config.accept_no_return_doc:
             return
 
-        func_node = node.frame(future=True)
-        if not isinstance(func_node, astroid.FunctionDef):
+        func_node: astroid.FunctionDef = node.frame(future=True)
+
+        # skip functions that match the 'no-docstring-rgx' config option
+        no_docstring_rgx = self.linter.config.no_docstring_rgx
+        if no_docstring_rgx and re.match(no_docstring_rgx, func_node.name):
             return
 
         doc = utils.docstringify(
             func_node.doc_node, self.linter.config.default_docstring_type
         )
 
         is_property = checker_utils.decorated_with_property(func_node)
 
         if not (doc.has_returns() or (doc.has_property_returns() and is_property)):
-            self.add_message("missing-return-doc", node=func_node)
+            self.add_message("missing-return-doc", node=func_node, confidence=HIGH)
 
         if func_node.returns:
             return
 
         if not (doc.has_rtype() or (doc.has_property_type() and is_property)):
-            self.add_message("missing-return-type-doc", node=func_node)
+            self.add_message("missing-return-type-doc", node=func_node, confidence=HIGH)
 
-    def visit_yield(self, node: nodes.Yield) -> None:
+    def visit_yield(self, node: nodes.Yield | nodes.YieldFrom) -> None:
         if self.linter.config.accept_no_yields_doc:
             return
 
-        func_node = node.frame(future=True)
-        if not isinstance(func_node, astroid.FunctionDef):
+        func_node: astroid.FunctionDef = node.frame(future=True)
+
+        # skip functions that match the 'no-docstring-rgx' config option
+        no_docstring_rgx = self.linter.config.no_docstring_rgx
+        if no_docstring_rgx and re.match(no_docstring_rgx, func_node.name):
             return
 
         doc = utils.docstringify(
             func_node.doc_node, self.linter.config.default_docstring_type
         )
 
         if doc.supports_yields:
             doc_has_yields = doc.has_yields()
             doc_has_yields_type = doc.has_yields_type()
         else:
             doc_has_yields = doc.has_returns()
             doc_has_yields_type = doc.has_rtype()
 
         if not doc_has_yields:
-            self.add_message("missing-yield-doc", node=func_node)
+            self.add_message("missing-yield-doc", node=func_node, confidence=HIGH)
 
         if not (doc_has_yields_type or func_node.returns):
-            self.add_message("missing-yield-type-doc", node=func_node)
+            self.add_message("missing-yield-type-doc", node=func_node, confidence=HIGH)
 
-    def visit_yieldfrom(self, node: nodes.YieldFrom) -> None:
-        self.visit_yield(node)
+    visit_yieldfrom = visit_yield
 
     def _compare_missing_args(
         self,
         found_argument_names: set[str],
         message_id: str,
         not_needed_names: set[str],
         expected_argument_names: set[str],
@@ -396,14 +417,15 @@
             missing_argument_names.add(name)
 
         if missing_argument_names:
             self.add_message(
                 message_id,
                 args=(", ".join(sorted(missing_argument_names)),),
                 node=warning_node,
+                confidence=HIGH,
             )
 
     def _compare_different_args(
         self,
         found_argument_names: set[str],
         message_id: str,
         not_needed_names: set[str],
@@ -438,54 +460,49 @@
         )
 
         if differing_argument_names:
             self.add_message(
                 message_id,
                 args=(", ".join(sorted(differing_argument_names)),),
                 node=warning_node,
+                confidence=HIGH,
             )
 
-    def _compare_ignored_args(
+    def _compare_ignored_args(  # pylint: disable=useless-param-doc
         self,
-        found_argument_names,
-        message_id,
-        ignored_argument_names,
-        warning_node,
-    ):
+        found_argument_names: set[str],
+        message_id: str,
+        ignored_argument_names: set[str],
+        warning_node: nodes.NodeNG,
+    ) -> None:
         """Compare the found argument names with the ignored ones and
         generate a message if there are ignored arguments found.
 
         :param found_argument_names: argument names found in the docstring
-        :type found_argument_names: set
-
         :param message_id: pylint message id
-        :type message_id: str
-
         :param ignored_argument_names: Expected argument names
-        :type ignored_argument_names: set
-
         :param warning_node: The node to be analyzed
-        :type warning_node: :class:`astroid.scoped_nodes.Node`
         """
         existing_ignored_argument_names = ignored_argument_names & found_argument_names
 
         if existing_ignored_argument_names:
             self.add_message(
                 message_id,
                 args=(", ".join(sorted(existing_ignored_argument_names)),),
                 node=warning_node,
+                confidence=HIGH,
             )
 
     def check_arguments_in_docstring(
         self,
         doc: Docstring,
         arguments_node: astroid.Arguments,
         warning_node: astroid.NodeNG,
         accept_no_param_doc: bool | None = None,
-    ):
+    ) -> None:
         """Check that all parameters are consistent with the parameters mentioned
         in the parameter documentation (e.g. the Sphinx tags 'param' and 'type').
 
         * Undocumented parameters except 'self' are noticed.
         * Undocumented parameter types except for 'self' and the ``*<args>``
           and ``**<kwargs>`` parameters are noticed.
         * Parameters mentioned in the parameter documentation that don't or no
@@ -520,14 +537,15 @@
         if accept_no_param_doc is None:
             accept_no_param_doc = self.linter.config.accept_no_param_doc
         tolerate_missing_params = doc.params_documented_elsewhere()
 
         # Collect the function arguments.
         expected_argument_names = {arg.name for arg in arguments_node.args}
         expected_argument_names.update(arg.name for arg in arguments_node.kwonlyargs)
+        expected_argument_names.update(arg.name for arg in arguments_node.posonlyargs)
         not_needed_type_in_docstring = self.not_needed_param_in_docstring.copy()
 
         expected_but_ignored_argument_names = set()
         ignored_argument_names = self.linter.config.ignored_argument_names
         if ignored_argument_names:
             expected_but_ignored_argument_names = {
                 arg
@@ -557,14 +575,17 @@
         )
         for index, arg_name in enumerate(arguments_node.args):
             if arguments_node.annotations[index]:
                 params_with_type.add(arg_name.name)
         for index, arg_name in enumerate(arguments_node.kwonlyargs):
             if arguments_node.kwonlyargs_annotations[index]:
                 params_with_type.add(arg_name.name)
+        for index, arg_name in enumerate(arguments_node.posonlyargs):
+            if arguments_node.posonlyargs_annotations[index]:
+                params_with_type.add(arg_name.name)
 
         if not tolerate_missing_params:
             missing_param_doc = (expected_argument_names - params_with_doc) - (
                 self.not_needed_param_in_docstring | expected_but_ignored_argument_names
             )
             missing_type_doc = (expected_argument_names - params_with_type) - (
                 not_needed_type_in_docstring | expected_but_ignored_argument_names
@@ -573,14 +594,15 @@
                 missing_param_doc == expected_argument_names == missing_type_doc
                 and len(expected_argument_names) != 0
             ):
                 self.add_message(
                     "missing-any-param-doc",
                     args=(warning_node.name,),
                     node=warning_node,
+                    confidence=HIGH,
                 )
             else:
                 self._compare_missing_args(
                     params_with_doc,
                     "missing-param-doc",
                     self.not_needed_param_in_docstring
                     | expected_but_ignored_argument_names,
@@ -612,44 +634,42 @@
         self._compare_ignored_args(
             params_with_doc,
             "useless-param-doc",
             expected_but_ignored_argument_names,
             warning_node,
         )
 
-    def check_single_constructor_params(self, class_doc, init_doc, class_node):
+    def check_single_constructor_params(
+        self, class_doc: Docstring, init_doc: Docstring, class_node: nodes.ClassDef
+    ) -> None:
         if class_doc.has_params() and init_doc.has_params():
             self.add_message(
-                "multiple-constructor-doc", args=(class_node.name,), node=class_node
+                "multiple-constructor-doc",
+                args=(class_node.name,),
+                node=class_node,
+                confidence=HIGH,
             )
 
-    def _handle_no_raise_doc(self, excs, node):
-        if self.linter.config.accept_no_raise_doc:
-            return
-
-        self._add_raise_message(excs, node)
-
-    def _add_raise_message(self, missing_excs, node):
+    def _add_raise_message(
+        self, missing_exceptions: set[str], node: nodes.FunctionDef
+    ) -> None:
         """Adds a message on :param:`node` for the missing exception type.
 
-        :param missing_excs: A list of missing exception types.
-        :type missing_excs: set(str)
-
+        :param missing_exceptions: A list of missing exception types.
         :param node: The node show the message on.
-        :type node: nodes.NodeNG
         """
         if node.is_abstract():
             try:
-                missing_excs.remove("NotImplementedError")
+                missing_exceptions.remove("NotImplementedError")
             except KeyError:
                 pass
-
-        if not missing_excs:
-            return
-
-        self.add_message(
-            "missing-raises-doc", args=(", ".join(sorted(missing_excs)),), node=node
-        )
+        if missing_exceptions:
+            self.add_message(
+                "missing-raises-doc",
+                args=(", ".join(sorted(missing_exceptions)),),
+                node=node,
+                confidence=HIGH,
+            )
 
 
 def register(linter: PyLinter) -> None:
     linter.register_checker(DocstringParameterChecker(linter))
```

### Comparing `pylint-3.0.0a5/pylint/extensions/docstyle.py` & `pylint-3.0.0a6/pylint/extensions/docstyle.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import linecache
 from typing import TYPE_CHECKING
 
 from astroid import nodes
@@ -44,15 +44,17 @@
 
     def visit_functiondef(self, node: nodes.FunctionDef) -> None:
         ftype = "method" if node.is_method() else "function"
         self._check_docstring(ftype, node)
 
     visit_asyncfunctiondef = visit_functiondef
 
-    def _check_docstring(self, node_type, node):
+    def _check_docstring(
+        self, node_type: str, node: nodes.Module | nodes.ClassDef | nodes.FunctionDef
+    ) -> None:
         docstring = node.doc_node.value if node.doc_node else None
         if docstring and docstring[0] == "\n":
             self.add_message(
                 "docstring-first-line-empty",
                 node=node,
                 args=(node_type,),
                 confidence=HIGH,
@@ -69,15 +71,15 @@
             if line and "'''" in line:
                 quotes = "'''"
             elif line and line[0] == '"':
                 quotes = '"'
             elif line and line[0] == "'":
                 quotes = "'"
             else:
-                quotes = False
+                quotes = ""
             if quotes:
                 self.add_message(
                     "bad-docstring-quotes",
                     node=node,
                     args=(node_type, quotes),
                     confidence=HIGH,
                 )
```

### Comparing `pylint-3.0.0a5/pylint/extensions/empty_comment.py` & `pylint-3.0.0a6/pylint/extensions/empty_comment.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,65 +1,64 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from astroid import nodes
 
 from pylint.checkers import BaseRawFileChecker
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
-def is_line_commented(line):
+def is_line_commented(line: bytes) -> bool:
     """Checks if a `# symbol that is not part of a string was found in line."""
 
     comment_idx = line.find(b"#")
     if comment_idx == -1:
         return False
     if comment_part_of_string(line, comment_idx):
         return is_line_commented(line[:comment_idx] + line[comment_idx + 1 :])
     return True
 
 
-def comment_part_of_string(line, comment_idx):
+def comment_part_of_string(line: bytes, comment_idx: int) -> bool:
     """Checks if the symbol at comment_idx is part of a string."""
 
     if (
         line[:comment_idx].count(b"'") % 2 == 1
         and line[comment_idx:].count(b"'") % 2 == 1
     ) or (
         line[:comment_idx].count(b'"') % 2 == 1
         and line[comment_idx:].count(b'"') % 2 == 1
     ):
         return True
     return False
 
 
 class CommentChecker(BaseRawFileChecker):
-
-    name = "refactoring"
+    name = "empty-comment"
     msgs = {
         "R2044": (
             "Line with empty comment",
             "empty-comment",
             (
                 "Used when a # symbol appears on a line not followed by an actual comment"
             ),
         )
     }
     options = ()
 
     def process_module(self, node: nodes.Module) -> None:
         with node.stream() as stream:
-            for (line_num, line) in enumerate(stream):
+            for line_num, line in enumerate(stream):
                 line = line.rstrip()
                 if line.endswith(b"#"):
                     if not is_line_commented(line[:-1]):
                         self.add_message("empty-comment", line=line_num + 1)
 
 
 def register(linter: PyLinter) -> None:
```

### Comparing `pylint-3.0.0a5/pylint/extensions/eq_without_hash.py` & `pylint-3.0.0a6/pylint/extensions/eq_without_hash.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,27 +1,26 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """This is the remnant of the python3 checker.
 
 It was removed because the transition from python 2 to python3 is
 behind us, but some checks are still useful in python3 after all.
-See https://github.com/PyCQA/pylint/issues/5025
+See https://github.com/pylint-dev/pylint/issues/5025
 """
 
 from astroid import nodes
 
 from pylint import checkers, interfaces
 from pylint.checkers import utils
 from pylint.lint import PyLinter
 
 
 class EqWithoutHash(checkers.BaseChecker):
-
     name = "eq-without-hash"
 
     msgs = {
         "W1641": (
             "Implementing __eq__ without also implementing __hash__",
             "eq-without-hash",
             "Used when a class implements __eq__ but not __hash__. Objects get "
```

### Comparing `pylint-3.0.0a5/pylint/extensions/mccabe.py` & `pylint-3.0.0a6/pylint/extensions/mccabe.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,55 +1,81 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Module to add McCabe checker class for pylint."""
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING
+from collections.abc import Sequence
+from typing import TYPE_CHECKING, Any, TypeVar, Union
 
 from astroid import nodes
 from mccabe import PathGraph as Mccabe_PathGraph
 from mccabe import PathGraphingAstVisitor as Mccabe_PathGraphingAstVisitor
 
 from pylint import checkers
 from pylint.checkers.utils import only_required_for_messages
 from pylint.interfaces import HIGH
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
+_StatementNodes = Union[
+    nodes.Assert,
+    nodes.Assign,
+    nodes.AugAssign,
+    nodes.Delete,
+    nodes.Raise,
+    nodes.Yield,
+    nodes.Import,
+    nodes.Call,
+    nodes.Subscript,
+    nodes.Pass,
+    nodes.Continue,
+    nodes.Break,
+    nodes.Global,
+    nodes.Return,
+    nodes.Expr,
+    nodes.Await,
+]
+
+_SubGraphNodes = Union[nodes.If, nodes.TryExcept, nodes.For, nodes.While]
+_AppendableNodeT = TypeVar(
+    "_AppendableNodeT", bound=Union[_StatementNodes, nodes.While, nodes.FunctionDef]
+)
 
-class PathGraph(Mccabe_PathGraph):
-    def __init__(self, node):
+
+class PathGraph(Mccabe_PathGraph):  # type: ignore[misc]
+    def __init__(self, node: _SubGraphNodes | nodes.FunctionDef):
         super().__init__(name="", entity="", lineno=1)
         self.root = node
 
 
-class PathGraphingAstVisitor(Mccabe_PathGraphingAstVisitor):
-    def __init__(self):
+class PathGraphingAstVisitor(Mccabe_PathGraphingAstVisitor):  # type: ignore[misc]
+    def __init__(self) -> None:
         super().__init__()
         self._bottom_counter = 0
+        self.graph: PathGraph | None = None
 
-    def default(self, node, *args):
+    def default(self, node: nodes.NodeNG, *args: Any) -> None:
         for child in node.get_children():
             self.dispatch(child, *args)
 
-    def dispatch(self, node, *args):
+    def dispatch(self, node: nodes.NodeNG, *args: Any) -> Any:
         self.node = node
         klass = node.__class__
         meth = self._cache.get(klass)
         if meth is None:
             class_name = klass.__name__
             meth = getattr(self.visitor, "visit" + class_name, self.default)
             self._cache[klass] = meth
         return meth(node, *args)
 
-    def visitFunctionDef(self, node):
+    def visitFunctionDef(self, node: nodes.FunctionDef) -> None:
         if self.graph is not None:
             # closure
             pathnode = self._append_node(node)
             self.tail = pathnode
             self.dispatch_list(node.body)
             bottom = f"{self._bottom_counter}"
             self._bottom_counter += 1
@@ -61,26 +87,24 @@
             self.tail = node
             self.dispatch_list(node.body)
             self.graphs[f"{self.classname}{node.name}"] = self.graph
             self.reset()
 
     visitAsyncFunctionDef = visitFunctionDef
 
-    def visitSimpleStatement(self, node):
+    def visitSimpleStatement(self, node: _StatementNodes) -> None:
         self._append_node(node)
 
     visitAssert = (
         visitAssign
     ) = (
         visitAugAssign
     ) = (
         visitDelete
     ) = (
-        visitPrint
-    ) = (
         visitRaise
     ) = (
         visitYield
     ) = (
         visitImport
     ) = (
         visitCall
@@ -90,40 +114,50 @@
         visitPass
     ) = (
         visitContinue
     ) = (
         visitBreak
     ) = visitGlobal = visitReturn = visitExpr = visitAwait = visitSimpleStatement
 
-    def visitWith(self, node):
+    def visitWith(self, node: nodes.With) -> None:
         self._append_node(node)
         self.dispatch_list(node.body)
 
     visitAsyncWith = visitWith
 
-    def _append_node(self, node):
-        if not self.tail:
+    def _append_node(self, node: _AppendableNodeT) -> _AppendableNodeT | None:
+        if not self.tail or not self.graph:
             return None
         self.graph.connect(self.tail, node)
         self.tail = node
         return node
 
-    def _subgraph(self, node, name, extra_blocks=()):
+    def _subgraph(
+        self,
+        node: _SubGraphNodes,
+        name: str,
+        extra_blocks: Sequence[nodes.ExceptHandler] = (),
+    ) -> None:
         """Create the subgraphs representing any `if` and `for` statements."""
         if self.graph is None:
             # global loop
             self.graph = PathGraph(node)
             self._subgraph_parse(node, node, extra_blocks)
             self.graphs[f"{self.classname}{name}"] = self.graph
             self.reset()
         else:
             self._append_node(node)
             self._subgraph_parse(node, node, extra_blocks)
 
-    def _subgraph_parse(self, node, pathnode, extra_blocks):
+    def _subgraph_parse(
+        self,
+        node: _SubGraphNodes,
+        pathnode: _SubGraphNodes,
+        extra_blocks: Sequence[nodes.ExceptHandler],
+    ) -> None:
         """Parse the body and any `else` block of `if` and `for` statements."""
         loose_ends = []
         self.tail = node
         self.dispatch_list(node.body)
         loose_ends.append(self.tail)
         for extra in extra_blocks:
             self.tail = node
@@ -131,15 +165,15 @@
             loose_ends.append(self.tail)
         if node.orelse:
             self.tail = node
             self.dispatch_list(node.orelse)
             loose_ends.append(self.tail)
         else:
             loose_ends.append(node)
-        if node:
+        if node and self.graph:
             bottom = f"{self._bottom_counter}"
             self._bottom_counter += 1
             for end in loose_ends:
                 self.graph.connect(end, bottom)
             self.tail = bottom
```

### Comparing `pylint-3.0.0a5/pylint/extensions/no_self_use.py` & `pylint-3.0.0a6/pylint/extensions/no_self_use.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from astroid import nodes
 
@@ -19,15 +19,14 @@
 from pylint.interfaces import INFERENCE
 
 if TYPE_CHECKING:
     from pylint.lint.pylinter import PyLinter
 
 
 class NoSelfUseChecker(BaseChecker):
-
     name = "no_self_use"
     msgs = {
         "R6301": (
             "Method could be a function",
             "no-self-use",
             "Used when a method doesn't use its bound instance, and so could "
             "be written as a function.",
```

### Comparing `pylint-3.0.0a5/pylint/extensions/overlapping_exceptions.py` & `pylint-3.0.0a6/pylint/extensions/overlapping_exceptions.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Looks for overlapping exceptions."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Any
 
 import astroid
-from astroid import nodes
+from astroid import nodes, util
 
 from pylint import checkers
 from pylint.checkers import utils
 from pylint.checkers.exceptions import _annotated_unpack_infer
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
@@ -47,15 +47,15 @@
             try:
                 excs = list(_annotated_unpack_infer(handler.type))
             except astroid.InferenceError:
                 continue
 
             handled_in_clause: list[tuple[Any, Any]] = []
             for part, exc in excs:
-                if exc is astroid.Uninferable:
+                if isinstance(exc, util.UninferableBase):
                     continue
                 if isinstance(exc, astroid.Instance) and utils.inherit_from_std_ex(exc):
                     exc = exc._proxied
 
                 if not isinstance(exc, astroid.ClassDef):
                     continue
```

### Comparing `pylint-3.0.0a5/pylint/extensions/private_import.py` & `pylint-3.0.0a6/pylint/extensions/private_import.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Check for imports on private external modules and names."""
 
 from __future__ import annotations
 
 from pathlib import Path
 from typing import TYPE_CHECKING
@@ -15,15 +15,14 @@
 from pylint.interfaces import HIGH
 
 if TYPE_CHECKING:
     from pylint.lint.pylinter import PyLinter
 
 
 class PrivateImportChecker(BaseChecker):
-
     name = "import-private-name"
     msgs = {
         "C2701": (
             "Imported private %s (%s)",
             "import-private-name",
             "Used when a private module or object prefixed with _ is imported. "
             "PEP8 guidance on Naming Conventions states that public attributes with "
@@ -36,15 +35,15 @@
 
         # A mapping of private names used as a type annotation to whether it is an acceptable import
         self.all_used_type_annotations: dict[str, bool] = {}
         self.populated_annotations = False
 
     @utils.only_required_for_messages("import-private-name")
     def visit_import(self, node: nodes.Import) -> None:
-        if utils.is_node_in_typing_guarded_import_block(node):
+        if utils.in_type_checking_block(node):
             return
         names = [name[0] for name in node.names]
         private_names = self._get_private_imports(names)
         private_names = self._get_type_annotation_names(node, private_names)
         if private_names:
             imported_identifier = "modules" if len(private_names) > 1 else "module"
             private_name_string = ", ".join(private_names)
@@ -53,23 +52,24 @@
                 node=node,
                 args=(imported_identifier, private_name_string),
                 confidence=HIGH,
             )
 
     @utils.only_required_for_messages("import-private-name")
     def visit_importfrom(self, node: nodes.ImportFrom) -> None:
-        if utils.is_node_in_typing_guarded_import_block(node):
+        if utils.in_type_checking_block(node):
             return
         # Only check imported names if the module is external
         if self.same_root_dir(node, node.modname):
             return
 
         names = [n[0] for n in node.names]
 
-        # Check the imported objects first. If they are all valid type annotations, the package can be private
+        # Check the imported objects first. If they are all valid type annotations,
+        # the package can be private
         private_names = self._get_type_annotation_names(node, names)
         if not private_names:
             return
 
         # There are invalid imported objects, so check the name of the package
         private_module_imports = self._get_private_imports([node.modname])
         private_module_imports = self._get_type_annotation_names(
@@ -136,15 +136,16 @@
     ) -> None:
         """Adds to `all_used_type_annotations` all names ever used as a type annotation
         in the node's (nested) scopes and whether they are only used as annotation.
         """
         for name in node.locals:
             # If we find a private type annotation, make sure we do not mask illegal usages
             private_name = None
-            # All the assignments using this variable that we might have to check for illegal usages later
+            # All the assignments using this variable that we might have to check for
+            # illegal usages later
             name_assignments = []
             for usage_node in node.locals[name]:
                 if isinstance(usage_node, nodes.AssignName) and isinstance(
                     usage_node.parent, (nodes.AnnAssign, nodes.Assign)
                 ):
                     assign_parent = usage_node.parent
                     if isinstance(assign_parent, nodes.AnnAssign):
@@ -191,26 +192,27 @@
         all_used_type_annotations: dict[str, bool],
     ) -> str | None:
         """Handles the possibility of an annotation either being a Name, i.e. just type,
         or a Subscript e.g. `Optional[type]` or an Attribute, e.g. `pylint.lint.linter`.
         """
         if isinstance(node, nodes.Name) and node.name not in all_used_type_annotations:
             all_used_type_annotations[node.name] = True
-            return node.name
+            return node.name  # type: ignore[no-any-return]
         if isinstance(node, nodes.Subscript):  # e.g. Optional[List[str]]
             # slice is the next nested type
             self._populate_type_annotations_annotation(
                 node.slice, all_used_type_annotations
             )
             # value is the current type name: could be a Name or Attribute
             return self._populate_type_annotations_annotation(
                 node.value, all_used_type_annotations
             )
         if isinstance(node, nodes.Attribute):
-            # An attribute is a type like `pylint.lint.pylinter`. node.expr is the next level up, could be another attribute
+            # An attribute is a type like `pylint.lint.pylinter`. node.expr is the next level
+            # up, could be another attribute
             return self._populate_type_annotations_annotation(
                 node.expr, all_used_type_annotations
             )
         return None
 
     @staticmethod
     def _assignments_call_private_name(
@@ -230,29 +232,32 @@
             elif isinstance(assignment.value, nodes.Name):
                 current_attribute = assignment.value.name
             if not current_attribute:
                 continue
             while isinstance(current_attribute, (nodes.Attribute, nodes.Call)):
                 if isinstance(current_attribute, nodes.Call):
                     current_attribute = current_attribute.func
-                current_attribute = current_attribute.expr
+                if not isinstance(current_attribute, nodes.Name):
+                    current_attribute = current_attribute.expr
             if (
                 isinstance(current_attribute, nodes.Name)
                 and current_attribute.name == private_name
             ):
                 return False
         return True
 
     @staticmethod
     def same_root_dir(
         node: nodes.Import | nodes.ImportFrom, import_mod_name: str
     ) -> bool:
         """Does the node's file's path contain the base name of `import_mod_name`?"""
         if not import_mod_name:  # from . import ...
             return True
+        if node.level:  # from .foo import ..., from ..bar import ...
+            return True
 
         base_import_package = import_mod_name.split(".")[0]
 
         return base_import_package in Path(node.root().file).parent.parts
 
 
 def register(linter: PyLinter) -> None:
```

### Comparing `pylint-3.0.0a5/pylint/extensions/redefined_loop_name.py` & `pylint-3.0.0a6/pylint/extensions/redefined_loop_name.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,25 +1,24 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Optional checker to warn when loop variables are overwritten in the loop's body."""
 
 from __future__ import annotations
 
 from astroid import nodes
 
 from pylint import checkers
 from pylint.checkers import utils
 from pylint.interfaces import HIGH
 from pylint.lint import PyLinter
 
 
 class RedefinedLoopNameChecker(checkers.BaseChecker):
-
     name = "redefined-loop-name"
 
     msgs = {
         "W2901": (
             "Redefining %r from loop (line %s)",
             "redefined-loop-name",
             "Used when a loop variable is overwritten in the loop body.",
```

### Comparing `pylint-3.0.0a5/pylint/extensions/redefined_variable_type.py` & `pylint-3.0.0a6/pylint/extensions/redefined_variable_type.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from astroid import nodes
 
@@ -42,21 +42,21 @@
     def visit_classdef(self, _: nodes.ClassDef) -> None:
         self._assigns.append({})
 
     @only_required_for_messages("redefined-variable-type")
     def leave_classdef(self, _: nodes.ClassDef) -> None:
         self._check_and_add_messages()
 
-    visit_functiondef = visit_classdef
-    leave_functiondef = leave_module = leave_classdef
+    visit_functiondef = visit_asyncfunctiondef = visit_classdef
+    leave_functiondef = leave_asyncfunctiondef = leave_module = leave_classdef
 
     def visit_module(self, _: nodes.Module) -> None:
-        self._assigns: list[dict] = [{}]
+        self._assigns: list[dict[str, list[tuple[nodes.Assign, str]]]] = [{}]
 
-    def _check_and_add_messages(self):
+    def _check_and_add_messages(self) -> None:
         assigns = self._assigns.pop()
         for name, args in assigns.items():
             if len(args) <= 1:
                 continue
             orig_node, orig_type = args[0]
             # Check if there is a type in the following nodes that would be
             # different from orig_type.
```

### Comparing `pylint-3.0.0a5/pylint/extensions/set_membership.py` & `pylint-3.0.0a6/pylint/extensions/set_membership.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from astroid import nodes
 
@@ -12,15 +12,14 @@
 from pylint.checkers.utils import only_required_for_messages
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
 class SetMembershipChecker(BaseChecker):
-
     name = "set_membership"
     msgs = {
         "R6201": (
             "Consider using set for membership test",
             "use-set-for-membership",
             "Membership tests are more efficient when performed on "
             "a lookup optimized datatype like ``sets``.",
```

### Comparing `pylint-3.0.0a5/pylint/extensions/typing.py` & `pylint-3.0.0a6/pylint/extensions/typing.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, NamedTuple
 
 import astroid.bases
 from astroid import nodes
@@ -13,15 +13,16 @@
 from pylint.checkers.utils import (
     in_type_checking_block,
     is_node_in_type_annotation_context,
     is_postponed_evaluation_enabled,
     only_required_for_messages,
     safe_infer,
 )
-from pylint.interfaces import INFERENCE
+from pylint.constants import TYPING_NORETURN
+from pylint.interfaces import HIGH, INFERENCE
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
 class TypingAlias(NamedTuple):
     name: str
@@ -71,20 +72,14 @@
     "typing.Match": TypingAlias("re.Match", True),
     "typing.Hashable": TypingAlias("collections.abc.Hashable", True),
     "typing.Sized": TypingAlias("collections.abc.Sized", True),
 }
 
 ALIAS_NAMES = frozenset(key.split(".")[1] for key in DEPRECATED_TYPING_ALIASES)
 UNION_NAMES = ("Optional", "Union")
-TYPING_NORETURN = frozenset(
-    (
-        "typing.NoReturn",
-        "typing_extensions.NoReturn",
-    )
-)
 
 
 class DeprecatedTypingAliasMsg(NamedTuple):
     node: nodes.Name | nodes.Attribute
     qname: str
     alias: str
     parent_subscript: bool = False
@@ -125,28 +120,34 @@
             "'collections.abc.Callable' inside Optional and Union is broken in "
             "3.9.0 / 3.9.1 (use 'typing.Callable' instead)",
             "broken-collections-callable",
             "``collections.abc.Callable`` inside Optional and Union is broken in "
             "Python 3.9.0 and 3.9.1. Use ``typing.Callable`` for these cases instead. "
             "https://bugs.python.org/issue42965",
         ),
+        "R6006": (
+            "Type `%s` is used more than once in union type annotation. Remove redundant typehints.",
+            "redundant-typehint-argument",
+            "Duplicated type arguments will be skipped by `mypy` tool, therefore should be "
+            "removed to avoid confusion.",
+        ),
     }
     options = (
         (
             "runtime-typing",
             {
                 "default": True,
                 "type": "yn",
                 "metavar": "<y or n>",
                 "help": (
                     "Set to ``no`` if the app / library does **NOT** need to "
                     "support runtime introspection of type annotations. "
                     "If you use type annotations **exclusively** for type checking "
                     "of an application, you're probably fine. For libraries, "
-                    "evaluate if some users what to access the type hints "
+                    "evaluate if some users want to access the type hints "
                     "at runtime first, e.g., through ``typing.get_type_hints``. "
                     "Applies to Python versions 3.7 - 3.9"
                 ),
             },
         ),
     )
 
@@ -220,14 +221,87 @@
         if self._should_check_alternative_union_syntax and node.attrname in UNION_NAMES:
             self._check_for_alternative_union_syntax(node, node.attrname)
         if self._should_check_noreturn and node.attrname == "NoReturn":
             self._check_broken_noreturn(node)
         if self._should_check_callable and node.attrname == "Callable":
             self._check_broken_callable(node)
 
+    @only_required_for_messages("redundant-typehint-argument")
+    def visit_annassign(self, node: nodes.AnnAssign) -> None:
+        annotation = node.annotation
+        if self._is_deprecated_union_annotation(annotation, "Optional"):
+            if self._is_optional_none_annotation(annotation):
+                self.add_message(
+                    "redundant-typehint-argument",
+                    node=annotation,
+                    args="None",
+                    confidence=HIGH,
+                )
+            return
+        if self._is_deprecated_union_annotation(annotation, "Union") and isinstance(
+            annotation.slice, nodes.Tuple
+        ):
+            types = annotation.slice.elts
+        elif self._is_binop_union_annotation(annotation):
+            types = self._parse_binops_typehints(annotation)
+        else:
+            return
+
+        self._check_union_types(types, node)
+
+    @staticmethod
+    def _is_deprecated_union_annotation(
+        annotation: nodes.NodeNG, union_name: str
+    ) -> bool:
+        return (
+            isinstance(annotation, nodes.Subscript)
+            and isinstance(annotation.value, nodes.Name)
+            and annotation.value.name == union_name
+        )
+
+    def _is_binop_union_annotation(self, annotation: nodes.NodeNG) -> bool:
+        return self._should_check_alternative_union_syntax and isinstance(
+            annotation, nodes.BinOp
+        )
+
+    @staticmethod
+    def _is_optional_none_annotation(annotation: nodes.Subscript) -> bool:
+        return (
+            isinstance(annotation.slice, nodes.Const) and annotation.slice.value is None
+        )
+
+    def _parse_binops_typehints(
+        self, binop_node: nodes.BinOp, typehints_list: list[nodes.NodeNG] | None = None
+    ) -> list[nodes.NodeNG]:
+        typehints_list = typehints_list or []
+        if isinstance(binop_node.left, nodes.BinOp):
+            typehints_list.extend(
+                self._parse_binops_typehints(binop_node.left, typehints_list)
+            )
+        else:
+            typehints_list.append(binop_node.left)
+        typehints_list.append(binop_node.right)
+        return typehints_list
+
+    def _check_union_types(
+        self, types: list[nodes.NodeNG], annotation: nodes.NodeNG
+    ) -> None:
+        types_set = set()
+        for typehint in types:
+            typehint_str = typehint.as_string()
+            if typehint_str in types_set:
+                self.add_message(
+                    "redundant-typehint-argument",
+                    node=annotation,
+                    args=(typehint_str),
+                    confidence=HIGH,
+                )
+            else:
+                types_set.add(typehint_str)
+
     def _check_for_alternative_union_syntax(
         self,
         node: nodes.Name | nodes.Attribute,
         name: str,
     ) -> None:
         """Check if alternative union syntax could be used.
```

### Comparing `pylint-3.0.0a5/pylint/extensions/while_used.py` & `pylint-3.0.0a6/pylint/extensions/while_used.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Check for use of while loops."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
@@ -14,21 +14,21 @@
 from pylint.checkers.utils import only_required_for_messages
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
 
 class WhileChecker(BaseChecker):
-
     name = "while_used"
     msgs = {
         "W0149": (
             "Used `while` loop",
             "while-used",
-            "Unbounded `while` loops can often be rewritten as bounded `for` loops.",
+            "Unbounded `while` loops can often be rewritten as bounded `for` loops. "
+            "Exceptions can be made for cases such as event loops, listeners, etc.",
         )
     }
 
     @only_required_for_messages("while-used")
     def visit_while(self, node: nodes.While) -> None:
         self.add_message("while-used", node=node)
```

### Comparing `pylint-3.0.0a5/pylint/graph.py` & `pylint-3.0.0a6/pylint/graph.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,23 +1,22 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Graph manipulation utilities.
 
 (dot generation adapted from pypy/translator/tool/make_dot.py)
 """
 
 from __future__ import annotations
 
 import codecs
 import os
 import shutil
 import subprocess
-import sys
 import tempfile
 from collections.abc import Sequence
 from typing import Any
 
 
 def target_info_from_filename(filename: str) -> tuple[str, str, str]:
     """Transforms /some/path/foo.png into ('/some/path', 'foo.png', 'png')."""
@@ -109,34 +108,33 @@
         if target not in graphviz_extensions:
             if shutil.which(self.renderer) is None:
                 raise RuntimeError(
                     f"Cannot generate `{outputfile}` because '{self.renderer}' "
                     "executable not found. Install graphviz, or specify a `.gv` "
                     "outputfile to produce the DOT source code."
                 )
-            use_shell = sys.platform == "win32"
             if mapfile:
-                subprocess.call(
+                subprocess.run(
                     [
                         self.renderer,
                         "-Tcmapx",
                         "-o",
                         mapfile,
                         "-T",
                         target,
                         dot_sourcepath,
                         "-o",
                         outputfile,
                     ],
-                    shell=use_shell,
+                    check=True,
                 )
             else:
-                subprocess.call(
+                subprocess.run(
                     [self.renderer, "-T", target, dot_sourcepath, "-o", outputfile],
-                    shell=use_shell,
+                    check=True,
                 )
             os.unlink(dot_sourcepath)
         return outputfile
 
     def emit(self, line: str) -> None:
         """Adds <line> to final output."""
         self.lines.append(line)
```

### Comparing `pylint-3.0.0a5/pylint/lint/__init__.py` & `pylint-3.0.0a6/pylint/lint/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Pylint [options] modules_or_packages.
 
   Check that module(s) satisfy a coding standard (and more !).
 
     pylint --help
 
@@ -14,33 +14,35 @@
 
   Display help messages about given message identifiers and exit.
 """
 import sys
 
 from pylint.config.exceptions import ArgumentPreprocessingError
 from pylint.lint.caching import load_results, save_results
+from pylint.lint.expand_modules import discover_package_path
 from pylint.lint.parallel import check_parallel
 from pylint.lint.pylinter import PyLinter
 from pylint.lint.report_functions import (
     report_messages_by_module_stats,
     report_messages_stats,
     report_total_messages_stats,
 )
 from pylint.lint.run import Run
-from pylint.lint.utils import _patch_sys_path, fix_import_path
+from pylint.lint.utils import _augment_sys_path, augmented_sys_path
 
 __all__ = [
     "check_parallel",
     "PyLinter",
     "report_messages_by_module_stats",
     "report_messages_stats",
     "report_total_messages_stats",
     "Run",
     "ArgumentPreprocessingError",
-    "_patch_sys_path",
-    "fix_import_path",
+    "_augment_sys_path",
+    "augmented_sys_path",
+    "discover_package_path",
     "save_results",
     "load_results",
 ]
 
 if __name__ == "__main__":
     Run(sys.argv[1:])
```

### Comparing `pylint-3.0.0a5/pylint/lint/base_options.py` & `pylint-3.0.0a6/pylint/lint/base_options.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Functions that creates the basic options for the Run and PyLinter classes."""
 
 from __future__ import annotations
 
 import re
 import sys
@@ -52,28 +52,29 @@
         (
             "ignore-patterns",
             {
                 "type": "regexp_csv",
                 "metavar": "<pattern>[,<pattern>...]",
                 "dest": "black_list_re",
                 "default": (re.compile(r"^\.#"),),
-                "help": "Files or directories matching the regex patterns are"
+                "help": "Files or directories matching the regular expression patterns are"
                 " skipped. The regex matches against base names, not paths. The default value "
                 "ignores Emacs file locks",
             },
         ),
         (
             "ignore-paths",
             {
                 "type": "regexp_paths_csv",
                 "metavar": "<pattern>[,<pattern>...]",
                 "default": [],
-                "help": "Add files or directories matching the regex patterns to the "
+                "help": "Add files or directories matching the regular expressions patterns to the "
                 "ignore-list. The regex matches against paths and can be in "
-                "Posix or Windows format.",
+                "Posix or Windows format. Because '\\\\' represents the directory delimiter "
+                "on Windows systems, it can't be used as an escape character.",
             },
         ),
         (
             "persistent",
             {
                 "default": True,
                 "type": "yn",
@@ -150,15 +151,15 @@
         ),
         (
             "fail-under",
             {
                 "default": 10,
                 "type": "float",
                 "metavar": "<score>",
-                "help": "Specify a score threshold to be exceeded before program exits with error.",
+                "help": "Specify a score threshold under which the program will exit with error.",
             },
         ),
         (
             "fail-on",
             {
                 "default": "",
                 "type": "csv",
@@ -240,15 +241,16 @@
             "jobs",
             {
                 "type": "int",
                 "metavar": "<n-processes>",
                 "short": "j",
                 "default": 1,
                 "help": "Use multiple processes to speed up Pylint. Specifying 0 will "
-                "auto-detect the number of processors available to use.",
+                "auto-detect the number of processors available to use, and will cap "
+                "the count on Windows to avoid hangs.",
             },
         ),
         (
             "unsafe-load-any-extension",
             {
                 "type": "yn",
                 "metavar": "<y or n>",
@@ -338,14 +340,26 @@
                 "help": (
                     "Interpret the stdin as a python script, whose filename "
                     "needs to be passed as the module_or_package argument."
                 ),
             },
         ),
         (
+            "source-roots",
+            {
+                "type": "glob_paths_csv",
+                "metavar": "<path>[,<path>...]",
+                "default": (),
+                "help": "Add paths to the list of the source roots. Supports globbing patterns. "
+                "The source root is an absolute path or a path relative to the current working "
+                "directory used to determine a package namespace for modules located under the "
+                "source root.",
+            },
+        ),
+        (
             "recursive",
             {
                 "type": "yn",
                 "metavar": "<yn>",
                 "default": False,
                 "help": "Discover python modules and packages in the file system subtree.",
             },
@@ -385,14 +399,24 @@
                 "help": "Analyse import fallback blocks. This can be used to "
                 "support both Python 2 and 3 compatible code, which "
                 "means that the block might have code that exists "
                 "only in one or another interpreter, leading to false "
                 "positives when analysed.",
             },
         ),
+        (
+            "clear-cache-post-run",
+            {
+                "default": False,
+                "type": "yn",
+                "metavar": "<y or n>",
+                "help": "Clear in-memory caches upon conclusion of linting. "
+                "Useful if running pylint in a server-like mode.",
+            },
+        ),
     )
 
 
 def _make_run_options(self: Run) -> Options:
     """Return the options used in a Run class."""
     return (
         (
@@ -525,17 +549,17 @@
         ),
         (
             "errors-only",
             {
                 "action": _ErrorsOnlyModeAction,
                 "kwargs": {"Run": self},
                 "short": "E",
-                "help": "In error mode, checkers without error messages are "
-                "disabled and for others, only the ERROR messages are "
-                "displayed, and no reports are done by default.",
+                "help": "In error mode, messages with a category besides "
+                "ERROR or FATAL are suppressed, and no reports are done by default. "
+                "Error mode is compatible with disabling specific errors. ",
                 "hide_from_config_file": True,
             },
         ),
         (
             "verbose",
             {
                 "action": _DoNothingAction,
```

### Comparing `pylint-3.0.0a5/pylint/lint/caching.py` & `pylint-3.0.0a6/pylint/lint/caching.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,27 +1,29 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import pickle
 import sys
 import warnings
 from pathlib import Path
 
 from pylint.constants import PYLINT_HOME
 from pylint.utils import LinterStats
 
+PYLINT_HOME_AS_PATH = Path(PYLINT_HOME)
+
 
 def _get_pdata_path(
-    base_name: Path, recurs: int, pylint_home: Path = Path(PYLINT_HOME)
+    base_name: Path, recurs: int, pylint_home: Path = PYLINT_HOME_AS_PATH
 ) -> Path:
-    # We strip all characters that can't be used in a filename
-    # Also strip '/' and '\\' because we want to create a single file, not sub-directories
+    # We strip all characters that can't be used in a filename. Also strip '/' and
+    # '\\' because we want to create a single file, not sub-directories.
     underscored_name = "_".join(
         str(p.replace(":", "_").replace("/", "_").replace("\\", "_"))
         for p in base_name.parts
     )
     return pylint_home / f"{underscored_name}_{recurs}.stats"
 
 
@@ -39,14 +41,15 @@
         with open(data_file, "rb") as stream:
             data = pickle.load(stream)
             if not isinstance(data, LinterStats):
                 warnings.warn(
                     "You're using an old pylint cache with invalid data following "
                     f"an upgrade, please delete '{data_file}'.",
                     UserWarning,
+                    stacklevel=2,
                 )
                 raise TypeError
             return data
     except Exception:  # pylint: disable=broad-except
         # There's an issue with the cache but we just continue as if it isn't there
         return None
```

### Comparing `pylint-3.0.0a5/pylint/lint/expand_modules.py` & `pylint-3.0.0a6/pylint/lint/expand_modules.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import os
 import sys
 from collections.abc import Sequence
 from re import Pattern
@@ -14,28 +14,33 @@
 from pylint.typing import ErrorDescriptionDict, ModuleDescriptionDict
 
 
 def _modpath_from_file(filename: str, is_namespace: bool, path: list[str]) -> list[str]:
     def _is_package_cb(inner_path: str, parts: list[str]) -> bool:
         return modutils.check_modpath_has_init(inner_path, parts) or is_namespace
 
-    return modutils.modpath_from_file_with_callback(
+    return modutils.modpath_from_file_with_callback(  # type: ignore[no-any-return]
         filename, path=path, is_package_cb=_is_package_cb
     )
 
 
-def get_python_path(filepath: str) -> str:
-    """TODO This get the python path with the (bad) assumption that there is always
-    an __init__.py.
-
-    This is not true since python 3.3 and is causing problem.
-    """
-    dirname = os.path.realpath(os.path.expanduser(filepath))
+def discover_package_path(modulepath: str, source_roots: Sequence[str]) -> str:
+    """Discover package path from one its modules and source roots."""
+    dirname = os.path.realpath(os.path.expanduser(modulepath))
     if not os.path.isdir(dirname):
         dirname = os.path.dirname(dirname)
+
+    # Look for a source root that contains the module directory
+    for source_root in source_roots:
+        source_root = os.path.realpath(os.path.expanduser(source_root))
+        if os.path.commonpath([source_root, dirname]) == source_root:
+            return source_root
+
+    # Fall back to legacy discovery by looking for __init__.py upwards as
+    # it's the only way given that source root was not found or was not provided
     while True:
         if not os.path.exists(os.path.join(dirname, "__init__.py")):
             return dirname
         old_dirname = dirname
         dirname = os.path.dirname(dirname)
         if old_dirname == dirname:
             return os.getcwd()
@@ -48,43 +53,46 @@
 
 def _is_ignored_file(
     element: str,
     ignore_list: list[str],
     ignore_list_re: list[Pattern[str]],
     ignore_list_paths_re: list[Pattern[str]],
 ) -> bool:
+    element = os.path.normpath(element)
     basename = os.path.basename(element)
     return (
         basename in ignore_list
         or _is_in_ignore_list_re(basename, ignore_list_re)
         or _is_in_ignore_list_re(element, ignore_list_paths_re)
     )
 
 
+# pylint: disable = too-many-locals, too-many-statements
 def expand_modules(
     files_or_modules: Sequence[str],
+    source_roots: Sequence[str],
     ignore_list: list[str],
     ignore_list_re: list[Pattern[str]],
     ignore_list_paths_re: list[Pattern[str]],
-) -> tuple[list[ModuleDescriptionDict], list[ErrorDescriptionDict]]:
+) -> tuple[dict[str, ModuleDescriptionDict], list[ErrorDescriptionDict]]:
     """Take a list of files/modules/packages and return the list of tuple
     (file, module name) which have to be actually checked.
     """
-    result: list[ModuleDescriptionDict] = []
+    result: dict[str, ModuleDescriptionDict] = {}
     errors: list[ErrorDescriptionDict] = []
     path = sys.path.copy()
 
     for something in files_or_modules:
         basename = os.path.basename(something)
         if _is_ignored_file(
             something, ignore_list, ignore_list_re, ignore_list_paths_re
         ):
             continue
-        module_path = get_python_path(something)
-        additional_search_path = [".", module_path] + path
+        module_package_path = discover_package_path(something, source_roots)
+        additional_search_path = [".", module_package_path, *path]
         if os.path.exists(something):
             # this is a file or a directory
             try:
                 modname = ".".join(
                     modutils.modpath_from_file(something, path=additional_search_path)
                 )
             except ImportError:
@@ -98,17 +106,15 @@
             modname = something
             try:
                 filepath = modutils.file_from_modpath(
                     modname.split("."), path=additional_search_path
                 )
                 if filepath is None:
                     continue
-            except (ImportError, SyntaxError) as ex:
-                # The SyntaxError is a Python bug and should be
-                # removed once we move away from imp.find_module: https://bugs.python.org/issue10588
+            except ImportError as ex:
                 errors.append({"key": "fatal", "mod": modname, "ex": ex})
                 continue
         filepath = os.path.normpath(filepath)
         modparts = (modname or something).split(".")
         try:
             spec = modutils.file_info_from_modpath(
                 modparts, path=additional_search_path
@@ -117,23 +123,25 @@
             # Might not be acceptable, don't crash.
             is_namespace = False
             is_directory = os.path.isdir(something)
         else:
             is_namespace = modutils.is_namespace(spec)
             is_directory = modutils.is_directory(spec)
         if not is_namespace:
-            result.append(
-                {
+            if filepath in result:
+                # Always set arg flag if module explicitly given.
+                result[filepath]["isarg"] = True
+            else:
+                result[filepath] = {
                     "path": filepath,
                     "name": modname,
                     "isarg": True,
                     "basepath": filepath,
                     "basename": modname,
                 }
-            )
         has_init = (
             not (modname.endswith(".__init__") or modname == "__init__")
             and os.path.basename(filepath) == "__init__.py"
         )
         if has_init or is_namespace or is_directory:
             for subfilepath in modutils.get_module_files(
                 os.path.dirname(filepath), ignore_list, list_all=is_namespace
@@ -145,17 +153,17 @@
                 ) or _is_in_ignore_list_re(subfilepath, ignore_list_paths_re):
                     continue
 
                 modpath = _modpath_from_file(
                     subfilepath, is_namespace, path=additional_search_path
                 )
                 submodname = ".".join(modpath)
-                result.append(
-                    {
-                        "path": subfilepath,
-                        "name": submodname,
-                        "isarg": False,
-                        "basepath": filepath,
-                        "basename": modname,
-                    }
-                )
+                # Preserve arg flag if module is also explicitly given.
+                isarg = subfilepath in result and result[subfilepath]["isarg"]
+                result[subfilepath] = {
+                    "path": subfilepath,
+                    "name": submodname,
+                    "isarg": isarg,
+                    "basepath": filepath,
+                    "basename": modname,
+                }
     return result, errors
```

### Comparing `pylint-3.0.0a5/pylint/lint/message_state_handler.py` & `pylint-3.0.0a6/pylint/lint/message_state_handler.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import sys
 import tokenize
 from collections import defaultdict
 from typing import TYPE_CHECKING
@@ -13,14 +13,15 @@
 from pylint.constants import (
     MSG_STATE_CONFIDENCE,
     MSG_STATE_SCOPE_CONFIG,
     MSG_STATE_SCOPE_MODULE,
     MSG_TYPES,
     MSG_TYPES_LONG,
 )
+from pylint.interfaces import HIGH
 from pylint.message import MessageDefinition
 from pylint.typing import ManagedMessage
 from pylint.utils.pragma_parser import (
     OPTION_PO,
     InvalidPragmaError,
     UnRecognizedOptionError,
     parse_pragma,
@@ -50,34 +51,32 @@
             "disable-next": self.disable_next,
         }
         self._bw_options_methods = {
             "disable-msg": self._options_methods["disable"],
             "enable-msg": self._options_methods["enable"],
         }
         self._pragma_lineno: dict[str, int] = {}
-        # TODO: 3.0: Update key type to str when current_name is always str
-        self._stashed_bad_option_value_messages: defaultdict[
-            str | None, list[tuple[str | None, str]]
+        self._stashed_messages: defaultdict[
+            tuple[str, str], list[tuple[str | None, str]]
         ] = defaultdict(list)
-        """Bad option values for --enable and --disable are encountered too early to
-        warn about them, i.e. before all option providers have been fully parsed.
+        """Some messages in the options (for --enable and --disable) are encountered
+        too early to warn about them.
 
-        Thus,
-        this dict stores option_value and msg_id needed to (later) emit the
-        bad-option-value messages keyed on module names.
+        i.e. before all option providers have been fully parsed. Thus, this dict stores
+        option_value and msg_id needed to (later) emit the messages keyed on module names.
         """
 
     def _set_one_msg_status(
         self, scope: str, msg: MessageDefinition, line: int | None, enable: bool
     ) -> None:
         """Set the status of an individual message."""
-        if scope == "module":
+        if scope in {"module", "line"}:
             assert isinstance(line, int)  # should always be int inside module scope
 
-            self.linter.file_state.set_msg_status(msg, line, enable)
+            self.linter.file_state.set_msg_status(msg, line, enable, scope)
             if not enable and msg.symbol != "locally-disabled":
                 self.linter.add_message(
                     "locally-disabled", line=line, args=(msg.symbol, msg.msgid)
                 )
         else:
             msgs = self._msgs_state
             msgs[msg.msgid] = enable
@@ -139,15 +138,15 @@
         msgid: str,
         enable: bool,
         scope: str = "package",
         line: int | None = None,
         ignore_unknown: bool = False,
     ) -> None:
         """Do some tests and then iterate over message definitions to set state."""
-        assert scope in {"package", "module"}
+        assert scope in {"package", "module", "line"}
 
         message_definitions = self._get_messages_to_set(msgid, enable, ignore_unknown)
 
         for message_definition in message_definitions:
             self._set_one_msg_status(scope, message_definition, line, enable)
 
         # sync configuration object
@@ -193,25 +192,25 @@
             msgid, enable=False, scope=scope, line=line, ignore_unknown=ignore_unknown
         )
         self._register_by_id_managed_msg(msgid, line)
 
     def disable_next(
         self,
         msgid: str,
-        scope: str = "package",
+        _: str = "package",
         line: int | None = None,
         ignore_unknown: bool = False,
     ) -> None:
         """Disable a message for the next line."""
         if not line:
             raise exceptions.NoLineSuppliedError
         self._set_msg_status(
             msgid,
             enable=False,
-            scope=scope,
+            scope="line",
             line=line + 1,
             ignore_unknown=ignore_unknown,
         )
         self._register_by_id_managed_msg(msgid, line + 1)
 
     def enable(
         self,
@@ -223,22 +222,19 @@
         """Enable a message for a scope."""
         self._set_msg_status(
             msgid, enable=True, scope=scope, line=line, ignore_unknown=ignore_unknown
         )
         self._register_by_id_managed_msg(msgid, line, is_disabled=False)
 
     def disable_noerror_messages(self) -> None:
-        for msgcat, msgids in self.linter.msgs_store._msgs_by_category.items():
-            # enable only messages with 'error' severity and above ('fatal')
+        """Disable message categories other than `error` and `fatal`."""
+        for msgcat in self.linter.msgs_store._msgs_by_category:
             if msgcat in {"E", "F"}:
-                for msgid in msgids:
-                    self.enable(msgid)
-            else:
-                for msgid in msgids:
-                    self.disable(msgid)
+                continue
+            self.disable(msgcat)
 
     def list_messages_enabled(self) -> None:
         emittable, non_emittable = self.linter.msgs_store.find_emittable_messages()
         enabled: list[str] = []
         disabled: list[str] = []
         for message in emittable:
             if self.is_message_enabled(message.msgid):
@@ -346,29 +342,29 @@
 
         See func_block_disable_msg.py test case for expected behaviour.
         """
         control_pragmas = {"disable", "disable-next", "enable"}
         prev_line = None
         saw_newline = True
         seen_newline = True
-        for (tok_type, content, start, _, _) in tokens:
+        for tok_type, content, start, _, _ in tokens:
             if prev_line and prev_line != start[0]:
                 saw_newline = seen_newline
                 seen_newline = False
 
             prev_line = start[0]
             if tok_type in (tokenize.NL, tokenize.NEWLINE):
                 seen_newline = True
 
             if tok_type != tokenize.COMMENT:
                 continue
             match = OPTION_PO.search(content)
             if match is None:
                 continue
-            try:
+            try:  # pylint: disable = too-many-try-statements
                 for pragma_repr in parse_pragma(match.group(2)):
                     if pragma_repr.action in {"disable-all", "skip-file"}:
                         if pragma_repr.action == "disable-all":
                             self.linter.add_message(
                                 "deprecated-pragma",
                                 line=start[0],
                                 args=("disable-all", "skip-file"),
@@ -406,19 +402,32 @@
                             # If we did not see a newline between the previous line and now,
                             # we saw a backslash so treat the two lines as one.
                         l_start = start[0]
                         if not saw_newline:
                             l_start -= 1
                         try:
                             meth(msgid, "module", l_start)
+                        except (
+                            exceptions.DeletedMessageError,
+                            exceptions.MessageBecameExtensionError,
+                        ) as e:
+                            self.linter.add_message(
+                                "useless-option-value",
+                                args=(pragma_repr.action, e),
+                                line=start[0],
+                                confidence=HIGH,
+                            )
                         except exceptions.UnknownMessageError:
-                            msg = f"{pragma_repr.action}. Don't recognize message {msgid}."
                             self.linter.add_message(
-                                "bad-option-value", args=msg, line=start[0]
+                                "unknown-option-value",
+                                args=(pragma_repr.action, msgid),
+                                line=start[0],
+                                confidence=HIGH,
                             )
+
             except UnRecognizedOptionError as err:
                 self.linter.add_message(
                     "unrecognized-inline-option", args=err.token, line=start[0]
                 )
                 continue
             except InvalidPragmaError as err:
                 self.linter.add_message(
```

### Comparing `pylint-3.0.0a5/pylint/lint/parallel.py` & `pylint-3.0.0a6/pylint/lint/parallel.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,95 +1,89 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import functools
-import warnings
 from collections import defaultdict
 from collections.abc import Iterable, Sequence
 from typing import TYPE_CHECKING, Any
 
 import dill
 
 from pylint import reporters
-from pylint.lint.utils import _patch_sys_path
+from pylint.lint.utils import _augment_sys_path
 from pylint.message import Message
 from pylint.typing import FileItem
 from pylint.utils import LinterStats, merge_stats
 
 try:
     import multiprocessing
 except ImportError:
     multiprocessing = None  # type: ignore[assignment]
 
+try:
+    from concurrent.futures import ProcessPoolExecutor
+except ImportError:
+    ProcessPoolExecutor = None  # type: ignore[assignment,misc]
+
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
 
-# PyLinter object used by worker processes when checking files using multiprocessing
+# PyLinter object used by worker processes when checking files using parallel mode
 # should only be used by the worker processes
 _worker_linter: PyLinter | None = None
 
 
 def _worker_initialize(
-    linter: bytes, arguments: None | str | Sequence[str] = None
+    linter: bytes, extra_packages_paths: Sequence[str] | None = None
 ) -> None:
-    """Function called to initialize a worker for a Process within a multiprocessing
-    Pool.
+    """Function called to initialize a worker for a Process within a concurrent Pool.
 
     :param linter: A linter-class (PyLinter) instance pickled with dill
-    :param arguments: File or module name(s) to lint and to be added to sys.path
+    :param extra_packages_paths: Extra entries to be added to `sys.path`
     """
     global _worker_linter  # pylint: disable=global-statement
     _worker_linter = dill.loads(linter)
     assert _worker_linter
 
     # On the worker process side the messages are just collected and passed back to
     # parent process as _worker_check_file function's return value
     _worker_linter.set_reporter(reporters.CollectingReporter())
     _worker_linter.open()
 
-    # Patch sys.path so that each argument is importable just like in single job mode
-    _patch_sys_path(arguments or ())
+    if extra_packages_paths:
+        _augment_sys_path(extra_packages_paths)
 
 
 def _worker_check_single_file(
     file_item: FileItem,
 ) -> tuple[
     int,
-    # TODO: 3.0: Make this only str after deprecation has been removed
-    str | None,
     str,
-    str | None,
+    str,
+    str,
     list[Message],
     LinterStats,
     int,
     defaultdict[str, list[Any]],
 ]:
     if not _worker_linter:
-        raise Exception("Worker linter not yet initialised")
+        raise RuntimeError("Worker linter not yet initialised")
     _worker_linter.open()
     _worker_linter.check_single_file_item(file_item)
     mapreduce_data = defaultdict(list)
     for checker in _worker_linter.get_checkers():
         data = checker.get_map_data()
         if data is not None:
             mapreduce_data[checker.name].append(data)
     msgs = _worker_linter.reporter.messages
     assert isinstance(_worker_linter.reporter, reporters.CollectingReporter)
     _worker_linter.reporter.reset()
-    if _worker_linter.current_name is None:
-        warnings.warn(
-            (
-                "In pylint 3.0 the current_name attribute of the linter object should be a string. "
-                "If unknown it should be initialized as an empty string."
-            ),
-            DeprecationWarning,
-        )
     return (
         id(multiprocessing.current_process()),
         _worker_linter.current_name,
         file_item.filepath,
         _worker_linter.file_state.base_name,
         msgs,
         _worker_linter.stats,
@@ -122,28 +116,30 @@
             checker.reduce_map_data(linter, collated_map_reduce_data[checker.name])
 
 
 def check_parallel(
     linter: PyLinter,
     jobs: int,
     files: Iterable[FileItem],
-    arguments: None | str | Sequence[str] = None,
+    extra_packages_paths: Sequence[str] | None = None,
 ) -> None:
     """Use the given linter to lint the files with given amount of workers (jobs).
 
     This splits the work filestream-by-filestream. If you need to do work across
     multiple files, as in the similarity-checker, then implement the map/reduce mixin functionality.
     """
     # The linter is inherited by all the pool's workers, i.e. the linter
     # is identical to the linter object here. This is required so that
     # a custom PyLinter object can be used.
-    initializer = functools.partial(_worker_initialize, arguments=arguments)
-    with multiprocessing.Pool(
-        jobs, initializer=initializer, initargs=[dill.dumps(linter)]
-    ) as pool:
+    initializer = functools.partial(
+        _worker_initialize, extra_packages_paths=extra_packages_paths
+    )
+    with ProcessPoolExecutor(
+        max_workers=jobs, initializer=initializer, initargs=(dill.dumps(linter),)
+    ) as executor:
         linter.open()
         all_stats = []
         all_mapreduce_data: defaultdict[
             int, list[defaultdict[str, list[Any]]]
         ] = defaultdict(list)
 
         # Maps each file to be worked on by a single _worker_check_single_file() call,
@@ -154,22 +150,19 @@
             module,
             file_path,
             base_name,
             messages,
             stats,
             msg_status,
             mapreduce_data,
-        ) in pool.imap_unordered(_worker_check_single_file, files):
+        ) in executor.map(_worker_check_single_file, files):
             linter.file_state.base_name = base_name
             linter.file_state._is_base_filestate = False
             linter.set_current_module(module, file_path)
             for msg in messages:
                 linter.reporter.handle_message(msg)
             all_stats.append(stats)
             all_mapreduce_data[worker_idx].append(mapreduce_data)
             linter.msg_status |= msg_status
 
-        pool.close()
-        pool.join()
-
     _merge_mapreduce_data(linter, all_mapreduce_data)
-    linter.stats = merge_stats([linter.stats] + all_stats)
+    linter.stats = merge_stats([linter.stats, *all_stats])
```

### Comparing `pylint-3.0.0a5/pylint/lint/pylinter.py` & `pylint-3.0.0a6/pylint/lint/pylinter.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,58 +1,68 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
+import argparse
 import collections
 import contextlib
 import functools
 import os
 import sys
 import tokenize
 import traceback
-import warnings
 from collections import defaultdict
-from collections.abc import Callable, Iterable, Iterator, Sequence
+from collections.abc import Callable, Iterator, Sequence
 from io import TextIOWrapper
+from pathlib import Path
+from re import Pattern
+from types import ModuleType
 from typing import Any
 
 import astroid
-from astroid import AstroidError, nodes
+from astroid import nodes
 
 from pylint import checkers, exceptions, interfaces, reporters
 from pylint.checkers.base_checker import BaseChecker
 from pylint.config.arguments_manager import _ArgumentsManager
 from pylint.constants import (
     MAIN_CHECKER_NAME,
     MSG_TYPES,
     MSG_TYPES_STATUS,
     WarningScope,
 )
+from pylint.interfaces import HIGH
 from pylint.lint.base_options import _make_linter_options
 from pylint.lint.caching import load_results, save_results
-from pylint.lint.expand_modules import _is_ignored_file, expand_modules
+from pylint.lint.expand_modules import (
+    _is_ignored_file,
+    discover_package_path,
+    expand_modules,
+)
 from pylint.lint.message_state_handler import _MessageStateHandler
 from pylint.lint.parallel import check_parallel
 from pylint.lint.report_functions import (
     report_messages_by_module_stats,
     report_messages_stats,
     report_total_messages_stats,
 )
 from pylint.lint.utils import (
-    fix_import_path,
+    _is_relative_to,
+    augmented_sys_path,
     get_fatal_error_message,
     prepare_crash_report,
 )
 from pylint.message import Message, MessageDefinition, MessageDefinitionStore
 from pylint.reporters.base_reporter import BaseReporter
 from pylint.reporters.text import TextReporter
 from pylint.reporters.ureports import nodes as report_nodes
 from pylint.typing import (
+    DirectoryNamespaceDict,
     FileItem,
     ManagedMessage,
     MessageDefinitionTuple,
     MessageLocationTuple,
     ModuleDescriptionDict,
     Options,
 )
@@ -84,15 +94,15 @@
 def _load_reporter_by_class(reporter_class: str) -> type[BaseReporter]:
     qname = reporter_class
     module_part = astroid.modutils.get_module_part(qname)
     module = astroid.modutils.load_module_from_name(module_part)
     class_name = qname.split(".")[-1]
     klass = getattr(module, class_name)
     assert issubclass(klass, BaseReporter), f"{klass} is not a BaseReporter"
-    return klass
+    return klass  # type: ignore[no-any-return]
 
 
 # Python Linter class #########################################################
 
 # pylint: disable-next=consider-using-namedtuple-or-dataclass
 MSGS: dict[str, MessageDefinitionTuple] = {
     "F0001": (
@@ -184,30 +194,44 @@
     ),
     "E0011": (
         "Unrecognized file option %r",
         "unrecognized-inline-option",
         "Used when an unknown inline option is encountered.",
         {"scope": WarningScope.LINE},
     ),
-    "E0012": (
-        "Bad option value for %s",
-        "bad-option-value",
-        "Used when a bad value for an inline option is encountered.",
-        {"scope": WarningScope.LINE},
+    "W0012": (
+        "Unknown option value for '%s', expected a valid pylint message and got '%s'",
+        "unknown-option-value",
+        "Used when an unknown value is encountered for an option.",
+        {
+            "scope": WarningScope.LINE,
+            "old_names": [("E0012", "bad-option-value")],
+        },
+    ),
+    "R0022": (
+        "Useless option value for '%s', %s",
+        "useless-option-value",
+        "Used when a value for an option that is now deleted from pylint"
+        " is encountered.",
+        {
+            "scope": WarningScope.LINE,
+            "old_names": [("E0012", "bad-option-value")],
+        },
     ),
     "E0013": (
         "Plugin '%s' is impossible to load, is it installed ? ('%s')",
         "bad-plugin-value",
         "Used when a bad value is used in 'load-plugins'.",
         {"scope": WarningScope.LINE},
     ),
     "E0014": (
         "Out-of-place setting encountered in top level configuration-section '%s' : '%s'",
         "bad-configuration-section",
-        "Used when we detect a setting in the top level of a toml configuration that shouldn't be there.",
+        "Used when we detect a setting in the top level of a toml configuration that"
+        " shouldn't be there.",
         {"scope": WarningScope.LINE},
     ),
     "E0015": (
         "Unrecognized option found: %s",
         "unrecognized-option",
         "Used when we detect an option that we do not recognize.",
         {"scope": WarningScope.LINE},
@@ -227,25 +251,25 @@
     This is the main checker controlling the other ones and the reports
     generation. It is itself both a raw checker and an astroid checker in order
     to:
     * handle message activation / deactivation at the module level
     * handle some basic but necessary stats' data (number of classes, methods...)
 
     IDE plugin developers: you may have to call
-    `astroid.builder.MANAGER.astroid_cache.clear()` across runs if you want
+    `astroid.MANAGER.clear_cache()` across runs if you want
     to ensure the latest code version is actually checked.
 
     This class needs to support pickling for parallel linting to work. The exception
     is reporter member; see check_parallel function for more details.
     """
 
     name = MAIN_CHECKER_NAME
     msgs = MSGS
     # Will be used like this : datetime.now().strftime(crash_file_path)
-    crash_file_path: str = "pylint-crash-%Y-%m-%d-%H.txt"
+    crash_file_path: str = "pylint-crash-%Y-%m-%d-%H-%M-%S.txt"
 
     option_groups_descs = {
         "Messages control": "Options controlling analysis messages",
         "Reports": "Options related to output formatting and reporting",
     }
 
     def __init__(
@@ -272,36 +296,26 @@
         """Dictionary of possible but non-initialized reporters."""
 
         # Attributes for checkers and plugins
         self._checkers: defaultdict[
             str, list[checkers.BaseChecker]
         ] = collections.defaultdict(list)
         """Dictionary of registered and initialized checkers."""
-        self._dynamic_plugins: set[str] = set()
+        self._dynamic_plugins: dict[str, ModuleType | ModuleNotFoundError | bool] = {}
         """Set of loaded plugin names."""
 
-        # Attributes related to registering messages and their handling
-        self.msgs_store = MessageDefinitionStore()
-        self.msg_status = 0
-        self._by_id_managed_msgs: list[ManagedMessage] = []
-
-        # Attributes related to visiting files
-        self.file_state = FileState("", self.msgs_store, is_base_filestate=True)
-        self.current_name: str | None = None
-        self.current_file: str | None = None
-        self._ignore_file = False
-
         # Attributes related to stats
         self.stats = LinterStats()
 
         # Attributes related to (command-line) options and their parsing
         self.options: Options = options + _make_linter_options(self)
         for opt_group in option_groups:
             self.option_groups_descs[opt_group[0]] = opt_group[1]
-        self._option_groups: tuple[tuple[str, str], ...] = option_groups + (
+        self._option_groups: tuple[tuple[str, str], ...] = (
+            *option_groups,
             ("Messages control", "Options controlling analysis messages"),
             ("Reports", "Options related to output formatting and reporting"),
         )
         self.fail_on_symbols: list[str] = []
         """List of message symbols on which pylint should fail, set by --fail-on."""
         self._error_mode = False
 
@@ -313,63 +327,81 @@
             (
                 "RP0002",
                 "% errors / warnings by module",
                 report_messages_by_module_stats,
             ),
             ("RP0003", "Messages", report_messages_stats),
         )
-        self.register_checker(self)
 
-    @property
-    def option_groups(self) -> tuple[tuple[str, str], ...]:
-        # TODO: 3.0: Remove deprecated attribute
-        warnings.warn(
-            "The option_groups attribute has been deprecated and will be removed in pylint 3.0",
-            DeprecationWarning,
-        )
-        return self._option_groups
+        # Attributes related to registering messages and their handling
+        self.msgs_store = MessageDefinitionStore(self.config.py_version)
+        self.msg_status = 0
+        self._by_id_managed_msgs: list[ManagedMessage] = []
 
-    @option_groups.setter
-    def option_groups(self, value: tuple[tuple[str, str], ...]) -> None:
-        warnings.warn(
-            "The option_groups attribute has been deprecated and will be removed in pylint 3.0",
-            DeprecationWarning,
-        )
-        self._option_groups = value
+        # Attributes related to visiting files
+        self.file_state = FileState("", self.msgs_store, is_base_filestate=True)
+        self.current_name: str = ""
+        self.current_file: str | None = None
+        self._ignore_file = False
+        self._ignore_paths: list[Pattern[str]] = []
+
+        self.register_checker(self)
 
     def load_default_plugins(self) -> None:
         checkers.initialize(self)
         reporters.initialize(self)
 
     def load_plugin_modules(self, modnames: list[str]) -> None:
-        """Check a list pylint plugins modules, load and register them."""
+        """Check a list of pylint plugins modules, load and register them.
+
+        If a module cannot be loaded, never try to load it again and instead
+        store the error message for later use in ``load_plugin_configuration``
+        below.
+        """
         for modname in modnames:
             if modname in self._dynamic_plugins:
                 continue
-            self._dynamic_plugins.add(modname)
             try:
                 module = astroid.modutils.load_module_from_name(modname)
                 module.register(self)
-            except ModuleNotFoundError:
-                pass
+                self._dynamic_plugins[modname] = module
+            except ModuleNotFoundError as mnf_e:
+                self._dynamic_plugins[modname] = mnf_e
 
     def load_plugin_configuration(self) -> None:
         """Call the configuration hook for plugins.
 
         This walks through the list of plugins, grabs the "load_configuration"
         hook, if exposed, and calls it to allow plugins to configure specific
         settings.
+
+        The result of attempting to load the plugin of the given name
+        is stored in the dynamic plugins dictionary in ``load_plugin_modules`` above.
+
+        ..note::
+            This function previously always tried to load modules again, which
+            led to some confusion and silent failure conditions as described
+            in GitHub issue #7264. Making it use the stored result is more efficient, and
+            means that we avoid the ``init-hook`` problems from before.
         """
-        for modname in self._dynamic_plugins:
-            try:
-                module = astroid.modutils.load_module_from_name(modname)
-                if hasattr(module, "load_configuration"):
-                    module.load_configuration(self)
-            except ModuleNotFoundError as e:
-                self.add_message("bad-plugin-value", args=(modname, e), line=0)
+        for modname, module_or_error in self._dynamic_plugins.items():
+            if isinstance(module_or_error, ModuleNotFoundError):
+                self.add_message(
+                    "bad-plugin-value", args=(modname, module_or_error), line=0
+                )
+            elif hasattr(module_or_error, "load_configuration"):
+                module_or_error.load_configuration(self)
+
+        # We re-set all the dictionary values to True here to make sure the dict
+        # is pickle-able. This is only a problem in multiprocessing/parallel mode.
+        # (e.g. invoking pylint -j 2)
+        self._dynamic_plugins = {
+            modname: not isinstance(val, ModuleNotFoundError)
+            for modname, val in self._dynamic_plugins.items()
+        }
 
     def _load_reporters(self, reporter_names: str) -> None:
         """Load the reporters if they are available on _reporters."""
         if not self._reporters:
             return
         sub_reporters = []
         output_files = []
@@ -404,16 +436,16 @@
         if name in self._reporters:
             return self._reporters[name]()
 
         try:
             reporter_class = _load_reporter_by_class(reporter_name)
         except (ImportError, AttributeError, AssertionError) as e:
             raise exceptions.InvalidReporterError(name) from e
-        else:
-            return reporter_class()
+
+        return reporter_class()
 
     def set_reporter(
         self, reporter: reporters.BaseReporter | reporters.MultiReporter
     ) -> None:
         """Set the reporter used to display messages and reports."""
         self.reporter = reporter
         reporter.linter = self
@@ -439,14 +471,17 @@
     def register_checker(self, checker: checkers.BaseChecker) -> None:
         """This method auto registers the checker."""
         self._checkers[checker.name].append(checker)
         for r_id, r_title, r_cb in checker.reports:
             self.register_report(r_id, r_title, r_cb, checker)
         if hasattr(checker, "msgs"):
             self.msgs_store.register_messages_from_checker(checker)
+            for message in checker.messages:
+                if not message.default_enabled:
+                    self.disable(message.msgid)
         # Register the checker, but disable all of its messages.
         if not getattr(checker, "enabled", True):
             self.disable(checker.name)
 
     def enable_fail_on_messages(self) -> None:
         """Enable 'fail on' msgs.
 
@@ -554,18 +589,19 @@
     # pylint: enable=unused-argument
 
     def initialize(self) -> None:
         """Initialize linter for linting.
 
         This method is called before any linting is done.
         """
+        self._ignore_paths = self.config.ignore_paths
         # initialize msgs_state now that all messages have been registered into
         # the store
         for msg in self.msgs_store.messages:
-            if not msg.may_be_emitted():
+            if not msg.may_be_emitted(self.config.py_version):
                 self._msgs_state[msg.msgid] = False
 
     def _discover_files(self, files_or_modules: Sequence[str]) -> Iterator[str]:
         """Discover python modules and packages in sub-directory.
 
         Returns iterator of paths to discovered modules and packages.
         """
@@ -596,107 +632,173 @@
                             os.path.join(root, file)
                             for file in files
                             if file.endswith(".py")
                         )
             else:
                 yield something
 
-    def check(self, files_or_modules: Sequence[str] | str) -> None:
+    def check(self, files_or_modules: Sequence[str]) -> None:
         """Main checking entry: check a list of files or modules from their name.
 
         files_or_modules is either a string or list of strings presenting modules to check.
         """
         self.initialize()
-        if not isinstance(files_or_modules, (list, tuple)):
-            # TODO: 3.0: Remove deprecated typing and update docstring
-            warnings.warn(
-                "In pylint 3.0, the checkers check function will only accept sequence of string",
-                DeprecationWarning,
-            )
-            files_or_modules = (files_or_modules,)  # type: ignore[assignment]
         if self.config.recursive:
             files_or_modules = tuple(self._discover_files(files_or_modules))
         if self.config.from_stdin:
             if len(files_or_modules) != 1:
                 raise exceptions.InvalidArgsError(
                     "Missing filename required for --from-stdin"
                 )
 
-            filepath = files_or_modules[0]
-            with fix_import_path(files_or_modules):
-                self._check_files(
-                    functools.partial(self.get_ast, data=_read_stdin()),
-                    [self._get_file_descr_from_stdin(filepath)],
-                )
-        elif self.config.jobs == 1:
-            with fix_import_path(files_or_modules):
-                self._check_files(
-                    self.get_ast, self._iterate_file_descrs(files_or_modules)
-                )
-        else:
+        extra_packages_paths = list(
+            {
+                discover_package_path(file_or_module, self.config.source_roots)
+                for file_or_module in files_or_modules
+            }
+        )
+
+        # TODO: Move the parallel invocation into step 3 of the checking process
+        if not self.config.from_stdin and self.config.jobs > 1:
+            original_sys_path = sys.path[:]
             check_parallel(
                 self,
                 self.config.jobs,
                 self._iterate_file_descrs(files_or_modules),
-                files_or_modules,
+                extra_packages_paths,
             )
+            sys.path = original_sys_path
+            return
 
-    def check_single_file(self, name: str, filepath: str, modname: str) -> None:
-        warnings.warn(
-            "In pylint 3.0, the checkers check_single_file function will be removed. "
-            "Use check_single_file_item instead.",
-            DeprecationWarning,
-        )
-        self.check_single_file_item(FileItem(name, filepath, modname))
+        # 1) Get all FileItems
+        with augmented_sys_path(extra_packages_paths):
+            if self.config.from_stdin:
+                fileitems = self._get_file_descr_from_stdin(files_or_modules[0])
+                data: str | None = _read_stdin()
+            else:
+                fileitems = self._iterate_file_descrs(files_or_modules)
+                data = None
+
+        # The contextmanager also opens all checkers and sets up the PyLinter class
+        with augmented_sys_path(extra_packages_paths):
+            with self._astroid_module_checker() as check_astroid_module:
+                # 2) Get the AST for each FileItem
+                ast_per_fileitem = self._get_asts(fileitems, data)
+
+                # 3) Lint each ast
+                self._lint_files(ast_per_fileitem, check_astroid_module)
+
+    def _get_asts(
+        self, fileitems: Iterator[FileItem], data: str | None
+    ) -> dict[FileItem, nodes.Module | None]:
+        """Get the AST for all given FileItems."""
+        ast_per_fileitem: dict[FileItem, nodes.Module | None] = {}
+
+        for fileitem in fileitems:
+            self.set_current_module(fileitem.name, fileitem.filepath)
+
+            try:
+                ast_per_fileitem[fileitem] = self.get_ast(
+                    fileitem.filepath, fileitem.name, data
+                )
+            except astroid.AstroidBuildingError as ex:
+                template_path = prepare_crash_report(
+                    ex, fileitem.filepath, self.crash_file_path
+                )
+                msg = get_fatal_error_message(fileitem.filepath, template_path)
+                self.add_message(
+                    "astroid-error",
+                    args=(fileitem.filepath, msg),
+                    confidence=HIGH,
+                )
+
+        return ast_per_fileitem
 
     def check_single_file_item(self, file: FileItem) -> None:
         """Check single file item.
 
         The arguments are the same that are documented in _check_files
 
         initialize() should be called before calling this method
         """
         with self._astroid_module_checker() as check_astroid_module:
             self._check_file(self.get_ast, check_astroid_module, file)
 
-    def _check_files(
+    def _lint_files(
         self,
-        get_ast: GetAstProtocol,
-        file_descrs: Iterable[FileItem],
+        ast_mapping: dict[FileItem, nodes.Module | None],
+        check_astroid_module: Callable[[nodes.Module], bool | None],
     ) -> None:
-        """Check all files from file_descrs."""
-        with self._astroid_module_checker() as check_astroid_module:
-            for file in file_descrs:
-                try:
-                    self._check_file(get_ast, check_astroid_module, file)
-                except Exception as ex:  # pylint: disable=broad-except
-                    template_path = prepare_crash_report(
-                        ex, file.filepath, self.crash_file_path
+        """Lint all AST modules from a mapping.."""
+        for fileitem, module in ast_mapping.items():
+            if module is None:
+                continue
+            try:
+                self._lint_file(fileitem, module, check_astroid_module)
+            except Exception as ex:  # pylint: disable=broad-except
+                template_path = prepare_crash_report(
+                    ex, fileitem.filepath, self.crash_file_path
+                )
+                msg = get_fatal_error_message(fileitem.filepath, template_path)
+                if isinstance(ex, astroid.AstroidError):
+                    self.add_message(
+                        "astroid-error", args=(fileitem.filepath, msg), confidence=HIGH
                     )
-                    msg = get_fatal_error_message(file.filepath, template_path)
-                    if isinstance(ex, AstroidError):
-                        symbol = "astroid-error"
-                        self.add_message(symbol, args=(file.filepath, msg))
-                    else:
-                        symbol = "fatal"
-                        self.add_message(symbol, args=msg)
+                else:
+                    self.add_message("fatal", args=msg, confidence=HIGH)
+
+    def _lint_file(
+        self,
+        file: FileItem,
+        module: nodes.Module,
+        check_astroid_module: Callable[[nodes.Module], bool | None],
+    ) -> None:
+        """Lint a file using the passed utility function check_astroid_module).
+
+        :param FileItem file: data about the file
+        :param nodes.Module module: the ast module to lint
+        :param Callable check_astroid_module: callable checking an AST taking the following
+               arguments
+        - ast: AST of the module
+        :raises AstroidError: for any failures stemming from astroid
+        """
+        self.set_current_module(file.name, file.filepath)
+        self._ignore_file = False
+        self.file_state = FileState(file.modpath, self.msgs_store, module)
+        # fix the current file (if the source file was not available or
+        # if it's actually a c extension)
+        self.current_file = module.file
+
+        try:
+            check_astroid_module(module)
+        except Exception as e:
+            raise astroid.AstroidError from e
+
+        # warn about spurious inline messages handling
+        spurious_messages = self.file_state.iter_spurious_suppression_messages(
+            self.msgs_store
+        )
+        for msgid, line, args in spurious_messages:
+            self.add_message(msgid, line, None, args)
 
     def _check_file(
         self,
         get_ast: GetAstProtocol,
         check_astroid_module: Callable[[nodes.Module], bool | None],
         file: FileItem,
     ) -> None:
         """Check a file using the passed utility functions (get_ast and
         check_astroid_module).
 
-        :param callable get_ast: callable returning AST from defined file taking the following arguments
+        :param callable get_ast: callable returning AST from defined file taking the
+                                 following arguments
         - filepath: path to the file to check
         - name: Python module name
-        :param callable check_astroid_module: callable checking an AST taking the following arguments
+        :param callable check_astroid_module: callable checking an AST taking the following
+               arguments
         - ast: AST of the module
         :param FileItem file: data about the file
         :raises AstroidError: for any failures stemming from astroid
         """
         self.set_current_module(file.name, file.filepath)
         # get the module representation
         ast_node = get_ast(file.filepath, file.name)
@@ -716,135 +818,119 @@
         # warn about spurious inline messages handling
         spurious_messages = self.file_state.iter_spurious_suppression_messages(
             self.msgs_store
         )
         for msgid, line, args in spurious_messages:
             self.add_message(msgid, line, None, args)
 
-    @staticmethod
-    def _get_file_descr_from_stdin(filepath: str) -> FileItem:
+    def _get_file_descr_from_stdin(self, filepath: str) -> Iterator[FileItem]:
         """Return file description (tuple of module name, file path, base name) from
         given file path.
 
         This method is used for creating suitable file description for _check_files when the
         source is standard input.
         """
+        if _is_ignored_file(
+            filepath,
+            self.config.ignore,
+            self.config.ignore_patterns,
+            self.config.ignore_paths,
+        ):
+            return
+
         try:
             # Note that this function does not really perform an
             # __import__ but may raise an ImportError exception, which
             # we want to catch here.
             modname = ".".join(astroid.modutils.modpath_from_file(filepath))
         except ImportError:
             modname = os.path.splitext(os.path.basename(filepath))[0]
 
-        return FileItem(modname, filepath, filepath)
+        yield FileItem(modname, filepath, filepath)
 
     def _iterate_file_descrs(
         self, files_or_modules: Sequence[str]
     ) -> Iterator[FileItem]:
         """Return generator yielding file descriptions (tuples of module name, file
         path, base name).
 
         The returned generator yield one item for each Python module that should be linted.
         """
-        for descr in self._expand_files(files_or_modules):
+        for descr in self._expand_files(files_or_modules).values():
             name, filepath, is_arg = descr["name"], descr["path"], descr["isarg"]
             if self.should_analyze_file(name, filepath, is_argument=is_arg):
                 yield FileItem(name, filepath, descr["basename"])
 
-    def _expand_files(self, modules: Sequence[str]) -> list[ModuleDescriptionDict]:
+    def _expand_files(
+        self, files_or_modules: Sequence[str]
+    ) -> dict[str, ModuleDescriptionDict]:
         """Get modules and errors from a list of modules and handle errors."""
         result, errors = expand_modules(
-            modules,
+            files_or_modules,
+            self.config.source_roots,
             self.config.ignore,
             self.config.ignore_patterns,
             self._ignore_paths,
         )
         for error in errors:
             message = modname = error["mod"]
             key = error["key"]
             self.set_current_module(modname)
             if key == "fatal":
                 message = str(error["ex"]).replace(os.getcwd() + os.sep, "")
             self.add_message(key, args=message)
         return result
 
-    def set_current_module(
-        self, modname: str | None, filepath: str | None = None
-    ) -> None:
+    def set_current_module(self, modname: str, filepath: str | None = None) -> None:
         """Set the name of the currently analyzed module and
         init statistics for it.
         """
         if not modname and filepath is None:
             return
         self.reporter.on_set_current_module(modname or "", filepath)
-        if modname is None:
-            # TODO: 3.0: Remove all modname or ""'s in this method
-            warnings.warn(
-                (
-                    "In pylint 3.0 modname should be a string so that it can be used to "
-                    "correctly set the current_name attribute of the linter instance. "
-                    "If unknown it should be initialized as an empty string."
-                ),
-                DeprecationWarning,
-            )
         self.current_name = modname
         self.current_file = filepath or modname
         self.stats.init_single_module(modname or "")
 
+        # If there is an actual filepath we might need to update the config attribute
+        if filepath:
+            namespace = self._get_namespace_for_file(
+                Path(filepath), self._directory_namespaces
+            )
+            if namespace:
+                self.config = namespace or self._base_config
+
+    def _get_namespace_for_file(
+        self, filepath: Path, namespaces: DirectoryNamespaceDict
+    ) -> argparse.Namespace | None:
+        for directory in namespaces:
+            if _is_relative_to(filepath, directory):
+                namespace = self._get_namespace_for_file(
+                    filepath, namespaces[directory][1]
+                )
+                if namespace is None:
+                    return namespaces[directory][0]
+        return None
+
     @contextlib.contextmanager
     def _astroid_module_checker(
         self,
     ) -> Iterator[Callable[[nodes.Module], bool | None]]:
         """Context manager for checking ASTs.
 
         The value in the context is callable accepting AST as its only argument.
         """
         walker = ASTWalker(self)
         _checkers = self.prepare_checkers()
         tokencheckers = [
-            c
-            for c in _checkers
-            if isinstance(c, checkers.BaseTokenChecker) and c is not self
+            c for c in _checkers if isinstance(c, checkers.BaseTokenChecker)
         ]
-        # TODO: 3.0: Remove deprecated for-loop
-        for c in _checkers:
-            with warnings.catch_warnings():
-                warnings.filterwarnings("ignore", category=DeprecationWarning)
-                if (
-                    interfaces.implements(c, interfaces.ITokenChecker)
-                    and c not in tokencheckers
-                    and c is not self
-                ):
-                    tokencheckers.append(c)  # type: ignore[arg-type]  # pragma: no cover
-                    warnings.warn(  # pragma: no cover
-                        "Checkers should subclass BaseTokenChecker "
-                        "instead of using the __implements__ mechanism. Use of __implements__ "
-                        "will no longer be supported in pylint 3.0",
-                        DeprecationWarning,
-                    )
         rawcheckers = [
             c for c in _checkers if isinstance(c, checkers.BaseRawFileChecker)
         ]
-        # TODO: 3.0: Remove deprecated if-statement
-        for c in _checkers:
-            with warnings.catch_warnings():
-                warnings.filterwarnings("ignore", category=DeprecationWarning)
-                if (
-                    interfaces.implements(c, interfaces.IRawChecker)
-                    and c not in rawcheckers
-                ):
-                    rawcheckers.append(c)  # type: ignore[arg-type] # pragma: no cover
-                    warnings.warn(  # pragma: no cover
-                        "Checkers should subclass BaseRawFileChecker "
-                        "instead of using the __implements__ mechanism. Use of __implements__ "
-                        "will no longer be supported in pylint 3.0",
-                        DeprecationWarning,
-                    )
-        # notify global begin
         for checker in _checkers:
             checker.open()
             walker.add_checker(checker)
 
         yield functools.partial(
             self.check_astroid_module,
             walker=walker,
@@ -855,37 +941,40 @@
         # notify global end
         self.stats.statement = walker.nbstatements
         for checker in reversed(_checkers):
             checker.close()
 
     def get_ast(
         self, filepath: str, modname: str, data: str | None = None
-    ) -> nodes.Module:
+    ) -> nodes.Module | None:
         """Return an ast(roid) representation of a module or a string.
 
-        :param str filepath: path to checked file.
+        :param filepath: path to checked file.
         :param str modname: The name of the module to be checked.
         :param str data: optional contents of the checked file.
         :returns: the AST
         :rtype: astroid.nodes.Module
         :raises AstroidBuildingError: Whenever we encounter an unexpected exception
         """
         try:
             if data is None:
                 return MANAGER.ast_from_file(filepath, modname, source=True)
             return astroid.builder.AstroidBuilder(MANAGER).string_build(
                 data, modname, filepath
             )
         except astroid.AstroidSyntaxError as ex:
-            # pylint: disable=no-member
+            line = getattr(ex.error, "lineno", None)
+            if line is None:
+                line = 0
             self.add_message(
                 "syntax-error",
-                line=getattr(ex.error, "lineno", 0),
+                line=line,
                 col_offset=getattr(ex.error, "offset", None),
-                args=str(ex.error),
+                args=f"Parsing failed: '{ex.error}'",
+                confidence=HIGH,
             )
         except astroid.AstroidBuildingError as ex:
             self.add_message("parse-error", args=ex)
         except Exception as ex:
             traceback.print_exc()
             # We raise BuildingError here as this is essentially an astroid issue
             # Creating an issue template and adding the 'astroid-error' message is handled
@@ -908,18 +997,14 @@
         For return value see _check_astroid_module
         """
         before_check_statements = walker.nbstatements
 
         retval = self._check_astroid_module(
             ast_node, walker, rawcheckers, tokencheckers
         )
-
-        # TODO: 3.0: Remove unnecessary assertion
-        assert self.current_name
-
         self.stats.by_module[self.current_name]["statement"] = (
             walker.nbstatements - before_check_statements
         )
 
         return retval
 
     def _check_astroid_module(
@@ -969,29 +1054,23 @@
         MANAGER.max_inferable_values = self.config.limit_inference_results
         MANAGER.extension_package_whitelist.update(self.config.extension_pkg_allow_list)
         if self.config.extension_pkg_whitelist:
             MANAGER.extension_package_whitelist.update(
                 self.config.extension_pkg_whitelist
             )
         self.stats.reset_message_count()
-        self._ignore_paths = self.linter.config.ignore_paths
 
     def generate_reports(self) -> int | None:
         """Close the whole package /module, it's time to make reports !
 
         if persistent run, pickle results for later comparison
         """
         # Display whatever messages are left on the reporter.
         self.reporter.display_messages(report_nodes.Section())
-
-        # TODO: 3.0: Remove second half of if-statement
-        if (
-            not self.file_state._is_base_filestate
-            and self.file_state.base_name is not None
-        ):
+        if not self.file_state._is_base_filestate:
             # load previous results if any
             previous_stats = load_results(self.file_state.base_name)
             self.reporter.on_close(self.stats, previous_stats)
             if self.config.reports:
                 sect = self.make_reports(self.stats, previous_stats)
             else:
                 sect = report_nodes.Section()
@@ -1005,19 +1084,17 @@
         else:
             self.reporter.on_close(self.stats, LinterStats())
             score_value = None
         return score_value
 
     def _report_evaluation(self) -> int | None:
         """Make the global evaluation report."""
-        # check with at least check 1 statements (usually 0 when there is a
+        # check with at least a statement (usually 0 when there is a
         # syntax error preventing pylint from further processing)
         note = None
-        # TODO: 3.0: Remove assertion
-        assert self.file_state.base_name is not None
         previous_stats = load_results(self.file_state.base_name)
         if self.stats.statement == 0:
             return note
 
         # get a global note for the code
         evaluation = self.config.evaluation
         try:
@@ -1094,19 +1171,15 @@
             )
             return
 
         # update stats
         msg_cat = MSG_TYPES[message_definition.msgid[0]]
         self.msg_status |= MSG_TYPES_STATUS[message_definition.msgid[0]]
         self.stats.increase_single_message_count(msg_cat, 1)
-        self.stats.increase_single_module_message_count(
-            self.current_name,  # type: ignore[arg-type] # Should be removable after https://github.com/PyCQA/pylint/pull/5580
-            msg_cat,
-            1,
-        )
+        self.stats.increase_single_module_message_count(self.current_name, msg_cat, 1)
         try:
             self.stats.by_msg[message_definition.symbol] += 1
         except KeyError:
             self.stats.by_msg[message_definition.symbol] = 1
         # Interpolate arguments into message string
         msg = message_definition.msg
         if args is not None:
@@ -1197,15 +1270,19 @@
                 self._get_message_state_scope(
                     message_definition.msgid, line, confidence
                 ),
                 message_definition.msgid,
                 line,
             )
 
-    def _emit_bad_option_value(self) -> None:
-        for modname in self._stashed_bad_option_value_messages:
+    def _emit_stashed_messages(self) -> None:
+        for keys, values in self._stashed_messages.items():
+            modname, symbol = keys
             self.linter.set_current_module(modname)
-            values = self._stashed_bad_option_value_messages[modname]
-            for option_string, msg_id in values:
-                msg = f"{option_string}. Don't recognize message {msg_id}."
-                self.add_message("bad-option-value", args=msg, line=0)
-        self._stashed_bad_option_value_messages = collections.defaultdict(list)
+            for args in values:
+                self.add_message(
+                    symbol,
+                    args=args,
+                    line=0,
+                    confidence=HIGH,
+                )
+        self._stashed_messages = collections.defaultdict(list)
```

### Comparing `pylint-3.0.0a5/pylint/lint/report_functions.py` & `pylint-3.0.0a6/pylint/lint/report_functions.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import collections
 from collections import defaultdict
 
 from pylint import checkers, exceptions
```

### Comparing `pylint-3.0.0a5/pylint/lint/run.py` & `pylint-3.0.0a6/pylint/lint/run.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,39 +1,45 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import os
 import sys
 import warnings
 from collections.abc import Sequence
 from pathlib import Path
-from typing import Any, ClassVar
+from typing import ClassVar
 
 from pylint import config
+from pylint.checkers.utils import clear_lru_caches
 from pylint.config._pylint_config import (
     _handle_pylint_config_commands,
     _register_generate_config_options,
 )
 from pylint.config.config_initialization import _config_initialization
 from pylint.config.exceptions import ArgumentPreprocessingError
 from pylint.config.utils import _preprocess_options
 from pylint.constants import full_version
 from pylint.lint.base_options import _make_run_options
-from pylint.lint.pylinter import PyLinter
+from pylint.lint.pylinter import MANAGER, PyLinter
 from pylint.reporters.base_reporter import BaseReporter
 
 try:
     import multiprocessing
     from multiprocessing import synchronize  # noqa pylint: disable=unused-import
 except ImportError:
     multiprocessing = None  # type: ignore[assignment]
 
+try:
+    from concurrent.futures import ProcessPoolExecutor
+except ImportError:
+    ProcessPoolExecutor = None  # type: ignore[assignment,misc]
+
 
 def _query_cpu() -> int | None:
     """Try to determine number of CPUs allotted in a docker container.
 
     This is based on discussion and copied from suggestions in
     https://bugs.python.org/issue36054.
     """
@@ -47,21 +53,29 @@
     if (
         cpu_quota
         and cpu_quota != -1
         and Path("/sys/fs/cgroup/cpu/cpu.cfs_period_us").is_file()
     ):
         with open("/sys/fs/cgroup/cpu/cpu.cfs_period_us", encoding="utf-8") as file:
             cpu_period = int(file.read().rstrip())
-        # Divide quota by period and you should get num of allotted CPU to the container, rounded down if fractional.
+        # Divide quota by period and you should get num of allotted CPU to the container,
+        # rounded down if fractional.
         avail_cpu = int(cpu_quota / cpu_period)
     elif Path("/sys/fs/cgroup/cpu/cpu.shares").is_file():
         with open("/sys/fs/cgroup/cpu/cpu.shares", encoding="utf-8") as file:
             cpu_shares = int(file.read().rstrip())
         # For AWS, gives correct value * 1024.
         avail_cpu = int(cpu_shares / 1024)
+
+    # In K8s Pods also a fraction of a single core could be available
+    # As multiprocessing is not able to run only a "fraction" of process
+    # assume we have 1 CPU available
+    if avail_cpu == 0:
+        avail_cpu = 1
+
     return avail_cpu
 
 
 def _cpu_count() -> int:
     """Use sched_affinity if available for virtualized or containerized
     environments.
     """
@@ -71,22 +85,22 @@
     # pylint: disable=not-callable,using-constant-test,useless-suppression
     if sched_getaffinity:
         cpu_count = len(sched_getaffinity(0))
     elif multiprocessing:
         cpu_count = multiprocessing.cpu_count()
     else:
         cpu_count = 1
+    if sys.platform == "win32":
+        # See also https://github.com/python/cpython/issues/94242
+        cpu_count = min(cpu_count, 56)  # pragma: no cover
     if cpu_share is not None:
         return min(cpu_share, cpu_count)
     return cpu_count
 
 
-UNUSED_PARAM_SENTINEL = object()
-
-
 class Run:
     """Helper class to use as main for pylint with 'run(*sys.argv[1:])'."""
 
     LinterClass = PyLinter
     option_groups = (
         (
             "Commands",
@@ -96,20 +110,20 @@
     )
     _is_pylint_config: ClassVar[bool] = False
     """Boolean whether or not this is a 'pylint-config' run.
 
     Used by _PylintConfigRun to make the 'pylint-config' command work.
     """
 
+    # pylint: disable = too-many-statements, too-many-branches
     def __init__(
         self,
         args: Sequence[str],
         reporter: BaseReporter | None = None,
         exit: bool = True,  # pylint: disable=redefined-builtin
-        do_exit: Any = UNUSED_PARAM_SENTINEL,
     ) -> None:
         # Immediately exit if user asks for version
         if "--version" in args:
             print(full_version)
             sys.exit(0)
 
         self._rcfile: str | None = None
@@ -153,14 +167,15 @@
         )
 
         # Handle the 'pylint-config' command
         if self._is_pylint_config:
             warnings.warn(
                 "NOTE: The 'pylint-config' command is experimental and usage can change",
                 UserWarning,
+                stacklevel=2,
             )
             code = _handle_pylint_config_commands(linter)
             if exit:
                 sys.exit(code)
             return
 
         # Display help messages if there are no files to lint
@@ -171,17 +186,17 @@
         if linter.config.jobs < 0:
             print(
                 f"Jobs number ({linter.config.jobs}) should be greater than or equal to 0",
                 file=sys.stderr,
             )
             sys.exit(32)
         if linter.config.jobs > 1 or linter.config.jobs == 0:
-            if multiprocessing is None:
+            if ProcessPoolExecutor is None:
                 print(
-                    "Multiprocessing library is missing, fallback to single process",
+                    "concurrent.futures module is missing, fallback to single process",
                     file=sys.stderr,
                 )
                 linter.set_option("jobs", 1)
             elif linter.config.jobs == 0:
                 linter.config.jobs = _cpu_count()
 
         if self._output:
@@ -192,21 +207,17 @@
                     score_value = linter.generate_reports()
             except OSError as ex:
                 print(ex, file=sys.stderr)
                 sys.exit(32)
         else:
             linter.check(args)
             score_value = linter.generate_reports()
-
-        if do_exit is not UNUSED_PARAM_SENTINEL:
-            warnings.warn(
-                "do_exit is deprecated and it is going to be removed in a future version.",
-                DeprecationWarning,
-            )
-            exit = do_exit
+        if linter.config.clear_cache_post_run:
+            clear_lru_caches()
+            MANAGER.clear_cache()
 
         if exit:
             if linter.config.exit_zero:
                 sys.exit(0)
             elif linter.any_fail_on_issues():
                 # We need to make sure we return a failing exit code in this case.
                 # So we use self.linter.msg_status if that is non-zero, otherwise we just return 1.
```

### Comparing `pylint-3.0.0a5/pylint/message/__init__.py` & `pylint-3.0.0a6/pylint/message/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """All the classes related to Message handling."""
 
 from pylint.message.message import Message
 from pylint.message.message_definition import MessageDefinition
 from pylint.message.message_definition_store import MessageDefinitionStore
 from pylint.message.message_id_store import MessageIdStore
```

### Comparing `pylint-3.0.0a5/pylint/message/message.py` & `pylint-3.0.0a6/pylint/message/message.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from dataclasses import asdict, dataclass
-from warnings import warn
 
 from pylint.constants import MSG_TYPES
 from pylint.interfaces import UNDEFINED, Confidence
 from pylint.typing import MessageLocationTuple
 
 
 @dataclass(unsafe_hash=True)
@@ -31,34 +30,18 @@
     end_line: int | None
     end_column: int | None
 
     def __init__(
         self,
         msg_id: str,
         symbol: str,
-        location: tuple[str, str, str, str, int, int] | MessageLocationTuple,
+        location: MessageLocationTuple,
         msg: str,
         confidence: Confidence | None,
     ) -> None:
-        if not isinstance(location, MessageLocationTuple):
-            warn(
-                "In pylint 3.0, Messages will only accept a MessageLocationTuple as location parameter",
-                DeprecationWarning,
-            )
-            location = MessageLocationTuple(
-                location[0],
-                location[1],
-                location[2],
-                location[3],
-                location[4],
-                location[5],
-                None,
-                None,
-            )
-
         self.msg_id = msg_id
         self.symbol = symbol
         self.msg = msg
         self.C = msg_id[0]
         self.category = MSG_TYPES[msg_id[0]]
         self.confidence = confidence or UNDEFINED
         self.abspath = location.abspath
@@ -73,7 +56,20 @@
     def format(self, template: str) -> str:
         """Format the message according to the given template.
 
         The template format is the one of the format method :
         cf. https://docs.python.org/2/library/string.html#formatstrings
         """
         return template.format(**asdict(self))
+
+    @property
+    def location(self) -> MessageLocationTuple:
+        return MessageLocationTuple(
+            self.abspath,
+            self.path,
+            self.module,
+            self.obj,
+            self.line,
+            self.column,
+            self.end_line,
+            self.end_column,
+        )
```

### Comparing `pylint-3.0.0a5/pylint/message/message_definition.py` & `pylint-3.0.0a6/pylint/message/message_definition.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import sys
 from typing import TYPE_CHECKING, Any
 
 from astroid import nodes
@@ -14,35 +14,40 @@
 from pylint.utils import normalize_text
 
 if TYPE_CHECKING:
     from pylint.checkers import BaseChecker
 
 
 class MessageDefinition:
+    # pylint: disable-next=too-many-arguments
     def __init__(
         self,
         checker: BaseChecker,
         msgid: str,
         msg: str,
         description: str,
         symbol: str,
         scope: str,
         minversion: tuple[int, int] | None = None,
         maxversion: tuple[int, int] | None = None,
         old_names: list[tuple[str, str]] | None = None,
+        shared: bool = False,
+        default_enabled: bool = True,
     ) -> None:
         self.checker_name = checker.name
         self.check_msgid(msgid)
         self.msgid = msgid
         self.symbol = symbol
         self.msg = msg
         self.description = description
         self.scope = scope
         self.minversion = minversion
         self.maxversion = maxversion
+        self.shared = shared
+        self.default_enabled = default_enabled
         self.old_names: list[tuple[str, str]] = []
         if old_names:
             for old_msgid, old_symbol in old_names:
                 self.check_msgid(old_msgid)
                 self.old_names.append(
                     (old_msgid, old_symbol),
                 )
@@ -63,19 +68,19 @@
 
     def __repr__(self) -> str:
         return f"MessageDefinition:{self.symbol} ({self.msgid})"
 
     def __str__(self) -> str:
         return f"{repr(self)}:\n{self.msg} {self.description}"
 
-    def may_be_emitted(self) -> bool:
-        """Return True if message may be emitted using the current interpreter."""
-        if self.minversion is not None and self.minversion > sys.version_info:
+    def may_be_emitted(self, py_version: tuple[int, ...] | sys._version_info) -> bool:
+        """May the message be emitted using the configured py_version?"""
+        if self.minversion is not None and self.minversion > py_version:
             return False
-        if self.maxversion is not None and self.maxversion <= sys.version_info:
+        if self.maxversion is not None and self.maxversion <= py_version:
             return False
         return True
 
     def format_help(self, checkerref: bool = False) -> str:
         """Return the help string for the given message id."""
         desc = self.description
         if checkerref:
```

### Comparing `pylint-3.0.0a5/pylint/message/message_definition_store.py` & `pylint-3.0.0a6/pylint/message/message_definition_store.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import collections
 import functools
+import sys
 from collections.abc import Sequence, ValuesView
 from typing import TYPE_CHECKING
 
 from pylint.exceptions import UnknownMessageError
 from pylint.message.message_definition import MessageDefinition
 from pylint.message.message_id_store import MessageIdStore
 
@@ -19,22 +20,25 @@
 
 class MessageDefinitionStore:
 
     """The messages store knows information about every possible message definition but
     has no particular state during analysis.
     """
 
-    def __init__(self) -> None:
+    def __init__(
+        self, py_version: tuple[int, ...] | sys._version_info = sys.version_info
+    ) -> None:
         self.message_id_store: MessageIdStore = MessageIdStore()
         # Primary registry for all active messages definitions.
         # It contains the 1:1 mapping from msgid to MessageDefinition.
         # Keys are msgid, values are MessageDefinition
         self._messages_definitions: dict[str, MessageDefinition] = {}
         # MessageDefinition kept by category
         self._msgs_by_category: dict[str, list[str]] = collections.defaultdict(list)
+        self.py_version = py_version
 
     @property
     def messages(self) -> ValuesView[MessageDefinition]:
         """The list of all active messages."""
         return self._messages_definitions.values()
 
     def register_messages_from_checker(self, checker: BaseChecker) -> None:
@@ -48,18 +52,20 @@
         self.message_id_store.register_message_definition(
             message.msgid, message.symbol, message.old_names
         )
         self._messages_definitions[message.msgid] = message
         self._msgs_by_category[message.msgid[0]].append(message.msgid)
 
     # Since MessageDefinitionStore is only initialized once
-    # and the arguments are relatively small in size we do not run the
+    # and the arguments are relatively small we do not run the
     # risk of creating a large memory leak.
-    # See discussion in: https://github.com/PyCQA/pylint/pull/5673
-    @functools.lru_cache(maxsize=None)  # pylint: disable=method-cache-max-size-none
+    # See discussion in: https://github.com/pylint-dev/pylint/pull/5673
+    @functools.lru_cache(  # pylint: disable=method-cache-max-size-none # noqa: B019
+        maxsize=None
+    )
     def get_message_definitions(self, msgid_or_symbol: str) -> list[MessageDefinition]:
         """Returns the Message definition for either a numeric or symbolic id.
 
         The cache has no limit as its size will likely stay minimal. For each message we store
         about 1000 characters, so even if we would have 1000 messages the cache would only
         take up ~= 1 Mb.
         """
@@ -104,12 +110,12 @@
         self,
     ) -> tuple[list[MessageDefinition], list[MessageDefinition]]:
         """Finds all emittable and non-emittable messages."""
         messages = sorted(self._messages_definitions.values(), key=lambda m: m.msgid)
         emittable = []
         non_emittable = []
         for message in messages:
-            if message.may_be_emitted():
+            if message.may_be_emitted(self.py_version):
                 emittable.append(message)
             else:
                 non_emittable.append(message)
         return emittable, non_emittable
```

### Comparing `pylint-3.0.0a5/pylint/message/message_id_store.py` & `pylint-3.0.0a6/pylint/message/message_id_store.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,16 +1,27 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import NoReturn
 
-from pylint.exceptions import InvalidMessageError, UnknownMessageError
+from pylint.exceptions import (
+    DeletedMessageError,
+    InvalidMessageError,
+    MessageBecameExtensionError,
+    UnknownMessageError,
+)
+from pylint.message._deleted_message_ids import (
+    is_deleted_msgid,
+    is_deleted_symbol,
+    is_moved_msgid,
+    is_moved_symbol,
+)
 
 
 class MessageIdStore:
 
     """The MessageIdStore store MessageId and make sure that there is a 1-1 relation
     between msgid and symbol.
     """
@@ -118,22 +129,35 @@
         try:
             return self.__active_msgids[msgid_or_symbol]
         except KeyError:
             pass
 
         # If we don't have a cached value yet we compute it
         msgid: str | None
+        deletion_reason = None
+        moved_reason = None
         if msgid_or_symbol[1:].isdigit():
             # Only msgid can have a digit as second letter
             msgid = msgid_or_symbol.upper()
             symbol = self.__msgid_to_symbol.get(msgid)
+            if not symbol:
+                deletion_reason = is_deleted_msgid(msgid)
+                if deletion_reason is None:
+                    moved_reason = is_moved_msgid(msgid)
         else:
-            msgid = self.__symbol_to_msgid.get(msgid_or_symbol)
             symbol = msgid_or_symbol
+            msgid = self.__symbol_to_msgid.get(msgid_or_symbol)
+            if not msgid:
+                deletion_reason = is_deleted_symbol(symbol)
+                if deletion_reason is None:
+                    moved_reason = is_moved_symbol(symbol)
         if not msgid or not symbol:
+            if deletion_reason is not None:
+                raise DeletedMessageError(msgid_or_symbol, deletion_reason)
+            if moved_reason is not None:
+                raise MessageBecameExtensionError(msgid_or_symbol, moved_reason)
             error_msg = f"No such message id or symbol '{msgid_or_symbol}'."
             raise UnknownMessageError(error_msg)
         ids = self.__old_names.get(msgid, [msgid])
-
         # Add to cache
         self.__active_msgids[msgid_or_symbol] = ids
         return ids
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/diadefslib.py` & `pylint-3.0.0a6/pylint/pyreverse/diadefslib.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,22 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Handle diagram generation options for class diagram or default diagrams."""
 
 from __future__ import annotations
 
 import argparse
 from collections.abc import Generator
 from typing import Any
 
 import astroid
 from astroid import nodes
+from astroid.modutils import is_stdlib_module
 
 from pylint.pyreverse.diagrams import ClassDiagram, PackageDiagram
 from pylint.pyreverse.inspector import Linker, Project
 from pylint.pyreverse.utils import LocalsVisitor
 
 # diagram generators ##########################################################
 
@@ -32,15 +33,15 @@
         self.classdiagram: ClassDiagram  # defined by subclasses
 
     def get_title(self, node: nodes.ClassDef) -> str:
         """Get title for objects."""
         title = node.name
         if self.module_names:
             title = f"{node.root().name}.{title}"
-        return title
+        return title  # type: ignore[no-any-return]
 
     def _set_option(self, option: bool | None) -> bool:
         """Activate some options if not explicitly deactivated."""
         # if we have a class diagram, we want more information by default;
         # so if the option is None, we return True
         if option is None:
             return bool(self.config.classes)
@@ -63,18 +64,22 @@
         self.anc_level, self.association_level = anc_level, association_level
 
     def _get_levels(self) -> tuple[int, int]:
         """Help function for search levels."""
         return self.anc_level, self.association_level
 
     def show_node(self, node: nodes.ClassDef) -> bool:
-        """True if builtins and not show_builtins."""
-        if self.config.show_builtin:
-            return True
-        return node.root().name != "builtins"
+        """Determine if node should be shown based on config."""
+        if node.root().name == "builtins":
+            return self.config.show_builtin  # type: ignore[no-any-return]
+
+        if is_stdlib_module(node.root().name):
+            return self.config.show_stdlib  # type: ignore[no-any-return]
+
+        return True
 
     def add_class(self, node: nodes.ClassDef) -> None:
         """Visit one class and add it to diagram."""
         self.linker.visit(node)
         self.classdiagram.add_object(self.get_title(node), node)
 
     def get_ancestors(
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/diagrams.py` & `pylint-3.0.0a6/pylint/pyreverse/diagrams.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Diagram objects."""
 
 from __future__ import annotations
 
 from collections.abc import Iterable
 from typing import Any
 
 import astroid
-from astroid import nodes
+from astroid import nodes, util
 
 from pylint.checkers.utils import decorated_with_property
-from pylint.pyreverse.utils import FilterMixIn, is_interface
+from pylint.pyreverse.utils import FilterMixIn
 
 
 class Figure:
     """Base class for counter handling."""
 
     def __init__(self) -> None:
         self.fig_id: str = ""
@@ -139,15 +139,15 @@
             m
             for m in node.values()
             if isinstance(m, nodes.FunctionDef)
             and not isinstance(m, astroid.objects.Property)
             and not decorated_with_property(m)
             and self.show_attr(m.name)
         ]
-        return sorted(methods, key=lambda n: n.name)
+        return sorted(methods, key=lambda n: n.name)  # type: ignore[no-any-return]
 
     def add_object(self, title: str, node: nodes.ClassDef) -> None:
         """Create a diagram object."""
         assert node not in self._nodes
         ent = ClassEntity(title, node)
         self._nodes[node] = ent
         self.objects.append(ent)
@@ -191,47 +191,50 @@
 
     def extract_relationships(self) -> None:
         """Extract relationships between nodes in the diagram."""
         for obj in self.classes():
             node = obj.node
             obj.attrs = self.get_attrs(node)
             obj.methods = self.get_methods(node)
-            # shape
-            if is_interface(node):
-                obj.shape = "interface"
-            else:
-                obj.shape = "class"
+            obj.shape = "class"
             # inheritance link
             for par_node in node.ancestors(recurs=False):
                 try:
                     par_obj = self.object_from_node(par_node)
                     self.add_relationship(obj, par_obj, "specialization")
                 except KeyError:
                     continue
-            # implements link
-            for impl_node in node.implements:
-                try:
-                    impl_obj = self.object_from_node(impl_node)
-                    self.add_relationship(obj, impl_obj, "implements")
-                except KeyError:
-                    continue
-            # associations link
-            for name, values in list(node.instance_attrs_type.items()) + list(
+
+            # associations & aggregations links
+            for name, values in list(node.aggregations_type.items()):
+                for value in values:
+                    self.assign_association_relationship(
+                        value, obj, name, "aggregation"
+                    )
+
+            for name, values in list(node.associations_type.items()) + list(
                 node.locals_type.items()
             ):
                 for value in values:
-                    if value is astroid.Uninferable:
-                        continue
-                    if isinstance(value, astroid.Instance):
-                        value = value._proxied
-                    try:
-                        associated_obj = self.object_from_node(value)
-                        self.add_relationship(associated_obj, obj, "association", name)
-                    except KeyError:
-                        continue
+                    self.assign_association_relationship(
+                        value, obj, name, "association"
+                    )
+
+    def assign_association_relationship(
+        self, value: astroid.NodeNG, obj: ClassEntity, name: str, type_relationship: str
+    ) -> None:
+        if isinstance(value, util.UninferableBase):
+            return
+        if isinstance(value, astroid.Instance):
+            value = value._proxied
+        try:
+            associated_obj = self.object_from_node(value)
+            self.add_relationship(associated_obj, obj, type_relationship, name)
+        except KeyError:
+            return
 
 
 class PackageDiagram(ClassDiagram):
     """Package diagram handling."""
 
     TYPE = "package"
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/dot_printer.py` & `pylint-3.0.0a6/pylint/pyreverse/dot_printer.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,39 +1,52 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Class to generate files in dot format and image formats supported by Graphviz."""
 
 from __future__ import annotations
 
 import os
 import subprocess
-import sys
 import tempfile
+from enum import Enum
 from pathlib import Path
 
 from astroid import nodes
 
 from pylint.pyreverse.printer import EdgeType, Layout, NodeProperties, NodeType, Printer
 from pylint.pyreverse.utils import get_annotation_label
 
+
+class HTMLLabels(Enum):
+    LINEBREAK_LEFT = '<br ALIGN="LEFT"/>'
+
+
 ALLOWED_CHARSETS: frozenset[str] = frozenset(("utf-8", "iso-8859-1", "latin1"))
 SHAPES: dict[NodeType, str] = {
     NodeType.PACKAGE: "box",
-    NodeType.INTERFACE: "record",
     NodeType.CLASS: "record",
 }
+# pylint: disable-next=consider-using-namedtuple-or-dataclass
 ARROWS: dict[EdgeType, dict[str, str]] = {
-    EdgeType.INHERITS: dict(arrowtail="none", arrowhead="empty"),
-    EdgeType.IMPLEMENTS: dict(arrowtail="node", arrowhead="empty", style="dashed"),
-    EdgeType.ASSOCIATION: dict(
-        fontcolor="green", arrowtail="none", arrowhead="diamond", style="solid"
-    ),
-    EdgeType.USES: dict(arrowtail="none", arrowhead="open"),
+    EdgeType.INHERITS: {"arrowtail": "none", "arrowhead": "empty"},
+    EdgeType.ASSOCIATION: {
+        "fontcolor": "green",
+        "arrowtail": "none",
+        "arrowhead": "diamond",
+        "style": "solid",
+    },
+    EdgeType.AGGREGATION: {
+        "fontcolor": "green",
+        "arrowtail": "none",
+        "arrowhead": "odiamond",
+        "style": "solid",
+    },
+    EdgeType.USES: {"arrowtail": "none", "arrowhead": "open"},
 }
 
 
 class DotPrinter(Printer):
     DEFAULT_COLOR = "black"
 
     def __init__(
@@ -69,15 +82,15 @@
         """
         if properties is None:
             properties = NodeProperties(label=name)
         shape = SHAPES[type_]
         color = properties.color if properties.color is not None else self.DEFAULT_COLOR
         style = "filled" if color != self.DEFAULT_COLOR else "solid"
         label = self._build_label_for_node(properties)
-        label_part = f', label="{label}"' if label else ""
+        label_part = f", label=<{label}>" if label else ""
         fontcolor_part = (
             f', fontcolor="{properties.fontcolor}"' if properties.fontcolor else ""
         )
         self.emit(
             f'"{name}" [color="{color}"{fontcolor_part}{label_part}, shape="{shape}", style="{style}"];'
         )
 
@@ -88,25 +101,30 @@
         label: str = properties.label
         if properties.attrs is None and properties.methods is None:
             # return a "compact" form which only displays the class name in a box
             return label
 
         # Add class attributes
         attrs: list[str] = properties.attrs or []
-        attrs_string = r"\l".join(attr.replace("|", r"\|") for attr in attrs)
-        label = rf"{{{label}|{attrs_string}\l|"
+        attrs_string = rf"{HTMLLabels.LINEBREAK_LEFT.value}".join(
+            attr.replace("|", r"\|") for attr in attrs
+        )
+        label = rf"{{{label}|{attrs_string}{HTMLLabels.LINEBREAK_LEFT.value}|"
 
         # Add class methods
         methods: list[nodes.FunctionDef] = properties.methods or []
         for func in methods:
             args = self._get_method_arguments(func)
-            label += rf"{func.name}({', '.join(args)})"
+            method_name = (
+                f"<I>{func.name}</I>" if func.is_abstract() else f"{func.name}"
+            )
+            label += rf"{method_name}({', '.join(args)})"
             if func.returns:
                 label += ": " + get_annotation_label(func.returns)
-            label += r"\l"
+            label += rf"{HTMLLabels.LINEBREAK_LEFT.value}"
         label += "}"
         return label
 
     def emit_edge(
         self,
         from_node: str,
         to_node: str,
@@ -139,17 +157,15 @@
                 pdot, dot_sourcepath = tempfile.mkstemp(".gv", name)
                 os.close(pdot)
             else:
                 dot_sourcepath = outputfile
         with open(dot_sourcepath, "w", encoding="utf8") as outfile:
             outfile.writelines(self.lines)
         if target not in graphviz_extensions:
-            use_shell = sys.platform == "win32"
-            subprocess.call(
-                ["dot", "-T", target, dot_sourcepath, "-o", outputfile],
-                shell=use_shell,
+            subprocess.run(
+                ["dot", "-T", target, dot_sourcepath, "-o", outputfile], check=True
             )
             os.unlink(dot_sourcepath)
 
     def _close_graph(self) -> None:
         """Emit the lines needed to properly close the graph."""
         self.emit("}\n")
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/inspector.py` & `pylint-3.0.0a6/pylint/pyreverse/inspector.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,24 +1,23 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Visitor doing some post-processing on the astroid tree.
 
 Try to resolve definitions (namespace) dictionary, relationship...
 """
 
 from __future__ import annotations
 
 import collections
 import os
 import traceback
-import warnings
-from collections.abc import Generator
-from typing import Any, Callable, Optional
+from abc import ABC, abstractmethod
+from typing import Callable, Optional
 
 import astroid
 from astroid import nodes
 
 from pylint import constants
 from pylint.pyreverse import utils
 
@@ -34,35 +33,14 @@
     except astroid.exceptions.AstroidBuildingException as exc:
         print(exc)
     except Exception:  # pylint: disable=broad-except
         traceback.print_exc()
     return None
 
 
-def interfaces(node: nodes.ClassDef) -> Generator[Any, None, None]:
-    """Return an iterator on interfaces implemented by the given class node."""
-    try:
-        implements = astroid.bases.Instance(node).getattr("__implements__")[0]
-    except astroid.exceptions.NotFoundError:
-        return
-    if implements.frame(future=True) is not node:
-        return
-    found = set()
-    missing = False
-    for iface in nodes.unpack_infer(implements):
-        if iface is astroid.Uninferable:
-            missing = True
-            continue
-        if iface not in found:
-            found.add(iface)
-            yield iface
-    if missing:
-        raise astroid.exceptions.InferenceError()
-
-
 class IdGeneratorMixIn:
     """Mixin adding the ability to generate integer uid."""
 
     def __init__(self, start_value: int = 0) -> None:
         self.id_count = start_value
 
     def init_counter(self, start_value: int = 0) -> None:
@@ -119,25 +97,30 @@
       a mapping from locals names to their bounded value, which may be a
       constant like a string or an integer, or an astroid node
       (on astroid.Module, astroid.Class and astroid.Function).
 
     * instance_attrs_type
       as locals_type but for klass member attributes (only on astroid.Class)
 
-    * implements,
-      list of implemented interface _objects_ (only on astroid.Class nodes)
+    * associations_type
+      as instance_attrs_type but for association relationships
+
+    * aggregations_type
+      as instance_attrs_type but for aggregations relationships
     """
 
     def __init__(self, project: Project, tag: bool = False) -> None:
         IdGeneratorMixIn.__init__(self)
         utils.LocalsVisitor.__init__(self)
         # tag nodes or not
         self.tag = tag
         # visited project
         self.project = project
+        self.associations_handler = AggregationsHandler()
+        self.associations_handler.set_next(OtherAssociationsHandler())
 
     def visit_project(self, node: Project) -> None:
         """Visit a pyreverse.utils.Project node.
 
         * optionally tag the node with a unique id
         """
         if self.tag:
@@ -159,49 +142,35 @@
         if self.tag:
             node.uid = self.generate_id()
 
     def visit_classdef(self, node: nodes.ClassDef) -> None:
         """Visit an astroid.Class node.
 
         * set the locals_type and instance_attrs_type mappings
-        * set the implements list and build it
         * optionally tag the node with a unique id
         """
         if hasattr(node, "locals_type"):
             return
         node.locals_type = collections.defaultdict(list)
         if self.tag:
             node.uid = self.generate_id()
         # resolve ancestors
         for baseobj in node.ancestors(recurs=False):
             specializations = getattr(baseobj, "specializations", [])
             specializations.append(node)
             baseobj.specializations = specializations
         # resolve instance attributes
         node.instance_attrs_type = collections.defaultdict(list)
+        node.aggregations_type = collections.defaultdict(list)
+        node.associations_type = collections.defaultdict(list)
         for assignattrs in tuple(node.instance_attrs.values()):
             for assignattr in assignattrs:
                 if not isinstance(assignattr, nodes.Unknown):
+                    self.associations_handler.handle(assignattr, node)
                     self.handle_assignattr_type(assignattr, node)
-        # resolve implemented interface
-        try:
-            ifaces = interfaces(node)
-            if ifaces is not None:
-                node.implements = list(ifaces)
-                # TODO: 3.0: Remove support for __implements__
-                warnings.warn(
-                    "pyreverse will drop support for resolving and displaying implemented interfaces in pylint 3.0. "
-                    "The implementation relies on the '__implements__'  attribute proposed in PEP 245, which was rejected "
-                    "in 2006.",
-                    DeprecationWarning,
-                )
-            else:
-                node.implements = []
-        except astroid.InferenceError:
-            node.implements = []
 
     def visit_functiondef(self, node: nodes.FunctionDef) -> None:
         """Visit an astroid.Function node.
 
         * set the locals_type mapping
         * optionally tag the node with a unique id
         """
@@ -282,22 +251,22 @@
                 try:
                     fullname = astroid.modutils.get_module_part(fullname, context_file)
                 except ImportError:
                     continue
             if fullname != basename:
                 self._imported_module(node, fullname, relative)
 
-    def compute_module(self, context_name: str, mod_path: str) -> int:
-        """Return true if the module should be added to dependencies."""
+    def compute_module(self, context_name: str, mod_path: str) -> bool:
+        """Should the module be added to dependencies ?"""
         package_dir = os.path.dirname(self.project.path)
         if context_name == mod_path:
-            return 0
-        if astroid.modutils.is_standard_module(mod_path, (package_dir,)):
-            return 1
-        return 0
+            return False
+        # astroid does return a boolean but is not typed correctly yet
+
+        return astroid.modutils.module_in_path(mod_path, (package_dir,))  # type: ignore[no-any-return]
 
     def _imported_module(
         self, node: nodes.Import | nodes.ImportFrom, mod_path: str, relative: bool
     ) -> None:
         """Notify an imported module, used to analyze dependencies."""
         module = node.root()
         context_name = module.name
@@ -308,14 +277,71 @@
             if not hasattr(module, "depends"):
                 module.depends = []
             mod_paths = module.depends
             if mod_path not in mod_paths:
                 mod_paths.append(mod_path)
 
 
+class AssociationHandlerInterface(ABC):
+    @abstractmethod
+    def set_next(
+        self, handler: AssociationHandlerInterface
+    ) -> AssociationHandlerInterface:
+        pass
+
+    @abstractmethod
+    def handle(self, node: nodes.AssignAttr, parent: nodes.ClassDef) -> None:
+        pass
+
+
+class AbstractAssociationHandler(AssociationHandlerInterface):
+    """
+    Chain of Responsibility for handling types of association, useful
+    to expand in the future if we want to add more distinct associations.
+
+    Every link of the chain checks if it's a certain type of association.
+    If no association is found it's set as a generic association in `associations_type`.
+
+    The default chaining behavior is implemented inside the base handler
+    class.
+    """
+
+    _next_handler: AssociationHandlerInterface
+
+    def set_next(
+        self, handler: AssociationHandlerInterface
+    ) -> AssociationHandlerInterface:
+        self._next_handler = handler
+        return handler
+
+    @abstractmethod
+    def handle(self, node: nodes.AssignAttr, parent: nodes.ClassDef) -> None:
+        if self._next_handler:
+            self._next_handler.handle(node, parent)
+
+
+class AggregationsHandler(AbstractAssociationHandler):
+    def handle(self, node: nodes.AssignAttr, parent: nodes.ClassDef) -> None:
+        if isinstance(node.parent, (nodes.AnnAssign, nodes.Assign)) and isinstance(
+            node.parent.value, astroid.node_classes.Name
+        ):
+            current = set(parent.aggregations_type[node.attrname])
+            parent.aggregations_type[node.attrname] = list(
+                current | utils.infer_node(node)
+            )
+        else:
+            super().handle(node, parent)
+
+
+class OtherAssociationsHandler(AbstractAssociationHandler):
+    def handle(self, node: nodes.AssignAttr, parent: nodes.ClassDef) -> None:
+        current = set(parent.associations_type[node.attrname])
+        parent.associations_type[node.attrname] = list(current | utils.infer_node(node))
+
+
 def project_from_files(
     files: list[str],
     func_wrapper: _WrapperFuncT = _astroid_wrapper,
     project_name: str = "no name",
     black_list: tuple[str, ...] = constants.DEFAULT_IGNORE_LIST,
 ) -> Project:
     """Return a Project from a list of files or modules."""
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/main.py` & `pylint-3.0.0a6/pylint/pyreverse/main.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,243 +1,298 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Create UML diagrams for classes and modules in <packages>."""
 
 from __future__ import annotations
 
 import sys
 from collections.abc import Sequence
 from typing import NoReturn
 
 from pylint import constants
 from pylint.config.arguments_manager import _ArgumentsManager
 from pylint.config.arguments_provider import _ArgumentsProvider
-from pylint.lint.utils import fix_import_path
+from pylint.lint import discover_package_path
+from pylint.lint.utils import augmented_sys_path
 from pylint.pyreverse import writer
 from pylint.pyreverse.diadefslib import DiadefsHandler
 from pylint.pyreverse.inspector import Linker, project_from_files
 from pylint.pyreverse.utils import (
     check_graphviz_availability,
     check_if_graphviz_supports_format,
     insert_default_options,
 )
 from pylint.typing import Options
 
 DIRECTLY_SUPPORTED_FORMATS = (
     "dot",
-    "vcg",
     "puml",
     "plantuml",
     "mmd",
     "html",
 )
 
+DEFAULT_COLOR_PALETTE = (
+    # colorblind scheme taken from https://personal.sron.nl/~pault/
+    "#77AADD",  # light blue
+    "#99DDFF",  # light cyan
+    "#44BB99",  # mint
+    "#BBCC33",  # pear
+    "#AAAA00",  # olive
+    "#EEDD88",  # light yellow
+    "#EE8866",  # orange
+    "#FFAABB",  # pink
+    "#DDDDDD",  # pale grey
+)
+
 OPTIONS: Options = (
     (
         "filter-mode",
-        dict(
-            short="f",
-            default="PUB_ONLY",
-            dest="mode",
-            type="string",
-            action="store",
-            metavar="<mode>",
-            help="""filter attributes and functions according to
+        {
+            "short": "f",
+            "default": "PUB_ONLY",
+            "dest": "mode",
+            "type": "string",
+            "action": "store",
+            "metavar": "<mode>",
+            "help": """filter attributes and functions according to
     <mode>. Correct modes are :
                             'PUB_ONLY' filter all non public attributes
                                 [DEFAULT], equivalent to PRIVATE+SPECIAL_A
                             'ALL' no filter
                             'SPECIAL' filter Python special functions
                                 except constructor
                             'OTHER' filter protected and private
                                 attributes""",
-        ),
+        },
     ),
     (
         "class",
-        dict(
-            short="c",
-            action="extend",
-            metavar="<class>",
-            type="csv",
-            dest="classes",
-            default=None,
-            help="create a class diagram with all classes related to <class>;\
+        {
+            "short": "c",
+            "action": "extend",
+            "metavar": "<class>",
+            "type": "csv",
+            "dest": "classes",
+            "default": None,
+            "help": "create a class diagram with all classes related to <class>;\
  this uses by default the options -ASmy",
-        ),
+        },
     ),
     (
         "show-ancestors",
-        dict(
-            short="a",
-            action="store",
-            metavar="<ancestor>",
-            type="int",
-            default=None,
-            help="show <ancestor> generations of ancestor classes not in <projects>",
-        ),
+        {
+            "short": "a",
+            "action": "store",
+            "metavar": "<ancestor>",
+            "type": "int",
+            "default": None,
+            "help": "show <ancestor> generations of ancestor classes not in <projects>",
+        },
     ),
     (
         "all-ancestors",
-        dict(
-            short="A",
-            default=None,
-            action="store_true",
-            help="show all ancestors off all classes in <projects>",
-        ),
+        {
+            "short": "A",
+            "default": None,
+            "action": "store_true",
+            "help": "show all ancestors off all classes in <projects>",
+        },
     ),
     (
         "show-associated",
-        dict(
-            short="s",
-            action="store",
-            metavar="<association_level>",
-            type="int",
-            default=None,
-            help="show <association_level> levels of associated classes not in <projects>",
-        ),
+        {
+            "short": "s",
+            "action": "store",
+            "metavar": "<association_level>",
+            "type": "int",
+            "default": None,
+            "help": "show <association_level> levels of associated classes not in <projects>",
+        },
     ),
     (
         "all-associated",
-        dict(
-            short="S",
-            default=None,
-            action="store_true",
-            help="show recursively all associated off all associated classes",
-        ),
+        {
+            "short": "S",
+            "default": None,
+            "action": "store_true",
+            "help": "show recursively all associated off all associated classes",
+        },
     ),
     (
         "show-builtin",
-        dict(
-            short="b",
-            action="store_true",
-            default=False,
-            help="include builtin objects in representation of classes",
-        ),
+        {
+            "short": "b",
+            "action": "store_true",
+            "default": False,
+            "help": "include builtin objects in representation of classes",
+        },
+    ),
+    (
+        "show-stdlib",
+        {
+            "short": "L",
+            "action": "store_true",
+            "default": False,
+            "help": "include standard library objects in representation of classes",
+        },
     ),
     (
         "module-names",
-        dict(
-            short="m",
-            default=None,
-            type="yn",
-            metavar="<y or n>",
-            help="include module name in representation of classes",
-        ),
+        {
+            "short": "m",
+            "default": None,
+            "type": "yn",
+            "metavar": "<y or n>",
+            "help": "include module name in representation of classes",
+        },
     ),
     (
         "only-classnames",
-        dict(
-            short="k",
-            action="store_true",
-            default=False,
-            help="don't show attributes and methods in the class boxes; this disables -f values",
-        ),
+        {
+            "short": "k",
+            "action": "store_true",
+            "default": False,
+            "help": "don't show attributes and methods in the class boxes; this disables -f values",
+        },
     ),
     (
         "output",
-        dict(
-            short="o",
-            dest="output_format",
-            action="store",
-            default="dot",
-            metavar="<format>",
-            type="string",
-            help=(
-                f"create a *.<format> output file if format is available. Available formats are: {', '.join(DIRECTLY_SUPPORTED_FORMATS)}. "
-                f"Any other format will be tried to create by means of the 'dot' command line tool, which requires a graphviz installation."
+        {
+            "short": "o",
+            "dest": "output_format",
+            "action": "store",
+            "default": "dot",
+            "metavar": "<format>",
+            "type": "string",
+            "help": (
+                "create a *.<format> output file if format is available. Available "
+                f"formats are: {', '.join(DIRECTLY_SUPPORTED_FORMATS)}. Any other "
+                f"format will be tried to create by means of the 'dot' command line "
+                f"tool, which requires a graphviz installation."
             ),
-        ),
+        },
     ),
     (
         "colorized",
-        dict(
-            dest="colorized",
-            action="store_true",
-            default=False,
-            help="Use colored output. Classes/modules of the same package get the same color.",
-        ),
+        {
+            "dest": "colorized",
+            "action": "store_true",
+            "default": False,
+            "help": "Use colored output. Classes/modules of the same package get the same color.",
+        },
     ),
     (
         "max-color-depth",
-        dict(
-            dest="max_color_depth",
-            action="store",
-            default=2,
-            metavar="<depth>",
-            type="int",
-            help="Use separate colors up to package depth of <depth>",
-        ),
+        {
+            "dest": "max_color_depth",
+            "action": "store",
+            "default": 2,
+            "metavar": "<depth>",
+            "type": "int",
+            "help": "Use separate colors up to package depth of <depth>",
+        },
+    ),
+    (
+        "color-palette",
+        {
+            "dest": "color_palette",
+            "action": "store",
+            "default": DEFAULT_COLOR_PALETTE,
+            "metavar": "<color1,color2,...>",
+            "type": "csv",
+            "help": "Comma separated list of colors to use",
+        },
     ),
     (
         "ignore",
-        dict(
-            type="csv",
-            metavar="<file[,file...]>",
-            dest="ignore_list",
-            default=constants.DEFAULT_IGNORE_LIST,
-            help="Files or directories to be skipped. They should be base names, not paths.",
-        ),
+        {
+            "type": "csv",
+            "metavar": "<file[,file...]>",
+            "dest": "ignore_list",
+            "default": constants.DEFAULT_IGNORE_LIST,
+            "help": "Files or directories to be skipped. They should be base names, not paths.",
+        },
     ),
     (
         "project",
-        dict(
-            default="",
-            type="string",
-            short="p",
-            metavar="<project name>",
-            help="set the project name.",
-        ),
+        {
+            "default": "",
+            "type": "string",
+            "short": "p",
+            "metavar": "<project name>",
+            "help": "set the project name.",
+        },
     ),
     (
         "output-directory",
-        dict(
-            default="",
-            type="path",
-            short="d",
-            action="store",
-            metavar="<output_directory>",
-            help="set the output directory path.",
-        ),
+        {
+            "default": "",
+            "type": "path",
+            "short": "d",
+            "action": "store",
+            "metavar": "<output_directory>",
+            "help": "set the output directory path.",
+        },
+    ),
+    (
+        "source-roots",
+        {
+            "type": "glob_paths_csv",
+            "metavar": "<path>[,<path>...]",
+            "default": (),
+            "help": "Add paths to the list of the source roots. Supports globbing patterns. The "
+            "source root is an absolute path or a path relative to the current working directory "
+            "used to determine a package namespace for modules located under the source root.",
+        },
     ),
 )
 
 
 class Run(_ArgumentsManager, _ArgumentsProvider):
     """Base class providing common behaviour for pyreverse commands."""
 
     options = OPTIONS
     name = "pyreverse"
 
-    # For mypy issue, see https://github.com/python/mypy/issues/10342
-    def __init__(self, args: Sequence[str]) -> NoReturn:  # type: ignore[misc]
+    def __init__(self, args: Sequence[str]) -> NoReturn:
+        # Immediately exit if user asks for version
+        if "--version" in args:
+            print("pyreverse is included in pylint:")
+            print(constants.full_version)
+            sys.exit(0)
+
         _ArgumentsManager.__init__(self, prog="pyreverse", description=__doc__)
         _ArgumentsProvider.__init__(self, self)
 
         # Parse options
         insert_default_options()
         args = self._parse_command_line_configuration(args)
 
         if self.config.output_format not in DIRECTLY_SUPPORTED_FORMATS:
             check_graphviz_availability()
             print(
-                f"Format {self.config.output_format} is not supported natively. Pyreverse will try to generate it using Graphviz..."
+                f"Format {self.config.output_format} is not supported natively."
+                " Pyreverse will try to generate it using Graphviz..."
             )
             check_if_graphviz_supports_format(self.config.output_format)
 
         sys.exit(self.run(args))
 
     def run(self, args: list[str]) -> int:
         """Checking arguments and run project."""
         if not args:
             print(self.help())
             return 1
-        with fix_import_path(args):
+        extra_packages_paths = list(
+            {discover_package_path(arg, self.config.source_roots) for arg in args}
+        )
+        with augmented_sys_path(extra_packages_paths):
             project = project_from_files(
                 args,
                 project_name=self.config.project,
                 black_list=self.config.ignore_list,
             )
             linker = Linker(project, tag=True)
             handler = DiadefsHandler(self.config)
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/mermaidjs_printer.py` & `pylint-3.0.0a6/pylint/pyreverse/mermaidjs_printer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Class to generate files in mermaidjs format."""
 
 from __future__ import annotations
 
 from pylint.pyreverse.printer import EdgeType, NodeProperties, NodeType, Printer
 from pylint.pyreverse.utils import get_annotation_label
@@ -13,21 +13,20 @@
 class MermaidJSPrinter(Printer):
     """Printer for MermaidJS diagrams."""
 
     DEFAULT_COLOR = "black"
 
     NODES: dict[NodeType, str] = {
         NodeType.CLASS: "class",
-        NodeType.INTERFACE: "class",
         NodeType.PACKAGE: "class",
     }
     ARROWS: dict[EdgeType, str] = {
         EdgeType.INHERITS: "--|>",
-        EdgeType.IMPLEMENTS: "..|>",
         EdgeType.ASSOCIATION: "--*",
+        EdgeType.AGGREGATION: "--o",
         EdgeType.USES: "-->",
     }
 
     def _open_graph(self) -> None:
         """Emit the header lines."""
         self.emit("classDiagram")
         self._inc_indent()
@@ -41,28 +40,28 @@
         """Create a new node.
 
         Nodes can be classes, packages, participants etc.
         """
         # pylint: disable=duplicate-code
         if properties is None:
             properties = NodeProperties(label=name)
-        stereotype = "~~Interface~~" if type_ is NodeType.INTERFACE else ""
         nodetype = self.NODES[type_]
         body = []
         if properties.attrs:
             body.extend(properties.attrs)
         if properties.methods:
             for func in properties.methods:
                 args = self._get_method_arguments(func)
                 line = f"{func.name}({', '.join(args)})"
+                line += "*" if func.is_abstract() else ""
                 if func.returns:
                     line += f" {get_annotation_label(func.returns)}"
                 body.append(line)
         name = name.split(".")[-1]
-        self.emit(f"{nodetype} {name}{stereotype} {{")
+        self.emit(f"{nodetype} {name} {{")
         self._inc_indent()
         for line in body:
             self.emit(line)
         self._dec_indent()
         self.emit("}")
 
     def emit_edge(
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/plantuml_printer.py` & `pylint-3.0.0a6/pylint/pyreverse/plantuml_printer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Class to generate files in dot format and image formats supported by Graphviz."""
 
 from __future__ import annotations
 
 from pylint.pyreverse.printer import EdgeType, Layout, NodeProperties, NodeType, Printer
 from pylint.pyreverse.utils import get_annotation_label
@@ -13,21 +13,20 @@
 class PlantUmlPrinter(Printer):
     """Printer for PlantUML diagrams."""
 
     DEFAULT_COLOR = "black"
 
     NODES: dict[NodeType, str] = {
         NodeType.CLASS: "class",
-        NodeType.INTERFACE: "class",
         NodeType.PACKAGE: "package",
     }
     ARROWS: dict[EdgeType, str] = {
         EdgeType.INHERITS: "--|>",
-        EdgeType.IMPLEMENTS: "..|>",
         EdgeType.ASSOCIATION: "--*",
+        EdgeType.AGGREGATION: "--o",
         EdgeType.USES: "-->",
     }
 
     def _open_graph(self) -> None:
         """Emit the header lines."""
         self.emit("@startuml " + self.title)
         if not self.use_automatic_namespace:
@@ -35,49 +34,50 @@
         if self.layout:
             if self.layout is Layout.LEFT_TO_RIGHT:
                 self.emit("left to right direction")
             elif self.layout is Layout.TOP_TO_BOTTOM:
                 self.emit("top to bottom direction")
             else:
                 raise ValueError(
-                    f"Unsupported layout {self.layout}. PlantUmlPrinter only supports left to right and top to bottom layout."
+                    f"Unsupported layout {self.layout}. PlantUmlPrinter only "
+                    "supports left to right and top to bottom layout."
                 )
 
     def emit_node(
         self,
         name: str,
         type_: NodeType,
         properties: NodeProperties | None = None,
     ) -> None:
         """Create a new node.
 
         Nodes can be classes, packages, participants etc.
         """
         if properties is None:
             properties = NodeProperties(label=name)
-        stereotype = " << interface >>" if type_ is NodeType.INTERFACE else ""
         nodetype = self.NODES[type_]
         if properties.color and properties.color != self.DEFAULT_COLOR:
-            color = f" #{properties.color}"
+            color = f" #{properties.color.lstrip('#')}"
         else:
             color = ""
         body = []
         if properties.attrs:
             body.extend(properties.attrs)
         if properties.methods:
             for func in properties.methods:
                 args = self._get_method_arguments(func)
-                line = f"{func.name}({', '.join(args)})"
+                line = "{abstract}" if func.is_abstract() else ""
+                line += f"{func.name}({', '.join(args)})"
                 if func.returns:
                     line += " -> " + get_annotation_label(func.returns)
                 body.append(line)
         label = properties.label if properties.label is not None else name
         if properties.fontcolor and properties.fontcolor != self.DEFAULT_COLOR:
             label = f"<color:{properties.fontcolor}>{label}</color>"
-        self.emit(f'{nodetype} "{label}" as {name}{stereotype}{color} {{')
+        self.emit(f'{nodetype} "{label}" as {name}{color} {{')
         self._inc_indent()
         for line in body:
             self.emit(line)
         self._dec_indent()
         self.emit("}")
 
     def emit_edge(
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/printer.py` & `pylint-3.0.0a6/pylint/pyreverse/printer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Base class defining the interface for a printer."""
 
 from __future__ import annotations
 
 from abc import ABC, abstractmethod
 from enum import Enum
@@ -13,22 +13,21 @@
 from astroid import nodes
 
 from pylint.pyreverse.utils import get_annotation_label
 
 
 class NodeType(Enum):
     CLASS = "class"
-    INTERFACE = "interface"
     PACKAGE = "package"
 
 
 class EdgeType(Enum):
     INHERITS = "inherits"
-    IMPLEMENTS = "implements"
     ASSOCIATION = "association"
+    AGGREGATION = "aggregation"
     USES = "uses"
 
 
 class Layout(Enum):
     LEFT_TO_RIGHT = "LR"
     RIGHT_TO_LEFT = "RL"
     TOP_TO_BOTTOM = "TB"
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/printer_factory.py` & `pylint-3.0.0a6/pylint/pyreverse/printer_factory.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,21 +1,19 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from pylint.pyreverse.dot_printer import DotPrinter
 from pylint.pyreverse.mermaidjs_printer import HTMLMermaidJSPrinter, MermaidJSPrinter
 from pylint.pyreverse.plantuml_printer import PlantUmlPrinter
 from pylint.pyreverse.printer import Printer
-from pylint.pyreverse.vcg_printer import VCGPrinter
 
 filetype_to_printer: dict[str, type[Printer]] = {
-    "vcg": VCGPrinter,
     "plantuml": PlantUmlPrinter,
     "puml": PlantUmlPrinter,
     "mmd": MermaidJSPrinter,
     "html": HTMLMermaidJSPrinter,
     "dot": DotPrinter,
 }
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/utils.py` & `pylint-3.0.0a6/pylint/pyreverse/utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,25 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Generic classes/functions for pyreverse core/extensions."""
 
 from __future__ import annotations
 
 import os
 import re
 import shutil
 import subprocess
 import sys
 from typing import TYPE_CHECKING, Any, Callable, Optional, Tuple, Union
 
 import astroid
 from astroid import nodes
+from astroid.typing import InferenceResult
 
 if TYPE_CHECKING:
     from pylint.pyreverse.diagrams import ClassDiagram, PackageDiagram
 
     _CallbackT = Callable[
         [nodes.NodeNG],
         Union[Tuple[ClassDiagram], Tuple[PackageDiagram, ClassDiagram], None],
@@ -67,22 +68,17 @@
         visibility = "protected"
 
     else:
         visibility = "public"
     return visibility
 
 
-def is_interface(node: nodes.ClassDef) -> bool:
-    # bw compatibility
-    return node.type == "interface"
-
-
 def is_exception(node: nodes.ClassDef) -> bool:
     # bw compatibility
-    return node.type == "exception"
+    return node.type == "exception"  # type: ignore[no-any-return]
 
 
 # Helpers #####################################################################
 
 _SPECIAL = 2
 _PROTECTED = 4
 _PRIVATE = 8
@@ -165,17 +161,17 @@
         if methods[1] is not None:
             return methods[1](node)
         return None
 
 
 def get_annotation_label(ann: nodes.Name | nodes.NodeNG) -> str:
     if isinstance(ann, nodes.Name) and ann.name is not None:
-        return ann.name
+        return ann.name  # type: ignore[no-any-return]
     if isinstance(ann, nodes.NodeNG):
-        return ann.as_string()
+        return ann.as_string()  # type: ignore[no-any-return]
     return ""
 
 
 def get_annotation(
     node: nodes.AssignAttr | nodes.AssignName,
 ) -> nodes.Name | nodes.Subscript | None:
     """Return the annotation for `node`."""
@@ -206,15 +202,15 @@
             else label
         )
     if label:
         ann.name = label
     return ann
 
 
-def infer_node(node: nodes.AssignAttr | nodes.AssignName) -> set[Any]:
+def infer_node(node: nodes.AssignAttr | nodes.AssignName) -> set[InferenceResult]:
     """Return a set containing the node annotation if it exists
     otherwise return a set of the inferred types using the NodeNG.infer method.
     """
 
     ann = get_annotation(node)
     try:
         if ann:
```

### Comparing `pylint-3.0.0a5/pylint/pyreverse/writer.py` & `pylint-3.0.0a6/pylint/pyreverse/writer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
-"""Utilities for creating VCG and Dot diagrams."""
+"""Utilities for creating diagrams."""
 
 from __future__ import annotations
 
 import argparse
 import itertools
 import os
 from collections.abc import Iterable
@@ -30,35 +30,16 @@
 
     def __init__(self, config: argparse.Namespace) -> None:
         self.config = config
         self.printer_class = get_printer_for_filetype(self.config.output_format)
         self.printer: Printer  # defined in set_printer
         self.file_name = ""  # defined in set_printer
         self.depth = self.config.max_color_depth
-        self.available_colors = itertools.cycle(
-            [
-                "aliceblue",
-                "antiquewhite",
-                "aquamarine",
-                "burlywood",
-                "cadetblue",
-                "chartreuse",
-                "chocolate",
-                "coral",
-                "cornflowerblue",
-                "cyan",
-                "darkgoldenrod",
-                "darkseagreen",
-                "dodgerblue",
-                "forestgreen",
-                "gold",
-                "hotpink",
-                "mediumspringgreen",
-            ]
-        )
+        # default colors are an adaption of the seaborn colorblind palette
+        self.available_colors = itertools.cycle(self.config.color_palette)
         self.used_colors: dict[str, str] = {}
 
     def write(self, diadefs: Iterable[ClassDiagram | PackageDiagram]) -> None:
         """Write files for <project> according to <diadefs>."""
         for diagram in diadefs:
             basename = diagram.title.strip().replace(" ", "_")
             file_name = f"{basename}.{self.config.output_format}"
@@ -88,41 +69,43 @@
                 rel.to_object.fig_id,
                 type_=EdgeType.USES,
             )
 
     def write_classes(self, diagram: ClassDiagram) -> None:
         """Write a class diagram."""
         # sorted to get predictable (hence testable) results
-        for obj in sorted(diagram.objects, key=lambda x: x.title):
+        for obj in sorted(diagram.objects, key=lambda x: x.title):  # type: ignore[no-any-return]
             obj.fig_id = obj.node.qname()
-            type_ = NodeType.INTERFACE if obj.shape == "interface" else NodeType.CLASS
             self.printer.emit_node(
-                obj.fig_id, type_=type_, properties=self.get_class_properties(obj)
+                obj.fig_id,
+                type_=NodeType.CLASS,
+                properties=self.get_class_properties(obj),
             )
         # inheritance links
         for rel in diagram.get_relationships("specialization"):
             self.printer.emit_edge(
                 rel.from_object.fig_id,
                 rel.to_object.fig_id,
                 type_=EdgeType.INHERITS,
             )
-        # implementation links
-        for rel in diagram.get_relationships("implements"):
+        # generate associations
+        for rel in diagram.get_relationships("association"):
             self.printer.emit_edge(
                 rel.from_object.fig_id,
                 rel.to_object.fig_id,
-                type_=EdgeType.IMPLEMENTS,
+                label=rel.name,
+                type_=EdgeType.ASSOCIATION,
             )
-        # generate associations
-        for rel in diagram.get_relationships("association"):
+        # generate aggregations
+        for rel in diagram.get_relationships("aggregation"):
             self.printer.emit_edge(
                 rel.from_object.fig_id,
                 rel.to_object.fig_id,
                 label=rel.name,
-                type_=EdgeType.ASSOCIATION,
+                type_=EdgeType.AGGREGATION,
             )
 
     def set_printer(self, file_name: str, basename: str) -> None:
         """Set printer."""
         self.printer = self.printer_class(basename)
         self.file_name = file_name
 
@@ -143,15 +126,15 @@
             color=self.get_shape_color(obj) if self.config.colorized else "black",
         )
         return properties
 
     def get_shape_color(self, obj: DiagramEntity) -> str:
         """Get shape color."""
         qualified_name = obj.node.qname()
-        if modutils.is_standard_module(qualified_name.split(".", maxsplit=1)[0]):
+        if modutils.is_stdlib_module(qualified_name.split(".", maxsplit=1)[0]):
             return "grey"
         if isinstance(obj.node, nodes.ClassDef):
             package = qualified_name.rsplit(".", maxsplit=2)[0]
         elif obj.node.package:
             package = qualified_name
         else:
             package = qualified_name.rsplit(".", maxsplit=1)[0]
```

### Comparing `pylint-3.0.0a5/pylint/reporters/__init__.py` & `pylint-3.0.0a6/pylint/reporters/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Utilities methods and classes for reporters."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
```

### Comparing `pylint-3.0.0a5/pylint/reporters/base_reporter.py` & `pylint-3.0.0a6/pylint/reporters/base_reporter.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,16 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import os
 import sys
-import warnings
 from typing import TYPE_CHECKING, TextIO
-from warnings import warn
 
 from pylint.message import Message
 from pylint.reporters.ureports.nodes import Text
 from pylint.utils import LinterStats
 
 if TYPE_CHECKING:
     from pylint.lint.pylinter import PyLinter
@@ -27,40 +25,25 @@
 
     extension = ""
 
     name = "base"
     """Name of the reporter."""
 
     def __init__(self, output: TextIO | None = None) -> None:
-        if getattr(self, "__implements__", None):
-            warnings.warn(
-                "Using the __implements__ inheritance pattern for BaseReporter is no "
-                "longer supported. Child classes should only inherit BaseReporter",
-                DeprecationWarning,
-            )
         self.linter: PyLinter
         self.section = 0
         self.out: TextIO = output or sys.stdout
         self.messages: list[Message] = []
         # Build the path prefix to strip to get relative paths
         self.path_strip_prefix = os.getcwd() + os.sep
 
     def handle_message(self, msg: Message) -> None:
         """Handle a new message triggered on the current file."""
         self.messages.append(msg)
 
-    def set_output(self, output: TextIO | None = None) -> None:
-        """Set output stream."""
-        # TODO: 3.0: Remove deprecated method
-        warn(
-            "'set_output' will be removed in 3.0, please use 'reporter.out = stream' instead",
-            DeprecationWarning,
-        )
-        self.out = output or sys.stdout
-
     def writeln(self, string: str = "") -> None:
         """Write a line in the output buffer."""
         print(string, file=self.out)
 
     def display_reports(self, layout: Section) -> None:
         """Display results encapsulated in the layout tree."""
         self.section = 0
```

### Comparing `pylint-3.0.0a5/pylint/reporters/collecting_reporter.py` & `pylint-3.0.0a6/pylint/reporters/collecting_reporter.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from pylint.reporters.base_reporter import BaseReporter
```

### Comparing `pylint-3.0.0a5/pylint/reporters/multi_reporter.py` & `pylint-3.0.0a6/pylint/reporters/multi_reporter.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import os
 from collections.abc import Callable
+from copy import copy
 from typing import TYPE_CHECKING, TextIO
 
 from pylint.message import Message
 from pylint.reporters.base_reporter import BaseReporter
 from pylint.utils import LinterStats
 
 if TYPE_CHECKING:
@@ -73,15 +74,16 @@
         self._linter = value
         for rep in self._sub_reporters:
             rep.linter = value
 
     def handle_message(self, msg: Message) -> None:
         """Handle a new message triggered on the current file."""
         for rep in self._sub_reporters:
-            rep.handle_message(msg)
+            # We provide a copy so reporters can't modify message for others.
+            rep.handle_message(copy(msg))
 
     def writeln(self, string: str = "") -> None:
         """Write a line in the output buffer."""
         for rep in self._sub_reporters:
             rep.writeln(string)
 
     def display_reports(self, layout: Section) -> None:
```

### Comparing `pylint-3.0.0a5/pylint/reporters/reports_handler_mix_in.py` & `pylint-3.0.0a6/pylint/reporters/reports_handler_mix_in.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import collections
 from collections.abc import MutableSequence
 from typing import TYPE_CHECKING, DefaultDict, List, Tuple
```

### Comparing `pylint-3.0.0a5/pylint/reporters/text.py` & `pylint-3.0.0a6/pylint/reporters/text.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,30 +1,29 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Plain text reporters:.
 
 :text: the default one grouping messages by module
 :colorized: an ANSI colorized text reporter
 """
 
 from __future__ import annotations
 
 import os
 import re
 import sys
 import warnings
 from dataclasses import asdict, fields
-from typing import TYPE_CHECKING, Dict, NamedTuple, Optional, TextIO, cast, overload
+from typing import TYPE_CHECKING, Dict, NamedTuple, TextIO
 
 from pylint.message import Message
 from pylint.reporters import BaseReporter
 from pylint.reporters.ureports.text_writer import TextWriter
-from pylint.utils import _splitstrip
 
 if TYPE_CHECKING:
     from pylint.lint import PyLinter
     from pylint.reporters.ureports.nodes import Section
 
 
 class MessageStyle(NamedTuple):
@@ -33,14 +32,42 @@
     color: str | None
     """The color name (see `ANSI_COLORS` for available values)
     or the color number when 256 colors are available.
     """
     style: tuple[str, ...] = ()
     """Tuple of style strings (see `ANSI_COLORS` for available values)."""
 
+    def __get_ansi_code(self) -> str:
+        """Return ANSI escape code corresponding to color and style.
+
+        :raise KeyError: if a nonexistent color or style identifier is given
+
+        :return: the built escape code
+        """
+        ansi_code = [ANSI_STYLES[effect] for effect in self.style]
+        if self.color:
+            if self.color.isdigit():
+                ansi_code.extend(["38", "5"])
+                ansi_code.append(self.color)
+            else:
+                ansi_code.append(ANSI_COLORS[self.color])
+        if ansi_code:
+            return ANSI_PREFIX + ";".join(ansi_code) + ANSI_END
+        return ""
+
+    def _colorize_ansi(self, msg: str) -> str:
+        if self.color is None and len(self.style) == 0:
+            # If both color and style are not defined, then leave the text as is.
+            return msg
+        escape_code = self.__get_ansi_code()
+        # If invalid (or unknown) color, don't wrap msg with ANSI codes
+        if escape_code:
+            return f"{escape_code}{msg}{ANSI_RESET}"
+        return msg
+
 
 ColorMappingDict = Dict[str, MessageStyle]
 
 TITLE_UNDERLINES = ["", "=", "-", "."]
 
 ANSI_PREFIX = "\033["
 ANSI_END = "m"
@@ -66,91 +93,21 @@
     "white": "37",
 }
 
 MESSAGE_FIELDS = {i.name for i in fields(Message)}
 """All fields of the Message class."""
 
 
-def _get_ansi_code(msg_style: MessageStyle) -> str:
-    """Return ANSI escape code corresponding to color and style.
-
-    :param msg_style: the message style
+def colorize_ansi(msg: str, msg_style: MessageStyle) -> str:
+    """Colorize message by wrapping it with ANSI escape codes."""
+    return msg_style._colorize_ansi(msg)
 
-    :raise KeyError: if a nonexistent color or style identifier is given
 
-    :return: the built escape code
-    """
-    ansi_code = [ANSI_STYLES[effect] for effect in msg_style.style]
-    if msg_style.color:
-        if msg_style.color.isdigit():
-            ansi_code.extend(["38", "5"])
-            ansi_code.append(msg_style.color)
-        else:
-            ansi_code.append(ANSI_COLORS[msg_style.color])
-    if ansi_code:
-        return ANSI_PREFIX + ";".join(ansi_code) + ANSI_END
-    return ""
-
-
-@overload
-def colorize_ansi(
-    msg: str,
-    msg_style: MessageStyle | None = ...,
-) -> str:
-    ...
-
-
-@overload
-def colorize_ansi(
-    msg: str,
-    msg_style: str | None = ...,
-    style: str = ...,
-    *,
-    color: str | None = ...,
-) -> str:
-    # Remove for pylint 3.0
-    ...
-
-
-def colorize_ansi(
-    msg: str,
-    msg_style: MessageStyle | str | None = None,
-    style: str = "",
-    **kwargs: str | None,
-) -> str:
-    r"""colorize message by wrapping it with ANSI escape codes
-
-    :param msg: the message string to colorize
-
-    :param msg_style: the message style
-        or color (for backwards compatibility): the color of the message style
-
-    :param style: the message's style elements, this will be deprecated
-
-    :param \**kwargs: used to accept `color` parameter while it is being deprecated
-
-    :return: the ANSI escaped string
-    """
-    # TODO: 3.0: Remove deprecated typing and only accept MessageStyle as parameter
-    if not isinstance(msg_style, MessageStyle):
-        warnings.warn(
-            "In pylint 3.0, the colorize_ansi function of Text reporters will only accept a MessageStyle parameter",
-            DeprecationWarning,
-        )
-        color = kwargs.get("color")
-        style_attrs = tuple(_splitstrip(style))
-        msg_style = MessageStyle(color or msg_style, style_attrs)
-    # If both color and style are not defined, then leave the text as is
-    if msg_style.color is None and len(msg_style.style) == 0:
-        return msg
-    escape_code = _get_ansi_code(msg_style)
-    # If invalid (or unknown) color, don't wrap msg with ANSI codes
-    if escape_code:
-        return f"{escape_code}{msg}{ANSI_RESET}"
-    return msg
+def make_header(msg: Message) -> str:
+    return f"************* Module {msg.module}"
 
 
 class TextReporter(BaseReporter):
     """Reports messages and layouts in plain text."""
 
     name = "text"
     extension = "txt"
@@ -171,20 +128,21 @@
         if template == self._template:
             return
 
         # Set template to the currently selected template
         self._template = template
 
         # Check to see if all parameters in the template are attributes of the Message
-        arguments = re.findall(r"\{(.+?)(:.*)?\}", template)
+        arguments = re.findall(r"\{(\w+?)(:.*)?\}", template)
         for argument in arguments:
             if argument[0] not in MESSAGE_FIELDS:
                 warnings.warn(
                     f"Don't recognize the argument '{argument[0]}' in the --msg-template. "
-                    "Are you sure it is supported on the current version of pylint?"
+                    "Are you sure it is supported on the current version of pylint?",
+                    stacklevel=2,
                 )
                 template = re.sub(r"\{" + argument[0] + r"(:.*?)?\}", "", template)
         self._fixed_template = template
 
     def write_message(self, msg: Message) -> None:
         """Convenience method to write a formatted message with class default
         template.
@@ -194,41 +152,51 @@
             self_dict[key] = self_dict[key] or ""
 
         self.writeln(self._fixed_template.format(**self_dict))
 
     def handle_message(self, msg: Message) -> None:
         """Manage message of different type and in the context of path."""
         if msg.module not in self._modules:
-            if msg.module:
-                self.writeln(f"************* Module {msg.module}")
-                self._modules.add(msg.module)
-            else:
-                self.writeln("************* ")
+            self.writeln(make_header(msg))
+            self._modules.add(msg.module)
         self.write_message(msg)
 
     def _display(self, layout: Section) -> None:
         """Launch layouts display."""
         print(file=self.out)
         TextWriter().format(layout, self.out)
 
 
+class NoHeaderReporter(TextReporter):
+    """Reports messages and layouts in plain text without a module header."""
+
+    name = "no-header"
+
+    def handle_message(self, msg: Message) -> None:
+        """Write message(s) without module header."""
+        if msg.module not in self._modules:
+            self._modules.add(msg.module)
+        self.write_message(msg)
+
+
 class ParseableTextReporter(TextReporter):
     """A reporter very similar to TextReporter, but display messages in a form
     recognized by most text editors :
 
     <filename>:<linenum>:<msg>
     """
 
     name = "parseable"
     line_format = "{path}:{line}: [{msg_id}({symbol}), {obj}] {msg}"
 
     def __init__(self, output: TextIO | None = None) -> None:
         warnings.warn(
             f"{self.name} output format is deprecated. This is equivalent to --msg-template={self.line_format}",
             DeprecationWarning,
+            stacklevel=2,
         )
         super().__init__(output)
 
 
 class VSTextReporter(ParseableTextReporter):
     """Visual studio text reporter."""
 
@@ -249,35 +217,17 @@
         "F": MessageStyle("red", ("bold", "underline")),
         "S": MessageStyle("yellow", ("inverse",)),  # S stands for module Separator
     }
 
     def __init__(
         self,
         output: TextIO | None = None,
-        color_mapping: (
-            ColorMappingDict | dict[str, tuple[str | None, str]] | None
-        ) = None,
+        color_mapping: ColorMappingDict | None = None,
     ) -> None:
         super().__init__(output)
-        # TODO: 3.0: Remove deprecated typing and only accept ColorMappingDict as color_mapping parameter
-        if color_mapping and not isinstance(
-            list(color_mapping.values())[0], MessageStyle
-        ):
-            warnings.warn(
-                "In pylint 3.0, the ColorizedTextReporter will only accept ColorMappingDict as color_mapping parameter",
-                DeprecationWarning,
-            )
-            temp_color_mapping: ColorMappingDict = {}
-            for key, value in color_mapping.items():
-                color = value[0]
-                style_attrs = tuple(_splitstrip(value[1]))  # type: ignore[arg-type]
-                temp_color_mapping[key] = MessageStyle(color, style_attrs)
-            color_mapping = temp_color_mapping
-        else:
-            color_mapping = cast(Optional[ColorMappingDict], color_mapping)
         self.color_mapping = color_mapping or ColorizedTextReporter.COLOR_MAPPING
         ansi_terms = ["xterm-16color", "xterm-256color"]
         if os.environ.get("TERM") not in ansi_terms:
             if sys.platform == "win32":
                 # pylint: disable=import-outside-toplevel
                 import colorama
 
@@ -289,27 +239,25 @@
 
     def handle_message(self, msg: Message) -> None:
         """Manage message of different types, and colorize output
         using ANSI escape codes.
         """
         if msg.module not in self._modules:
             msg_style = self._get_decoration("S")
-            if msg.module:
-                modsep = colorize_ansi(f"************* Module {msg.module}", msg_style)
-            else:
-                modsep = colorize_ansi(f"************* {msg.module}", msg_style)
+            modsep = colorize_ansi(make_header(msg), msg_style)
             self.writeln(modsep)
             self._modules.add(msg.module)
         msg_style = self._get_decoration(msg.C)
 
         msg.msg = colorize_ansi(msg.msg, msg_style)
         msg.symbol = colorize_ansi(msg.symbol, msg_style)
         msg.category = colorize_ansi(msg.category, msg_style)
         msg.C = colorize_ansi(msg.C, msg_style)
         self.write_message(msg)
 
 
 def register(linter: PyLinter) -> None:
     linter.register_reporter(TextReporter)
+    linter.register_reporter(NoHeaderReporter)
     linter.register_reporter(ParseableTextReporter)
     linter.register_reporter(VSTextReporter)
     linter.register_reporter(ColorizedTextReporter)
```

### Comparing `pylint-3.0.0a5/pylint/reporters/ureports/base_writer.py` & `pylint-3.0.0a6/pylint/reporters/ureports/base_writer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Universal report objects and some formatting drivers.
 
 A way to create simple reports using python objects, primarily designed to be
 formatted as text and html.
 """
```

### Comparing `pylint-3.0.0a5/pylint/reporters/ureports/nodes.py` & `pylint-3.0.0a6/pylint/reporters/ureports/nodes.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Micro reports objects.
 
 A micro report is a tree of layout and content objects.
 """
 
 from __future__ import annotations
@@ -68,15 +68,15 @@
         child.parent = self
 
     def parents(self) -> list[BaseLayout]:
         """Return the ancestor nodes."""
         assert self.parent is not self
         if self.parent is None:
             return []
-        return [self.parent] + self.parent.parents()
+        return [self.parent, *self.parent.parents()]
 
     def add_text(self, text: str) -> None:
         """Shortcut to add text data."""
         self.children.append(Text(text))
 
 
 # non container nodes #########################################################
```

### Comparing `pylint-3.0.0a5/pylint/reporters/ureports/text_writer.py` & `pylint-3.0.0a6/pylint/reporters/ureports/text_writer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Text formatting drivers for ureports."""
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
```

### Comparing `pylint-3.0.0a5/pylint/testutils/__init__.py` & `pylint-3.0.0a6/pylint/testutils/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Functional/non regression tests for pylint."""
 
 __all__ = [
     "_get_tests_info",
     "_tokenize_str",
     "CheckerTestCase",
```

### Comparing `pylint-3.0.0a5/pylint/testutils/_run.py` & `pylint-3.0.0a6/pylint/testutils/_run.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,23 +1,21 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Classes and functions used to mimic normal pylint runs.
 
 This module is considered private and can change at any time.
 """
 
 from __future__ import annotations
 
 from collections.abc import Sequence
-from typing import Any
 
 from pylint.lint import Run as LintRun
-from pylint.lint.run import UNUSED_PARAM_SENTINEL
 from pylint.reporters.base_reporter import BaseReporter
 from pylint.testutils.lint_module_test import PYLINTRC
 
 
 def _add_rcfile_default_pylintrc(args: list[str]) -> list[str]:
     """Add a default pylintrc with the rcfile option in a list of pylint args."""
     if not any("--rcfile" in arg for arg in args):
@@ -35,11 +33,10 @@
     """
 
     def __init__(
         self,
         args: Sequence[str],
         reporter: BaseReporter | None = None,
         exit: bool = True,  # pylint: disable=redefined-builtin
-        do_exit: Any = UNUSED_PARAM_SENTINEL,
     ) -> None:
         args = _add_rcfile_default_pylintrc(list(args))
-        super().__init__(args, reporter, exit, do_exit)
+        super().__init__(args, reporter, exit)
```

### Comparing `pylint-3.0.0a5/pylint/testutils/configuration_test.py` & `pylint-3.0.0a6/pylint/testutils/configuration_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Utility functions for configuration testing."""
 
 from __future__ import annotations
 
 import copy
 import json
```

### Comparing `pylint-3.0.0a5/pylint/testutils/constants.py` & `pylint-3.0.0a6/pylint/testutils/constants.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 import operator
 import re
 import sys
 from pathlib import Path
 
 SYS_VERS_STR = (
```

### Comparing `pylint-3.0.0a5/pylint/testutils/decorator.py` & `pylint-3.0.0a6/pylint/testutils/decorator.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import functools
 from collections.abc import Callable
 from typing import Any
```

### Comparing `pylint-3.0.0a5/pylint/testutils/functional/__init__.py` & `pylint-3.0.0a6/pylint/testutils/functional/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 __all__ = [
     "FunctionalTestFile",
     "REASONABLY_DISPLAYABLE_VERTICALLY",
     "get_functional_test_files_from_directory",
     "NoFileError",
     "parse_python_version",
```

### Comparing `pylint-3.0.0a5/pylint/testutils/functional/lint_module_output_update.py` & `pylint-3.0.0a6/pylint/testutils/functional/lint_module_output_update.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import csv
 import os
 
 from _pytest.config import Config
```

### Comparing `pylint-3.0.0a5/pylint/testutils/functional/test_file.py` & `pylint-3.0.0a6/pylint/testutils/functional/test_file.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import configparser
 import sys
 from collections.abc import Callable
 from os.path import basename, exists, join
@@ -58,15 +58,16 @@
         "except_implementations": lambda s: [i.strip() for i in s.split(",")],
         "exclude_platforms": lambda s: [i.strip() for i in s.split(",")],
     }
 
     def __init__(self, directory: str, filename: str) -> None:
         self._directory = directory
         self.base = filename.replace(".py", "")
-        # TODO: 2.15: Deprecate FunctionalTestFile.options and related code
+        # TODO: 3.0: Deprecate FunctionalTestFile.options and related code
+        # We should just parse these options like a normal configuration file.
         self.options: TestFileOptions = {
             "min_pyver": (2, 5),
             "max_pyver": (4, 0),
             "min_pyver_end_position": (3, 8),
             "requires": [],
             "except_implementations": [],
             "exclude_platforms": [],
@@ -86,15 +87,15 @@
             pass
 
         for name, value in cp.items("testoptions"):
             conv = self._CONVERTERS.get(name, lambda v: v)
 
             assert (
                 name in POSSIBLE_TEST_OPTIONS
-            ), f"[testoptions]' can only contains one of {POSSIBLE_TEST_OPTIONS}"
+            ), f"[testoptions]' can only contains one of {POSSIBLE_TEST_OPTIONS} and had '{name}'"
             self.options[name] = conv(value)  # type: ignore[literal-required]
 
     @property
     def option_file(self) -> str:
         return self._file_type(".rc")
 
     @property
```

### Comparing `pylint-3.0.0a5/pylint/testutils/get_test_info.py` & `pylint-3.0.0a6/pylint/testutils/get_test_info.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from glob import glob
 from os.path import basename, join, splitext
 
 from pylint.testutils.constants import SYS_VERS_STR
```

### Comparing `pylint-3.0.0a5/pylint/testutils/global_test_linter.py` & `pylint-3.0.0a6/pylint/testutils/global_test_linter.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from pylint import checkers
 from pylint.lint import PyLinter
 from pylint.testutils.reporter_for_tests import GenericTestReporter
 
 
 def create_test_linter() -> PyLinter:
```

### Comparing `pylint-3.0.0a5/pylint/testutils/lint_module_test.py` & `pylint-3.0.0a6/pylint/testutils/lint_module_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import csv
 import operator
 import platform
 import sys
@@ -19,15 +19,17 @@
 
 from pylint import checkers
 from pylint.config.config_initialization import _config_initialization
 from pylint.constants import IS_PYPY
 from pylint.lint import PyLinter
 from pylint.message.message import Message
 from pylint.testutils.constants import _EXPECTED_RE, _OPERATORS, UPDATE_OPTION
-from pylint.testutils.functional.test_file import (  # need to import from functional.test_file to avoid cyclic import
+
+# need to import from functional.test_file to avoid cyclic import
+from pylint.testutils.functional.test_file import (
     FunctionalTestFile,
     NoFileError,
     parse_python_version,
 )
 from pylint.testutils.output_line import OutputLine
 from pylint.testutils.reporter_for_tests import FunctionalTestReporter
 
@@ -141,15 +143,15 @@
         ):
             pytest.skip("Test excluded from --minimal-messages-config")
 
     def runTest(self) -> None:
         self._runTest()
 
     def _should_be_skipped_due_to_version(self) -> bool:
-        return (
+        return (  # type: ignore[no-any-return]
             sys.version_info < self._linter.config.min_pyver
             or sys.version_info > self._linter.config.max_pyver
         )
 
     def __str__(self) -> str:
         return f"{self._test_file.base} ({self.__class__.__module__}.{self.__class__.__name__})"
 
@@ -260,15 +262,15 @@
 
     def error_msg_for_unequal_messages(
         self,
         actual_messages: MessageCounter,
         expected_messages: MessageCounter,
         actual_output: list[OutputLine],
     ) -> str:
-        msg = [f'Wrong results for file "{self._test_file.base}":']
+        msg = [f'Wrong message(s) raised for "{Path(self._test_file.source).name}":']
         missing, unexpected = self.multiset_difference(
             expected_messages, actual_messages
         )
         if missing:
             msg.append("\nExpected in testdata:")
             msg.extend(f" {msg[0]:3}: {msg[1]}" for msg in sorted(missing))
         if unexpected:
@@ -283,29 +285,35 @@
     def error_msg_for_unequal_output(
         self,
         expected_lines: list[OutputLine],
         received_lines: list[OutputLine],
     ) -> str:
         missing = set(expected_lines) - set(received_lines)
         unexpected = set(received_lines) - set(expected_lines)
-        error_msg = (
-            f"Wrong output for '{self._test_file.base}.txt':\n"
-            "You can update the expected output automatically with: '"
-            f"python tests/test_functional.py {UPDATE_OPTION} -k "
-            f'"test_functional[{self._test_file.base}]"\'\n\n'
-        )
+        error_msg = f'Wrong output for "{Path(self._test_file.expected_output).name}":'
         sort_by_line_number = operator.attrgetter("lineno")
         if missing:
             error_msg += "\n- Missing lines:\n"
             for line in sorted(missing, key=sort_by_line_number):
                 error_msg += f"{line}\n"
         if unexpected:
             error_msg += "\n- Unexpected lines:\n"
             for line in sorted(unexpected, key=sort_by_line_number):
                 error_msg += f"{line}\n"
+            error_msg += (
+                "\nYou can update the expected output automatically with:\n'"
+                f"python tests/test_functional.py {UPDATE_OPTION} -k "
+                f'"test_functional[{self._test_file.base}]"\'\n\n'
+                "Here's the update text in case you can't:\n"
+            )
+            expected_csv = StringIO()
+            writer = csv.writer(expected_csv, dialect="test")
+            for line in sorted(received_lines, key=sort_by_line_number):
+                writer.writerow(line.to_csv())
+            error_msg += expected_csv.getvalue()
         return error_msg
 
     def _check_output_text(
         self,
         _: MessageCounter,
         expected_output: list[OutputLine],
         actual_output: list[OutputLine],
```

### Comparing `pylint-3.0.0a5/pylint/testutils/primer.py` & `pylint-3.0.0a6/pylint/testutils/_primer/package_to_lint.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,25 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import logging
+import sys
 from pathlib import Path
 
-import git
+from git import GitCommandError
+from git.cmd import Git
+from git.repo import Repo
+
+if sys.version_info >= (3, 8):
+    from typing import Literal
+else:
+    from typing_extensions import Literal
 
 PRIMER_DIRECTORY_PATH = Path("tests") / ".pylint_primer_tests"
 
 
 class PackageToLint:
     """Represents data about a package to be tested during primer tests."""
 
@@ -29,34 +37,40 @@
 
     pylint_additional_args: list[str]
     """Arguments to give to pylint."""
 
     pylintrc_relpath: str | None
     """Path relative to project's main directory to the pylintrc if it exists."""
 
+    minimum_python: str | None
+    """Minimum python version supported by the package."""
+
     def __init__(
         self,
         url: str,
         branch: str,
         directories: list[str],
         commit: str | None = None,
         pylint_additional_args: list[str] | None = None,
         pylintrc_relpath: str | None = None,
+        minimum_python: str | None = None,
     ) -> None:
         self.url = url
         self.branch = branch
         self.directories = directories
         self.commit = commit
         self.pylint_additional_args = pylint_additional_args or []
         self.pylintrc_relpath = pylintrc_relpath
+        self.minimum_python = minimum_python
 
     @property
-    def pylintrc(self) -> Path | None:
+    def pylintrc(self) -> Path | Literal[""]:
         if self.pylintrc_relpath is None:
-            return None
+            # Fall back to "" to ensure pylint's own pylintrc is not discovered
+            return ""
         return self.clone_directory / self.pylintrc_relpath
 
     @property
     def clone_directory(self) -> Path:
         """Directory to clone repository into."""
         clone_name = "/".join(self.url.split("/")[-2:]).replace(".git", "")
         return PRIMER_DIRECTORY_PATH / clone_name
@@ -65,49 +79,58 @@
     def paths_to_lint(self) -> list[str]:
         """The paths we need to lint."""
         return [str(self.clone_directory / path) for path in self.directories]
 
     @property
     def pylint_args(self) -> list[str]:
         options: list[str] = []
-        if self.pylintrc is not None:
-            # There is an error if rcfile is given but does not exist
-            options += [f"--rcfile={self.pylintrc}"]
+        # There is an error if rcfile is given but does not exist
+        options += [f"--rcfile={self.pylintrc}"]
         return self.paths_to_lint + options + self.pylint_additional_args
 
     def lazy_clone(self) -> str:  # pragma: no cover
         """Concatenates the target directory and clones the file.
 
         Not expected to be tested as the primer won't work if it doesn't.
         It's tested in the continuous integration primers, only the coverage
         is not calculated on everything. If lazy clone breaks for local use
         we'll probably notice because we'll have a fatal when launching the
         primer locally.
         """
         logging.info("Lazy cloning %s", self.url)
         if not self.clone_directory.exists():
-            options: dict[str, str | int] = {
-                "url": self.url,
-                "to_path": str(self.clone_directory),
-                "branch": self.branch,
-                "depth": 1,
-            }
-            logging.info("Directory does not exists, cloning: %s", options)
-            repo = git.Repo.clone_from(**options)
-            return repo.head.object.hexsha
+            return self._clone_repository()
+        return self._pull_repository()
 
-        remote_sha1_commit = (
-            git.cmd.Git().ls_remote(self.url, self.branch).split("\t")[0]
+    def _clone_repository(self) -> str:
+        options: dict[str, str | int] = {
+            "url": self.url,
+            "to_path": str(self.clone_directory),
+            "branch": self.branch,
+            "depth": 1,
+        }
+        logging.info("Directory does not exists, cloning: %s", options)
+        repo = Repo.clone_from(
+            url=self.url, to_path=self.clone_directory, branch=self.branch, depth=1
         )
-        local_sha1_commit = git.Repo(self.clone_directory).head.object.hexsha
+        return str(repo.head.object.hexsha)
+
+    def _pull_repository(self) -> str:
+        remote_sha1_commit = Git().ls_remote(self.url, self.branch).split("\t")[0]
+        local_sha1_commit = Repo(self.clone_directory).head.object.hexsha
         if remote_sha1_commit != local_sha1_commit:
             logging.info(
                 "Remote sha is '%s' while local sha is '%s': pulling new commits",
                 remote_sha1_commit,
                 local_sha1_commit,
             )
-            repo = git.Repo(self.clone_directory)
-            origin = repo.remotes.origin
-            origin.pull()
+            try:
+                repo = Repo(self.clone_directory)
+                origin = repo.remotes.origin
+                origin.pull()
+            except GitCommandError as e:
+                raise SystemError(
+                    f"Failed to clone repository for {self.clone_directory}"
+                ) from e
         else:
             logging.info("Repository already up to date.")
-        return remote_sha1_commit
+        return str(remote_sha1_commit)
```

### Comparing `pylint-3.0.0a5/pylint/testutils/pyreverse.py` & `pylint-3.0.0a6/pylint/testutils/pyreverse.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,20 +1,22 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import argparse
 import configparser
 import shlex
 import sys
 from pathlib import Path
 from typing import NamedTuple
 
+from pylint.pyreverse.main import DEFAULT_COLOR_PALETTE
+
 if sys.version_info >= (3, 8):
     from typing import TypedDict
 else:
     from typing_extensions import TypedDict
 
 
 # This class could and should be replaced with a simple dataclass when support for Python < 3.7 is dropped.
@@ -32,19 +34,21 @@
         mode: str = "PUB_ONLY",
         classes: list[str] | None = None,
         show_ancestors: int | None = None,
         all_ancestors: bool | None = None,
         show_associated: int | None = None,
         all_associated: bool | None = None,
         show_builtin: bool = False,
+        show_stdlib: bool = False,
         module_names: bool | None = None,
         only_classnames: bool = False,
         output_format: str = "dot",
         colorized: bool = False,
         max_color_depth: int = 2,
+        color_palette: tuple[str, ...] = DEFAULT_COLOR_PALETTE,
         ignore_list: tuple[str, ...] = tuple(),
         project: str = "",
         output_directory: str = "",
     ) -> None:
         super().__init__()
         self.mode = mode
         if classes:
@@ -52,25 +56,28 @@
         else:
             self.classes = []
         self.show_ancestors = show_ancestors
         self.all_ancestors = all_ancestors
         self.show_associated = show_associated
         self.all_associated = all_associated
         self.show_builtin = show_builtin
+        self.show_stdlib = show_stdlib
         self.module_names = module_names
         self.only_classnames = only_classnames
         self.output_format = output_format
         self.colorized = colorized
         self.max_color_depth = max_color_depth
+        self.color_palette = color_palette
         self.ignore_list = ignore_list
         self.project = project
         self.output_directory = output_directory
 
 
 class TestFileOptions(TypedDict):
+    source_roots: list[str]
     output_formats: list[str]
     command_line_args: list[str]
 
 
 class FunctionalPyreverseTestfile(NamedTuple):
     """Named tuple containing the test file and the expected output."""
 
@@ -93,24 +100,30 @@
                     source=path, options=_read_config(config_file)
                 )
             )
         else:
             test_files.append(
                 FunctionalPyreverseTestfile(
                     source=path,
-                    options={"output_formats": ["mmd"], "command_line_args": []},
+                    options={
+                        "source_roots": [],
+                        "output_formats": ["mmd"],
+                        "command_line_args": [],
+                    },
                 )
             )
     return test_files
 
 
 def _read_config(config_file: Path) -> TestFileOptions:
     config = configparser.ConfigParser()
     config.read(str(config_file))
+    source_roots = config.get("testoptions", "source_roots", fallback=None)
     return {
+        "source_roots": source_roots.split(",") if source_roots else [],
         "output_formats": config.get(
             "testoptions", "output_formats", fallback="mmd"
         ).split(","),
         "command_line_args": shlex.split(
             config.get("testoptions", "command_line_args", fallback="")
         ),
     }
```

### Comparing `pylint-3.0.0a5/pylint/testutils/reporter_for_tests.py` & `pylint-3.0.0a6/pylint/testutils/reporter_for_tests.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 from io import StringIO
 from os import getcwd, sep
 from typing import TYPE_CHECKING
 
@@ -16,15 +16,15 @@
 
 
 class GenericTestReporter(BaseReporter):
     """Reporter storing plain text messages."""
 
     out: StringIO
 
-    def __init__(  # pylint: disable=super-init-not-called # See https://github.com/PyCQA/pylint/issues/4941
+    def __init__(  # pylint: disable=super-init-not-called # See https://github.com/pylint-dev/pylint/issues/4941
         self,
     ) -> None:
         self.path_strip_prefix: str = getcwd() + sep
         self.reset()
 
     def reset(self) -> None:
         self.out = StringIO()
@@ -68,15 +68,12 @@
         self.messages = []
 
     def _display(self, layout: Section) -> None:
         pass
 
 
 class FunctionalTestReporter(BaseReporter):
-    def on_set_current_module(self, module: str, filepath: str | None) -> None:
-        self.messages = []
-
     def display_reports(self, layout: Section) -> None:
         """Ignore layouts and don't call self._display()."""
 
     def _display(self, layout: Section) -> None:
         pass
```

### Comparing `pylint-3.0.0a5/pylint/testutils/unittest_linter.py` & `pylint-3.0.0a6/pylint/testutils/unittest_linter.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 # pylint: disable=duplicate-code
 
 from __future__ import annotations
 
 import sys
 from typing import Any
@@ -20,16 +20,14 @@
 else:
     from typing_extensions import Literal
 
 
 class UnittestLinter(PyLinter):
     """A fake linter class to capture checker messages."""
 
-    # pylint: disable=unused-argument
-
     def __init__(self) -> None:
         self._messages: list[MessageTest] = []
         super().__init__()
 
     def release_messages(self) -> list[MessageTest]:
         try:
             return self._messages
```

### Comparing `pylint-3.0.0a5/pylint/typing.py` & `pylint-3.0.0a6/pylint/typing.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """A collection of typing utilities."""
 
 from __future__ import annotations
 
+import argparse
 import sys
+from pathlib import Path
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
     Dict,
     Iterable,
     NamedTuple,
@@ -18,20 +20,21 @@
     Pattern,
     Tuple,
     Type,
     Union,
 )
 
 if sys.version_info >= (3, 8):
-    from typing import Literal, TypedDict
+    from typing import Literal, Protocol, TypedDict
 else:
-    from typing_extensions import Literal, TypedDict
+    from typing_extensions import Literal, Protocol, TypedDict
 
 if TYPE_CHECKING:
     from pylint.config.callback_actions import _CallbackAction
+    from pylint.pyreverse.inspector import Project
     from pylint.reporters.ureports.nodes import Section
     from pylint.utils import LinterStats
 
 
 class FileItem(NamedTuple):
     """Represents data about a file handled by pylint.
 
@@ -117,13 +120,21 @@
 class ExtraMessageOptions(TypedDict, total=False):
     """All allowed keys in the extra options for message definitions."""
 
     scope: str
     old_names: list[tuple[str, str]]
     maxversion: tuple[int, int]
     minversion: tuple[int, int]
+    shared: bool
+    default_enabled: bool
 
 
 MessageDefinitionTuple = Union[
     Tuple[str, str, str],
     Tuple[str, str, str, ExtraMessageOptions],
 ]
+DirectoryNamespaceDict = Dict[Path, Tuple[argparse.Namespace, "DirectoryNamespaceDict"]]
+
+
+class GetProjectCallable(Protocol):
+    def __call__(self, module: str, name: str | None = "No Name") -> Project:
+        ...  # pragma: no cover
```

### Comparing `pylint-3.0.0a5/pylint/utils/__init__.py` & `pylint-3.0.0a6/pylint/utils/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,51 +1,47 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Some various utilities and helper classes, most of them used in the
 main pylint class.
 """
 
 from pylint.utils.ast_walker import ASTWalker
 from pylint.utils.docs import print_full_documentation
 from pylint.utils.file_state import FileState
 from pylint.utils.linterstats import LinterStats, ModuleStats, merge_stats
 from pylint.utils.utils import (
     HAS_ISORT_5,
     IsortDriver,
     _check_csv,
-    _format_option_value,
     _splitstrip,
     _unquote,
     decoding_stream,
     diff_string,
     format_section,
-    get_global_option,
     get_module_and_frameid,
     get_rst_section,
     get_rst_title,
     normalize_text,
     register_plugins,
     tokenize_module,
 )
 
 __all__ = [
     "ASTWalker",
     "HAS_ISORT_5",
     "IsortDriver",
     "_check_csv",
-    "_format_option_value",
     "_splitstrip",
     "_unquote",
     "decoding_stream",
     "diff_string",
     "FileState",
     "format_section",
-    "get_global_option",
     "get_module_and_frameid",
     "get_rst_section",
     "get_rst_title",
     "normalize_text",
     "register_plugins",
     "tokenize_module",
     "merge_stats",
```

### Comparing `pylint-3.0.0a5/pylint/utils/ast_walker.py` & `pylint-3.0.0a6/pylint/utils/ast_walker.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import sys
 import traceback
 from collections import defaultdict
 from collections.abc import Sequence
@@ -33,15 +33,15 @@
         self.leave_events: defaultdict[str, list[AstCallback]] = defaultdict(list)
         self.linter = linter
         self.exception_msg = False
 
     def _is_method_enabled(self, method: AstCallback) -> bool:
         if not hasattr(method, "checks_msgs"):
             return True
-        return any(self.linter.is_message_enabled(m) for m in method.checks_msgs)  # type: ignore[attr-defined]
+        return any(self.linter.is_message_enabled(m) for m in method.checks_msgs)
 
     def add_checker(self, checker: BaseChecker) -> None:
         """Walk to the checker's dir and collect visit and leave methods."""
         vcids: set[str] = set()
         lcids: set[str] = set()
         visits = self.visit_events
         leaves = self.leave_events
@@ -78,14 +78,15 @@
         # Detect if the node is a new name for a deprecated alias.
         # In this case, favour the methods for the deprecated
         # alias if any,  in order to maintain backwards
         # compatibility.
         visit_events: Sequence[AstCallback] = self.visit_events.get(cid, ())
         leave_events: Sequence[AstCallback] = self.leave_events.get(cid, ())
 
+        # pylint: disable = too-many-try-statements
         try:
             if astroid.is_statement:
                 self.nbstatements += 1
             # generate events for this node on each checker
             for callback in visit_events:
                 callback(astroid)
             # recurse on children
```

### Comparing `pylint-3.0.0a5/pylint/utils/docs.py` & `pylint-3.0.0a6/pylint/utils/docs.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,16 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 """Various helper functions to create the docs of a linter object."""
 
 from __future__ import annotations
 
 import sys
-import warnings
 from typing import TYPE_CHECKING, Any, TextIO
 
 from pylint.constants import MAIN_CHECKER_NAME
 from pylint.utils.utils import get_rst_section, get_rst_title
 
 if TYPE_CHECKING:
     from pylint.lint.pylinter import PyLinter
@@ -21,56 +20,54 @@
     """Get info from a checker and handle KeyError."""
     by_checker: dict[str, dict[str, Any]] = {}
     for checker in linter.get_checkers():
         name = checker.name
         if name != MAIN_CHECKER_NAME:
             try:
                 by_checker[name]["checker"] = checker
-                with warnings.catch_warnings():
-                    warnings.filterwarnings("ignore", category=DeprecationWarning)
-                    by_checker[name]["options"] += checker.options_and_values()
+                by_checker[name]["options"] += checker._options_and_values()
                 by_checker[name]["msgs"].update(checker.msgs)
                 by_checker[name]["reports"] += checker.reports
             except KeyError:
-                with warnings.catch_warnings():
-                    warnings.filterwarnings("ignore", category=DeprecationWarning)
-                    by_checker[name] = {
-                        "checker": checker,
-                        "options": list(checker.options_and_values()),
-                        "msgs": dict(checker.msgs),
-                        "reports": list(checker.reports),
-                    }
+                by_checker[name] = {
+                    "checker": checker,
+                    "options": list(checker._options_and_values()),
+                    "msgs": dict(checker.msgs),
+                    "reports": list(checker.reports),
+                }
     return by_checker
 
 
 def _get_global_options_documentation(linter: PyLinter) -> str:
     """Get documentation for the main checker."""
     result = get_rst_title("Pylint global options and switches", "-")
     result += """
 Pylint provides global options and switches.
 
 """
     for checker in linter.get_checkers():
         if checker.name == MAIN_CHECKER_NAME and checker.options:
-            with warnings.catch_warnings():
-                warnings.filterwarnings("ignore", category=DeprecationWarning)
-                for section, options in checker.options_by_section():
-                    if section is None:
-                        title = "General options"
-                    else:
-                        title = f"{section.capitalize()} options"
-                    result += get_rst_title(title, "~")
-                    assert isinstance(options, list)
-                    result += f"{get_rst_section(None, options)}\n"
+            for section, options in checker._options_by_section():
+                if section is None:
+                    title = "General options"
+                else:
+                    title = f"{section.capitalize()} options"
+                result += get_rst_title(title, "~")
+                assert isinstance(options, list)
+                result += f"{get_rst_section(None, options)}\n"
     return result
 
 
-def _get_checkers_documentation(linter: PyLinter) -> str:
+def _get_checkers_documentation(linter: PyLinter, show_options: bool = True) -> str:
     """Get documentation for individual checkers."""
-    result = _get_global_options_documentation(linter)
+    if show_options:
+        result = _get_global_options_documentation(linter)
+    else:
+        result = ""
+
     result += get_rst_title("Pylint checkers' options and switches", "-")
     result += """\
 
 Pylint checkers can provide three set of features:
 
 * options that control their execution,
 * messages that they can raise,
@@ -80,14 +77,20 @@
 
 """
     by_checker = _get_checkers_infos(linter)
     for checker_name in sorted(by_checker):
         information = by_checker[checker_name]
         checker = information["checker"]
         del information["checker"]
-        result += checker.get_full_documentation(**information)
+        result += checker.get_full_documentation(
+            **information, show_options=show_options
+        )
     return result
 
 
-def print_full_documentation(linter: PyLinter, stream: TextIO = sys.stdout) -> None:
+def print_full_documentation(
+    linter: PyLinter, stream: TextIO = sys.stdout, show_options: bool = True
+) -> None:
     """Output a full documentation in ReST format."""
-    print(_get_checkers_documentation(linter)[:-3], file=stream)
+    print(
+        _get_checkers_documentation(linter, show_options=show_options)[:-3], file=stream
+    )
```

### Comparing `pylint-3.0.0a5/pylint/utils/file_state.py` & `pylint-3.0.0a6/pylint/utils/file_state.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,16 +1,15 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import collections
 import sys
-import warnings
 from collections import defaultdict
 from collections.abc import Iterator
 from typing import TYPE_CHECKING, Dict
 
 from astroid import nodes
 
 from pylint.constants import (
@@ -32,32 +31,20 @@
 
 
 class FileState:
     """Hold internal state specific to the currently analyzed file."""
 
     def __init__(
         self,
-        modname: str | None = None,
-        msg_store: MessageDefinitionStore | None = None,
+        modname: str,
+        msg_store: MessageDefinitionStore,
         node: nodes.Module | None = None,
         *,
         is_base_filestate: bool = False,
     ) -> None:
-        if modname is None:
-            warnings.warn(
-                "FileState needs a string as modname argument. "
-                "This argument will be required in pylint 3.0",
-                DeprecationWarning,
-            )
-        if msg_store is None:
-            warnings.warn(
-                "FileState needs a 'MessageDefinitionStore' as msg_store argument. "
-                "This argument will be required in pylint 3.0",
-                DeprecationWarning,
-            )
         self.base_name = modname
         self._module_msgs_state: MessageStateDict = {}
         self._raw_module_msgs_state: MessageStateDict = {}
         self._ignored_msgs: defaultdict[
             tuple[str, int], set[int]
         ] = collections.defaultdict(set)
         self._suppression_mapping: dict[tuple[str, int], int] = {}
@@ -68,32 +55,14 @@
             self._effective_max_line_number = None
         self._msgs_store = msg_store
         self._is_base_filestate = is_base_filestate
         """If this FileState is the base state made during initialization of
         PyLinter.
         """
 
-    def collect_block_lines(
-        self, msgs_store: MessageDefinitionStore, module_node: nodes.Module
-    ) -> None:
-        """Walk the AST to collect block level options line numbers."""
-        warnings.warn(
-            "'collect_block_lines' has been deprecated and will be removed in pylint 3.0.",
-            DeprecationWarning,
-        )
-        for msg, lines in self._module_msgs_state.items():
-            self._raw_module_msgs_state[msg] = lines.copy()
-        orig_state = self._module_msgs_state.copy()
-        self._module_msgs_state = {}
-        self._suppression_mapping = {}
-        self._effective_max_line_number = module_node.tolineno
-        for msgid, lines in orig_state.items():
-            for msgdef in msgs_store.get_message_definitions(msgid):
-                self._set_state_on_block_lines(msgs_store, module_node, msgdef, lines)
-
     def _set_state_on_block_lines(
         self,
         msgs_store: MessageDefinitionStore,
         node: nodes.NodeNG,
         msg: MessageDefinition,
         msg_state: dict[int, bool],
     ) -> None:
@@ -190,38 +159,54 @@
                     )
                 ) and line in self._module_msgs_state.get(msg.msgid, ()):
                     continue
                 if line in lines:  # state change in the same block
                     state = lines[line]
                     original_lineno = line
 
-                # Update suppression mapping
-                if not state:
-                    self._suppression_mapping[(msg.msgid, line)] = original_lineno
-                else:
-                    self._suppression_mapping.pop((msg.msgid, line), None)
-
-                # Update message state for respective line
-                try:
-                    self._module_msgs_state[msg.msgid][line] = state
-                except KeyError:
-                    self._module_msgs_state[msg.msgid] = {line: state}
+                self._set_message_state_on_line(msg, line, state, original_lineno)
+
             del lines[lineno]
 
-    def set_msg_status(self, msg: MessageDefinition, line: int, status: bool) -> None:
+    def _set_message_state_on_line(
+        self,
+        msg: MessageDefinition,
+        line: int,
+        state: bool,
+        original_lineno: int,
+    ) -> None:
+        """Set the state of a message on a line."""
+        # Update suppression mapping
+        if not state:
+            self._suppression_mapping[(msg.msgid, line)] = original_lineno
+        else:
+            self._suppression_mapping.pop((msg.msgid, line), None)
+
+        # Update message state for respective line
+        try:
+            self._module_msgs_state[msg.msgid][line] = state
+        except KeyError:
+            self._module_msgs_state[msg.msgid] = {line: state}
+
+    def set_msg_status(
+        self,
+        msg: MessageDefinition,
+        line: int,
+        status: bool,
+        scope: str = "package",
+    ) -> None:
         """Set status (enabled/disable) for a given message at a given line."""
         assert line > 0
-        assert self._module
-        # TODO: 3.0: Remove unnecessary assertion
-        assert self._msgs_store
-
-        # Expand the status to cover all relevant block lines
-        self._set_state_on_block_lines(
-            self._msgs_store, self._module, msg, {line: status}
-        )
+        if scope != "line":
+            # Expand the status to cover all relevant block lines
+            self._set_state_on_block_lines(
+                self._msgs_store, self._module, msg, {line: status}
+            )
+        else:
+            self._set_message_state_on_line(msg, line, status, line)
 
         # Store the raw value
         try:
             self._raw_module_msgs_state[msg.msgid][line] = status
         except KeyError:
             self._raw_module_msgs_state[msg.msgid] = {line: status}
 
@@ -268,8 +253,8 @@
             for line in ignored_lines:
                 yield "suppressed-message", line, (
                     msgs_store.get_msg_display_string(warning),
                     from_,
                 )
 
     def get_effective_max_line_number(self) -> int | None:
-        return self._effective_max_line_number
+        return self._effective_max_line_number  # type: ignore[no-any-return]
```

### Comparing `pylint-3.0.0a5/pylint/utils/linterstats.py` & `pylint-3.0.0a6/pylint/utils/linterstats.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import sys
 from typing import cast
 
 from pylint.typing import MessageTypesFullName
@@ -26,14 +26,15 @@
     const: int
     inlinevar: int
     function: int
     method: int
     module: int
     variable: int
     typevar: int
+    typealias: int
 
 
 class CodeTypeCount(TypedDict):
     """TypedDict to store counts of lines of code types."""
 
     code: int
     comment: int
@@ -103,14 +104,15 @@
             const=0,
             inlinevar=0,
             function=0,
             method=0,
             module=0,
             variable=0,
             typevar=0,
+            typealias=0,
         )
         self.by_module: dict[str, ModuleStats] = by_module or {}
         self.by_msg: dict[str, int] = by_msg or {}
         self.code_type_count = code_type_count or CodeTypeCount(
             code=0, comment=0, docstring=0, empty=0, total=0
         )
 
@@ -178,14 +180,15 @@
             "const",
             "inlinevar",
             "function",
             "method",
             "module",
             "variable",
             "typevar",
+            "typealias",
         ],
     ) -> int:
         """Get a bad names node count."""
         if node_name == "class":
             return self.bad_names.get("klass", 0)
         return self.bad_names.get(node_name, 0)
 
@@ -200,14 +203,15 @@
             "const",
             "inlinevar",
             "function",
             "method",
             "module",
             "variable",
             "typevar",
+            "typealias",
         }:
             raise ValueError("Node type not part of the bad_names stat")
 
         node_name = cast(
             Literal[
                 "argument",
                 "attr",
@@ -217,14 +221,15 @@
                 "const",
                 "inlinevar",
                 "function",
                 "method",
                 "module",
                 "variable",
                 "typevar",
+                "typealias",
             ],
             node_name,
         )
         if node_name == "class":
             self.bad_names["klass"] += increase
         else:
             self.bad_names[node_name] += increase
@@ -240,14 +245,15 @@
             const=0,
             inlinevar=0,
             function=0,
             method=0,
             module=0,
             variable=0,
             typevar=0,
+            typealias=0,
         )
 
     def get_code_count(
         self, type_name: Literal["code", "comment", "docstring", "empty", "total"]
     ) -> int:
         """Get a code type count."""
         return self.code_type_count.get(type_name, 0)
@@ -332,14 +338,15 @@
         merged.bad_names["const"] += stat.bad_names["const"]
         merged.bad_names["inlinevar"] += stat.bad_names["inlinevar"]
         merged.bad_names["function"] += stat.bad_names["function"]
         merged.bad_names["method"] += stat.bad_names["method"]
         merged.bad_names["module"] += stat.bad_names["module"]
         merged.bad_names["variable"] += stat.bad_names["variable"]
         merged.bad_names["typevar"] += stat.bad_names["typevar"]
+        merged.bad_names["typealias"] += stat.bad_names["typealias"]
 
         for mod_key, mod_value in stat.by_module.items():
             merged.by_module[mod_key] = mod_value
 
         for msg_key, msg_value in stat.by_msg.items():
             try:
                 merged.by_msg[msg_key] += msg_value
```

### Comparing `pylint-3.0.0a5/pylint/utils/pragma_parser.py` & `pylint-3.0.0a6/pylint/utils/pragma_parser.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 import re
-from collections import namedtuple
 from collections.abc import Generator
+from typing import NamedTuple
 
 # Allow stopping after the first semicolon/hash encountered,
 # so that an option can be continued with the reasons
 # why it is active or disabled.
 OPTION_RGX = r"""
     (?:^\s*\#.*|\s*|               # Comment line, or whitespaces,
        \s*\#.*(?=\#.*?\bpylint:))  # or a beginning of an inline comment
@@ -23,15 +23,17 @@
                                    # newline (it is the second matched group)
                                    # and end of the first matched group
     [;#]{0,1}                      # From 0 to 1 repetition of semicolon or hash
 """
 OPTION_PO = re.compile(OPTION_RGX, re.VERBOSE)
 
 
-PragmaRepresenter = namedtuple("PragmaRepresenter", "action messages")
+class PragmaRepresenter(NamedTuple):
+    action: str
+    messages: list[str]
 
 
 ATOMIC_KEYWORDS = frozenset(("disable-all", "skip-file"))
 MESSAGE_KEYWORDS = frozenset(
     ("disable-next", "disable-msg", "enable-msg", "disable", "enable")
 )
 # sorted is necessary because sets are unordered collections and ALL_KEYWORDS
```

### Comparing `pylint-3.0.0a5/pylint/utils/utils.py` & `pylint-3.0.0a6/pylint/utils/utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html
-# For details: https://github.com/PyCQA/pylint/blob/main/LICENSE
-# Copyright (c) https://github.com/PyCQA/pylint/blob/main/CONTRIBUTORS.txt
+# For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE
+# Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt
 
 from __future__ import annotations
 
 try:
     import isort.api
+    import isort.settings
 
     HAS_ISORT_5 = True
 except ImportError:  # isort < 5
     import isort
 
     HAS_ISORT_5 = False
 
@@ -19,38 +20,27 @@
 import re
 import sys
 import textwrap
 import tokenize
 import warnings
 from collections.abc import Sequence
 from io import BufferedReader, BytesIO
-from typing import (
-    TYPE_CHECKING,
-    Any,
-    List,
-    Pattern,
-    TextIO,
-    Tuple,
-    TypeVar,
-    Union,
-    overload,
-)
+from typing import TYPE_CHECKING, Any, List, Pattern, TextIO, Tuple, TypeVar, Union
 
 from astroid import Module, modutils, nodes
 
 from pylint.constants import PY_EXTS
 from pylint.typing import OptionDict
 
 if sys.version_info >= (3, 8):
     from typing import Literal
 else:
     from typing_extensions import Literal
 
 if TYPE_CHECKING:
-    from pylint.checkers.base_checker import BaseChecker
     from pylint.lint import PyLinter
 
 DEFAULT_LINE_LENGTH = 79
 
 # These are types used to overload get_global_option() and refer to the options type
 GLOBAL_OPTION_BOOL = Literal[
     "suggestion-mode",
@@ -210,84 +200,14 @@
                 print(f"Problem importing module {filename}: {exc}", file=sys.stderr)
             else:
                 if hasattr(module, "register"):
                     module.register(linter)
                     imported[base] = 1
 
 
-@overload
-def get_global_option(
-    checker: BaseChecker, option: GLOBAL_OPTION_BOOL, default: bool | None = ...
-) -> bool:
-    ...
-
-
-@overload
-def get_global_option(
-    checker: BaseChecker, option: GLOBAL_OPTION_INT, default: int | None = ...
-) -> int:
-    ...
-
-
-@overload
-def get_global_option(
-    checker: BaseChecker,
-    option: GLOBAL_OPTION_LIST,
-    default: list[str] | None = ...,
-) -> list[str]:
-    ...
-
-
-@overload
-def get_global_option(
-    checker: BaseChecker,
-    option: GLOBAL_OPTION_PATTERN,
-    default: Pattern[str] | None = ...,
-) -> Pattern[str]:
-    ...
-
-
-@overload
-def get_global_option(
-    checker: BaseChecker,
-    option: GLOBAL_OPTION_PATTERN_LIST,
-    default: list[Pattern[str]] | None = ...,
-) -> list[Pattern[str]]:
-    ...
-
-
-@overload
-def get_global_option(
-    checker: BaseChecker,
-    option: GLOBAL_OPTION_TUPLE_INT,
-    default: tuple[int, ...] | None = ...,
-) -> tuple[int, ...]:
-    ...
-
-
-def get_global_option(
-    checker: BaseChecker,
-    option: GLOBAL_OPTION_NAMES,
-    default: T_GlobalOptionReturnTypes | None = None,  # pylint: disable=unused-argument
-) -> T_GlobalOptionReturnTypes | None | Any:
-    """DEPRECATED: Retrieve an option defined by the given *checker* or
-    by all known option providers.
-
-    It will look in the list of all options providers
-    until the given *option* will be found.
-    If the option wasn't found, the *default* value will be returned.
-    """
-    warnings.warn(
-        "get_global_option has been deprecated. You can use "
-        "checker.linter.config to get all global options instead.",
-        DeprecationWarning,
-    )
-    return getattr(checker.linter.config, option.replace("-", "_"))
-
-
 def _splitstrip(string: str, sep: str = ",") -> list[str]:
     """Return a list of stripped string by splitting the string given as
     argument on `sep` (',' by default), empty strings are discarded.
 
     >>> _splitstrip('a, b, c   ,  4,,')
     ['a', 'b', 'c', '4']
     >>> _splitstrip('a')
@@ -334,15 +254,15 @@
     sep = "\n"
     return "# " + f"{sep}# ".join(lines)
 
 
 def _format_option_value(optdict: OptionDict, value: Any) -> str:
     """Return the user input's value from a 'compiled' value.
 
-    TODO: 3.0: Remove deprecated function
+    TODO: Refactor the code to not use this deprecated function
     """
     if optdict.get("type", None) == "py_version":
         value = ".".join(str(item) for item in value)
     elif isinstance(value, (list, tuple)):
         value = ",".join(_format_option_value(optdict, item) for item in value)
     elif isinstance(value, dict):
         value = ",".join(f"{k}:{v}" for k, v in value.items())
@@ -362,28 +282,30 @@
     options: list[tuple[str, OptionDict, Any]],
     doc: str | None = None,
 ) -> None:
     """Format an option's section using the INI format."""
     warnings.warn(
         "format_section has been deprecated. It will be removed in pylint 3.0.",
         DeprecationWarning,
+        stacklevel=2,
     )
     if doc:
         print(_comment(doc), file=stream)
     print(f"[{section}]", file=stream)
     with warnings.catch_warnings():
         warnings.filterwarnings("ignore", category=DeprecationWarning)
         _ini_format(stream, options)
 
 
 def _ini_format(stream: TextIO, options: list[tuple[str, OptionDict, Any]]) -> None:
     """Format options using the INI format."""
     warnings.warn(
         "_ini_format has been deprecated. It will be removed in pylint 3.0.",
         DeprecationWarning,
+        stacklevel=2,
     )
     for optname, optdict, value in options:
         # Skip deprecated option
         if "kwargs" in optdict:
             assert isinstance(optdict["kwargs"], dict)
             if "new_names" in optdict["kwargs"]:
                 continue
@@ -409,27 +331,27 @@
 
 
 class IsortDriver:
     """A wrapper around isort API that changed between versions 4 and 5."""
 
     def __init__(self, config: argparse.Namespace) -> None:
         if HAS_ISORT_5:
-            self.isort5_config = isort.api.Config(
+            self.isort5_config = isort.settings.Config(
                 # There is no typo here. EXTRA_standard_library is
                 # what most users want. The option has been named
                 # KNOWN_standard_library for ages in pylint, and we
                 # don't want to break compatibility.
                 extra_standard_library=config.known_standard_library,
                 known_third_party=config.known_third_party,
             )
         else:
             # pylint: disable-next=no-member
-            self.isort4_obj = isort.SortImports(
+            self.isort4_obj = isort.SortImports(  # type: ignore[attr-defined]
                 file_contents="",
                 known_standard_library=config.known_standard_library,
                 known_third_party=config.known_third_party,
             )
 
     def place_module(self, package: str) -> str:
         if HAS_ISORT_5:
             return isort.api.place_module(package, self.isort5_config)
-        return self.isort4_obj.place_module(package)
+        return self.isort4_obj.place_module(package)  # type: ignore[no-any-return]
```

### Comparing `pylint-3.0.0a5/pylint.egg-info/PKG-INFO` & `pylint-3.0.0a6/pylint.egg-info/PKG-INFO`

 * *Files 18% similar despite different names*

```diff
@@ -1,202 +1,258 @@
 Metadata-Version: 2.1
 Name: pylint
-Version: 3.0.0a5
+Version: 3.0.0a6
 Summary: python code static checker
-Author: Python Code Quality Authority
-Author-email: code-quality@python.org
+Author-email: Python Code Quality Authority <code-quality@python.org>
 License: GPL-2.0-or-later
-Project-URL: Homepage, https://www.pylint.org/
-Project-URL: Source Code, https://github.com/PyCQA/pylint
-Project-URL: What's New, https://pylint.pycqa.org/en/latest/whatsnew/
-Project-URL: Bug Tracker, https://github.com/PyCQA/pylint/issues
+Project-URL: Docs: User Guide, https://pylint.readthedocs.io/en/latest/
+Project-URL: Source Code, https://github.com/pylint-dev/pylint
+Project-URL: homepage, https://github.com/pylint-dev/pylint
+Project-URL: What's New, https://pylint.readthedocs.io/en/latest/whatsnew/2/
+Project-URL: Bug Tracker, https://github.com/pylint-dev/pylint/issues
 Project-URL: Discord Server, https://discord.com/invite/Egy6P8AMB5
-Project-URL: Docs: User Guide, https://pylint.pycqa.org/en/latest/
-Project-URL: Docs: Contributing, https://pylint.pycqa.org/en/latest/development_guide/contribute.html
-Project-URL: Docs: Technical Reference, https://pylint.pycqa.org/en/latest/technical_reference/index.html
-Keywords: static code analysis linter python lint
+Project-URL: Docs: Contributor Guide, https://pylint.readthedocs.io/en/latest/development_guide/contributor_guide/index.html
+Keywords: static code analysis,linter,python,lint
 Classifier: Development Status :: 6 - Mature
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: GNU General Public License v2 (GPLv2)
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3 :: Only
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Programming Language :: Python :: Implementation :: PyPy
 Classifier: Topic :: Software Development :: Debuggers
 Classifier: Topic :: Software Development :: Quality Assurance
 Classifier: Topic :: Software Development :: Testing
+Classifier: Typing :: Typed
 Requires-Python: >=3.7.2
 Description-Content-Type: text/x-rst
 Provides-Extra: testutils
 Provides-Extra: spelling
 License-File: LICENSE
 License-File: CONTRIBUTORS.txt
 
 `Pylint`_
 =========
 
-.. _`Pylint`: https://pylint.pycqa.org/
+.. _`Pylint`: https://pylint.readthedocs.io/
 
 .. This is used inside the doc to recover the start of the introduction
 
-.. image:: https://github.com/PyCQA/pylint/actions/workflows/tests.yaml/badge.svg?branch=main
-    :target: https://github.com/PyCQA/pylint/actions
+.. image:: https://github.com/pylint-dev/pylint/actions/workflows/tests.yaml/badge.svg?branch=main
+    :target: https://github.com/pylint-dev/pylint/actions
 
-.. image:: https://coveralls.io/repos/github/PyCQA/pylint/badge.svg?branch=main
-    :target: https://coveralls.io/github/PyCQA/pylint?branch=main
+.. image:: https://codecov.io/gh/pylint-dev/pylint/branch/main/graph/badge.svg?token=ZETEzayrfk
+    :target: https://codecov.io/gh/pylint-dev/pylint
 
 .. image:: https://img.shields.io/pypi/v/pylint.svg
     :alt: Pypi Package version
     :target: https://pypi.python.org/pypi/pylint
 
 .. image:: https://readthedocs.org/projects/pylint/badge/?version=latest
     :target: https://pylint.readthedocs.io/en/latest/?badge=latest
     :alt: Documentation Status
 
 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg
     :target: https://github.com/ambv/black
 
 .. image:: https://img.shields.io/badge/linting-pylint-yellowgreen
-    :target: https://github.com/PyCQA/pylint
+    :target: https://github.com/pylint-dev/pylint
 
-.. image:: https://results.pre-commit.ci/badge/github/PyCQA/pylint/main.svg
-   :target: https://results.pre-commit.ci/latest/github/PyCQA/pylint/main
+.. image:: https://results.pre-commit.ci/badge/github/pylint-dev/pylint/main.svg
+   :target: https://results.pre-commit.ci/latest/github/pylint-dev/pylint/main
    :alt: pre-commit.ci status
 
+.. image:: https://bestpractices.coreinfrastructure.org/projects/6328/badge
+   :target: https://bestpractices.coreinfrastructure.org/projects/6328
+   :alt: CII Best Practices
+
+.. image:: https://img.shields.io/ossf-scorecard/github.com/PyCQA/pylint?label=openssf%20scorecard&style=flat
+   :target: https://api.securityscorecards.dev/projects/github.com/PyCQA/pylint
+   :alt: OpenSSF Scorecard
+
+.. image:: https://img.shields.io/discord/825463413634891776.svg
+   :target: https://discord.gg/qYxpadCgkx
+   :alt: Discord
+
 What is Pylint?
-================
+---------------
 
 Pylint is a `static code analyser`_ for Python 2 or 3. The latest version supports Python
 3.7.2 and above.
 
 .. _`static code analyser`: https://en.wikipedia.org/wiki/Static_code_analysis
 
 Pylint analyses your code without actually running it. It checks for errors, enforces a
 coding standard, looks for `code smells`_, and can make suggestions about how the code
-could be refactored. Pylint can infer actual values from your code using its internal
-code representation (astroid). If your code is ``import logging as argparse``, Pylint
-will know that ``argparse.error(...)`` is in fact a logging call and not an argparse call.
+could be refactored.
 
 .. _`code smells`: https://martinfowler.com/bliki/CodeSmell.html
 
-Pylint is highly configurable and permits to write plugins in order to add your
-own checks (for example, for internal libraries or an internal rule). Pylint has an
-ecosystem of existing plugins for popular frameworks such as `pylint-django`_ or
-`pylint-i18n`_.
+Install
+-------
 
-.. _`pylint-django`: https://github.com/PyCQA/pylint-django
-.. _`pylint-i18n`: https://github.com/amandasaurus/python-pylint-i18n
+.. This is used inside the doc to recover the start of the short text for installation
+
+For command line use, pylint is installed with::
+
+    pip install pylint
+
+Or if you want to also check spelling with ``enchant`` (you might need to
+`install the enchant C library <https://pyenchant.github.io/pyenchant/install.html#installing-the-enchant-c-library>`_):
+
+.. code-block:: sh
+
+   pip install pylint[spelling]
+
+It can also be integrated in most editors or IDEs. More information can be found
+`in the documentation`_.
+
+.. _in the documentation: https://pylint.readthedocs.io/en/latest/user_guide/installation/index.html
+
+.. This is used inside the doc to recover the end of the short text for installation
+
+What differentiates Pylint?
+---------------------------
+
+Pylint is not trusting your typing and is inferring the actual value of nodes (for a
+start because there was no typing when pylint started off) using its internal code
+representation (astroid). If your code is ``import logging as argparse``, Pylint
+can check and know that ``argparse.error(...)`` is in fact a logging call and not an
+argparse call. This makes pylint slower, but it also lets pylint find more issues if
+your code is not fully typed.
+
+    [inference] is the killer feature that keeps us using [pylint] in our project despite how painfully slow it is.
+    - `Realist pylint user`_, 2022
+
+.. _`Realist pylint user`: https://github.com/charliermarsh/ruff/issues/970#issuecomment-1381067064
+
+pylint, not afraid of being a little slower than it already is, is also a lot more thorough than other linters.
+There are more checks, including some opinionated ones that are deactivated by default
+but can be enabled using configuration.
+
+How to use pylint
+-----------------
 
 Pylint isn't smarter than you: it may warn you about things that you have
 conscientiously done or check for some things that you don't care about.
 During adoption, especially in a legacy project where pylint was never enforced,
 it's best to start with the ``--errors-only`` flag, then disable
-convention and refactor message with ``--disable=C,R`` and progressively
+convention and refactor messages with ``--disable=C,R`` and progressively
 re-evaluate and re-enable messages as your priorities evolve.
 
-Pylint ships with three additional tools:
+Pylint is highly configurable and permits to write plugins in order to add your
+own checks (for example, for internal libraries or an internal rule). Pylint also has an
+ecosystem of existing plugins for popular frameworks and third-party libraries.
 
-- pyreverse_ (standalone tool that generates package and class diagrams.)
-- symilar_  (duplicate code finder that is also integrated in pylint)
-- epylint_ (Emacs and Flymake compatible Pylint)
+.. note::
+
+    Pylint supports the Python standard library out of the box. Third-party
+    libraries are not always supported, so a plugin might be needed. A good place
+    to start is ``PyPI`` which often returns a plugin by searching for
+    ``pylint <library>``. `pylint-pydantic`_, `pylint-django`_ and
+    `pylint-sonarjson`_ are examples of such plugins. More information about plugins
+    and how to load them can be found at `plugins`_.
 
-.. _pyreverse: https://pylint.pycqa.org/en/latest/pyreverse.html
-.. _symilar: https://pylint.pycqa.org/en/latest/symilar.html
-.. _epylint: https://pylint.pycqa.org/en/latest/user_guide/ide_integration/flymake-emacs.html
-
-Projects that you might want to use alongside pylint include flake8_ (faster and simpler checks
-with very few false positives), mypy_, pyright_ or pyre_ (typing checks), bandit_ (security
-oriented checks), black_ and isort_ (auto-formatting), autoflake_ (automated removal of
-unused imports or variables), pyupgrade_ (automated upgrade to newer python syntax) and
-pydocstringformatter_ (automated pep257).
+.. _`plugins`: https://pylint.readthedocs.io/en/latest/development_guide/how_tos/plugins.html#plugins
+.. _`pylint-pydantic`: https://pypi.org/project/pylint-pydantic
+.. _`pylint-django`: https://github.com/PyCQA/pylint-django
+.. _`pylint-sonarjson`: https://github.com/omegacen/pylint-sonarjson
 
-.. _flake8: https://gitlab.com/pycqa/flake8/
+Advised linters alongside pylint
+--------------------------------
+
+Projects that you might want to use alongside pylint include ruff_ (**really** fast,
+with builtin auto-fix and a growing number of checks taken from popular
+linters but implemented in ``rust``) or flake8_ (faster and simpler checks with very few false positives),
+mypy_, pyright_ or pyre_ (typing checks), bandit_ (security oriented checks), black_ and
+isort_ (auto-formatting), autoflake_ (automated removal of unused imports or variables),
+pyupgrade_ (automated upgrade to newer python syntax) and pydocstringformatter_ (automated pep257).
+
+.. _ruff: https://github.com/charliermarsh/ruff
+.. _flake8: https://github.com/PyCQA/flake8
 .. _bandit: https://github.com/PyCQA/bandit
 .. _mypy: https://github.com/python/mypy
 .. _pyright: https://github.com/microsoft/pyright
 .. _pyre: https://github.com/facebook/pyre-check
 .. _black: https://github.com/psf/black
 .. _autoflake: https://github.com/myint/autoflake
 .. _pyupgrade: https://github.com/asottile/pyupgrade
 .. _pydocstringformatter: https://github.com/DanielNoord/pydocstringformatter
 .. _isort: https://pycqa.github.io/isort/
 
-.. This is used inside the doc to recover the end of the introduction
-
-Install
--------
-
-.. This is used inside the doc to recover the start of the short text for installation
+Additional tools included in pylint
+-----------------------------------
 
-For command line use, pylint is installed with::
+Pylint ships with two additional tools:
 
-    pip install pylint
+- pyreverse_ (standalone tool that generates package and class diagrams.)
+- symilar_  (duplicate code finder that is also integrated in pylint)
 
-It can also be integrated in most editors or IDEs. More information can be found
-`in the documentation`_.
+.. _pyreverse: https://pylint.readthedocs.io/en/latest/pyreverse.html
+.. _symilar: https://pylint.readthedocs.io/en/latest/symilar.html
 
-.. _in the documentation: https://pylint.pycqa.org/en/latest/user_guide/installation/index.html
 
-.. This is used inside the doc to recover the end of the short text for installation
+.. This is used inside the doc to recover the end of the introduction
 
 Contributing
 ------------
 
 .. This is used inside the doc to recover the start of the short text for contribution
 
 We welcome all forms of contributions such as updates for documentation, new code, checking issues for duplicates or telling us
 that we can close them, confirming that issues still exist, `creating issues because
 you found a bug or want a feature`_, etc. Everything is much appreciated!
 
 Please follow the `code of conduct`_ and check `the Contributor Guides`_ if you want to
 make a code contribution.
 
-.. _creating issues because you found a bug or want a feature: https://pylint.pycqa.org/en/latest/contact.html#bug-reports-feedback
-.. _code of conduct: https://github.com/PyCQA/pylint/blob/main/CODE_OF_CONDUCT.md
-.. _the Contributor Guides: https://pylint.pycqa.org/en/latest/development_guide/contribute.html
+.. _creating issues because you found a bug or want a feature: https://pylint.readthedocs.io/en/latest/contact.html#bug-reports-feedback
+.. _code of conduct: https://github.com/pylint-dev/pylint/blob/main/CODE_OF_CONDUCT.md
+.. _the Contributor Guides: https://pylint.readthedocs.io/en/latest/development_guide/contribute.html
 
 .. This is used inside the doc to recover the end of the short text for contribution
 
 Show your usage
 -----------------
 
 You can place this badge in your README to let others know your project uses pylint.
 
     .. image:: https://img.shields.io/badge/linting-pylint-yellowgreen
-        :target: https://github.com/PyCQA/pylint
+        :target: https://github.com/pylint-dev/pylint
 
 Learn how to add a badge to your documentation in the `the badge documentation`_.
 
-.. _the badge documentation: https://pylint.pycqa.org/en/latest/user_guide/installation/badge.html
+.. _the badge documentation: https://pylint.readthedocs.io/en/latest/user_guide/installation/badge.html
 
 License
 -------
 
-pylint is, with a few exceptions listed below, `GPLv2 <https://github.com/PyCQA/pylint/blob/main/LICENSE>`_.
+pylint is, with a few exceptions listed below, `GPLv2 <https://github.com/pylint-dev/pylint/blob/main/LICENSE>`_.
 
 The icon files are licensed under the `CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0/>`_ license:
 
-- `doc/logo.png <https://raw.githubusercontent.com/PyCQA/pylint/main/doc/logo.png>`_
-- `doc/logo.svg <https://raw.githubusercontent.com/PyCQA/pylint/main/doc/logo.svg>`_
+- `doc/logo.png <https://raw.githubusercontent.com/pylint-dev/pylint/main/doc/logo.png>`_
+- `doc/logo.svg <https://raw.githubusercontent.com/pylint-dev/pylint/main/doc/logo.svg>`_
 
 Support
 -------
 
 Please check `the contact information`_.
 
-.. _`the contact information`: https://pylint.pycqa.org/en/latest/contact.html
+.. _`the contact information`: https://pylint.readthedocs.io/en/latest/contact.html
 
-.. |tideliftlogo| image:: https://raw.githubusercontent.com/PyCQA/pylint/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png
+.. |tideliftlogo| image:: https://raw.githubusercontent.com/pylint-dev/pylint/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png
    :width: 200
    :alt: Tidelift
 
 .. list-table::
    :widths: 10 100
 
    * - |tideliftlogo|
```

### Comparing `pylint-3.0.0a5/pylint.egg-info/SOURCES.txt` & `pylint-3.0.0a6/pylint.egg-info/SOURCES.txt`

 * *Files 3% similar despite different names*

```diff
@@ -1,42 +1,45 @@
 CONTRIBUTORS.txt
 LICENSE
 MANIFEST.in
+README.rst
+pyproject.toml
 setup.cfg
-setup.py
 pylint/__init__.py
 pylint/__main__.py
 pylint/__pkginfo__.py
 pylint/constants.py
-pylint/epylint.py
 pylint/exceptions.py
 pylint/graph.py
 pylint/interfaces.py
+pylint/py.typed
 pylint/typing.py
 pylint.egg-info/PKG-INFO
 pylint.egg-info/SOURCES.txt
 pylint.egg-info/dependency_links.txt
 pylint.egg-info/entry_points.txt
 pylint.egg-info/requires.txt
 pylint.egg-info/top_level.txt
 pylint/checkers/__init__.py
 pylint/checkers/async.py
+pylint/checkers/bad_chained_comparison.py
 pylint/checkers/base_checker.py
 pylint/checkers/deprecated.py
 pylint/checkers/design_analysis.py
 pylint/checkers/dunder_methods.py
 pylint/checkers/ellipsis_checker.py
 pylint/checkers/exceptions.py
 pylint/checkers/format.py
 pylint/checkers/imports.py
 pylint/checkers/lambda_expressions.py
 pylint/checkers/logging.py
-pylint/checkers/mapreduce_checker.py
+pylint/checkers/method_args.py
 pylint/checkers/misc.py
 pylint/checkers/modified_iterating_checker.py
+pylint/checkers/nested_min_max.py
 pylint/checkers/newstyle.py
 pylint/checkers/non_ascii_names.py
 pylint/checkers/raw_metrics.py
 pylint/checkers/similar.py
 pylint/checkers/spelling.py
 pylint/checkers/stdlib.py
 pylint/checkers/strings.py
@@ -66,24 +69,18 @@
 pylint/config/__init__.py
 pylint/config/argument.py
 pylint/config/arguments_manager.py
 pylint/config/arguments_provider.py
 pylint/config/callback_actions.py
 pylint/config/config_file_parser.py
 pylint/config/config_initialization.py
-pylint/config/configuration_mixin.py
 pylint/config/deprecation_actions.py
-pylint/config/environment_variable.py
 pylint/config/exceptions.py
 pylint/config/find_default_config_files.py
 pylint/config/help_formatter.py
-pylint/config/option.py
-pylint/config/option_manager_mixin.py
-pylint/config/option_parser.py
-pylint/config/options_provider_mixin.py
 pylint/config/utils.py
 pylint/config/_pylint_config/__init__.py
 pylint/config/_pylint_config/generate_command.py
 pylint/config/_pylint_config/help_message.py
 pylint/config/_pylint_config/main.py
 pylint/config/_pylint_config/setup.py
 pylint/config/_pylint_config/utils.py
@@ -92,21 +89,25 @@
 pylint/extensions/bad_builtin.py
 pylint/extensions/broad_try_clause.py
 pylint/extensions/check_elif.py
 pylint/extensions/code_style.py
 pylint/extensions/comparetozero.py
 pylint/extensions/comparison_placement.py
 pylint/extensions/confusing_elif.py
+pylint/extensions/consider_refactoring_into_while_condition.py
 pylint/extensions/consider_ternary_expression.py
+pylint/extensions/dict_init_mutate.py
 pylint/extensions/docparams.py
 pylint/extensions/docstyle.py
+pylint/extensions/dunder.py
 pylint/extensions/empty_comment.py
 pylint/extensions/emptystring.py
 pylint/extensions/eq_without_hash.py
 pylint/extensions/for_any_all.py
+pylint/extensions/magic_value.py
 pylint/extensions/mccabe.py
 pylint/extensions/no_self_use.py
 pylint/extensions/overlapping_exceptions.py
 pylint/extensions/private_import.py
 pylint/extensions/redefined_loop_name.py
 pylint/extensions/redefined_variable_type.py
 pylint/extensions/set_membership.py
@@ -119,14 +120,15 @@
 pylint/lint/message_state_handler.py
 pylint/lint/parallel.py
 pylint/lint/pylinter.py
 pylint/lint/report_functions.py
 pylint/lint/run.py
 pylint/lint/utils.py
 pylint/message/__init__.py
+pylint/message/_deleted_message_ids.py
 pylint/message/message.py
 pylint/message/message_definition.py
 pylint/message/message_definition_store.py
 pylint/message/message_id_store.py
 pylint/pyreverse/__init__.py
 pylint/pyreverse/diadefslib.py
 pylint/pyreverse/diagrams.py
@@ -134,15 +136,14 @@
 pylint/pyreverse/inspector.py
 pylint/pyreverse/main.py
 pylint/pyreverse/mermaidjs_printer.py
 pylint/pyreverse/plantuml_printer.py
 pylint/pyreverse/printer.py
 pylint/pyreverse/printer_factory.py
 pylint/pyreverse/utils.py
-pylint/pyreverse/vcg_printer.py
 pylint/pyreverse/writer.py
 pylint/reporters/__init__.py
 pylint/reporters/base_reporter.py
 pylint/reporters/collecting_reporter.py
 pylint/reporters/json_reporter.py
 pylint/reporters/multi_reporter.py
 pylint/reporters/reports_handler_mix_in.py
@@ -153,26 +154,31 @@
 pylint/reporters/ureports/text_writer.py
 pylint/testutils/__init__.py
 pylint/testutils/_run.py
 pylint/testutils/checker_test_case.py
 pylint/testutils/configuration_test.py
 pylint/testutils/constants.py
 pylint/testutils/decorator.py
-pylint/testutils/functional_test_file.py
 pylint/testutils/get_test_info.py
 pylint/testutils/global_test_linter.py
 pylint/testutils/lint_module_test.py
 pylint/testutils/output_line.py
-pylint/testutils/primer.py
 pylint/testutils/pyreverse.py
 pylint/testutils/reporter_for_tests.py
 pylint/testutils/testing_pylintrc
 pylint/testutils/tokenize_str.py
 pylint/testutils/unittest_linter.py
 pylint/testutils/utils.py
+pylint/testutils/_primer/__init__.py
+pylint/testutils/_primer/package_to_lint.py
+pylint/testutils/_primer/primer.py
+pylint/testutils/_primer/primer_command.py
+pylint/testutils/_primer/primer_compare_command.py
+pylint/testutils/_primer/primer_prepare_command.py
+pylint/testutils/_primer/primer_run_command.py
 pylint/testutils/functional/__init__.py
 pylint/testutils/functional/find_functional_tests.py
 pylint/testutils/functional/lint_module_output_update.py
 pylint/testutils/functional/test_file.py
 pylint/utils/__init__.py
 pylint/utils/ast_walker.py
 pylint/utils/docs.py
```

