# Comparing `tmp/dashscope-1.3.1-py3-none-any.whl.zip` & `tmp/dashscope-1.4.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,49 +1,48 @@
-Zip file size: 56152 bytes, number of entries: 47
--rw-r--r--  2.0 unx     1131 b- defN 23-Jun-20 06:30 dashscope/__init__.py
--rw-r--r--  2.0 unx    13474 b- defN 23-May-16 06:21 dashscope/cli.py
--rw-r--r--  2.0 unx     3445 b- defN 23-Mar-30 08:43 dashscope/deployment.py
--rw-r--r--  2.0 unx     3753 b- defN 23-Mar-30 08:43 dashscope/file.py
--rw-r--r--  2.0 unx     4808 b- defN 23-Mar-30 08:43 dashscope/finetune.py
--rw-r--r--  2.0 unx     1696 b- defN 23-Mar-30 08:43 dashscope/model.py
--rw-r--r--  2.0 unx       22 b- defN 23-Jun-25 08:03 dashscope/version.py
--rw-r--r--  2.0 unx      239 b- defN 23-May-16 06:21 dashscope/aigc/__init__.py
--rw-r--r--  2.0 unx     8844 b- defN 23-May-17 12:24 dashscope/aigc/conversation.py
--rw-r--r--  2.0 unx     5084 b- defN 23-Jun-25 08:03 dashscope/aigc/generation.py
--rw-r--r--  2.0 unx     7669 b- defN 23-May-16 06:21 dashscope/aigc/image_synthesis.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-23 09:23 dashscope/api_entities/__init__.py
--rw-r--r--  2.0 unx    10361 b- defN 23-Apr-06 08:21 dashscope/api_entities/aiohttp_request.py
--rw-r--r--  2.0 unx     5331 b- defN 23-May-30 06:21 dashscope/api_entities/api_request_data.py
--rw-r--r--  2.0 unx     4057 b- defN 23-Apr-06 03:24 dashscope/api_entities/api_request_factory.py
--rw-r--r--  2.0 unx      928 b- defN 23-May-24 01:18 dashscope/api_entities/base_request.py
--rw-r--r--  2.0 unx     9654 b- defN 23-Jun-20 06:30 dashscope/api_entities/dashscope_response.py
--rw-r--r--  2.0 unx     9456 b- defN 23-Jun-20 06:30 dashscope/api_entities/http_request.py
--rw-r--r--  2.0 unx     8798 b- defN 23-Apr-05 03:15 dashscope/api_entities/sync_http_request.py
--rw-r--r--  2.0 unx    15705 b- defN 23-May-16 06:21 dashscope/api_entities/websocket_request.py
--rw-r--r--  2.0 unx       45 b- defN 23-Jun-20 06:30 dashscope/audio/__init__.py
--rw-r--r--  2.0 unx       75 b- defN 23-Apr-04 06:54 dashscope/audio/asr/__init__.py
--rw-r--r--  2.0 unx     6946 b- defN 23-Apr-04 01:24 dashscope/audio/asr/transcribe.py
--rw-r--r--  2.0 unx     5103 b- defN 23-Apr-10 06:30 dashscope/audio/asr/transcription.py
--rw-r--r--  2.0 unx      194 b- defN 23-Jun-20 06:30 dashscope/audio/tts/__init__.py
--rw-r--r--  2.0 unx     7425 b- defN 23-Jun-20 06:30 dashscope/audio/tts/speech_synthesizer.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-23 09:23 dashscope/client/__init__.py
--rw-r--r--  2.0 unx    25911 b- defN 23-Jun-20 06:30 dashscope/client/base_api.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-23 09:23 dashscope/common/__init__.py
--rw-r--r--  2.0 unx     1986 b- defN 23-Mar-23 09:23 dashscope/common/api_key.py
--rw-r--r--  2.0 unx     2249 b- defN 23-May-30 06:21 dashscope/common/constants.py
--rw-r--r--  2.0 unx      869 b- defN 23-Apr-10 12:54 dashscope/common/env.py
--rw-r--r--  2.0 unx     1592 b- defN 23-May-16 06:21 dashscope/common/error.py
--rw-r--r--  2.0 unx      984 b- defN 23-Mar-23 09:23 dashscope/common/logging.py
--rw-r--r--  2.0 unx     4038 b- defN 23-May-16 06:21 dashscope/common/utils.py
--rw-r--r--  2.0 unx       69 b- defN 23-May-30 06:21 dashscope/embeddings/__init__.py
--rw-r--r--  2.0 unx     1666 b- defN 23-May-30 06:21 dashscope/embeddings/text_embedding.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-23 09:23 dashscope/io/__init__.py
--rw-r--r--  2.0 unx     3941 b- defN 23-May-30 06:21 dashscope/io/input_output.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-23 09:23 dashscope/protocol/__init__.py
--rw-r--r--  2.0 unx      561 b- defN 23-Mar-23 09:23 dashscope/protocol/websocket.py
--rw-r--r--  2.0 unx    11413 b- defN 23-Jun-25 08:03 dashscope-1.3.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     7201 b- defN 23-Jun-25 08:03 dashscope-1.3.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-25 08:03 dashscope-1.3.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       50 b- defN 23-Jun-25 08:03 dashscope-1.3.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 23-Jun-25 08:03 dashscope-1.3.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     4049 b- defN 23-Jun-25 08:03 dashscope-1.3.1.dist-info/RECORD
-47 files, 200924 bytes uncompressed, 49650 bytes compressed:  75.3%
+Zip file size: 57311 bytes, number of entries: 46
+-rw-r--r--  2.0 unx     1131 b- defN 23-Jul-20 09:33 dashscope/__init__.py
+-rw-r--r--  2.0 unx    23035 b- defN 23-Jul-24 11:09 dashscope/cli.py
+-rw-r--r--  2.0 unx     4600 b- defN 23-Jul-24 11:09 dashscope/deployment.py
+-rw-r--r--  2.0 unx     3324 b- defN 23-Jul-24 11:09 dashscope/file.py
+-rw-r--r--  2.0 unx     5008 b- defN 23-Jul-24 11:09 dashscope/finetune.py
+-rw-r--r--  2.0 unx     1158 b- defN 23-Jul-24 11:09 dashscope/model.py
+-rw-r--r--  2.0 unx       22 b- defN 23-Jul-20 09:33 dashscope/version.py
+-rw-r--r--  2.0 unx      239 b- defN 23-Jul-20 09:33 dashscope/aigc/__init__.py
+-rw-r--r--  2.0 unx     8846 b- defN 23-Jul-24 11:09 dashscope/aigc/conversation.py
+-rw-r--r--  2.0 unx     5086 b- defN 23-Jul-24 11:09 dashscope/aigc/generation.py
+-rw-r--r--  2.0 unx     7669 b- defN 23-Jul-20 09:33 dashscope/aigc/image_synthesis.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-20 09:33 dashscope/api_entities/__init__.py
+-rw-r--r--  2.0 unx    10359 b- defN 23-Jul-24 11:09 dashscope/api_entities/aiohttp_request.py
+-rw-r--r--  2.0 unx     5272 b- defN 23-Jul-20 09:33 dashscope/api_entities/api_request_data.py
+-rw-r--r--  2.0 unx     4128 b- defN 23-Jul-24 11:09 dashscope/api_entities/api_request_factory.py
+-rw-r--r--  2.0 unx      926 b- defN 23-Jul-20 09:33 dashscope/api_entities/base_request.py
+-rw-r--r--  2.0 unx    11775 b- defN 23-Jul-20 09:33 dashscope/api_entities/dashscope_response.py
+-rw-r--r--  2.0 unx     9457 b- defN 23-Jul-20 09:33 dashscope/api_entities/http_request.py
+-rw-r--r--  2.0 unx    15844 b- defN 23-Jul-20 09:33 dashscope/api_entities/websocket_request.py
+-rw-r--r--  2.0 unx       45 b- defN 23-Jul-20 09:33 dashscope/audio/__init__.py
+-rw-r--r--  2.0 unx       68 b- defN 23-Jul-24 11:09 dashscope/audio/asr/__init__.py
+-rw-r--r--  2.0 unx    14281 b- defN 23-Jul-20 09:33 dashscope/audio/asr/recognition.py
+-rw-r--r--  2.0 unx     5103 b- defN 23-Jul-20 09:33 dashscope/audio/asr/transcription.py
+-rw-r--r--  2.0 unx      194 b- defN 23-Jul-20 09:33 dashscope/audio/tts/__init__.py
+-rw-r--r--  2.0 unx     7425 b- defN 23-Jul-20 09:33 dashscope/audio/tts/speech_synthesizer.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-20 09:33 dashscope/client/__init__.py
+-rw-r--r--  2.0 unx    33160 b- defN 23-Jul-24 11:09 dashscope/client/base_api.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-20 09:33 dashscope/common/__init__.py
+-rw-r--r--  2.0 unx     1986 b- defN 23-Jul-20 09:33 dashscope/common/api_key.py
+-rw-r--r--  2.0 unx     2317 b- defN 23-Jul-24 11:09 dashscope/common/constants.py
+-rw-r--r--  2.0 unx      869 b- defN 23-Jul-20 09:33 dashscope/common/env.py
+-rw-r--r--  2.0 unx     1592 b- defN 23-Jul-20 09:33 dashscope/common/error.py
+-rw-r--r--  2.0 unx      984 b- defN 23-Jul-20 09:33 dashscope/common/logging.py
+-rw-r--r--  2.0 unx     6410 b- defN 23-Jul-24 11:09 dashscope/common/utils.py
+-rw-r--r--  2.0 unx       69 b- defN 23-Jul-20 09:33 dashscope/embeddings/__init__.py
+-rw-r--r--  2.0 unx     1666 b- defN 23-Jul-20 09:33 dashscope/embeddings/text_embedding.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-20 09:33 dashscope/io/__init__.py
+-rw-r--r--  2.0 unx     3941 b- defN 23-Jul-20 09:33 dashscope/io/input_output.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-20 09:33 dashscope/protocol/__init__.py
+-rw-r--r--  2.0 unx      561 b- defN 23-Jul-20 09:33 dashscope/protocol/websocket.py
+-rw-r--r--  2.0 unx    11413 b- defN 23-Jul-25 03:45 dashscope-1.4.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     7201 b- defN 23-Jul-25 03:45 dashscope-1.4.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-25 03:45 dashscope-1.4.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       50 b- defN 23-Jul-25 03:45 dashscope-1.4.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 23-Jul-25 03:45 dashscope-1.4.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     3952 b- defN 23-Jul-25 03:45 dashscope-1.4.0.dist-info/RECORD
+46 files, 221268 bytes uncompressed, 50969 bytes compressed:  77.0%
```

## zipnote {}

```diff
@@ -48,27 +48,24 @@
 
 Filename: dashscope/api_entities/dashscope_response.py
 Comment: 
 
 Filename: dashscope/api_entities/http_request.py
 Comment: 
 
-Filename: dashscope/api_entities/sync_http_request.py
-Comment: 
-
 Filename: dashscope/api_entities/websocket_request.py
 Comment: 
 
 Filename: dashscope/audio/__init__.py
 Comment: 
 
 Filename: dashscope/audio/asr/__init__.py
 Comment: 
 
-Filename: dashscope/audio/asr/transcribe.py
+Filename: dashscope/audio/asr/recognition.py
 Comment: 
 
 Filename: dashscope/audio/asr/transcription.py
 Comment: 
 
 Filename: dashscope/audio/tts/__init__.py
 Comment: 
@@ -117,26 +114,26 @@
 
 Filename: dashscope/protocol/__init__.py
 Comment: 
 
 Filename: dashscope/protocol/websocket.py
 Comment: 
 
-Filename: dashscope-1.3.1.dist-info/LICENSE
+Filename: dashscope-1.4.0.dist-info/LICENSE
 Comment: 
 
-Filename: dashscope-1.3.1.dist-info/METADATA
+Filename: dashscope-1.4.0.dist-info/METADATA
 Comment: 
 
-Filename: dashscope-1.3.1.dist-info/WHEEL
+Filename: dashscope-1.4.0.dist-info/WHEEL
 Comment: 
 
-Filename: dashscope-1.3.1.dist-info/entry_points.txt
+Filename: dashscope-1.4.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: dashscope-1.3.1.dist-info/top_level.txt
+Filename: dashscope-1.4.0.dist-info/top_level.txt
 Comment: 
 
-Filename: dashscope-1.3.1.dist-info/RECORD
+Filename: dashscope-1.4.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## dashscope/cli.py

```diff
@@ -1,234 +1,363 @@
 #!/usr/bin/env python
 import argparse
-import json
 import sys
 import time
 from http import HTTPStatus
 
 import dashscope
 from dashscope.aigc import Generation
 from dashscope.common.constants import (DeploymentStatus, FilePurpose,
                                         TaskStatus)
 
 
+def print_failed_message(rsp):
+    print('Failed, request_id: %s, status_code: %s, code: %s, message: %s' %
+          (rsp.request_id, rsp.status_code, rsp.code, rsp.message))
+
+
 def text_generation(args):
     response = Generation.call(args.model, args.prompt, stream=args.stream)
     if args.stream:
         for rsp in response:
-            if rsp.status_code == 200:
+            if rsp.status_code == HTTPStatus.OK:
                 print(rsp.output)
+                print(rsp.usage)
+            else:
+                print_failed_message(rsp)
     else:
-        if response.status_code == 200:
+        if response.status_code == HTTPStatus.OK:
             print(response.output)
+            print(response.usage)
+        else:
+            print_failed_message(response)
 
 
 class FineTunes:
     @classmethod
     def call(cls, args):
-        hyper_parameters = None
-        if args.hyper_parameters:
-            hyper_parameters = json.loads(args.hyper_parameters)
+        params = {}
+        if args.n_epochs is not None:
+            params['n_epochs'] = args.n_epochs
+        if args.batch_size is not None:
+            params['batch_size'] = args.batch_size
+        if args.learning_rate is not None:
+            params['learning_rate'] = args.learning_rate
+        if args.prompt_loss is not None:
+            params['prompt_loss'] = args.prompt_loss
         rsp = dashscope.FineTune.call(
             model=args.model,
             training_file_ids=args.training_file_ids,
             validation_file_ids=args.validation_file_ids,
-            hyper_parameters=hyper_parameters)
+            mode=args.mode,
+            hyper_parameters=params)
         if rsp.status_code == HTTPStatus.OK:
             print('Create fine-tune job success, job_id: %s' %
                   rsp.output['job_id'])
             cls.wait(rsp.output['job_id'])
         else:
-            print('Failed, status_code: %s, code: %s, message: %s' %
-                  (rsp.status_code, rsp.code, rsp.message))
+            print_failed_message(rsp)
 
     @classmethod
     def wait(cls, job_id):
-        while True:
-            rsp = dashscope.FineTune.get(job_id)
-            if rsp.status_code == HTTPStatus.OK:
-                if rsp.output['status'] == TaskStatus.FAILED:
-                    print('Fine-tune failed!')
-                    break
-                elif rsp.output['status'] == TaskStatus.CANCELED:
-                    print('Fine-tune task canceled')
-                    break
-                elif rsp.output['status'] == TaskStatus.SUCCEEDED:
-                    print('Fine-tune task success, fine-tuned model:%s' %
-                          rsp.output['output_model'])
-                    break
+        try:
+            while True:
+                rsp = dashscope.FineTune.get(job_id)
+                if rsp.status_code == HTTPStatus.OK:
+                    if rsp.output['status'] == TaskStatus.FAILED:
+                        print('Fine-tune FAILED!')
+                        break
+                    elif rsp.output['status'] == TaskStatus.CANCELED:
+                        print('Fine-tune task CANCELED')
+                        break
+                    elif rsp.output['status'] == TaskStatus.RUNNING:
+                        print(
+                            'Fine-tuning is RUNNING, start get output stream.')
+                        cls.stream_events(job_id)
+                    elif rsp.output['status'] == TaskStatus.SUCCEEDED:
+                        print('Fine-tune task success, fine-tuned model:%s' %
+                              rsp.output['finetuned_output'])
+                        break
+                    else:
+                        print('The fine-tune task is: %s' %
+                              rsp.output['status'])
+                        time.sleep(30)
                 else:
-                    print('The fine-tune task is: %s' % rsp.output['status'])
-                    time.sleep(30)
-            else:
-                print('Failed, status_code: %s, code: %s, message: %s' %
-                      (rsp.status_code, rsp.code, rsp.message))
+                    print_failed_message(rsp)
+        except Exception:
+            print(
+                'You can stream output via: dashscope fine_tunes.stream -j %s'
+                % job_id)
 
     @classmethod
     def get(cls, args):
         rsp = dashscope.FineTune.get(args.job)
         if rsp.status_code == HTTPStatus.OK:
             if rsp.output['status'] == TaskStatus.FAILED:
                 print('Fine-tune failed!')
             elif rsp.output['status'] == TaskStatus.CANCELED:
                 print('Fine-tune task canceled')
             elif rsp.output['status'] == TaskStatus.SUCCEEDED:
                 print('Fine-tune task success, fine-tuned model : %s' %
-                      rsp.output['output_model'])
+                      rsp.output['finetuned_output'])
             else:
                 print('The fine-tune task is: %s' % rsp.output['status'])
         else:
-            print('Failed, status_code: %s, code: %s, message: %s' %
-                  (rsp.status_code, rsp.code, rsp.message))
+            print_failed_message(rsp)
 
     @classmethod
     def list(cls, args):
-        rsp = dashscope.FineTune.list()
+        rsp = dashscope.FineTune.list(page=args.start_page,
+                                      page_size=args.page_size)
         if rsp.status_code == HTTPStatus.OK:
-            for job in rsp.output['jobs']:
-                if job['status'] == TaskStatus.SUCCEEDED:
-                    print(
-                        'job: %s, status: %s, base model: %s, output model: %s'
-                        % (job['job_id'], job['status'], job['model'],
-                           job['output_model']))
+            if rsp.output is not None:
+                for job in rsp.output['jobs']:
+                    if job['status'] == TaskStatus.SUCCEEDED:
+                        print(
+                            'job: %s, status: %s, base model: %s, fine-tuned model: %s'  # noqa E501
+                            %  # noqa
+                            (job['job_id'], job['status'], job['model'],
+                             job['finetuned_output']))
+                    else:
+                        print('job: %s, status: %s, base model: %s' %
+                              (job['job_id'], job['status'], job['model']))
+            else:
+                print('There is no fine-tuned model.')
+        else:
+            print_failed_message(rsp)
+
+    @classmethod
+    def stream_events(cls, job_id):
+        # check job status if job is completed, get log.
+        rsp = dashscope.FineTune.get(job_id)
+        if rsp.status_code == HTTPStatus.OK:
+            if rsp.output['status'] in [
+                    TaskStatus.FAILED, TaskStatus.CANCELED,
+                    TaskStatus.SUCCEEDED
+            ]:
+                print('Fine-tune job: %s is %s' %
+                      (job_id, rsp.output['status']))
+                cls.log(job_id)
+                return
+        else:
+            print_failed_message(rsp)
+            return
+        # start streaming events.
+        try:
+            stream_events = dashscope.FineTune.stream_events(job_id)
+            for rsp in stream_events:
+                if rsp.status_code == HTTPStatus.OK:
+                    print(rsp.output)
                 else:
-                    print('job: %s, status: %s, base model: %s' %
-                          (job['job_id'], job['status'], job['model']))
+                    print_failed_message(rsp)
+        except Exception:
+            print(
+                'You can stream output via: dashscope fine-tunes.stream -j %s'
+                % job_id)
 
     @classmethod
     def events(cls, args):
-        rsp = dashscope.FineTune.stream_events(args.job)
-        if rsp.status_code == HTTPStatus.OK:
-            print('TODO process result.')
+        cls.stream_events(args.job)
 
     @classmethod
-    def follow(cls, args):
-        rsp = dashscope.FineTune.stream_events(args.job)
-        if rsp.status_code == HTTPStatus.OK:
-            print('TODO support future')
+    def log(cls, job_id):
+        start = 1
+        n_line = 1000  # 1000 line per request
+        while True:
+            rsp = dashscope.FineTune.logs(job_id, start, n_line)
+            if rsp.status_code == HTTPStatus.OK:
+                for line in rsp.output['logs']:
+                    print(line)
+                if rsp.output['total'] < n_line:
+                    break
+                else:
+                    start += n_line
+            else:
+                print_failed_message(rsp)
 
     @classmethod
     def cancel(cls, args):
         rsp = dashscope.FineTune.cancel(args.job)
         if rsp.status_code == HTTPStatus.OK:
-            print(rsp.output['message'])
+            print('Cancel fine-tune job: %s success!')
+        else:
+            print_failed_message(rsp)
+
+    @classmethod
+    def delete(cls, args):
+        rsp = dashscope.FineTune.delete(args.job)
+        if rsp.status_code == HTTPStatus.OK:
+            print('fine_tune job: %s delete success' % args.job)
+        else:
+            print_failed_message(rsp)
 
 
 class Files:
     @classmethod
     def upload(cls, args):
-        rsp = dashscope.File.upload(file_path=args.file, purpose=args.purpose)
+        rsp = dashscope.File.upload(file_path=args.file,
+                                    purpose=args.purpose,
+                                    description=args.description)
+        print(rsp)
         if rsp.status_code == HTTPStatus.OK:
             print('Upload success, file id: %s' %
-                  rsp.output['data']['success_data'][0]['file_id'])
+                  rsp.output['uploaded_files'][0]['file_id'])
         else:
-            print('Upload failed, reason: %s' % rsp.message)
+            print_failed_message(rsp)
 
     @classmethod
     def get(cls, args):
         rsp = dashscope.File.get(file_id=args.id)
         if rsp.status_code == HTTPStatus.OK:
             print('file_id: %s, name: %s, description: %s' %
-                  (rsp.output['data']['file_id'], rsp.output['data']['name'],
-                   rsp.output['data']['description']))
+                  (rsp.output['file_id'], rsp.output['name'],
+                   rsp.output['description']))
         else:
-            print('Get file failed, reason: %s' % rsp.message)
+            print_failed_message(rsp)
 
     @classmethod
     def list(cls, args):
-        rsp = dashscope.File.list()
+        rsp = dashscope.File.list(page=args.start_page,
+                                  page_size=args.page_size)
         if rsp.status_code == HTTPStatus.OK:
-            print('Files')
-            for f in rsp.output['data']['files']:
-                print('file_id: %s, name: %s, description: %s' %
-                      (f['file_id'], f['name'], f['description']))
+            if rsp.output is not None:
+                for f in rsp.output['files']:
+                    print('file_id: %s, name: %s, description: %s, time: %s' %
+                          (f['file_id'], f['name'], f['description'],
+                           f['gmt_create']))
+            else:
+                print('There is no uploaded file.')
         else:
-            print('List failed, reason: %s' % rsp.message)
+            print_failed_message(rsp)
 
     @classmethod
     def delete(cls, args):
         rsp = dashscope.File.delete(args.id)
         if rsp.status_code == HTTPStatus.OK:
             print('Delete success')
         else:
-            print('Delete failed, reason: %s' % rsp.message)
+            print_failed_message(rsp)
 
 
 class Deployments:
     @classmethod
     def call(cls, args):
-        rsp = dashscope.Deployment.call(model=args.model, suffix=args.suffix)
+        rsp = dashscope.Deployment.call(model=args.model, capacity=args.capacity, suffix=args.suffix)
         if rsp.status_code == HTTPStatus.OK:
-            deployment_id = rsp.output['deployment_id']
-            print('Create deployment id: %s' % deployment_id)
-            while True:  # wait for deployment ok.
-                status = dashscope.Deployment.get(deployment_id)
-                if status.status_code == HTTPStatus.OK:
-                    if status.output['status'] == DeploymentStatus.DEPLOYING:
-                        time.sleep(30)
-                        print('Deployment %s is deploying' % deployment_id)
-                    else:
-                        print('Deployment: %s status: %s' %
-                              (deployment_id, status.output['status']))
-                        break
+            deployed_model = rsp.output['deployed_model']
+            print('Create model: %s deployment' % deployed_model)
+            try:
+                while True:  # wait for deployment ok.
+                    status = dashscope.Deployment.get(deployed_model)
+                    if status.status_code == HTTPStatus.OK:
+                        if status.output['status'] in [
+                                DeploymentStatus.PENDING,
+                                DeploymentStatus.DEPLOYING
+                        ]:
+                            time.sleep(30)
+                            print('Deployment %s is %s' %
+                                  (deployed_model, status.output['status']))
+                        else:
+                            print('Deployment: %s status: %s' %
+                                  (deployed_model, status.output['status']))
+                            break
 
-                else:
-                    print('Get deployment %s failed, code: %s, message: %s' %
-                          (deployment_id, rsp.code, rsp.message))
+                    else:
+                        print_failed_message(rsp)
+            except Exception:
+                print('You can get deployment status via: \
+                        dashscope deployments.get -d %s' % deployed_model)
         else:
-            print(('Create deployment failed, status_code: %s, \
-                    code: %s, message: %s') %
-                  (rsp.status_code, rsp.code, rsp.message))
+            print_failed_message(rsp)
 
     @classmethod
     def get(cls, args):
-        rsp = dashscope.Deployment.get(args.id)
+        rsp = dashscope.Deployment.get(args.deploy)
         if rsp.status_code == HTTPStatus.OK:
-            print('Deployment %s status: %s' % (args.id, rsp.output['status']))
+            print('Deployed model: %s capacity: %s status: %s' %
+                  (rsp.output['deployed_model'], rsp.output['capacity'], rsp.output['status']))
         else:
-            print('Get failed, status_code: %s, code: %s, message: %s' %
-                  (rsp.status_code, rsp.code, rsp.message))
+            print_failed_message(rsp)
 
     @classmethod
     def list(cls, args):
-        rsp = dashscope.Deployment.list()  # TODO page.
+        rsp = dashscope.Deployment.list(page_no=args.start_page,
+                                        page_size=args.page_size)
         if rsp.status_code == HTTPStatus.OK:
-            if 'deployments' in rsp.output:
+            if rsp.output is not None:
+                if 'deployments' not in rsp.output:
+                    print('There is no deployed model!')
+                    return
                 for deployment in rsp.output['deployments']:
-                    print('Deployment: %s, model: %s, status: %s' %
-                          (deployment['deployment_id'], deployment['model'],
+                    print('Deployed_model: %s, model: %s, status: %s' %
+                          (deployment['deployed_model'],
+                           deployment['model_name'],
                            deployment['status']))
             else:
-                print('There is no deployments!')
-
+                print('There is no deployed model.')
+        else:
+            print_failed_message(rsp)
+    @classmethod
+    def update(cls, args):
+        rsp = dashscope.Deployment.update(args.deployed_model, args.version)
+        if rsp.status_code == HTTPStatus.OK:
+            if rsp.output is not None:
+                if 'deployments' not in rsp.output:
+                    print('There is no deployed model!')
+                    return
+                for deployment in rsp.output['deployments']:
+                    print('Deployed_model: %s, model: %s, status: %s' %
+                          (deployment['deployed_model'],
+                           deployment['model_name'],
+                           deployment['status']))
+            else:
+                print('There is no deployed model.')
+        else:
+            print_failed_message(rsp)
+    @classmethod
+    def scale(cls, args):
+        rsp = dashscope.Deployment.scale(args.deployed_model, args.capacity)
+        if rsp.status_code == HTTPStatus.OK:
+            if rsp.output is not None:
+                print('Deployed_model: %s, model: %s, status: %s' %
+                        (rsp.output['deployed_model'],
+                        rsp.output['model_name'],
+                        rsp.output['status']))
+            else:
+                print('There is no deployed model.')
+        else:
+            print_failed_message(rsp)
+            
     @classmethod
     def delete(cls, args):
-        rsp = dashscope.Deployment.delete(args.id)
+        rsp = dashscope.Deployment.delete(args.deploy)
         if rsp.status_code == HTTPStatus.OK:
-            print(rsp.output['message'])
+            print('Deployed model: %s delete success' % args.deploy)
         else:
-            print('Delete failed, status_code: %s, code: %s, message: %s' %
-                  (rsp.status_code, rsp.code, rsp.message))
+            print_failed_message(rsp)
 
 
 def main():
     parser = argparse.ArgumentParser(
         prog='dashscope', description='dashscope command line tools.')
     parser.add_argument('-k', '--api-key', help='Dashscope API key.')
     sub_parsers = parser.add_subparsers(help='Api subcommands')
     text_generation_parser = sub_parsers.add_parser('generation.call')
     text_generation_parser.add_argument('-p',
                                         '--prompt',
+                                        type=str,
                                         required=True,
                                         help='Input prompt')
     text_generation_parser.add_argument('-m',
                                         '--model',
+                                        type=str,
                                         required=True,
                                         help='The model to call.')
     text_generation_parser.add_argument('--history',
+                                        type=str,
                                         required=False,
                                         help='The history of the request.')
     text_generation_parser.add_argument('-s',
                                         '--stream',
                                         default=False,
                                         action='store_true',
                                         help='Use stream mode default false.')
@@ -245,90 +374,190 @@
         '--validation_file_ids',
         required=False,
         nargs='+',
         default=[],
         help='Validation file ids which upload by File command.')
     fine_tune_call.add_argument('-m',
                                 '--model',
+                                type=str,
                                 required=True,
                                 help='The based model to start fine-tune.')
-    fine_tune_call.add_argument(
-        '-p',
-        '--hyper_parameters',
-        required=False,
-        help='The fine-tune hyper parameters, json string.')
+    fine_tune_call.add_argument('--mode',
+                                type=str,
+                                required=False,
+                                choices=['sft', 'efficient_sft'],
+                                help='Select fine-tune mode sft or efficient_sft')
+    fine_tune_call.add_argument('-e',
+                                '--n_epochs',
+                                type=int,
+                                required=False,
+                                help='How many epochs to fine-tune.')
+    fine_tune_call.add_argument('-b',
+                                '--batch_size',
+                                type=int,
+                                required=False,
+                                help='How big is batch_size.')
+    fine_tune_call.add_argument('-l',
+                                '--learning_rate',
+                                type=float,
+                                required=False,
+                                help='The fine-tune learning rate.')
+    fine_tune_call.add_argument('-p',
+                                '--prompt_loss',
+                                type=float,
+                                required=False,
+                                help='The fine-tune prompt loss.')
     fine_tune_call.set_defaults(func=FineTunes.call)
     fine_tune_get = sub_parsers.add_parser('fine_tunes.get')
     fine_tune_get.add_argument('-j',
                                '--job',
+                               type=str,
                                required=True,
                                help='The fine-tune job id.')
     fine_tune_get.set_defaults(func=FineTunes.get)
+    fine_tune_delete = sub_parsers.add_parser('fine_tunes.delete')
+    fine_tune_delete.add_argument('-j',
+                                  '--job',
+                                  type=str,
+                                  required=True,
+                                  help='The fine-tune job id.')
+    fine_tune_delete.set_defaults(func=FineTunes.delete)
+    fine_tune_stream = sub_parsers.add_parser('fine_tunes.stream')
+    fine_tune_stream.add_argument('-j',
+                                  '--job',
+                                  type=str,
+                                  required=True,
+                                  help='The fine-tune job id.')
+    fine_tune_stream.set_defaults(func=FineTunes.events)
     fine_tune_list = sub_parsers.add_parser('fine_tunes.list')
+    fine_tune_list.add_argument('-s',
+                                '--start_page',
+                                type=int,
+                                default=1,
+                                help='Start of page, default 1')
+    fine_tune_list.add_argument('-p',
+                                '--page_size',
+                                type=int,
+                                default=10,
+                                help='The page size, default 10')
     fine_tune_list.set_defaults(func=FineTunes.list)
     fine_tune_cancel = sub_parsers.add_parser('fine_tunes.cancel')
     fine_tune_cancel.add_argument('-j',
                                   '--job',
+                                  type=str,
                                   required=True,
                                   help='The fine-tune job id.')
     fine_tune_cancel.set_defaults(func=FineTunes.cancel)
 
     file_upload = sub_parsers.add_parser('files.upload')
     file_upload.add_argument(
         '-f',
         '--file',
+        type=str,
         required=True,
         help='The file path to upload',
     )
     file_upload.add_argument(
         '-p',
         '--purpose',
         default=FilePurpose.fine_tune,
         const=FilePurpose.fine_tune,
         nargs='?',
-        choices=[FilePurpose.fine_tune],
         help='Purpose to upload file[fine-tune]',
         required=True,
     )
+    file_upload.add_argument(
+        '-d',
+        '--description',
+        type=str,
+        help='The file description.',
+        required=False,
+    )
     file_upload.set_defaults(func=Files.upload)
     file_get = sub_parsers.add_parser('files.get')
-    file_get.add_argument('-i', '--id', required=True, help='The file ID')
+    file_get.add_argument('-i',
+                          '--id',
+                          type=str,
+                          required=True,
+                          help='The file ID')
     file_get.set_defaults(func=Files.get)
     file_delete = sub_parsers.add_parser('files.delete')
-    file_delete.add_argument('-i', '--id', required=True, help='The files ID')
+    file_delete.add_argument('-i',
+                             '--id',
+                             type=str,
+                             required=True,
+                             help='The files ID')
     file_delete.set_defaults(func=Files.delete)
     file_list = sub_parsers.add_parser('files.list')
+    file_list.add_argument('-s',
+                           '--start_page',
+                           type=int,
+                           default=1,
+                           help='Start of page, default 1')
+    file_list.add_argument('-p',
+                           '--page_size',
+                           type=int,
+                           default=10,
+                           help='The page size, default 10')
     file_list.set_defaults(func=Files.list)
 
     deployments_call = sub_parsers.add_parser('deployments.call')
     deployments_call.add_argument('-m',
                                   '--model',
                                   required=True,
                                   help='The model ID')
     deployments_call.add_argument('-s',
                                   '--suffix',
                                   required=False,
                                   help=('The suffix of the deployment, \
             lower cased characters 8 chars max.'))
+    deployments_call.add_argument('-c',
+                                  '--capacity',
+                                  type=int,
+                                  required=False,
+                                  default=1,
+                                  help='The target capacity')
     deployments_call.set_defaults(func=Deployments.call)
 
     deployments_get = sub_parsers.add_parser('deployments.get')
-    deployments_get.add_argument('-i',
-                                 '--id',
+    deployments_get.add_argument('-d',
+                                 '--deploy',
                                  required=True,
-                                 help='The deployment ID')
+                                 help='The deployed model.')
     deployments_get.set_defaults(func=Deployments.get)
     deployments_delete = sub_parsers.add_parser('deployments.delete')
-    deployments_delete.add_argument('-i',
-                                    '--id',
+    deployments_delete.add_argument('-d',
+                                    '--deploy',
                                     required=True,
-                                    help='The deployment ID')
+                                    help='The deployed model.')
     deployments_delete.set_defaults(func=Deployments.delete)
     deployments_list = sub_parsers.add_parser('deployments.list')
+    deployments_list.add_argument('-s',
+                                  '--start_page',
+                                  type=int,
+                                  default=1,
+                                  help='Start of page, default 1')
+    deployments_list.add_argument('-p',
+                                  '--page_size',
+                                  type=int,
+                                  default=10,
+                                  help='The page size, default 10')
     deployments_list.set_defaults(func=Deployments.list)
+    deployments_scale = sub_parsers.add_parser('deployments.scale')
+    deployments_scale.add_argument('-d',
+                                  '--deployed_model',
+                                  type=str,
+                                  required=True,
+                                  help='The deployed model to scale')
+    deployments_scale.add_argument('-c',
+                                  '--capacity',
+                                  type=int,
+                                  required=True,
+                                  help='The target capacity')
+    deployments_scale.set_defaults(func=Deployments.scale)
 
     args = parser.parse_args()
     if args.api_key is not None:
         dashscope.api_key = args.api_key
     args.func(args)
```

## dashscope/deployment.py

```diff
@@ -1,88 +1,85 @@
-import asyncio
-from typing import Any
+from dataclasses import dataclass
 
-from dashscope.api_entities.dashscope_response import DashScopeAPIResponse
+from dashscope.api_entities.dashscope_response import (DashScopeAPIResponse,
+                                                       DictMixin)
 from dashscope.client.base_api import (CreateMixin, DeleteMixin, GetMixin,
-                                       ListMixin, StreamEventMixin)
-
+                                       ListMixin, PutMixin, StreamEventMixin)
+from dashscope.common.error import InvalidParameter
 
 class Deployment(CreateMixin, DeleteMixin, ListMixin, GetMixin,
-                 StreamEventMixin):
+                 StreamEventMixin, PutMixin):
     SUB_PATH = 'deployments'
     """Deploy a model.
     """
     @classmethod
     def call(cls,
              model: str,
-             scale: Any = None,
+             capacity: int,
+             version: str = None,
              suffix: str = None,
              api_key: str = None,
              **kwargs) -> DashScopeAPIResponse:
-        """Deploy a model service.
+        """Call to deployment a model service.
 
         Args:
-            model (str): The model id.
-            scale (Any): Currently not supported.
-            suffix (str, optional): The name suffix of the deployment,
-               default: model_a_b_c, with suffix will be:
-               model_suffix.
-            api_key (str, optional): The api api_key, can be None,
-                if None, will get by default rule(TODO: api key doc).
+            model (str): The model name.
+            version (str, optional): The model version, unnecessary
+                for fine-tuned model. Defaults to None.
+            suffix (str, optional): The name suffix of the model deployment,
+                If specified, the final model name will be model_suffix.
+                Defaults to None.
+            capacity (int, optional): The model service capacity.
+            api_key (str, optional): The api-key. Defaults to None.
 
         Returns:
-            DashScopeAPIResponse: The request result.
+            DashScopeAPIResponse: _description_
         """
-        req = {'model': model, 'suffix': suffix}
-        return asyncio.run(super().async_call(req, api_key, **kwargs))
+        req = {'model_name': model, 'capacity': capacity}
+        
+        if version is not None:
+            req['model_version'] = version
+        if suffix is not None:
+            req['suffix'] = suffix
+        return super().call(req, api_key, **kwargs)
 
     @classmethod
     def list(cls,
+             page_no=1,
+             page_size=10,
              api_key: str = None,
-             limits=10,
-             page=1,
-             per_page=10,
-             offset=1,
-             sortby='id',
-             order='asc',
              **kwargs) -> DashScopeAPIResponse:
         """List deployments.
 
         Args:
             api_key (str, optional): The api api_key, if not present,
                 will get by default rule(TODO: api key doc). Defaults to None.
-            limits (int, optional): Total return items. Defaults to 10.
-            page (int, optional): Page number. Defaults to 1.
-            per_page (int, optional): Items per page. Defaults to 10.
-            offset (int, optional): Item start position. Defaults to 1.
-            sortby (str, optional): Items sort by. Defaults to 'id'.
-            order (str, optional): Items order['desc', 'asc'].
-                Defaults to 'asc'.
+            page_no (int, optional): Page number. Defaults to 1.
+            page_size (int, optional): Items per page. Defaults to 10.
 
         Returns:
             DashScopeAPIResponse: The deployment list.
         """
-        return asyncio.run(super().async_list(api_key, limits, per_page,
-                                              offset, sortby, order, **kwargs))
+        return super().list(page_no, page_size, api_key, **kwargs)
 
     @classmethod
     def get(cls,
-            deployment_id: str,
+            deployed_model: str,
             api_key: str = None,
             **kwargs) -> DashScopeAPIResponse:
         """Get model deployment information.
 
         Args:
-            deployment_id (str): The deployment_id.
+            deployed_model (str): The deployment_id.
             api_key (str, optional): The api key. Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The deployment information.
         """
-        return asyncio.run(super().async_get(deployment_id, api_key, **kwargs))
+        return super().get(deployed_model, api_key, **kwargs)
 
     @classmethod
     def delete(cls,
                deployment_id: str,
                api_key: str = None,
                **kwargs) -> DashScopeAPIResponse:
         """Delete model deployment.
@@ -90,9 +87,48 @@
         Args:
             deployment_id (str): The deployment id.
             api_key (str, optional): The api key. Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The delete result.
         """
-        return asyncio.run(super().async_delete(deployment_id, api_key,
-                                                **kwargs))
+        return super().delete(deployment_id, api_key, **kwargs)
+    
+    @classmethod
+    def update(cls,
+               deployment_id: str,
+               version: str,
+               api_key: str = None,
+               **kwargs) -> DashScopeAPIResponse:
+        """Update model deployment.
+
+        Args:
+            deployment_id (str): The deployment id.
+            version (str): The target model version.
+            api_key (str, optional): The api key. Defaults to None.
+
+        Returns:
+            DashScopeAPIResponse: The delete result.
+        """
+        req = {'deployment_model': deployment_id,
+               'model_version': version}
+        return super().put(deployment_id, req, api_key, **kwargs)
+
+    @classmethod
+    def scale(cls,
+               deployment_id: str,
+               capacity: int,
+               api_key: str = None,
+               **kwargs) -> DashScopeAPIResponse:
+        """Scaling model deployment.
+
+        Args:
+            deployment_id (str): The deployment id.
+            capacity (int): The target service capacity.
+            api_key (str, optional): The api key. Defaults to None.
+
+        Returns:
+            DashScopeAPIResponse: The delete result.
+        """
+        req = {'deployed_model': deployment_id,
+               'capacity': capacity}
+        return super().put(deployment_id, req, 'scale', api_key, **kwargs)
```

## dashscope/file.py

```diff
@@ -1,8 +1,8 @@
-import asyncio
+import os
 
 from dashscope.api_entities.dashscope_response import DashScopeAPIResponse
 from dashscope.client.base_api import (DeleteMixin, FileUploadMixin, GetMixin,
                                        ListMixin)
 from dashscope.common.constants import FilePurpose
 from dashscope.common.error import InvalidFileFormat
 from dashscope.common.utils import is_validate_fine_tune_file
@@ -30,49 +30,40 @@
             DashScopeAPIResponse: The upload information
         """
         if purpose == FilePurpose.fine_tune:
             if not is_validate_fine_tune_file(file_path):
                 raise InvalidFileFormat(
                     'The file %s is not in valid jsonl format' % file_path)
         with open(file_path, 'rb') as f:
-            return asyncio.run(super().async_upload(
-                files=[('files', f, None)],
-                descriptions=[description]
-                if description is not None else None,
-                api_key=api_key,
-                **kwargs))
+            return super().upload(files=[('files', (os.path.basename(f.name),
+                                                    f, None))],
+                                  descriptions=[description]
+                                  if description is not None else None,
+                                  api_key=api_key,
+                                  **kwargs)
 
     @classmethod
     def list(cls,
-             api_key: str = None,
-             limits=10,
              page=1,
-             per_page=10,
-             offset=1,
-             sortby='id',
-             order='asc',
+             page_size=10,
+             api_key: str = None,
              **kwargs) -> DashScopeAPIResponse:
         """List uploaded files.
 
         Args:
             api_key (str, optional):
             The api api_key, can be None,
                 if None, will get by default rule(TODO: api key doc).
-            limits (int, optional): Total return items. Defaults to 10.
             page (int, optional): Page number. Defaults to 1.
-            per_page (int, optional): Items per page. Defaults to 10.
-            offset (int, optional): Item start position. Defaults to 1.
-            sortby (str, optional): Items sort by. Defaults to 'id'.
-            order (str, optional): Items order['desc', 'asc'].
-                Defaults to 'asc'.
+            page_size (int, optional): Items per page. Defaults to 10.
+
         Returns:
             DashScopeAPIResponse: The fine-tune jobs in the result.
         """
-        return asyncio.run(super().async_list(api_key, limits, page, per_page,
-                                              offset, sortby, order, **kwargs))
+        return super().list(page, page_size, api_key, **kwargs)
 
     @classmethod
     def get(cls,
             file_id: str,
             api_key: str = None,
             **kwargs) -> DashScopeAPIResponse:
         """Get the file info.
@@ -80,15 +71,15 @@
         Args:
             file_id (str): The file id.
             api_key (str, optional): The api key. Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The job info
         """
-        return asyncio.run(super().async_get(file_id, api_key, **kwargs))
+        return super().get(file_id, api_key, **kwargs)
 
     @classmethod
     def delete(cls,
                file_id: str,
                api_key: str = None,
                **kwargs) -> DashScopeAPIResponse:
         """Delete uploaded file.
@@ -96,8 +87,8 @@
         Args:
             file_id (str): The file id want to delete.
             api_key (str, optional): The api key. Defaults to None.
 
         Returns:
             DashScopeAPIResponse: Delete result.
         """
-        return asyncio.run(super().async_delete(file_id, api_key, **kwargs))
+        return super().delete(file_id, api_key, **kwargs)
```

## dashscope/finetune.py

```diff
@@ -1,49 +1,53 @@
-import asyncio
 from typing import Union
 
 from dashscope.api_entities.dashscope_response import DashScopeAPIResponse
 from dashscope.client.base_api import (CancelMixin, CreateMixin, DeleteMixin,
-                                       GetMixin, ListMixin, StreamEventMixin)
+                                       GetStatusMixin, ListMixin, LogMixin,
+                                       StreamEventMixin)
 
 
-class FineTune(CreateMixin, CancelMixin, DeleteMixin, ListMixin, GetMixin,
-               StreamEventMixin):
+class FineTune(CreateMixin, CancelMixin, DeleteMixin, ListMixin,
+               GetStatusMixin, StreamEventMixin, LogMixin):
     SUB_PATH = 'fine-tunes'
 
     @classmethod
     def call(cls,
              model: str,
              training_file_ids: Union[list, str],
              validation_file_ids: Union[list, str] = None,
+             mode: str = None,
              hyper_parameters: dict = {},
              api_key: str = None,
              **kwargs) -> DashScopeAPIResponse:
         """Create fine-tune job
 
         Args:
             model (str): The model to be fine-tuned
             training_file_ids (list, str): Ids of the fine-tune training data,
                 which can be pre-uploaded using the File API.
             validation_file_ids ([list,str], optional): Ids of the fine-tune
                 validating data, which can be pre-uploaded using the File API.
+            mode (str): The fine-tune mode, sft or efficient_sft.
             hyper_parameters (dict, optional): The fine-tune hyper parameters.
                 Defaults to empty.
             api_key (str, optional): The api key. Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The request result.
         """
         request = {
             'model': model,
             'training_file_ids': training_file_ids,
             'validation_file_ids': validation_file_ids,
             'hyper_parameters': hyper_parameters if hyper_parameters else {},
         }
-        return asyncio.run(super().async_call(request, api_key, **kwargs))
+        if mode is not None:
+            request["training_type"] = mode
+        return super().call(request, api_key, **kwargs)
 
     @classmethod
     def cancel(cls,
                job_id: str,
                api_key: str = None,
                **kwargs) -> DashScopeAPIResponse:
         """Cancel a running fine-tune job.
@@ -52,43 +56,33 @@
             job_id (str): The fine-tune job id.
             api_key (str, optional): The api api_key, can be None,
                 if None, will get by default rule(TODO: api key doc).
 
         Returns:
             DashScopeAPIResponse: The request result.
         """
-        return asyncio.run(super().async_cancel(job_id, api_key, **kwargs))
+        return super().cancel(job_id, api_key, **kwargs)
 
     @classmethod
     def list(cls,
-             api_key: str = None,
-             limits=10,
              page=1,
-             per_page=10,
-             offset=1,
-             sortby='id',
-             order='asc',
+             page_size=10,
+             api_key: str = None,
              **kwargs) -> DashScopeAPIResponse:
         """List fine-tune job.
 
         Args:
             api_key (str, optional): The api key
-            limits (int, optional): Total return items. Defaults to 10.
             page (int, optional): Page number. Defaults to 1.
-            per_page (int, optional): Items per page. Defaults to 10.
-            offset (int, optional): Item start position. Defaults to 1.
-            sortby (str, optional): Items sort by. Defaults to 'id'.
-            order (str, optional): Items order['desc', 'asc'].
-                Defaults to 'asc'.
+            page_size (int, optional): Items per page. Defaults to 10.
 
         Returns:
             DashScopeAPIResponse: The fine-tune jobs in the result.
         """
-        return asyncio.run(super().async_list(api_key, limits, page, per_page,
-                                              offset, sortby, order, **kwargs))
+        return super().list(page, page_size, api_key, **kwargs)
 
     @classmethod
     def get(cls,
             job_id: str,
             api_key: str = None,
             **kwargs) -> DashScopeAPIResponse:
         """Get fine-tune job information.
@@ -96,15 +90,15 @@
         Args:
             job_id (str): The fine-tune job id
             api_key (str, optional): The api key. Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The job info
         """
-        return asyncio.run(super().async_get(job_id, api_key, **kwargs))
+        return super().get(job_id, api_key, **kwargs)
 
     @classmethod
     def delete(cls,
                job_id: str,
                api_key: str = None,
                **kwargs) -> DashScopeAPIResponse:
         """Delete a fine-tune job.
@@ -112,15 +106,15 @@
         Args:
             job_id (str): The fine-tune job id.
             api_key (str, optional): The api key. Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The delete result.
         """
-        return asyncio.run(super().async_delete(job_id, api_key, **kwargs))
+        return super().delete(job_id, api_key, **kwargs)
 
     @classmethod
     def stream_events(cls,
                       job_id: str,
                       api_key: str = None,
                       **kwargs) -> DashScopeAPIResponse:
         """Get fine-tune job events.
@@ -128,9 +122,28 @@
         Args:
             job_id (str): The fine-tune job id
             api_key (str, optional): the api key. Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The job log events.
         """
-        return asyncio.run(super().async_stream_events(job_id, api_key,
-                                                       **kwargs))
+        return super().stream_events(job_id, api_key, **kwargs)
+
+    @classmethod
+    def logs(cls,
+             job_id: str,
+             offset=1,
+             line=1000,
+             api_key: str = None,
+             **kwargs) -> DashScopeAPIResponse:
+        """Get log of the job.
+
+        Args:
+            job_id (str): The job id(used for fine-tune)
+            offset (int, optional): start log line. Defaults to 1.
+            line (int, optional): total line return. Defaults to 1000.
+            api_key (str, optional): The api key. Defaults to None.
+
+        Returns:
+            DashScopeAPIResponse: The response
+        """
+        return super().logs(job_id, offset, line)
```

## dashscope/model.py

```diff
@@ -1,9 +1,7 @@
-import asyncio
-
 from dashscope.api_entities.dashscope_response import DashScopeAPIResponse
 from dashscope.client.base_api import GetMixin, ListMixin
 
 
 class Model(ListMixin, GetMixin):
     SUB_PATH = 'models'
 
@@ -17,36 +15,26 @@
         Args:
             name (str): The model name.
             api_key (str, optional): The api key. Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The model information.
         """
-        return asyncio.run(super().async_get(name, api_key, **kwargs))
+        return super().get(name, api_key, **kwargs)
 
     @classmethod
     def list(cls,
-             api_key: str = None,
-             limits=10,
              page=1,
-             per_page=10,
-             offset=1,
-             sortby='id',
-             order='asc',
+             page_size=10,
+             api_key: str = None,
              **kwargs) -> DashScopeAPIResponse:
         """List models.
 
         Args:
             api_key (str, optional): The api key
-            limits (int, optional): Total return items. Defaults to 10.
             page (int, optional): Page number. Defaults to 1.
-            per_page (int, optional): Items per page. Defaults to 10.
-            offset (int, optional): Item start position. Defaults to 1.
-            sortby (str, optional): Items sort by. Defaults to 'id'.
-            order (str, optional): Items order['desc', 'asc'].
-                Defaults to 'asc'.
+            page_size (int, optional): Items per page. Defaults to 10.
 
         Returns:
             DashScopeAPIResponse: The models.
         """
-        return asyncio.run(super().async_list(api_key, limits, page, per_page,
-                                              offset, sortby, order, **kwargs))
+        return super().list(api_key, page, page_size, **kwargs)
```

## dashscope/version.py

```diff
@@ -1 +1 @@
-__version__ = '1.3.1'
+__version__ = '1.4.0'
```

## dashscope/aigc/conversation.py

```diff
@@ -134,15 +134,15 @@
                 stream(bool, `optional`): Enable server-sent events
                     (ref: https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events)  # noqa E501
                     the result will back partially.
                 max_length(int, `optional`): The maximum length of tokens to
                     generate. The token count of your prompt plus max_length
                     cannot exceed the model's context length. Most models
                     have a context length of 2000 tokens.
-                top_p(int, `optional`): A sampling strategy, called nucleus
+                top_p(float, `optional`): A sampling strategy, called nucleus
                     sampling, where the model considers the results of the
                     tokens with top_p probability mass. So 0.1 means only
                     the tokens comprising the top 10% probability mass are
                     considered.
                 enable_search(bool, `optional`): Whether to enable web search(quark).  # noqa E501
                     Currently works best only on the first round of conversation.
                     Default to False.
```

## dashscope/aigc/generation.py

```diff
@@ -42,15 +42,15 @@
                 stream(bool, `optional`): Enable server-sent events
                     (ref: https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events)  # noqa E501
                     the result will back partially[qwen-v1,bailian-v1].
                 max_length(int, `optional`): The maximum length of tokens to
                     generate. The token count of your prompt plus max_length
                     cannot exceed the model's context length. Most models
                     have a context length of 2000 tokens[qwen-v1,bailian-v1]. # noqa E501
-                top_p(int, `optional`): A sampling strategy, called nucleus
+                top_p(float, `optional`): A sampling strategy, called nucleus
                     sampling, where the model considers the results of the
                     tokens with top_p probability mass. So 0.1 means only
                     the tokens comprising the top 10% probability mass are
                     considered[qwen-v1,bailian-v1].
                 enable_search(bool, `optional`): Whether to enable web search(quark).  # noqa E501
                     Currently works best only on the first round of conversation.
                     Default to False, support model: [qwen-v1].
```

## dashscope/api_entities/aiohttp_request.py

```diff
@@ -81,15 +81,15 @@
             output = next(response)
             try:
                 next(response)
             except StopIteration:
                 pass
             return output
 
-    async def async_call(self):
+    async def aio_call(self):
         response = self._handle_request()
         if self.stream:
             return (item async for item in response)
         else:
             result = await response.__anext__()
             try:
                 await response.__anext__()
```

## dashscope/api_entities/api_request_data.py

```diff
@@ -1,14 +1,13 @@
 import json
 from urllib.parse import urlencode
 
 import aiohttp
 
 from dashscope.common.constants import ApiProtocol
-from dashscope.common.error import MultiInputsWithBinaryNotSupported
 from dashscope.io.input_output import InputResolver
 
 
 class ApiRequestData():
     def __init__(
         self,
         model,
@@ -102,18 +101,15 @@
     def get_websocket_start_data(self):
         """Process websocket start data.
         If the input data is str, can carry the data in start action package,
         otherwise only parameters.
         Current, only one binary input is supported.
         Return: is_binary, start_package
         """
-        if self._is_binary_input and len(self._input) > 1:
-            raise MultiInputsWithBinaryNotSupported(
-                'Not support multiple binary input data.')
-        elif self._is_binary_input:
+        if self._is_binary_input:
             return self._only_parameters()
         else:
             for content in self._input_resolver:
                 self.input = content
                 break
 
         data = {
@@ -143,17 +139,21 @@
         Returns:
             bytes: The binary content, such as audio,image,video file content.
         """
         for content in self._input_resolver:
             return content
 
     def _only_parameters(self) -> str:
-        obj = {'model': self.model, 'parameters': self.parameters}
+        obj = {'model': self.model, 'parameters': self.parameters, 'input': {}}
         if self.task is not None:
             obj['task'] = self.task
+        if self.task_group is not None:
+            obj['task_group'] = self.task_group
+        if self.function is not None:
+            obj['function'] = self.function
         return obj
 
     def to_query_parameters(self) -> str:
         query_string = '?'
         for key, value in self.parameters.items:
             param = '%s/%s&' % (key, value)
             query_string += param
```

## dashscope/api_entities/api_request_factory.py

```diff
@@ -1,27 +1,28 @@
 import dashscope
 from dashscope.api_entities.api_request_data import ApiRequestData
 from dashscope.api_entities.http_request import HttpRequest
 from dashscope.api_entities.websocket_request import WebSocketRequest
-from dashscope.common.constants import (SERVICE_API_PATH, ApiProtocol,
+from dashscope.common.constants import (REQUEST_TIMEOUT_KEYWORD,
+                                        SERVICE_API_PATH, ApiProtocol,
                                         HTTPMethod, StreamResultMode)
 from dashscope.common.error import InputDataRequired, UnsupportedApiProtocol
 from dashscope.protocol.websocket import WebsocketStreamingMode
 
 
 def _get_protocol_params(kwargs):
     api_protocol = kwargs.pop('api_protocol', ApiProtocol.HTTPS)
     ws_stream_mode = kwargs.pop('ws_stream_mode', WebsocketStreamingMode.OUT)
     is_binary_input = kwargs.pop('is_binary_input', False)
     http_method = kwargs.pop('http_method', HTTPMethod.POST)
     stream = kwargs.pop('stream', False)
     async_request = kwargs.pop('async_request', False)
     query = kwargs.pop('query', False)
     headers = kwargs.pop('headers', None)
-    request_timeout = kwargs.pop('request_timeout', None)
+    request_timeout = kwargs.pop(REQUEST_TIMEOUT_KEYWORD, None)
     stream_result_mode = kwargs.pop('stream_result_mode',
                                     StreamResultMode.ACCUMULATE)
     form = kwargs.pop('form', None)
     return (api_protocol, ws_stream_mode, is_binary_input, http_method, stream,
             async_request, query, headers, request_timeout, stream_result_mode,
             form)
```

## dashscope/api_entities/base_request.py

```diff
@@ -24,9 +24,9 @@
     @abstractmethod
     def call(self):
         raise NotImplementedError()
 
 
 class AioBaseRequest(BaseRequest):
     @abstractmethod
-    async def async_call(self):
+    async def aio_call(self):
         raise NotImplementedError()
```

## dashscope/api_entities/dashscope_response.py

```diff
@@ -1,11 +1,11 @@
 import json
 from dataclasses import dataclass
 from http import HTTPStatus
-from typing import Any, Dict, List
+from typing import Any, Dict, List, Union
 
 
 @dataclass(init=False)
 class DictMixin(dict):
     __slots__ = ()
 
     def __init__(self, *args, **kwargs):
@@ -188,14 +188,71 @@
             return TranscriptionResponse(status_code=api_response.status_code,
                                          request_id=api_response.request_id,
                                          code=api_response.code,
                                          message=api_response.message)
 
 
 @dataclass(init=False)
+class RecognitionOutput(DictMixin):
+    sentence: Union[Dict[str, Any], List[Any]]
+
+    def __init__(self, sentence: Union[Dict[str, Any], List[Any]], **kwargs):
+        super().__init__(sentence=sentence, **kwargs)
+
+
+@dataclass(init=False)
+class RecognitionUsage(DictMixin):
+    duration: int
+
+    def __init__(self, duration: int = 0, **kwargs):
+        super().__init__(duration=duration, **kwargs)
+
+
+@dataclass(init=False)
+class RecognitionResponse(DashScopeAPIResponse):
+    output: RecognitionOutput
+    usage: RecognitionUsage
+
+    @staticmethod
+    def from_api_response(api_response: DashScopeAPIResponse):
+        if api_response.status_code == HTTPStatus.OK:
+            output = None
+            usage = None
+            if api_response.output is not None:
+                if 'sentence' in api_response.output:
+                    output = RecognitionOutput(**api_response.output)
+            if api_response.usage is not None:
+                usage = RecognitionUsage(**api_response.usage)
+
+            return RecognitionResponse(status_code=api_response.status_code,
+                                       request_id=api_response.request_id,
+                                       code=api_response.code,
+                                       message=api_response.message,
+                                       output=output,
+                                       usage=usage)
+
+        else:
+            return RecognitionResponse(status_code=api_response.status_code,
+                                       request_id=api_response.request_id,
+                                       code=api_response.code,
+                                       message=api_response.message)
+
+    @staticmethod
+    def is_sentence_end(sentence: Dict[str, Any]) -> bool:
+        """Determine whether the speech recognition result is the end of a sentence.
+           This is a static method.
+        """
+        result = False
+        if sentence is not None and 'end_time' in sentence and sentence[
+                'end_time'] is not None:
+            result = True
+        return result
+
+
+@dataclass(init=False)
 class SpeechSynthesisOutput(DictMixin):
     sentence: Dict[str, Any]
 
     def __init__(self, sentence: Dict[str, Any], **kwargs):
         super().__init__(sentence=sentence, **kwargs)
```

## dashscope/api_entities/http_request.py

```diff
@@ -1,11 +1,12 @@
 import json
 from http import HTTPStatus
 
 import requests
+
 from dashscope.api_entities.base_request import BaseRequest
 from dashscope.api_entities.dashscope_response import DashScopeAPIResponse
 from dashscope.common.constants import (DEFAULT_REQUEST_TIMEOUT_SECONDS,
                                         SSE_CONTENT_TYPE, HTTPMethod,
                                         StreamResultMode)
 from dashscope.common.error import UnsupportedHTTPMethod
 from dashscope.common.logging import logger
```

## dashscope/api_entities/websocket_request.py

```diff
@@ -73,15 +73,15 @@
             output = next(response)
             try:
                 next(response)
             except StopIteration:
                 pass
             return output
 
-    async def async_call(self):
+    async def aio_call(self):
         response = self.connection_handler()
         if self.stream:
             return (item async for item in response)
         else:
             result = await response.__anext__()
             try:
                 await response.__anext__()
@@ -248,27 +248,30 @@
         # for binary data, the start action has no input, only parameters.
         start_data = self.data.get_websocket_start_data()
         message = self._build_up_message(task_header, start_data)
         await ws.send_str(message)
 
     async def _send_finished_task(self, ws):
         task_header = {**self.task_headers, ACTION_KEY: ActionType.FINISHED}
-        payload = {}
+        payload = {'input': {}}
         message = self._build_up_message(task_header, payload)
         await ws.send_str(message)
 
     async def _send_continue_task_data(self, ws):
         headers = {
             'task_id': self.task_headers['task_id'],
             'action': 'continue-task'
         }
         for input in self.data.get_websocket_continue_data():
             if self.is_binary_input:
                 if len(input) > 0:
-                    await ws.send_bytes(list(input.values())[0])
+                    if isinstance(input, bytes):
+                        await ws.send_bytes(input)
+                    else:
+                        await ws.send_bytes(list(input.values())[0])
             else:
                 if len(input) > 0:
                     message = self._build_up_message(headers=headers,
                                                      payload=input)
                     await ws.send_str(message)
             await asyncio.sleep(0.000001)
```

## dashscope/audio/asr/__init__.py

```diff
@@ -1,5 +1,3 @@
 from .transcription import Transcription
 
-__all__ = [
-    Transcription,
-]
+__all__ = [Transcription]
```

## dashscope/client/base_api.py

```diff
@@ -1,60 +1,87 @@
-import json
-import os
 import time
 from http import HTTPStatus
 from typing import List, Union
 
-import aiohttp
+import requests
 
 import dashscope
-import requests
 from dashscope.api_entities.api_request_factory import _build_api_request
 from dashscope.api_entities.dashscope_response import DashScopeAPIResponse
 from dashscope.common.api_key import get_default_api_key
 from dashscope.common.constants import (DEFAULT_REQUEST_TIMEOUT_SECONDS,
-                                        REPEATABLE_STATUS, TaskStatus)
+                                        REPEATABLE_STATUS,
+                                        REQUEST_TIMEOUT_KEYWORD,
+                                        SSE_CONTENT_TYPE, TaskStatus)
 from dashscope.common.error import InvalidParameter, InvalidTask, ModelRequired
 from dashscope.common.logging import logger
-from dashscope.common.utils import _handle_http_response, default_headers
-
-
-def _handle_http_failed_response(
-        response: requests.Response) -> DashScopeAPIResponse:
-    msg = ''
-    code = None
-    request_id = ''
-    if 'application/json' in response.headers.get('content-type', ''):
-        error = response.json()
-        if 'message' in error:
-            msg = error['message']
-        if 'code' in error:
-            code = error['code']
-        if 'request_id' in error:
-            request_id = error['request_id']
-        return DashScopeAPIResponse(request_id=request_id,
-                                    status_code=response.status_code,
-                                    code=code,
-                                    message=msg)
-    else:
-        msg = response.content.decode('utf-8')
-        return DashScopeAPIResponse(request_id=request_id,
-                                    status_code=response.status_code,
-                                    code='Unknown',
-                                    message=msg)
+from dashscope.common.utils import (_handle_http_failed_response,
+                                    _handle_http_response, default_headers,
+                                    join_url)
 
 
 def _normalization_url(*args):
     url = dashscope.base_http_api_url
-    if not url.endswith('/'):
-        url += '/'
-    for arg in args:
-        url += arg
-        url += '/'
-    return url[:-1]
+    return join_url(url, *args)
+
+
+class BaseAioApi():
+    """BaseApi, internal use only.
+
+    """
+    @classmethod
+    def _validate_params(cls, api_key, model):
+        if api_key is None:
+            api_key = get_default_api_key()
+        if model is None or not model:
+            raise ModelRequired('Model is required!')
+        return api_key, model
+
+    @classmethod
+    def aio_call(cls,
+                 model: str,
+                 input: object,
+                 task_group: str,
+                 task: str = None,
+                 function: str = None,
+                 api_key: str = None,
+                 **kwargs) -> DashScopeAPIResponse:
+        """Call service and get result.
+
+        Args:
+            model (str): The requested model, such as gpt3-v2
+            input (object): The api input data, cannot be None.
+            task_group (str, optional): The api task group.
+            task (str, optional): The task name. Defaults to None.
+            function (str, optional): The function of the task.
+                Defaults to None.
+            api_key (str, optional): The api api_key, if not present,
+                will get by default rule(TODO: api key doc). Defaults to None.
+            api_protocol (str, optional): Api protocol websocket or http.
+                Defaults to None.
+            ws_stream_mode (str, optional): websocket stream mode,
+                [none, in, out, duplex]. Defaults to out.
+            is_binary_input (bool, optional): Is input data binary.
+                Defaults to False.
+            http_method (str, optional): If api protocol is http, specifies
+                method[GET, POST]. Defaults to POST.
+
+        Returns:
+            DashScopeAPIResponse: The service response.
+        """
+        api_key, model = BaseAioApi._validate_params(api_key, model)
+        request = _build_api_request(model=model,
+                                     input=input,
+                                     task_group=task_group,
+                                     task=task,
+                                     function=function,
+                                     api_key=api_key,
+                                     **kwargs)
+        # call request service.
+        return request.aio_call()
 
 
 class BaseApi():
     """BaseApi, internal use only.
 
     """
     @classmethod
@@ -105,55 +132,83 @@
                                      function=function,
                                      api_key=api_key,
                                      **kwargs)
         # call request service.
         return request.call()
 
 
+class BaseAioApi():
+    """BaseApi, internal use only.
+
+    """
+    @classmethod
+    def _validate_params(cls, api_key, model):
+        if api_key is None:
+            api_key = get_default_api_key()
+        if model is None or not model:
+            raise ModelRequired('Model is required!')
+        return api_key, model
+
+    @classmethod
+    async def aio_call(cls,
+                       model: str,
+                       input: object,
+                       task_group: str,
+                       task: str = None,
+                       function: str = None,
+                       api_key: str = None,
+                       **kwargs) -> DashScopeAPIResponse:
+        """Call service and get result.
+
+        Args:
+            model (str): The requested model, such as gpt3-v2
+            input (object): The api input data, cannot be None.
+            task_group (str, optional): The api task group.
+            task (str, optional): The task name. Defaults to None.
+            function (str, optional): The function of the task.
+                Defaults to None.
+            api_key (str, optional): The api api_key, if not present,
+                will get by default rule(TODO: api key doc). Defaults to None.
+            api_protocol (str, optional): Api protocol websocket or http.
+                Defaults to None.
+            ws_stream_mode (str, optional): websocket stream mode,
+                [none, in, out, duplex]. Defaults to out.
+            is_binary_input (bool, optional): Is input data binary.
+                Defaults to False.
+            http_method (str, optional): If api protocol is http, specifies
+                method[GET, POST]. Defaults to POST.
+
+        Returns:
+            DashScopeAPIResponse: The service response.
+        """
+        api_key, model = BaseAioApi._validate_params(api_key, model)
+        request = _build_api_request(model=model,
+                                     input=input,
+                                     task_group=task_group,
+                                     task=task,
+                                     function=function,
+                                     api_key=api_key,
+                                     **kwargs)
+        # call request service.
+        return await request.aio_call()
+
+
 class AsyncTaskGetMixin():
     @classmethod
     def _get(cls, task_id: str, api_key: str = None) -> DashScopeAPIResponse:
         status_url = _normalization_url('tasks', task_id)
         with requests.Session() as session:
             logger.debug('Starting request: %s' % status_url)
             response = session.get(status_url,
                                    headers={
                                        **default_headers(api_key),
                                    },
                                    timeout=DEFAULT_REQUEST_TIMEOUT_SECONDS)
             logger.debug('Starting processing response: %s' % status_url)
-            return cls._handle_http_response(response)
-
-    @classmethod
-    def _handle_http_response(cls, response: requests.Response):
-        request_id = ''
-        if response.status_code == HTTPStatus.OK:
-            output = None
-            usage = None
-            code = None
-            msg = ''
-            json_content = response.json()
-            if 'code' in json_content:
-                code = json_content['code']
-            if 'message' in json_content:
-                msg = json_content['message']
-            if 'output' in json_content:
-                output = json_content['output']
-            if 'usage' in json_content:
-                usage = json_content['usage']
-            if 'request_id' in json_content:
-                request_id = json_content['request_id']
-            return DashScopeAPIResponse(request_id=request_id,
-                                        status_code=response.status_code,
-                                        code=code,
-                                        output=output,
-                                        usage=usage,
-                                        message=msg)
-        else:
-            return _handle_http_failed_response(response)
+            return _handle_http_response(response)
 
 
 class BaseAsyncApi(AsyncTaskGetMixin):
     """BaseAsyncApi,for async task, internal use only.
 
     """
     @classmethod
@@ -205,27 +260,15 @@
         task_id = cls._get_task_id(task)
         url = _normalization_url('tasks', task_id, 'cancel')
         with requests.Session() as session:
             response = session.post(url,
                                     headers={
                                         **default_headers(api_key),
                                     })
-            if response.status_code == HTTPStatus.OK:
-                json_content = response.json()
-                request_id = ''
-                if 'request_id' in json_content:
-                    request_id = json_content['request_id']
-                return DashScopeAPIResponse(request_id=request_id,
-                                            status_code=response.status_code,
-                                            code=None,
-                                            output=None,
-                                            usage=None,
-                                            message='')
-            else:
-                return _handle_http_failed_response(response)
+            return _handle_http_response(response)
 
     @classmethod
     def list(cls,
              start_time: str = None,
              end_time: str = None,
              model_name: str = None,
              api_key_id: str = None,
@@ -307,19 +350,18 @@
         Returns:
             DashScopeAPIResponse: The async task information.
         """
         task_id = cls._get_task_id(task)
         return cls._get(task_id, api_key)
 
     @classmethod
-    def wait(
-        cls,
-        task: Union[str, DashScopeAPIResponse],
-        api_key: str = None,
-    ) -> DashScopeAPIResponse:
+    def wait(cls,
+             task: Union[str, DashScopeAPIResponse],
+             api_key: str = None,
+             **kwargs) -> DashScopeAPIResponse:
         """Wait for async task completion and return task result.
 
         Args:
             task (Union[str, DashScopeAPIResponse]): The task_id, or
                 async_call response.
             api_key (str, optional): The api_key. Defaults to None.
 
@@ -389,260 +431,407 @@
                                      api_key=api_key,
                                      async_request=True,
                                      query=False,
                                      **kwargs)
         return request.call()
 
 
+def _get(url, params={}, api_key=None, **kwargs) -> DashScopeAPIResponse:
+    timeout = kwargs.pop(REQUEST_TIMEOUT_KEYWORD,
+                         DEFAULT_REQUEST_TIMEOUT_SECONDS)
+    with requests.Session() as session:
+        logger.debug('Starting request: %s' % url)
+        response = session.get(url,
+                               headers={
+                                   **default_headers(api_key),
+                                   **kwargs.pop('headers', {})
+                               },
+                               params=params,
+                               timeout=timeout)
+        logger.debug('Starting processing response: %s' % url)
+        return _handle_http_response(response)
+
+
 class ListMixin():
     @classmethod
-    async def async_list(cls,
-                         api_key: str = None,
-                         limits=10,
-                         page=1,
-                         per_page=10,
-                         offset=1,
-                         sortby='id',
-                         order='asc',
-                         **kwargs) -> DashScopeAPIResponse:
+    def list(cls,
+             page_no=1,
+             page_size=10,
+             api_key: str = None,
+             **kwargs) -> DashScopeAPIResponse:
         """list objects
 
         Args:
             api_key (str, optional): The api api_key, if not present,
                 will get by default rule(TODO: api key doc). Defaults to None.
-            limits (int, optional): Total return items. Defaults to 10.
-            page (int, optional): Page number. Defaults to 1.
-            per_page (int, optional): Items per page. Defaults to 10.
-            offset (int, optional): Item start position. Defaults to 1.
-            sortby (str, optional): Items sort by. Defaults to 'id'.
-            order (str, optional): Items order['desc', 'asc'].
-                Defaults to 'desc'.
+            page_no (int, optional): Page number. Defaults to 1.
+            page_size (int, optional): Items per page. Defaults to 10.
 
         Returns:
             DashScopeAPIResponse: The object list in output.
         """
-        headers = kwargs.pop('headers', {})
-        url = _normalization_url(cls.SUB_PATH.lower())
-        async with aiohttp.ClientSession() as client:
-            response = await client.get(url=url,
-                                        params={
-                                            'limits': limits,
-                                            'page': page,
-                                            'per_page': per_page,
-                                            'offset': offset,
-                                            'sortby': sortby,
-                                            'order': order,
-                                        },
-                                        headers={
-                                            **default_headers(api_key),
-                                            **headers
-                                        })  # noqa E501
-            return await _handle_http_response(response)
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower())
+        params = {'page_no': page_no, 'page_size': page_size}
+        return _get(url, params=params, api_key=api_key, **kwargs)
+
+
+class LogMixin():
+    @classmethod
+    def logs(cls,
+             job_id: str,
+             offset=1,
+             line=1000,
+             api_key: str = None,
+             **kwargs) -> DashScopeAPIResponse:
+        """Get log of the job.
+
+        Args:
+            job_id (str): The job id(used for fine-tune)
+            offset (int, optional): start log line. Defaults to 1.
+            line (int, optional): total line return. Defaults to 1000.
+            api_key (str, optional): The api key. Defaults to None.
+
+        Returns:
+            DashScopeAPIResponse: The response
+        """
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower(),
+                       job_id, 'logs')
+        params = {'offset': offset, 'line': line}
+        return _get(url, params=params, api_key=api_key, **kwargs)
 
 
 class GetMixin():
     @classmethod
-    async def async_get(cls,
-                        target,
-                        api_key: str = None,
-                        **kwargs) -> DashScopeAPIResponse:
+    def get(cls,
+            target,
+            api_key: str = None,
+            **kwargs) -> DashScopeAPIResponse:
         """Get object information.
 
         Args:
             target (str): The target to get, such as model_id.
             api_key (str, optional): The api api_key, if not present,
                 will get by default rule(TODO: api key doc). Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The object information in output.
         """
-        headers = kwargs.pop('headers', {})
-        url = _normalization_url(cls.SUB_PATH.lower(), target)
-        async with aiohttp.ClientSession() as client:
-            response = await client.get(url=url,
-                                        headers={
-                                            **default_headers(api_key),
-                                            **headers
-                                        })  # noqa E501
-            return await _handle_http_response(response)
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower(),
+                       target)
+        return _get(url, api_key, **kwargs)
 
 
-class DeleteMixin():
+class GetStatusMixin():
     @classmethod
-    async def async_delete(cls,
-                           target: str,
-                           api_key: str = None,
-                           **kwargs) -> DashScopeAPIResponse:
+    def get(cls,
+            target,
+            api_key: str = None,
+            **kwargs) -> DashScopeAPIResponse:
         """Get object information.
 
         Args:
+            target (str): The target to get, such as model_id.
+            api_key (str, optional): The api api_key, if not present,
+                will get by default rule(TODO: api key doc). Defaults to None.
+
+        Returns:
+            DashScopeAPIResponse: The object information in output.
+        """
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower(),
+                       target)
+        return _get(url, api_key, **kwargs)
+
+
+class DeleteMixin():
+    @classmethod
+    def delete(cls,
+               target: str,
+               api_key: str = None,
+               **kwargs) -> DashScopeAPIResponse:
+        """Delete object.
+
+        Args:
             target (str): The object to delete, .
             api_key (str, optional): The api api_key, if not present,
                 will get by default rule(TODO: api key doc). Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The delete result.
         """
-        headers = kwargs.pop('headers', {})
-        url = _normalization_url(cls.SUB_PATH.lower(), target)
-        async with aiohttp.ClientSession() as client:
-            response = await client.delete(url=url,
-                                           headers={
-                                               **default_headers(api_key),
-                                               **headers
-                                           })  # noqa E501
-            return await _handle_http_response(response)
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower(),
+                       target)
+        timeout = kwargs.pop(REQUEST_TIMEOUT_KEYWORD,
+                             DEFAULT_REQUEST_TIMEOUT_SECONDS)
+        with requests.Session() as session:
+            logger.debug('Starting request: %s' % url)
+            response = session.delete(url,
+                                      headers={
+                                          **default_headers(api_key),
+                                          **kwargs.pop('headers', {})
+                                      },
+                                      timeout=timeout)
+            logger.debug('Starting processing response: %s' % url)
+            return _handle_http_response(response)
 
 
 class CreateMixin():
     @classmethod
-    async def async_call(cls,
-                         json: object,
-                         api_key: str = None,
-                         **kwargs) -> DashScopeAPIResponse:
+    def call(cls,
+             data: object,
+             api_key: str = None,
+             **kwargs) -> DashScopeAPIResponse:
         """Create a object
 
         Args:
-            json (object): The create request json body.
+            data (object): The create request json body.
             api_key (str, optional): The api api_key, if not present,
                 will get by default rule(TODO: api key doc). Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The created object in output.
         """
-        headers = kwargs.pop('headers', {})
-        url = _normalization_url(cls.SUB_PATH.lower())
-        async with aiohttp.ClientSession() as client:
-            response = await client.post(url=url,
-                                         json=json,
-                                         headers={
-                                             **default_headers(api_key),
-                                             **headers
-                                         })  # noqa E501
-            return await _handle_http_response(response)
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower())
+        timeout = kwargs.pop(REQUEST_TIMEOUT_KEYWORD,
+                             DEFAULT_REQUEST_TIMEOUT_SECONDS)
+        with requests.Session() as session:
+            logger.debug('Starting request: %s' % url)
+            response = session.post(url,
+                                    json=data,
+                                    headers={
+                                        **default_headers(api_key),
+                                        **kwargs.pop('headers', {})
+                                    },
+                                    timeout=timeout)
+            logger.debug('Starting processing response: %s' % url)
+            return _handle_http_response(response)
 
 
 class UpdateMixin():
     @classmethod
-    async def async_update(cls,
-                           target: str,
-                           json: object,
-                           api_key: str = None,
-                           **kwargs) -> DashScopeAPIResponse:
+    def update(cls,
+               target: str,
+               json: object,
+               api_key: str = None,
+               **kwargs) -> DashScopeAPIResponse:
         """Async update a object
 
         Args:
             target (str): The target to update.
             json (object): The create request json body.
             api_key (str, optional): The api api_key, if not present,
                 will get by default rule(TODO: api key doc). Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The updated object information in output.
         """
-        headers = kwargs.pop('headers', {})
-        url = _normalization_url(cls.SUB_PATH.lower(), target)
-        async with aiohttp.ClientSession() as client:
-            response = await client.patch(url=url,
-                                          json=json,
-                                          headers={
-                                              **default_headers(api_key),
-                                              **headers
-                                          })  # noqa E501
-            return await _handle_http_response(response)
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower(),
+                       target)
+        timeout = kwargs.pop(REQUEST_TIMEOUT_KEYWORD,
+                             DEFAULT_REQUEST_TIMEOUT_SECONDS)
+        with requests.Session() as session:
+            logger.debug('Starting request: %s' % url)
+            response = session.patch(url,
+                                     json=json,
+                                     headers={
+                                         **default_headers(api_key),
+                                         **kwargs.pop('headers', {})
+                                     },
+                                     timeout=timeout)
+            logger.debug('Starting processing response: %s' % url)
+            return _handle_http_response(response)
+
+class PutMixin():
+    @classmethod
+    def put(cls,
+            target: str,
+            json: object,
+            extra_path: str = None,
+            api_key: str = None,
+            **kwargs) -> DashScopeAPIResponse:
+        """Async update a object
 
+        Args:
+            target (str): The target to update.
+            json (object): The create request json body.
+            api_key (str, optional): The api api_key, if not present,
+                will get by default rule(TODO: api key doc). Defaults to None.
+
+        Returns:
+            DashScopeAPIResponse: The updated object information in output.
+        """
+        if extra_path is None:
+            url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower(),
+                       target)
+        else:
+            url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower(),
+                       target, extra_path)
+        print(url)
+        timeout = kwargs.pop(REQUEST_TIMEOUT_KEYWORD,
+                             DEFAULT_REQUEST_TIMEOUT_SECONDS)
+        with requests.Session() as session:
+            logger.debug('Starting request: %s' % url)
+            response = session.put(url,
+                                   json=json,
+                                   headers={
+                                        **default_headers(api_key),
+                                        **kwargs.pop('headers', {})
+                                   },
+                                   timeout=timeout)
+            logger.debug('Starting processing response: %s' % url)
+            return _handle_http_response(response)
 
 class FileUploadMixin():
     @classmethod
-    async def async_upload(cls,
-                           files: list,
-                           descriptions: List[str] = None,
-                           params: dict = None,
-                           api_key: str = None,
-                           **kwargs) -> DashScopeAPIResponse:
+    def upload(cls,
+               files: list,
+               descriptions: List[str] = None,
+               params: dict = None,
+               api_key: str = None,
+               **kwargs) -> DashScopeAPIResponse:
         """Upload files
 
         Args:
             files (list): List of (name, opened file, file_name).
             descriptions (list[str]): The file description messages.
             params (dict): The parameters
             api_key (str, optional): The api api_key, if not present,
                 will get by default rule(TODO: api key doc). Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The uploaded file information in the output.
         """
-        headers = kwargs.pop('headers', {})
-        url = _normalization_url(cls.SUB_PATH.lower())
-        form = aiohttp.FormData()
-        for name, file, file_name in files:
-            if name is None:
-                form.add_field(os.path.basename(file.name),
-                               file,
-                               filename=file_name)
-            else:
-                form.add_field(name, file, filename=file_name)
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower())
+        js = None
         if descriptions:
-            form.add_field('descriptions', json.dumps(descriptions))
-        async with aiohttp.ClientSession() as client:
-            response = await client.post(url=url,
-                                         data=form(),
-                                         params=params,
-                                         headers={
-                                             **default_headers(api_key),
-                                             **headers
-                                         })  # noqa E501
-            return await _handle_http_response(response)
+            js = {'descriptions': descriptions}
+        timeout = kwargs.pop(REQUEST_TIMEOUT_KEYWORD,
+                             DEFAULT_REQUEST_TIMEOUT_SECONDS)
+        with requests.Session() as session:
+            logger.debug('Starting request: %s' % url)
+            response = session.post(url,
+                                    data=js,
+                                    headers={
+                                        **default_headers(api_key),
+                                        **kwargs.pop('headers', {})
+                                    },
+                                    files=files,
+                                    timeout=timeout)
+            logger.debug('Starting processing response: %s' % url)
+            return _handle_http_response(response)
 
 
 class CancelMixin():
     @classmethod
-    async def async_cancel(cls,
-                           target: str,
-                           api_key: str = None,
-                           **kwargs) -> DashScopeAPIResponse:
+    def cancel(cls,
+               target: str,
+               api_key: str = None,
+               **kwargs) -> DashScopeAPIResponse:
         """Cancel a job.
 
         Args:
             target (str): The request params, key/value map.
             api_key (str, optional): The api api_key, if not present,
                 will get by default rule(TODO: api key doc). Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The cancel result.
         """
-        headers = kwargs.pop('headers', {})
-        url = _normalization_url(cls.SUB_PATH.lower(), target, 'cancel')
-        async with aiohttp.ClientSession() as client:
-            response = await client.post(url=url,
-                                         headers={
-                                             **default_headers(api_key),
-                                             **headers
-                                         })  # noqa E501
-            return await _handle_http_response(response)
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower(),
+                       target, 'cancel')
+        timeout = kwargs.pop(REQUEST_TIMEOUT_KEYWORD,
+                             DEFAULT_REQUEST_TIMEOUT_SECONDS)
+        with requests.Session() as session:
+            logger.debug('Starting request: %s' % url)
+            response = session.post(url,
+                                    headers={
+                                        **default_headers(api_key),
+                                        **kwargs.pop('headers', {})
+                                    },
+                                    timeout=timeout)
+            logger.debug('Starting processing response: %s' % url)
+            return _handle_http_response(response)
 
 
 class StreamEventMixin():
     @classmethod
-    async def async_stream_events(cls,
-                                  target,
-                                  api_key: str = None,
-                                  **kwargs) -> DashScopeAPIResponse:
+    def _handle_stream(cls, response: requests.Response):
+        # TODO define done message.
+        is_error = False
+        status_code = HTTPStatus.INTERNAL_SERVER_ERROR
+        for line in response.iter_lines():
+            if line:
+                line = line.decode('utf8')
+                line = line.rstrip('\n').rstrip('\r')
+                if line.startswith('event:error'):
+                    is_error = True
+                elif line.startswith('status:'):
+                    status_code = line[len('status:'):]
+                    status_code = int(status_code.strip())
+                elif line.startswith('data:'):
+                    line = line[len('data:'):]
+                    yield (is_error, status_code, line)
+                    if is_error:
+                        break
+                else:
+                    continue  # ignore heartbeat...
+
+    @classmethod
+    def _handle_response(cls, response: requests.Response):
+        request_id = ''
+        if (response.status_code == HTTPStatus.OK
+                and SSE_CONTENT_TYPE in response.headers.get(
+                    'content-type', '')):
+            for is_error, status_code, data in cls._handle_stream(response):
+                if is_error:
+                    yield DashScopeAPIResponse(request_id=request_id,
+                                               status_code=status_code,
+                                               output=None,
+                                               code='',
+                                               message='')  # noqa E501
+                else:
+                    yield DashScopeAPIResponse(request_id=request_id,
+                                               status_code=HTTPStatus.OK,
+                                               output=data,
+                                               usage=None)
+        elif response.status_code == HTTPStatus.OK:
+            json_content = response.json()
+            request_id = ''
+            if 'request_id' in json_content:
+                request_id = json_content['request_id']
+            yield DashScopeAPIResponse(request_id=request_id,
+                                       status_code=HTTPStatus.OK,
+                                       output=json_content,
+                                       usage=None)
+        else:
+            _handle_http_failed_response(response)
+
+    @classmethod
+    def stream_events(cls,
+                      target,
+                      api_key: str = None,
+                      **kwargs) -> DashScopeAPIResponse:
         """Get job log.
 
         Args:
             target (str): The target to get, such as model_id.
             api_key (str, optional): The api api_key, if not present,
                 will get by default rule(TODO: api key doc). Defaults to None.
 
         Returns:
             DashScopeAPIResponse: The target outputs.
         """
-        headers = kwargs.pop('headers', {})
-        url = _normalization_url(cls.SUB_PATH.lower(), target, 'events')
-        async with aiohttp.ClientSession() as client:
-            response = await client.get(url=url,
-                                        headers={
-                                            **default_headers(api_key),
-                                            **headers
-                                        })  # noqa E501
-            return await _handle_http_response(response)
+        url = join_url(dashscope.base_http_api_url, cls.SUB_PATH.lower(),
+                       target, 'stream')
+        timeout = kwargs.pop(REQUEST_TIMEOUT_KEYWORD,
+                             DEFAULT_REQUEST_TIMEOUT_SECONDS)
+        with requests.Session() as session:
+            logger.debug('Starting request: %s' % url)
+            response = session.get(url,
+                                   headers={
+                                       **default_headers(api_key),
+                                       **kwargs.pop('headers', {})
+                                   },
+                                   stream=True,
+                                   timeout=timeout)
+            logger.debug('Starting processing response: %s' % url)
+            for rsp in cls._handle_response(response):
+                yield rsp
```

## dashscope/common/constants.py

```diff
@@ -9,14 +9,15 @@
 # export DASHSCOPE_DISABLE_DATA_INSPECTION=true
 DASHSCOPE_DISABLE_DATA_INSPECTION_ENV = 'DASHSCOPE_DISABLE_DATA_INSPECTION'
 DEFAULT_DASHSCOPE_CACHE_PATH = Path.home().joinpath('.dashscope')
 DEFAULT_DASHSCOPE_API_KEY_FILE_PATH = Path.joinpath(
     DEFAULT_DASHSCOPE_CACHE_PATH, 'api_key')
 
 DEFAULT_REQUEST_TIMEOUT_SECONDS = 300
+REQUEST_TIMEOUT_KEYWORD = 'request_timeout'
 SERVICE_API_PATH = 'services'
 DASHSCOPE_LOGGING_LEVEL_ENV = 'DASHSCOPE_LOGGING_LEVEL'
 # task config keys.
 PROMPT = 'prompt'
 NEGATIVE_PROMPT = 'negative_prompt'
 HISTORY = 'history'
 CUSTOMIZED_MODEL_ID = 'customized_model_id'
@@ -48,18 +49,19 @@
                 apple
     """
     ACCUMULATE = 'accumulate'
     DIVIDE = 'divide'
 
 
 class DeploymentStatus:
-    DEPLOYING = 'deploying'
-    SERVING = 'running'
-    DELETING = 'deleting'
-    FAILED = 'failed'
+    DEPLOYING = 'DEPLOYING'
+    SERVING = 'RUNNING'
+    DELETING = 'DELETING'
+    FAILED = 'FAILED'
+    PENDING = 'PENDING'
 
 
 class ApiProtocol:
     WEBSOCKET = 'websocket'
     HTTP = 'http'
     HTTPS = 'https'
```

## dashscope/common/utils.py

```diff
@@ -3,14 +3,15 @@
 import os
 import platform
 from http import HTTPStatus
 from typing import Dict
 from urllib.parse import urlparse
 
 import aiohttp
+import requests
 
 from dashscope.api_entities.dashscope_response import DashScopeAPIResponse
 from dashscope.common.api_key import get_default_api_key
 from dashscope.version import __version__
 
 
 def is_validate_fine_tune_file(file_path):
@@ -85,15 +86,15 @@
         done, obj = loop.run_until_complete(get_next())
         if done:
             break
         yield obj
 
 
 def async_to_sync(async_generator):
-    loop = asyncio.new_event_loop()
+    loop = asyncio.get_event_loop_policy().new_event_loop()
     asyncio.set_event_loop(loop)
     for message in iter_over_async(async_generator, loop):
         yield message
 
 
 def default_headers(api_key: str = None) -> Dict[str, str]:
     ua = 'dashscope/%s; python/%s; platform/%s; processor/%s' % (
@@ -106,15 +107,24 @@
     if api_key is None:
         api_key = get_default_api_key()
     headers['Authorization'] = 'Bearer %s' % api_key
     headers['Accept'] = 'application/json'
     return headers
 
 
-async def _handle_http_response(response: aiohttp.ClientResponse):
+def join_url(base_url, *args):
+    if not base_url.endswith('/'):
+        base_url = base_url + '/'
+    url = base_url
+    for arg in args:
+        url += arg + '/'
+    return url[:-1]
+
+
+async def _handle_aiohttp_response(response: aiohttp.ClientResponse):
     request_id = ''
     if response.status == HTTPStatus.OK:
         json_content = await response.json()
         if 'request_id' in json_content:
             request_id = json_content['request_id']
         return DashScopeAPIResponse(request_id=request_id,
                                     status_code=HTTPStatus.OK,
@@ -135,7 +145,64 @@
         else:
             msg = await response.read()
             return DashScopeAPIResponse(request_id=request_id,
                                         status_code=response.status,
                                         output=None,
                                         code='Unknown',
                                         message=msg)
+
+
+def _handle_http_failed_response(
+        response: requests.Response) -> DashScopeAPIResponse:
+    msg = ''
+    code = None
+    request_id = ''
+    if 'application/json' in response.headers.get('content-type', ''):
+        error = response.json()
+        if 'message' in error:
+            msg = error['message']
+        if 'msg' in error:
+            msg = error['msg']
+        if 'code' in error:
+            code = error['code']
+        if 'request_id' in error:
+            request_id = error['request_id']
+        return DashScopeAPIResponse(request_id=request_id,
+                                    status_code=response.status_code,
+                                    code=code,
+                                    message=msg)
+    else:
+        msg = response.content.decode('utf-8')
+        return DashScopeAPIResponse(request_id=request_id,
+                                    status_code=response.status_code,
+                                    code='Unknown',
+                                    message=msg)
+
+
+def _handle_http_response(response: requests.Response):
+    request_id = ''
+    if response.status_code == HTTPStatus.OK:
+        output = None
+        usage = None
+        code = None
+        msg = ''
+        json_content = response.json()
+        if 'data' in json_content:
+            output = json_content['data']
+        if 'code' in json_content:
+            code = json_content['code']
+        if 'message' in json_content:
+            msg = json_content['message']
+        if 'output' in json_content:
+            output = json_content['output']
+        if 'usage' in json_content:
+            usage = json_content['usage']
+        if 'request_id' in json_content:
+            request_id = json_content['request_id']
+        return DashScopeAPIResponse(request_id=request_id,
+                                    status_code=response.status_code,
+                                    code=code,
+                                    output=output,
+                                    usage=usage,
+                                    message=msg)
+    else:
+        return _handle_http_failed_response(response)
```

## Comparing `dashscope-1.3.1.dist-info/LICENSE` & `dashscope-1.4.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `dashscope-1.3.1.dist-info/METADATA` & `dashscope-1.4.0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dashscope
-Version: 1.3.1
+Version: 1.4.0
 Summary: dashscope client sdk library
 Home-page: https://dashscope.aliyun.com/
 Author: Alibaba
 Author-email: dashscope@alibaba-inc.com
 License: Apache 2.0
 Platform: Posix; MacOS X; Windows
 Classifier: Development Status :: 4 - Beta
```

## Comparing `dashscope-1.3.1.dist-info/RECORD` & `dashscope-1.4.0.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,47 +1,46 @@
 dashscope/__init__.py,sha256=OIQFNWbRNTCTCTZZaTR0dw1sR20Bvsrh5krvV_v7B-I,1131
-dashscope/cli.py,sha256=FHz1UGh8dCDBV25FQttJM1uxZT3rNKGDp_krfCel7rY,13474
-dashscope/deployment.py,sha256=OA7FMkFTXwKDTcLLZe57_ZlCk38S29krdijy-_W64G4,3445
-dashscope/file.py,sha256=maMrfMB5_WVltYEyGN4QcAH0Xxj0eHkScisP8AXx4RQ,3753
-dashscope/finetune.py,sha256=jUj43EmwtCDYNqMvjKimuCQigG0Ux2EvZBypGcmkqHg,4808
-dashscope/model.py,sha256=kLXawzbbq4VkFFFjruz06MkuY-uEMUWCqs-4quqV7Us,1696
-dashscope/version.py,sha256=P2DFKJQEJRlJhF0IW0Lwt4G4uMYyJJ5ymhv-XrCcPGo,22
+dashscope/cli.py,sha256=o_r5LeWVqJqkv2odhe1gzXVV_suzwi2xJiJh6qj1EvU,23035
+dashscope/deployment.py,sha256=Msrmxw7TF1XjK8kuIhziirH7L6zrOYXRGYDPMyKIIBc,4600
+dashscope/file.py,sha256=Dv2Fz3DLbcye2uuQxyQwRM7ky27OthouLXIpSQagQy4,3324
+dashscope/finetune.py,sha256=Z9jcRSnM4MnoSqzz1rnIAew-1rMM_vMccQ_54J0MwtQ,5008
+dashscope/model.py,sha256=iuIfal-vOo0yav0HXPdA7f93vd5JNTGIAdCG_WIYkW8,1158
+dashscope/version.py,sha256=EyMGX1ADFzN6XVXHWbJUtKPONYKeFkvWoKIFPDDB2I8,22
 dashscope/aigc/__init__.py,sha256=llQdhMk9N11SKlTSAvYK-E4xT46GcXUAF51I-oDDDMM,239
-dashscope/aigc/conversation.py,sha256=H46NzB7CvCNBVFeD61bG-IBxcdfe3hjenszvI4M0AeY,8844
-dashscope/aigc/generation.py,sha256=ZpiVcm8Vf5MGyBeQsfmDXiq-VwzCsPveHJWN0tPp1iA,5084
+dashscope/aigc/conversation.py,sha256=LrqT2Dl6bU-gd8hZHPbdx0XBOd4dCvryiY_t0Sq8gyA,8846
+dashscope/aigc/generation.py,sha256=7KW00Woxk2Mt6CHi4336iTQ305jl--O2XYSfebFfzCQ,5086
 dashscope/aigc/image_synthesis.py,sha256=zZhpny20azLinMhhvAgyLY4qHugtl1EEApJQ5vuHNZI,7669
 dashscope/api_entities/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dashscope/api_entities/aiohttp_request.py,sha256=LpUM-BGKTHUeBnZ6cOfmdlp4-7czWLkhdNSzS2ydOh0,10361
-dashscope/api_entities/api_request_data.py,sha256=THH0jHQazlmjGId0e8-4aJG5jH71_jMm-CulGCZ6DV4,5331
-dashscope/api_entities/api_request_factory.py,sha256=4COz8WMEJOBP2_7jkW62Rua21SpoyrthCOMT0yg_z_k,4057
-dashscope/api_entities/base_request.py,sha256=y1SmJQ2csMy43y3c66BrC_usfn93XmJyhyu3Ge5aRKI,928
-dashscope/api_entities/dashscope_response.py,sha256=slVvNjW-tu3Di6HNVV4FnZ3dMyS1HiL1CnWrELJS5rs,9654
-dashscope/api_entities/http_request.py,sha256=7_qMWX-stOgci4A-hlv_R88QYOQzHL8VEkLUlFILd7c,9456
-dashscope/api_entities/sync_http_request.py,sha256=Yn1ursuviL5enxs87hraKkUBenQLyiHDV487KKQq5A0,8798
-dashscope/api_entities/websocket_request.py,sha256=dUU6-wRP28IZQDDL_OTytQxpzKwXKMJcCijii06bheI,15705
+dashscope/api_entities/aiohttp_request.py,sha256=1WuvODWcm-merZnAFpxV2Y9QohcB3hSGS_YkwK18O7g,10359
+dashscope/api_entities/api_request_data.py,sha256=Jorbrh4US9yVs-G2udxRjeOLegsc9fbhxY0n1FffjY0,5272
+dashscope/api_entities/api_request_factory.py,sha256=bdT9NwcxJN51ONtyk-hh_DN0uzDNe-ddHIh8NWr3DMo,4128
+dashscope/api_entities/base_request.py,sha256=cXUL7xqSV8wBr5d-1kx65AO3IsRR9A_ps6Lok-v-MKM,926
+dashscope/api_entities/dashscope_response.py,sha256=3h2olayx3QRXWolAN2zIk9hJrvU342ZsxEqQ642CKlk,11775
+dashscope/api_entities/http_request.py,sha256=fP8E54rX2Sz2aiYSAqT9mEiRjtSFSy_-hBnDsfAq3dk,9457
+dashscope/api_entities/websocket_request.py,sha256=VK4488_3Qi2Rwx7i1FGb-lPu_BSNZAoedOqnHzOxTH8,15844
 dashscope/audio/__init__.py,sha256=vlw0TFVRdeRWfzmJxhzarVUqkMs-DZNf4GiMtm3C8XE,45
-dashscope/audio/asr/__init__.py,sha256=kgQYk8-q7lg64oBD7sRhCuZECvOWswmoA-zRoeU2aqw,75
-dashscope/audio/asr/transcribe.py,sha256=tJYu2u9qdnoTDmv__KIUDZ1u1LEc8mUX78vqacvxMtI,6946
+dashscope/audio/asr/__init__.py,sha256=qfYsW1VBkV9k9XWxSukh2xU84faDU3XKx78P4QpHzHw,68
+dashscope/audio/asr/recognition.py,sha256=kD0VVJ9P-xbmCrFdp8xeGBzP5B64R8SsHIVOSlLV7t0,14281
 dashscope/audio/asr/transcription.py,sha256=niqgLGcvpsnv1LR2JFFinN7Gan92CJiMV_DrhfbY9e8,5103
 dashscope/audio/tts/__init__.py,sha256=fbnieZX9yNFNh5BsxLpLXb63jlxzxrdCJakV3ignjlQ,194
 dashscope/audio/tts/speech_synthesizer.py,sha256=wKcpUo6L1yc0OZUajUh0xbtYubTkm-M89IGSAyDwLBo,7425
 dashscope/client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dashscope/client/base_api.py,sha256=k9cBZDmJ9et9aXpYckp02MH1hdAMN6TKjk1AsFe-Xfo,25911
+dashscope/client/base_api.py,sha256=_rmSX2t77PHMz4g-IfMXKtpLTxN20PWqHgTgoC20tUY,33160
 dashscope/common/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 dashscope/common/api_key.py,sha256=5Stp0odL5JSuIO3qJBp23QNppuGbqhhvKPS66qbMs0I,1986
-dashscope/common/constants.py,sha256=4AUIydT7uZqWg0_nB2mGHR1s5LSSYpuC4Tr4wIyW930,2249
+dashscope/common/constants.py,sha256=_REB6_eyMGHQQre2AsOe4T6vC7M0bzuJLTFJh_nE_rY,2317
 dashscope/common/env.py,sha256=oQOZW5JyEeTSde394un2lpDJ5RBh4fMU9hBfbtrKKkc,869
 dashscope/common/error.py,sha256=zbWWjgBXWFNtyVBMQpjuLhOKN4k5XlyByrHn1yWy4Qc,1592
 dashscope/common/logging.py,sha256=ecGxylG3bWES_Xv5-BD6ep4_0Ciu7F6ZPBjiZtu9Jx4,984
-dashscope/common/utils.py,sha256=F5GOEMIzB2Sh1ohzx_nNgGKe752F92aQQpsaqFh-4nM,4038
+dashscope/common/utils.py,sha256=TsZwq0FNswmN0HOucRBN4FQZuZrOCb-J8mLwj4U4coo,6410
 dashscope/embeddings/__init__.py,sha256=InVIZayFfGZq9Q13Mok6c_ocdV3PCFcbxjURBcLYMEg,69
 dashscope/embeddings/text_embedding.py,sha256=nI-d4zcuZA_tpfu7ktI5SZ8V-dGngVclZwxGFAh4qmE,1666
 dashscope/io/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 dashscope/io/input_output.py,sha256=iZ1X1x1btdoZK2VeC9JsKkag2eaXwqfNT3Q6SrmRi2w,3941
 dashscope/protocol/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 dashscope/protocol/websocket.py,sha256=z-v6PGx3L4zYBANuC48s7SWSQSwRCDoh0zcfhv9Bf8U,561
-dashscope-1.3.1.dist-info/LICENSE,sha256=Izp5L1DF1Mbza6qojkqNNWlE_mYLnr4rmzx2EBF8YFw,11413
-dashscope-1.3.1.dist-info/METADATA,sha256=SPOZfPLAaswQUKAhDQpsIgZW9IhHZEgd0Jc9eSATIlo,7201
-dashscope-1.3.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-dashscope-1.3.1.dist-info/entry_points.txt,sha256=raEp5dOuj8whJ7yqZlDM8WQ5p2RfnGrGNo0QLQEnatY,50
-dashscope-1.3.1.dist-info/top_level.txt,sha256=woqavFJK9zas5xTqynmALqOtlafghjsk63Xk86powTU,10
-dashscope-1.3.1.dist-info/RECORD,,
+dashscope-1.4.0.dist-info/LICENSE,sha256=Izp5L1DF1Mbza6qojkqNNWlE_mYLnr4rmzx2EBF8YFw,11413
+dashscope-1.4.0.dist-info/METADATA,sha256=YyG1utzzvBpF2EkI3etlAlW6OQvKZgaOaKiGybGkBIc,7201
+dashscope-1.4.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+dashscope-1.4.0.dist-info/entry_points.txt,sha256=raEp5dOuj8whJ7yqZlDM8WQ5p2RfnGrGNo0QLQEnatY,50
+dashscope-1.4.0.dist-info/top_level.txt,sha256=woqavFJK9zas5xTqynmALqOtlafghjsk63Xk86powTU,10
+dashscope-1.4.0.dist-info/RECORD,,
```

